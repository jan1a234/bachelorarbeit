{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc854955-cdcb-4454-80ba-d4e62f83d88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACTIVE LEARNING AUF MNIST - ROBUSTE VERSION MIT STATISTISCHER ANALYSE\n",
      "================================================================================\n",
      "Python Version: 3.13.5\n",
      "PyTorch Version: 2.7.1+cu126\n",
      "NumPy Version: 2.2.6\n",
      "Pandas Version: 2.2.3\n",
      "Scikit-learn Version: 1.7.1\n",
      "SciPy Version: 1.16.0\n",
      "Verwende GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "GPU Memory: 7.6 GB\n",
      "\n",
      "Experiment-Konfiguration:\n",
      "- Anzahl Runs: 3\n",
      "- Budget-Stufen: ['20%', '40%', '60%', '80%', '100%']\n",
      "- Batch-Größe: 500\n",
      "- Signifikanzniveau: 0.05\n",
      "================================================================================\n",
      "14:11:55 [INFO] Lade vollständigen MNIST-Datensatz...\n",
      "14:11:58 [INFO] [ok] Datensatz geladen: 60,000 Trainingsbilder, 10,000 Testbilder\n",
      "14:11:58 [INFO]   CNN Format: (60000, 1, 28, 28) | Flat Format: (60000, 784)\n",
      "14:11:58 [INFO]   Klassen: 10\n",
      "14:11:58 [INFO]   Speicherbedarf: 358.9 MB\n",
      "\n",
      "============================================================\n",
      "Experiment 1/12: CNN + Random Sampling\n",
      "============================================================\n",
      "14:11:58 [INFO] \n",
      "CNN + Random Sampling - Budget: 20% (12,000 Samples)\n",
      "14:11:58 [INFO]   Run 1/3\n",
      "14:12:36 [INFO]     12,000 labeled -> Accuracy: 0.9888 (Train: 2.7s, Query: 0.02s)\n",
      "14:12:42 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9901, F1: 0.9900\n",
      "14:12:42 [INFO]   Run 2/3\n",
      "14:13:20 [INFO]     12,000 labeled -> Accuracy: 0.9885 (Train: 2.7s, Query: 0.02s)\n",
      "14:13:26 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9912, F1: 0.9912\n",
      "14:13:26 [INFO]   Run 3/3\n",
      "14:14:04 [INFO]     12,000 labeled -> Accuracy: 0.9904 (Train: 2.7s, Query: 0.02s)\n",
      "14:14:10 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9918, F1: 0.9918\n",
      "14:14:10 [INFO] \n",
      "CNN + Random Sampling - Budget: 40% (24,000 Samples)\n",
      "14:14:10 [INFO]   Run 1/3\n",
      "14:16:34 [INFO]     24,000 labeled -> Accuracy: 0.9917 (Train: 5.6s, Query: 0.02s)\n",
      "14:16:46 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9928, F1: 0.9927\n",
      "14:16:46 [INFO]   Run 2/3\n",
      "14:19:10 [INFO]     24,000 labeled -> Accuracy: 0.9911 (Train: 5.6s, Query: 0.02s)\n",
      "14:19:22 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9934, F1: 0.9934\n",
      "14:19:22 [INFO]   Run 3/3\n",
      "14:21:47 [INFO]     24,000 labeled -> Accuracy: 0.9919 (Train: 5.6s, Query: 0.02s)\n",
      "14:21:59 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9941, F1: 0.9941\n",
      "14:21:59 [INFO] \n",
      "CNN + Random Sampling - Budget: 60% (36,000 Samples)\n",
      "14:21:59 [INFO]   Run 1/3\n",
      "14:27:20 [INFO]     36,000 labeled -> Accuracy: 0.9931 (Train: 8.5s, Query: 0.01s)\n",
      "14:27:38 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9948, F1: 0.9947\n",
      "14:27:38 [INFO]   Run 2/3\n",
      "14:33:00 [INFO]     36,000 labeled -> Accuracy: 0.9933 (Train: 8.5s, Query: 0.01s)\n",
      "14:33:18 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9945, F1: 0.9945\n",
      "14:33:18 [INFO]   Run 3/3\n",
      "14:38:40 [INFO]     36,000 labeled -> Accuracy: 0.9944 (Train: 8.5s, Query: 0.01s)\n",
      "14:38:57 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9950, F1: 0.9950\n",
      "14:38:57 [INFO] \n",
      "CNN + Random Sampling - Budget: 80% (48,000 Samples)\n",
      "14:38:57 [INFO]   Run 1/3\n",
      "14:48:25 [INFO]     48,000 labeled -> Accuracy: 0.9942 (Train: 11.4s, Query: 0.01s)\n",
      "14:48:48 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9954, F1: 0.9953\n",
      "14:48:48 [INFO]   Run 2/3\n",
      "14:58:15 [INFO]     48,000 labeled -> Accuracy: 0.9956 (Train: 11.4s, Query: 0.01s)\n",
      "14:58:38 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9946, F1: 0.9945\n",
      "14:58:38 [INFO]   Run 3/3\n",
      "15:08:06 [INFO]     48,000 labeled -> Accuracy: 0.9953 (Train: 11.4s, Query: 0.01s)\n",
      "15:08:29 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9952, F1: 0.9952\n",
      "15:08:29 [INFO] \n",
      "CNN + Random Sampling - Budget: 100% (60,000 Samples)\n",
      "15:08:29 [INFO]   Run 1/3\n",
      "15:23:12 [INFO]     60,000 labeled -> Accuracy: 0.9951 (Train: 14.3s, Query: 0.00s)\n",
      "15:23:40 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9962, F1: 0.9962\n",
      "15:23:40 [INFO]   Run 2/3\n",
      "15:38:24 [INFO]     60,000 labeled -> Accuracy: 0.9941 (Train: 14.4s, Query: 0.00s)\n",
      "15:38:53 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9961, F1: 0.9961\n",
      "15:38:53 [INFO]   Run 3/3\n",
      "15:53:41 [INFO]     60,000 labeled -> Accuracy: 0.9950 (Train: 14.4s, Query: 0.00s)\n",
      "15:54:10 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9955, F1: 0.9955\n",
      "\n",
      "[ok] CNN + Random Sampling abgeschlossen in 102.2 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 2/12: CNN + Entropy Sampling\n",
      "============================================================\n",
      "15:54:10 [INFO] \n",
      "CNN + Entropy Sampling - Budget: 20% (12,000 Samples)\n",
      "15:54:10 [INFO]   Run 1/3\n",
      "15:55:12 [INFO]     12,000 labeled -> Accuracy: 0.9934 (Train: 2.8s, Query: 0.92s)\n",
      "15:55:18 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9950, F1: 0.9949\n",
      "15:55:18 [INFO]   Run 2/3\n",
      "15:56:21 [INFO]     12,000 labeled -> Accuracy: 0.9938 (Train: 2.8s, Query: 0.91s)\n",
      "15:56:27 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9951, F1: 0.9951\n",
      "15:56:27 [INFO]   Run 3/3\n",
      "15:57:29 [INFO]     12,000 labeled -> Accuracy: 0.9941 (Train: 2.8s, Query: 0.93s)\n",
      "15:57:35 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9954, F1: 0.9954\n",
      "15:57:35 [INFO] \n",
      "CNN + Entropy Sampling - Budget: 40% (24,000 Samples)\n",
      "15:57:35 [INFO]   Run 1/3\n",
      "16:00:45 [INFO]     24,000 labeled -> Accuracy: 0.9947 (Train: 5.7s, Query: 0.70s)\n",
      "16:00:57 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9955, F1: 0.9954\n",
      "16:00:57 [INFO]   Run 2/3\n",
      "16:04:07 [INFO]     24,000 labeled -> Accuracy: 0.9938 (Train: 5.7s, Query: 0.72s)\n",
      "16:04:19 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9953, F1: 0.9953\n",
      "16:04:19 [INFO]   Run 3/3\n",
      "16:07:30 [INFO]     24,000 labeled -> Accuracy: 0.9938 (Train: 5.7s, Query: 0.70s)\n",
      "16:07:41 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9951, F1: 0.9951\n",
      "16:07:41 [INFO] \n",
      "CNN + Entropy Sampling - Budget: 60% (36,000 Samples)\n",
      "16:07:41 [INFO]   Run 1/3\n",
      "16:14:04 [INFO]     36,000 labeled -> Accuracy: 0.9946 (Train: 8.6s, Query: 0.46s)\n",
      "16:14:22 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9957, F1: 0.9957\n",
      "16:14:22 [INFO]   Run 2/3\n",
      "16:20:44 [INFO]     36,000 labeled -> Accuracy: 0.9945 (Train: 8.6s, Query: 0.47s)\n",
      "16:21:02 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9963, F1: 0.9963\n",
      "16:21:02 [INFO]   Run 3/3\n",
      "16:27:25 [INFO]     36,000 labeled -> Accuracy: 0.9950 (Train: 8.6s, Query: 0.47s)\n",
      "16:27:43 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9956, F1: 0.9956\n",
      "16:27:43 [INFO] \n",
      "CNN + Entropy Sampling - Budget: 80% (48,000 Samples)\n",
      "16:27:43 [INFO]   Run 1/3\n",
      "16:38:22 [INFO]     48,000 labeled -> Accuracy: 0.9936 (Train: 11.9s, Query: 0.26s)\n",
      "16:38:46 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9961, F1: 0.9960\n",
      "16:38:46 [INFO]   Run 2/3\n",
      "16:49:47 [INFO]     48,000 labeled -> Accuracy: 0.9945 (Train: 11.8s, Query: 0.26s)\n",
      "16:50:11 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9957, F1: 0.9957\n",
      "16:50:11 [INFO]   Run 3/3\n",
      "17:01:11 [INFO]     48,000 labeled -> Accuracy: 0.9946 (Train: 11.8s, Query: 0.26s)\n",
      "17:01:35 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9963, F1: 0.9963\n",
      "17:01:35 [INFO] \n",
      "CNN + Entropy Sampling - Budget: 100% (60,000 Samples)\n",
      "17:01:35 [INFO]   Run 1/3\n",
      "17:18:04 [INFO]     60,000 labeled -> Accuracy: 0.9950 (Train: 14.8s, Query: 0.01s)\n",
      "17:18:34 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9962, F1: 0.9962\n",
      "17:18:34 [INFO]   Run 2/3\n",
      "17:35:03 [INFO]     60,000 labeled -> Accuracy: 0.9950 (Train: 14.8s, Query: 0.01s)\n",
      "17:35:33 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9956, F1: 0.9956\n",
      "17:35:33 [INFO]   Run 3/3\n",
      "17:52:02 [INFO]     60,000 labeled -> Accuracy: 0.9953 (Train: 14.8s, Query: 0.01s)\n",
      "17:52:32 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9958, F1: 0.9958\n",
      "\n",
      "[ok] CNN + Entropy Sampling abgeschlossen in 118.4 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 3/12: CNN + Margin Sampling\n",
      "============================================================\n",
      "17:52:32 [INFO] \n",
      "CNN + Margin Sampling - Budget: 20% (12,000 Samples)\n",
      "17:52:32 [INFO]   Run 1/3\n",
      "17:53:38 [INFO]     12,000 labeled -> Accuracy: 0.9937 (Train: 2.9s, Query: 1.00s)\n",
      "17:53:44 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9947, F1: 0.9947\n",
      "17:53:44 [INFO]   Run 2/3\n",
      "17:54:50 [INFO]     12,000 labeled -> Accuracy: 0.9928 (Train: 2.9s, Query: 1.00s)\n",
      "17:54:56 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9947, F1: 0.9946\n",
      "17:54:56 [INFO]   Run 3/3\n",
      "17:56:02 [INFO]     12,000 labeled -> Accuracy: 0.9941 (Train: 2.9s, Query: 1.02s)\n",
      "17:56:08 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9953, F1: 0.9953\n",
      "17:56:08 [INFO] \n",
      "CNN + Margin Sampling - Budget: 40% (24,000 Samples)\n",
      "17:56:08 [INFO]   Run 1/3\n",
      "17:59:26 [INFO]     24,000 labeled -> Accuracy: 0.9953 (Train: 5.8s, Query: 0.77s)\n",
      "17:59:38 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9951, F1: 0.9951\n",
      "17:59:38 [INFO]   Run 2/3\n",
      "18:02:57 [INFO]     24,000 labeled -> Accuracy: 0.9941 (Train: 5.8s, Query: 0.76s)\n",
      "18:03:09 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9946, F1: 0.9945\n",
      "18:03:09 [INFO]   Run 3/3\n",
      "18:06:27 [INFO]     24,000 labeled -> Accuracy: 0.9941 (Train: 5.8s, Query: 0.77s)\n",
      "18:06:39 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9949, F1: 0.9949\n",
      "18:06:39 [INFO] \n",
      "CNN + Margin Sampling - Budget: 60% (36,000 Samples)\n",
      "18:06:39 [INFO]   Run 1/3\n",
      "18:13:16 [INFO]     36,000 labeled -> Accuracy: 0.9946 (Train: 8.9s, Query: 0.51s)\n",
      "18:13:34 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9957, F1: 0.9957\n",
      "18:13:34 [INFO]   Run 2/3\n",
      "18:20:11 [INFO]     36,000 labeled -> Accuracy: 0.9952 (Train: 8.8s, Query: 0.52s)\n",
      "18:20:29 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9959, F1: 0.9958\n",
      "18:20:29 [INFO]   Run 3/3\n",
      "18:27:05 [INFO]     36,000 labeled -> Accuracy: 0.9949 (Train: 8.8s, Query: 0.51s)\n",
      "18:27:23 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9950, F1: 0.9949\n",
      "18:27:23 [INFO] \n",
      "CNN + Margin Sampling - Budget: 80% (48,000 Samples)\n",
      "18:27:23 [INFO]   Run 1/3\n",
      "18:38:24 [INFO]     48,000 labeled -> Accuracy: 0.9940 (Train: 11.8s, Query: 0.26s)\n",
      "18:38:48 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9959, F1: 0.9959\n",
      "18:38:48 [INFO]   Run 2/3\n",
      "18:49:47 [INFO]     48,000 labeled -> Accuracy: 0.9956 (Train: 11.8s, Query: 0.26s)\n",
      "18:50:11 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9950, F1: 0.9950\n",
      "18:50:11 [INFO]   Run 3/3\n",
      "19:01:11 [INFO]     48,000 labeled -> Accuracy: 0.9953 (Train: 11.8s, Query: 0.27s)\n",
      "19:01:35 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9959, F1: 0.9959\n",
      "19:01:35 [INFO] \n",
      "CNN + Margin Sampling - Budget: 100% (60,000 Samples)\n",
      "19:01:35 [INFO]   Run 1/3\n",
      "19:18:05 [INFO]     60,000 labeled -> Accuracy: 0.9955 (Train: 14.8s, Query: 0.01s)\n",
      "19:18:34 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9956, F1: 0.9956\n",
      "19:18:34 [INFO]   Run 2/3\n",
      "19:35:03 [INFO]     60,000 labeled -> Accuracy: 0.9943 (Train: 14.8s, Query: 0.01s)\n",
      "19:35:33 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9958, F1: 0.9958\n",
      "19:35:33 [INFO]   Run 3/3\n",
      "19:52:03 [INFO]     60,000 labeled -> Accuracy: 0.9950 (Train: 14.8s, Query: 0.01s)\n",
      "19:52:33 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9955, F1: 0.9955\n",
      "\n",
      "[ok] CNN + Margin Sampling abgeschlossen in 120.0 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 4/12: CNN + Least Confidence\n",
      "============================================================\n",
      "19:52:33 [INFO] \n",
      "CNN + Least Confidence - Budget: 20% (12,000 Samples)\n",
      "19:52:33 [INFO]   Run 1/3\n",
      "19:53:38 [INFO]     12,000 labeled -> Accuracy: 0.9938 (Train: 2.9s, Query: 1.01s)\n",
      "19:53:45 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9956, F1: 0.9956\n",
      "19:53:45 [INFO]   Run 2/3\n",
      "19:54:50 [INFO]     12,000 labeled -> Accuracy: 0.9936 (Train: 2.9s, Query: 1.00s)\n",
      "19:54:57 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9952, F1: 0.9951\n",
      "19:54:57 [INFO]   Run 3/3\n",
      "19:56:02 [INFO]     12,000 labeled -> Accuracy: 0.9938 (Train: 2.9s, Query: 1.02s)\n",
      "19:56:09 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9958, F1: 0.9958\n",
      "19:56:09 [INFO] \n",
      "CNN + Least Confidence - Budget: 40% (24,000 Samples)\n",
      "19:56:09 [INFO]   Run 1/3\n",
      "19:59:27 [INFO]     24,000 labeled -> Accuracy: 0.9943 (Train: 5.8s, Query: 0.78s)\n",
      "19:59:39 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9958, F1: 0.9957\n",
      "19:59:39 [INFO]   Run 2/3\n",
      "20:02:57 [INFO]     24,000 labeled -> Accuracy: 0.9937 (Train: 5.8s, Query: 0.77s)\n",
      "20:03:10 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9952, F1: 0.9952\n",
      "20:03:10 [INFO]   Run 3/3\n",
      "20:06:28 [INFO]     24,000 labeled -> Accuracy: 0.9935 (Train: 5.8s, Query: 0.77s)\n",
      "20:06:40 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9951, F1: 0.9951\n",
      "20:06:40 [INFO] \n",
      "CNN + Least Confidence - Budget: 60% (36,000 Samples)\n",
      "20:06:40 [INFO]   Run 1/3\n",
      "20:13:17 [INFO]     36,000 labeled -> Accuracy: 0.9944 (Train: 8.8s, Query: 0.52s)\n",
      "20:13:35 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9956, F1: 0.9956\n",
      "20:13:35 [INFO]   Run 2/3\n",
      "20:20:13 [INFO]     36,000 labeled -> Accuracy: 0.9948 (Train: 8.8s, Query: 0.51s)\n",
      "20:20:31 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9956, F1: 0.9956\n",
      "20:20:31 [INFO]   Run 3/3\n",
      "20:27:08 [INFO]     36,000 labeled -> Accuracy: 0.9939 (Train: 8.9s, Query: 0.51s)\n",
      "20:27:26 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9955, F1: 0.9955\n",
      "20:27:26 [INFO] \n",
      "CNN + Least Confidence - Budget: 80% (48,000 Samples)\n",
      "20:27:26 [INFO]   Run 1/3\n",
      "20:38:27 [INFO]     48,000 labeled -> Accuracy: 0.9938 (Train: 11.8s, Query: 0.26s)\n",
      "20:38:51 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9959, F1: 0.9958\n",
      "20:38:51 [INFO]   Run 2/3\n",
      "20:49:53 [INFO]     48,000 labeled -> Accuracy: 0.9959 (Train: 11.8s, Query: 0.27s)\n",
      "20:50:17 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9961, F1: 0.9961\n",
      "20:50:17 [INFO]   Run 3/3\n",
      "21:01:18 [INFO]     48,000 labeled -> Accuracy: 0.9955 (Train: 11.8s, Query: 0.26s)\n",
      "21:01:42 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9955, F1: 0.9955\n",
      "21:01:42 [INFO] \n",
      "CNN + Least Confidence - Budget: 100% (60,000 Samples)\n",
      "21:01:42 [INFO]   Run 1/3\n",
      "21:18:14 [INFO]     60,000 labeled -> Accuracy: 0.9941 (Train: 14.8s, Query: 0.01s)\n",
      "21:18:44 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9962, F1: 0.9962\n",
      "21:18:44 [INFO]   Run 2/3\n",
      "21:35:15 [INFO]     60,000 labeled -> Accuracy: 0.9947 (Train: 14.8s, Query: 0.01s)\n",
      "21:35:45 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9955, F1: 0.9955\n",
      "21:35:45 [INFO]   Run 3/3\n",
      "21:52:16 [INFO]     60,000 labeled -> Accuracy: 0.9946 (Train: 14.8s, Query: 0.01s)\n",
      "21:52:46 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9957, F1: 0.9957\n",
      "\n",
      "[ok] CNN + Least Confidence abgeschlossen in 120.2 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 5/12: Naive Bayes + Random Sampling\n",
      "============================================================\n",
      "21:52:46 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 20% (12,000 Samples)\n",
      "21:52:46 [INFO]   Run 1/3\n",
      "21:52:53 [INFO]     12,000 labeled -> Accuracy: 0.5549 (Train: 0.0s, Query: 0.02s)\n",
      "21:52:53 [INFO]     Final: 12,000 labeled -> Accuracy: 0.5576, F1: 0.5056\n",
      "21:52:53 [INFO]   Run 2/3\n",
      "21:53:00 [INFO]     12,000 labeled -> Accuracy: 0.5374 (Train: 0.0s, Query: 0.02s)\n",
      "21:53:00 [INFO]     Final: 12,000 labeled -> Accuracy: 0.5400, F1: 0.4899\n",
      "21:53:00 [INFO]   Run 3/3\n",
      "21:53:07 [INFO]     12,000 labeled -> Accuracy: 0.5804 (Train: 0.0s, Query: 0.02s)\n",
      "21:53:07 [INFO]     Final: 12,000 labeled -> Accuracy: 0.5815, F1: 0.5385\n",
      "21:53:07 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 40% (24,000 Samples)\n",
      "21:53:07 [INFO]   Run 1/3\n",
      "21:53:21 [INFO]     24,000 labeled -> Accuracy: 0.5442 (Train: 0.1s, Query: 0.01s)\n",
      "21:53:21 [INFO]     Final: 24,000 labeled -> Accuracy: 0.5435, F1: 0.4900\n",
      "21:53:21 [INFO]   Run 2/3\n",
      "21:53:35 [INFO]     24,000 labeled -> Accuracy: 0.5422 (Train: 0.1s, Query: 0.01s)\n",
      "21:53:35 [INFO]     Final: 24,000 labeled -> Accuracy: 0.5456, F1: 0.4900\n",
      "21:53:35 [INFO]   Run 3/3\n",
      "21:53:49 [INFO]     24,000 labeled -> Accuracy: 0.5889 (Train: 0.1s, Query: 0.01s)\n",
      "21:53:49 [INFO]     Final: 24,000 labeled -> Accuracy: 0.5903, F1: 0.5500\n",
      "21:53:49 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 60% (36,000 Samples)\n",
      "21:53:49 [INFO]   Run 1/3\n",
      "21:54:11 [INFO]     36,000 labeled -> Accuracy: 0.5511 (Train: 0.1s, Query: 0.01s)\n",
      "21:54:12 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5494, F1: 0.4943\n",
      "21:54:12 [INFO]   Run 2/3\n",
      "21:54:34 [INFO]     36,000 labeled -> Accuracy: 0.5430 (Train: 0.1s, Query: 0.01s)\n",
      "21:54:34 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5422, F1: 0.4933\n",
      "21:54:34 [INFO]   Run 3/3\n",
      "21:54:56 [INFO]     36,000 labeled -> Accuracy: 0.5710 (Train: 0.1s, Query: 0.01s)\n",
      "21:54:56 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5728, F1: 0.5295\n",
      "21:54:56 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 80% (48,000 Samples)\n",
      "21:54:56 [INFO]   Run 1/3\n",
      "21:55:27 [INFO]     48,000 labeled -> Accuracy: 0.5467 (Train: 0.1s, Query: 0.01s)\n",
      "21:55:27 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5473, F1: 0.4985\n",
      "21:55:27 [INFO]   Run 2/3\n",
      "21:55:58 [INFO]     48,000 labeled -> Accuracy: 0.5535 (Train: 0.1s, Query: 0.01s)\n",
      "21:55:58 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5536, F1: 0.5076\n",
      "21:55:58 [INFO]   Run 3/3\n",
      "21:56:29 [INFO]     48,000 labeled -> Accuracy: 0.5596 (Train: 0.1s, Query: 0.01s)\n",
      "21:56:30 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5596, F1: 0.5141\n",
      "21:56:30 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 100% (60,000 Samples)\n",
      "21:56:30 [INFO]   Run 1/3\n",
      "21:57:10 [INFO]     60,000 labeled -> Accuracy: 0.5561 (Train: 0.2s, Query: 0.00s)\n",
      "21:57:10 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "21:57:10 [INFO]   Run 2/3\n",
      "21:57:50 [INFO]     60,000 labeled -> Accuracy: 0.5572 (Train: 0.2s, Query: 0.00s)\n",
      "21:57:51 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "21:57:51 [INFO]   Run 3/3\n",
      "21:58:31 [INFO]     60,000 labeled -> Accuracy: 0.5569 (Train: 0.2s, Query: 0.00s)\n",
      "21:58:31 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "\n",
      "[ok] Naive Bayes + Random Sampling abgeschlossen in 5.8 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 6/12: Naive Bayes + Entropy Sampling\n",
      "============================================================\n",
      "21:58:31 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 20% (12,000 Samples)\n",
      "21:58:31 [INFO]   Run 1/3\n",
      "21:59:09 [INFO]     12,000 labeled -> Accuracy: 0.6141 (Train: 0.0s, Query: 1.23s)\n",
      "21:59:09 [INFO]     Final: 12,000 labeled -> Accuracy: 0.6126, F1: 0.5824\n",
      "21:59:09 [INFO]   Run 2/3\n",
      "21:59:47 [INFO]     12,000 labeled -> Accuracy: 0.5894 (Train: 0.0s, Query: 1.23s)\n",
      "21:59:47 [INFO]     Final: 12,000 labeled -> Accuracy: 0.5992, F1: 0.5710\n",
      "21:59:47 [INFO]   Run 3/3\n",
      "22:00:24 [INFO]     12,000 labeled -> Accuracy: 0.6305 (Train: 0.0s, Query: 1.23s)\n",
      "22:00:25 [INFO]     Final: 12,000 labeled -> Accuracy: 0.6326, F1: 0.6074\n",
      "22:00:25 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 40% (24,000 Samples)\n",
      "22:00:25 [INFO]   Run 1/3\n",
      "22:01:35 [INFO]     24,000 labeled -> Accuracy: 0.6333 (Train: 0.1s, Query: 0.93s)\n",
      "22:01:35 [INFO]     Final: 24,000 labeled -> Accuracy: 0.6328, F1: 0.6011\n",
      "22:01:35 [INFO]   Run 2/3\n",
      "22:02:46 [INFO]     24,000 labeled -> Accuracy: 0.6346 (Train: 0.1s, Query: 0.92s)\n",
      "22:02:46 [INFO]     Final: 24,000 labeled -> Accuracy: 0.6327, F1: 0.5992\n",
      "22:02:46 [INFO]   Run 3/3\n",
      "22:03:56 [INFO]     24,000 labeled -> Accuracy: 0.6187 (Train: 0.1s, Query: 0.92s)\n",
      "22:03:57 [INFO]     Final: 24,000 labeled -> Accuracy: 0.6116, F1: 0.5772\n",
      "22:03:57 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 60% (36,000 Samples)\n",
      "22:03:57 [INFO]   Run 1/3\n",
      "22:05:33 [INFO]     36,000 labeled -> Accuracy: 0.5750 (Train: 0.1s, Query: 0.62s)\n",
      "22:05:34 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5787, F1: 0.5572\n",
      "22:05:34 [INFO]   Run 2/3\n",
      "22:07:10 [INFO]     36,000 labeled -> Accuracy: 0.5576 (Train: 0.1s, Query: 0.62s)\n",
      "22:07:10 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5547, F1: 0.5271\n",
      "22:07:10 [INFO]   Run 3/3\n",
      "22:08:47 [INFO]     36,000 labeled -> Accuracy: 0.5579 (Train: 0.1s, Query: 0.62s)\n",
      "22:08:47 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5540, F1: 0.5289\n",
      "22:08:47 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 80% (48,000 Samples)\n",
      "22:08:47 [INFO]   Run 1/3\n",
      "22:10:44 [INFO]     48,000 labeled -> Accuracy: 0.5609 (Train: 0.1s, Query: 0.31s)\n",
      "22:10:44 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5590, F1: 0.5349\n",
      "22:10:44 [INFO]   Run 2/3\n",
      "22:12:40 [INFO]     48,000 labeled -> Accuracy: 0.5455 (Train: 0.1s, Query: 0.31s)\n",
      "22:12:40 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5453, F1: 0.5189\n",
      "22:12:40 [INFO]   Run 3/3\n",
      "22:14:36 [INFO]     48,000 labeled -> Accuracy: 0.5450 (Train: 0.1s, Query: 0.31s)\n",
      "22:14:37 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5457, F1: 0.5201\n",
      "22:14:37 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 100% (60,000 Samples)\n",
      "22:14:37 [INFO]   Run 1/3\n",
      "22:16:46 [INFO]     60,000 labeled -> Accuracy: 0.5577 (Train: 0.2s, Query: 0.01s)\n",
      "22:16:47 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "22:16:47 [INFO]   Run 2/3\n",
      "22:18:56 [INFO]     60,000 labeled -> Accuracy: 0.5543 (Train: 0.2s, Query: 0.01s)\n",
      "22:18:57 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "22:18:57 [INFO]   Run 3/3\n",
      "22:21:06 [INFO]     60,000 labeled -> Accuracy: 0.5559 (Train: 0.2s, Query: 0.01s)\n",
      "22:21:06 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "\n",
      "[ok] Naive Bayes + Entropy Sampling abgeschlossen in 22.6 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 7/12: Naive Bayes + Margin Sampling\n",
      "============================================================\n",
      "22:21:06 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 20% (12,000 Samples)\n",
      "22:21:06 [INFO]   Run 1/3\n",
      "22:21:44 [INFO]     12,000 labeled -> Accuracy: 0.6251 (Train: 0.0s, Query: 1.22s)\n",
      "22:21:45 [INFO]     Final: 12,000 labeled -> Accuracy: 0.6196, F1: 0.5907\n",
      "22:21:45 [INFO]   Run 2/3\n",
      "22:22:22 [INFO]     12,000 labeled -> Accuracy: 0.5715 (Train: 0.0s, Query: 1.23s)\n",
      "22:22:22 [INFO]     Final: 12,000 labeled -> Accuracy: 0.5709, F1: 0.5423\n",
      "22:22:22 [INFO]   Run 3/3\n",
      "22:23:00 [INFO]     12,000 labeled -> Accuracy: 0.6014 (Train: 0.0s, Query: 1.23s)\n",
      "22:23:00 [INFO]     Final: 12,000 labeled -> Accuracy: 0.5961, F1: 0.5765\n",
      "22:23:00 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 40% (24,000 Samples)\n",
      "22:23:00 [INFO]   Run 1/3\n",
      "22:24:10 [INFO]     24,000 labeled -> Accuracy: 0.5734 (Train: 0.1s, Query: 0.92s)\n",
      "22:24:11 [INFO]     Final: 24,000 labeled -> Accuracy: 0.5717, F1: 0.5331\n",
      "22:24:11 [INFO]   Run 2/3\n",
      "22:25:21 [INFO]     24,000 labeled -> Accuracy: 0.5476 (Train: 0.1s, Query: 0.92s)\n",
      "22:25:21 [INFO]     Final: 24,000 labeled -> Accuracy: 0.5496, F1: 0.5081\n",
      "22:25:21 [INFO]   Run 3/3\n",
      "22:26:31 [INFO]     24,000 labeled -> Accuracy: 0.5649 (Train: 0.1s, Query: 0.92s)\n",
      "22:26:32 [INFO]     Final: 24,000 labeled -> Accuracy: 0.5691, F1: 0.5334\n",
      "22:26:32 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 60% (36,000 Samples)\n",
      "22:26:32 [INFO]   Run 1/3\n",
      "22:28:08 [INFO]     36,000 labeled -> Accuracy: 0.5731 (Train: 0.1s, Query: 0.62s)\n",
      "22:28:09 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5590, F1: 0.5073\n",
      "22:28:09 [INFO]   Run 2/3\n",
      "22:29:45 [INFO]     36,000 labeled -> Accuracy: 0.5526 (Train: 0.1s, Query: 0.63s)\n",
      "22:29:46 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5512, F1: 0.4954\n",
      "22:29:46 [INFO]   Run 3/3\n",
      "22:31:22 [INFO]     36,000 labeled -> Accuracy: 0.5603 (Train: 0.1s, Query: 0.62s)\n",
      "22:31:23 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5552, F1: 0.5092\n",
      "22:31:23 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 80% (48,000 Samples)\n",
      "22:31:23 [INFO]   Run 1/3\n",
      "22:33:19 [INFO]     48,000 labeled -> Accuracy: 0.5574 (Train: 0.1s, Query: 0.31s)\n",
      "22:33:20 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5583, F1: 0.5101\n",
      "22:33:20 [INFO]   Run 2/3\n",
      "22:35:16 [INFO]     48,000 labeled -> Accuracy: 0.5537 (Train: 0.1s, Query: 0.31s)\n",
      "22:35:16 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5539, F1: 0.5011\n",
      "22:35:16 [INFO]   Run 3/3\n",
      "22:37:13 [INFO]     48,000 labeled -> Accuracy: 0.5569 (Train: 0.1s, Query: 0.31s)\n",
      "22:37:13 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5564, F1: 0.5068\n",
      "22:37:13 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 100% (60,000 Samples)\n",
      "22:37:13 [INFO]   Run 1/3\n",
      "22:39:22 [INFO]     60,000 labeled -> Accuracy: 0.5574 (Train: 0.2s, Query: 0.01s)\n",
      "22:39:23 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "22:39:23 [INFO]   Run 2/3\n",
      "22:41:32 [INFO]     60,000 labeled -> Accuracy: 0.5575 (Train: 0.2s, Query: 0.01s)\n",
      "22:41:32 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "22:41:32 [INFO]   Run 3/3\n",
      "22:43:41 [INFO]     60,000 labeled -> Accuracy: 0.5577 (Train: 0.2s, Query: 0.01s)\n",
      "22:43:42 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "\n",
      "[ok] Naive Bayes + Margin Sampling abgeschlossen in 22.6 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 8/12: Naive Bayes + Least Confidence\n",
      "============================================================\n",
      "22:43:42 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 20% (12,000 Samples)\n",
      "22:43:42 [INFO]   Run 1/3\n",
      "22:44:19 [INFO]     12,000 labeled -> Accuracy: 0.6013 (Train: 0.0s, Query: 1.23s)\n",
      "22:44:19 [INFO]     Final: 12,000 labeled -> Accuracy: 0.5987, F1: 0.5688\n",
      "22:44:19 [INFO]   Run 2/3\n",
      "22:44:57 [INFO]     12,000 labeled -> Accuracy: 0.5715 (Train: 0.0s, Query: 1.23s)\n",
      "22:44:57 [INFO]     Final: 12,000 labeled -> Accuracy: 0.5709, F1: 0.5423\n",
      "22:44:57 [INFO]   Run 3/3\n",
      "22:45:35 [INFO]     12,000 labeled -> Accuracy: 0.5990 (Train: 0.0s, Query: 1.23s)\n",
      "22:45:35 [INFO]     Final: 12,000 labeled -> Accuracy: 0.6004, F1: 0.5697\n",
      "22:45:35 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 40% (24,000 Samples)\n",
      "22:45:35 [INFO]   Run 1/3\n",
      "22:46:45 [INFO]     24,000 labeled -> Accuracy: 0.5720 (Train: 0.1s, Query: 0.92s)\n",
      "22:46:46 [INFO]     Final: 24,000 labeled -> Accuracy: 0.5709, F1: 0.5315\n",
      "22:46:46 [INFO]   Run 2/3\n",
      "22:47:56 [INFO]     24,000 labeled -> Accuracy: 0.5497 (Train: 0.1s, Query: 0.93s)\n",
      "22:47:56 [INFO]     Final: 24,000 labeled -> Accuracy: 0.5568, F1: 0.5115\n",
      "22:47:56 [INFO]   Run 3/3\n",
      "22:49:07 [INFO]     24,000 labeled -> Accuracy: 0.6077 (Train: 0.1s, Query: 0.93s)\n",
      "22:49:07 [INFO]     Final: 24,000 labeled -> Accuracy: 0.5847, F1: 0.5511\n",
      "22:49:07 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 60% (36,000 Samples)\n",
      "22:49:07 [INFO]   Run 1/3\n",
      "22:50:43 [INFO]     36,000 labeled -> Accuracy: 0.5634 (Train: 0.1s, Query: 0.62s)\n",
      "22:50:44 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5632, F1: 0.5159\n",
      "22:50:44 [INFO]   Run 2/3\n",
      "22:52:20 [INFO]     36,000 labeled -> Accuracy: 0.5523 (Train: 0.1s, Query: 0.62s)\n",
      "22:52:21 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5500, F1: 0.4968\n",
      "22:52:21 [INFO]   Run 3/3\n",
      "22:53:58 [INFO]     36,000 labeled -> Accuracy: 0.5668 (Train: 0.1s, Query: 0.62s)\n",
      "22:53:58 [INFO]     Final: 36,000 labeled -> Accuracy: 0.5653, F1: 0.5203\n",
      "22:53:58 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 80% (48,000 Samples)\n",
      "22:53:58 [INFO]   Run 1/3\n",
      "22:55:55 [INFO]     48,000 labeled -> Accuracy: 0.5584 (Train: 0.1s, Query: 0.36s)\n",
      "22:55:55 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5587, F1: 0.5096\n",
      "22:55:55 [INFO]   Run 2/3\n",
      "22:57:51 [INFO]     48,000 labeled -> Accuracy: 0.5578 (Train: 0.1s, Query: 0.31s)\n",
      "22:57:52 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5587, F1: 0.5101\n",
      "22:57:52 [INFO]   Run 3/3\n",
      "22:59:48 [INFO]     48,000 labeled -> Accuracy: 0.5574 (Train: 0.1s, Query: 0.31s)\n",
      "22:59:48 [INFO]     Final: 48,000 labeled -> Accuracy: 0.5579, F1: 0.5075\n",
      "22:59:48 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 100% (60,000 Samples)\n",
      "22:59:48 [INFO]   Run 1/3\n",
      "23:01:57 [INFO]     60,000 labeled -> Accuracy: 0.5574 (Train: 0.2s, Query: 0.01s)\n",
      "23:01:58 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "23:01:58 [INFO]   Run 2/3\n",
      "23:04:07 [INFO]     60,000 labeled -> Accuracy: 0.5575 (Train: 0.2s, Query: 0.01s)\n",
      "23:04:07 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "23:04:07 [INFO]   Run 3/3\n",
      "23:06:17 [INFO]     60,000 labeled -> Accuracy: 0.5578 (Train: 0.2s, Query: 0.01s)\n",
      "23:06:17 [INFO]     Final: 60,000 labeled -> Accuracy: 0.5560, F1: 0.5095\n",
      "\n",
      "[ok] Naive Bayes + Least Confidence abgeschlossen in 22.6 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 9/12: Random Forest + Random Sampling\n",
      "============================================================\n",
      "23:06:17 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 20% (12,000 Samples)\n",
      "23:06:17 [INFO]   Run 1/3\n",
      "23:06:23 [INFO]     12,000 labeled -> Accuracy: 0.9552 (Train: 0.4s, Query: 0.02s)\n",
      "23:06:24 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9528, F1: 0.9523\n",
      "23:06:24 [INFO]   Run 2/3\n",
      "23:06:30 [INFO]     12,000 labeled -> Accuracy: 0.9524 (Train: 0.4s, Query: 0.02s)\n",
      "23:06:30 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9530, F1: 0.9525\n",
      "23:06:30 [INFO]   Run 3/3\n",
      "23:06:37 [INFO]     12,000 labeled -> Accuracy: 0.9526 (Train: 0.4s, Query: 0.02s)\n",
      "23:06:37 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9525, F1: 0.9520\n",
      "23:06:37 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 40% (24,000 Samples)\n",
      "23:06:37 [INFO]   Run 1/3\n",
      "23:07:00 [INFO]     24,000 labeled -> Accuracy: 0.9597 (Train: 0.9s, Query: 0.02s)\n",
      "23:07:01 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9614, F1: 0.9610\n",
      "23:07:01 [INFO]   Run 2/3\n",
      "23:07:24 [INFO]     24,000 labeled -> Accuracy: 0.9596 (Train: 0.9s, Query: 0.02s)\n",
      "23:07:25 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9627, F1: 0.9624\n",
      "23:07:25 [INFO]   Run 3/3\n",
      "23:07:49 [INFO]     24,000 labeled -> Accuracy: 0.9615 (Train: 0.9s, Query: 0.02s)\n",
      "23:07:50 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9627, F1: 0.9623\n",
      "23:07:50 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 60% (36,000 Samples)\n",
      "23:07:50 [INFO]   Run 1/3\n",
      "23:08:43 [INFO]     36,000 labeled -> Accuracy: 0.9653 (Train: 1.4s, Query: 0.01s)\n",
      "23:08:45 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9647, F1: 0.9644\n",
      "23:08:45 [INFO]   Run 2/3\n",
      "23:09:39 [INFO]     36,000 labeled -> Accuracy: 0.9655 (Train: 1.5s, Query: 0.01s)\n",
      "23:09:41 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9642, F1: 0.9639\n",
      "23:09:41 [INFO]   Run 3/3\n",
      "23:10:36 [INFO]     36,000 labeled -> Accuracy: 0.9636 (Train: 1.5s, Query: 0.01s)\n",
      "23:10:38 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9644, F1: 0.9641\n",
      "23:10:38 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 80% (48,000 Samples)\n",
      "23:10:38 [INFO]   Run 1/3\n",
      "23:12:18 [INFO]     48,000 labeled -> Accuracy: 0.9688 (Train: 2.1s, Query: 0.00s)\n",
      "23:12:20 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9672, F1: 0.9670\n",
      "23:12:20 [INFO]   Run 2/3\n",
      "23:14:00 [INFO]     48,000 labeled -> Accuracy: 0.9669 (Train: 2.1s, Query: 0.00s)\n",
      "23:14:03 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9669, F1: 0.9666\n",
      "23:14:03 [INFO]   Run 3/3\n",
      "23:15:44 [INFO]     48,000 labeled -> Accuracy: 0.9668 (Train: 2.2s, Query: 0.00s)\n",
      "23:15:46 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9666, F1: 0.9663\n",
      "23:15:46 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 100% (60,000 Samples)\n",
      "23:15:46 [INFO]   Run 1/3\n",
      "23:18:28 [INFO]     60,000 labeled -> Accuracy: 0.9693 (Train: 2.8s, Query: 0.00s)\n",
      "23:18:31 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9685, F1: 0.9683\n",
      "23:18:31 [INFO]   Run 2/3\n",
      "23:21:14 [INFO]     60,000 labeled -> Accuracy: 0.9694 (Train: 2.8s, Query: 0.00s)\n",
      "23:21:17 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9680, F1: 0.9678\n",
      "23:21:17 [INFO]   Run 3/3\n",
      "23:24:00 [INFO]     60,000 labeled -> Accuracy: 0.9691 (Train: 2.8s, Query: 0.00s)\n",
      "23:24:03 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9704, F1: 0.9702\n",
      "\n",
      "[ok] Random Forest + Random Sampling abgeschlossen in 17.8 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 10/12: Random Forest + Entropy Sampling\n",
      "============================================================\n",
      "23:24:03 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 20% (12,000 Samples)\n",
      "23:24:03 [INFO]   Run 1/3\n",
      "23:24:15 [INFO]     12,000 labeled -> Accuracy: 0.9713 (Train: 0.5s, Query: 0.17s)\n",
      "23:24:15 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9712, F1: 0.9710\n",
      "23:24:15 [INFO]   Run 2/3\n",
      "23:24:27 [INFO]     12,000 labeled -> Accuracy: 0.9711 (Train: 0.5s, Query: 0.18s)\n",
      "23:24:27 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9701, F1: 0.9699\n",
      "23:24:27 [INFO]   Run 3/3\n",
      "23:24:39 [INFO]     12,000 labeled -> Accuracy: 0.9701 (Train: 0.5s, Query: 0.17s)\n",
      "23:24:39 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9693, F1: 0.9690\n",
      "23:24:39 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 40% (24,000 Samples)\n",
      "23:24:39 [INFO]   Run 1/3\n",
      "23:25:14 [INFO]     24,000 labeled -> Accuracy: 0.9729 (Train: 1.0s, Query: 0.13s)\n",
      "23:25:15 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9724, F1: 0.9722\n",
      "23:25:15 [INFO]   Run 2/3\n",
      "23:25:50 [INFO]     24,000 labeled -> Accuracy: 0.9715 (Train: 1.0s, Query: 0.13s)\n",
      "23:25:51 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9728, F1: 0.9726\n",
      "23:25:51 [INFO]   Run 3/3\n",
      "23:26:26 [INFO]     24,000 labeled -> Accuracy: 0.9718 (Train: 1.0s, Query: 0.13s)\n",
      "23:26:27 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9732, F1: 0.9730\n",
      "23:26:27 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 60% (36,000 Samples)\n",
      "23:26:27 [INFO]   Run 1/3\n",
      "23:27:37 [INFO]     36,000 labeled -> Accuracy: 0.9694 (Train: 1.6s, Query: 0.09s)\n",
      "23:27:39 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9690, F1: 0.9687\n",
      "23:27:39 [INFO]   Run 2/3\n",
      "23:28:49 [INFO]     36,000 labeled -> Accuracy: 0.9696 (Train: 1.6s, Query: 0.08s)\n",
      "23:28:51 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9700, F1: 0.9698\n",
      "23:28:51 [INFO]   Run 3/3\n",
      "23:30:01 [INFO]     36,000 labeled -> Accuracy: 0.9698 (Train: 1.6s, Query: 0.08s)\n",
      "23:30:03 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9698, F1: 0.9696\n",
      "23:30:03 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 80% (48,000 Samples)\n",
      "23:30:03 [INFO]   Run 1/3\n",
      "23:32:01 [INFO]     48,000 labeled -> Accuracy: 0.9697 (Train: 2.2s, Query: 0.04s)\n",
      "23:32:03 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9701, F1: 0.9699\n",
      "23:32:03 [INFO]   Run 2/3\n",
      "23:34:02 [INFO]     48,000 labeled -> Accuracy: 0.9695 (Train: 2.2s, Query: 0.04s)\n",
      "23:34:04 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9678, F1: 0.9676\n",
      "23:34:04 [INFO]   Run 3/3\n",
      "23:36:03 [INFO]     48,000 labeled -> Accuracy: 0.9686 (Train: 2.2s, Query: 0.04s)\n",
      "23:36:05 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9705, F1: 0.9703\n",
      "23:36:05 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 100% (60,000 Samples)\n",
      "23:36:05 [INFO]   Run 1/3\n",
      "23:39:06 [INFO]     60,000 labeled -> Accuracy: 0.9691 (Train: 2.8s, Query: 0.01s)\n",
      "23:39:09 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9673, F1: 0.9670\n",
      "23:39:09 [INFO]   Run 2/3\n",
      "23:42:10 [INFO]     60,000 labeled -> Accuracy: 0.9698 (Train: 2.8s, Query: 0.01s)\n",
      "23:42:13 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9691, F1: 0.9689\n",
      "23:42:13 [INFO]   Run 3/3\n",
      "23:45:14 [INFO]     60,000 labeled -> Accuracy: 0.9697 (Train: 2.8s, Query: 0.01s)\n",
      "23:45:17 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9688, F1: 0.9686\n",
      "\n",
      "[ok] Random Forest + Entropy Sampling abgeschlossen in 21.2 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 11/12: Random Forest + Margin Sampling\n",
      "============================================================\n",
      "23:45:17 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 20% (12,000 Samples)\n",
      "23:45:17 [INFO]   Run 1/3\n",
      "23:45:28 [INFO]     12,000 labeled -> Accuracy: 0.9752 (Train: 0.5s, Query: 0.18s)\n",
      "23:45:29 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9767, F1: 0.9765\n",
      "23:45:29 [INFO]   Run 2/3\n",
      "23:45:41 [INFO]     12,000 labeled -> Accuracy: 0.9750 (Train: 0.5s, Query: 0.18s)\n",
      "23:45:41 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9759, F1: 0.9757\n",
      "23:45:41 [INFO]   Run 3/3\n",
      "23:45:53 [INFO]     12,000 labeled -> Accuracy: 0.9767 (Train: 0.5s, Query: 0.17s)\n",
      "23:45:53 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9766, F1: 0.9764\n",
      "23:45:53 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 40% (24,000 Samples)\n",
      "23:45:53 [INFO]   Run 1/3\n",
      "23:46:28 [INFO]     24,000 labeled -> Accuracy: 0.9730 (Train: 1.0s, Query: 0.13s)\n",
      "23:46:29 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9724, F1: 0.9722\n",
      "23:46:29 [INFO]   Run 2/3\n",
      "23:47:04 [INFO]     24,000 labeled -> Accuracy: 0.9716 (Train: 1.0s, Query: 0.13s)\n",
      "23:47:05 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9725, F1: 0.9723\n",
      "23:47:05 [INFO]   Run 3/3\n",
      "23:47:40 [INFO]     24,000 labeled -> Accuracy: 0.9738 (Train: 1.0s, Query: 0.13s)\n",
      "23:47:41 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9717, F1: 0.9715\n",
      "23:47:41 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 60% (36,000 Samples)\n",
      "23:47:41 [INFO]   Run 1/3\n",
      "23:48:52 [INFO]     36,000 labeled -> Accuracy: 0.9701 (Train: 1.6s, Query: 0.09s)\n",
      "23:48:53 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9701, F1: 0.9699\n",
      "23:48:53 [INFO]   Run 2/3\n",
      "23:50:04 [INFO]     36,000 labeled -> Accuracy: 0.9692 (Train: 1.6s, Query: 0.08s)\n",
      "23:50:05 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9695, F1: 0.9693\n",
      "23:50:05 [INFO]   Run 3/3\n",
      "23:51:15 [INFO]     36,000 labeled -> Accuracy: 0.9694 (Train: 1.6s, Query: 0.08s)\n",
      "23:51:17 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9709, F1: 0.9707\n",
      "23:51:17 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 80% (48,000 Samples)\n",
      "23:51:17 [INFO]   Run 1/3\n",
      "23:53:16 [INFO]     48,000 labeled -> Accuracy: 0.9681 (Train: 2.2s, Query: 0.04s)\n",
      "23:53:18 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9693, F1: 0.9691\n",
      "23:53:18 [INFO]   Run 2/3\n",
      "23:55:17 [INFO]     48,000 labeled -> Accuracy: 0.9695 (Train: 2.2s, Query: 0.04s)\n",
      "23:55:20 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9705, F1: 0.9703\n",
      "23:55:20 [INFO]   Run 3/3\n",
      "23:57:18 [INFO]     48,000 labeled -> Accuracy: 0.9674 (Train: 2.2s, Query: 0.04s)\n",
      "23:57:21 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9690, F1: 0.9687\n",
      "23:57:21 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 100% (60,000 Samples)\n",
      "23:57:21 [INFO]   Run 1/3\n",
      "00:00:21 [INFO]     60,000 labeled -> Accuracy: 0.9694 (Train: 2.8s, Query: 0.01s)\n",
      "00:00:24 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9683, F1: 0.9681\n",
      "00:00:24 [INFO]   Run 2/3\n",
      "00:03:26 [INFO]     60,000 labeled -> Accuracy: 0.9698 (Train: 2.8s, Query: 0.01s)\n",
      "00:03:29 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9696, F1: 0.9694\n",
      "00:03:29 [INFO]   Run 3/3\n",
      "00:06:30 [INFO]     60,000 labeled -> Accuracy: 0.9700 (Train: 2.9s, Query: 0.01s)\n",
      "00:06:33 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9680, F1: 0.9677\n",
      "\n",
      "[ok] Random Forest + Margin Sampling abgeschlossen in 21.3 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 12/12: Random Forest + Least Confidence\n",
      "============================================================\n",
      "00:06:33 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 20% (12,000 Samples)\n",
      "00:06:33 [INFO]   Run 1/3\n",
      "00:06:44 [INFO]     12,000 labeled -> Accuracy: 0.9761 (Train: 0.5s, Query: 0.17s)\n",
      "00:06:45 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9748, F1: 0.9746\n",
      "00:06:45 [INFO]   Run 2/3\n",
      "00:06:57 [INFO]     12,000 labeled -> Accuracy: 0.9757 (Train: 0.5s, Query: 0.17s)\n",
      "00:06:57 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9748, F1: 0.9746\n",
      "00:06:57 [INFO]   Run 3/3\n",
      "00:07:09 [INFO]     12,000 labeled -> Accuracy: 0.9749 (Train: 0.5s, Query: 0.18s)\n",
      "00:07:09 [INFO]     Final: 12,000 labeled -> Accuracy: 0.9747, F1: 0.9744\n",
      "00:07:09 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 40% (24,000 Samples)\n",
      "00:07:09 [INFO]   Run 1/3\n",
      "00:07:44 [INFO]     24,000 labeled -> Accuracy: 0.9731 (Train: 1.1s, Query: 0.13s)\n",
      "00:07:45 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9730, F1: 0.9728\n",
      "00:07:45 [INFO]   Run 2/3\n",
      "00:08:20 [INFO]     24,000 labeled -> Accuracy: 0.9725 (Train: 1.0s, Query: 0.13s)\n",
      "00:08:21 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9731, F1: 0.9729\n",
      "00:08:21 [INFO]   Run 3/3\n",
      "00:08:56 [INFO]     24,000 labeled -> Accuracy: 0.9729 (Train: 1.0s, Query: 0.13s)\n",
      "00:08:57 [INFO]     Final: 24,000 labeled -> Accuracy: 0.9715, F1: 0.9713\n",
      "00:08:57 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 60% (36,000 Samples)\n",
      "00:08:57 [INFO]   Run 1/3\n",
      "00:10:08 [INFO]     36,000 labeled -> Accuracy: 0.9707 (Train: 1.6s, Query: 0.08s)\n",
      "00:10:10 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9703, F1: 0.9701\n",
      "00:10:10 [INFO]   Run 2/3\n",
      "00:11:20 [INFO]     36,000 labeled -> Accuracy: 0.9704 (Train: 1.6s, Query: 0.08s)\n",
      "00:11:22 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9705, F1: 0.9703\n",
      "00:11:22 [INFO]   Run 3/3\n",
      "00:12:32 [INFO]     36,000 labeled -> Accuracy: 0.9701 (Train: 1.6s, Query: 0.09s)\n",
      "00:12:34 [INFO]     Final: 36,000 labeled -> Accuracy: 0.9710, F1: 0.9708\n",
      "00:12:34 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 80% (48,000 Samples)\n",
      "00:12:34 [INFO]   Run 1/3\n",
      "00:14:33 [INFO]     48,000 labeled -> Accuracy: 0.9692 (Train: 2.2s, Query: 0.04s)\n",
      "00:14:36 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9691, F1: 0.9689\n",
      "00:14:36 [INFO]   Run 2/3\n",
      "00:16:35 [INFO]     48,000 labeled -> Accuracy: 0.9699 (Train: 2.2s, Query: 0.04s)\n",
      "00:16:37 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9693, F1: 0.9691\n",
      "00:16:37 [INFO]   Run 3/3\n",
      "00:18:36 [INFO]     48,000 labeled -> Accuracy: 0.9681 (Train: 2.2s, Query: 0.04s)\n",
      "00:18:39 [INFO]     Final: 48,000 labeled -> Accuracy: 0.9701, F1: 0.9699\n",
      "00:18:39 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 100% (60,000 Samples)\n",
      "00:18:39 [INFO]   Run 1/3\n",
      "00:21:40 [INFO]     60,000 labeled -> Accuracy: 0.9716 (Train: 2.8s, Query: 0.01s)\n",
      "00:21:43 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9691, F1: 0.9688\n",
      "00:21:43 [INFO]   Run 2/3\n",
      "00:24:45 [INFO]     60,000 labeled -> Accuracy: 0.9688 (Train: 2.8s, Query: 0.01s)\n",
      "00:24:48 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9710, F1: 0.9708\n",
      "00:24:48 [INFO]   Run 3/3\n",
      "00:27:49 [INFO]     60,000 labeled -> Accuracy: 0.9691 (Train: 2.8s, Query: 0.01s)\n",
      "00:27:52 [INFO]     Final: 60,000 labeled -> Accuracy: 0.9695, F1: 0.9693\n",
      "\n",
      "[ok] Random Forest + Least Confidence abgeschlossen in 21.3 Minuten\n",
      "\n",
      "[ok] Alle Experimente abgeschlossen in 615.9 Minuten\n",
      "\n",
      "============================================================\n",
      "Führe statistische Analyse durch...\n",
      "============================================================\n",
      "\n",
      "====================================================================================================\n",
      "DETAILLIERTER STATISTISCHER BERICHT\n",
      "====================================================================================================\n",
      "Signifikanzniveau: 0.05 (mit Bonferroni-Korrektur)\n",
      "Anzahl Runs pro Experiment: 3\n",
      "Statistischer Test: Wilcoxon Signed-Rank Test\n",
      "Effektstärkemaß: Cliff's Delta\n",
      "\n",
      "\n",
      "Keine signifikanten Verbesserungen gefunden!\n",
      "\n",
      "\n",
      "ZUSAMMENFASSUNG NACH STRATEGIE:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Entropy Sampling:\n",
      "  - Signifikante Verbesserungen: 0/15 (0.0%)\n",
      "  - Durchschnittliche Verbesserung: 1.79%\n",
      "  - Durchschnittliche Effektstärke: 0.659\n",
      "\n",
      "Margin Sampling:\n",
      "  - Signifikante Verbesserungen: 0/15 (0.0%)\n",
      "  - Durchschnittliche Verbesserung: 0.84%\n",
      "  - Durchschnittliche Effektstärke: 0.570\n",
      "\n",
      "Least Confidence:\n",
      "  - Signifikante Verbesserungen: 0/15 (0.0%)\n",
      "  - Durchschnittliche Verbesserung: 0.95%\n",
      "  - Durchschnittliche Effektstärke: 0.681\n",
      "\n",
      "\n",
      "ZUSAMMENFASSUNG NACH KLASSIFIKATOR:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CNN:\n",
      "  - Signifikante Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "Naive Bayes:\n",
      "  - Signifikante Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "Random Forest:\n",
      "  - Signifikante Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "====================================================================================================\n",
      "00:27:52 [INFO] [ok] Statistischer Bericht gespeichert: reports/statistical_report.txt\n",
      "\n",
      "============================================================\n",
      "Berechne Label-Einsparungen...\n",
      "============================================================\n",
      "[ok] Label-Einsparungs-Analyse erstellt: plots/mnist_label_savings_analysis.png\n",
      "\n",
      "================================================================================\n",
      "LABEL-EINSPARUNGS-BERICHT - MNIST\n",
      "================================================================================\n",
      "\n",
      "ZIEL: 90% der Baseline-Performance\n",
      "------------------------------------------------------------\n",
      "\n",
      "CNN:\n",
      "  Baseline (Random 100%): 0.9959\n",
      "  Ziel-Accuracy: 0.8963\n",
      "  Labels benötigt:\n",
      "    - Margin Sampling     :  1,600 ±    0 ( 97.3% gespart)\n",
      "      -> 17.2% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :  1,933 ±  235 ( 96.8% gespart)\n",
      "    - Entropy Sampling    :  1,933 ±  235 ( 96.8% gespart)\n",
      "    - Least Confidence    :  2,433 ±  623 ( 95.9% gespart)\n",
      "\n",
      "Naive Bayes:\n",
      "  Baseline (Random 100%): 0.5560\n",
      "  Ziel-Accuracy: 0.5004\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    600 ±    0 ( 99.0% gespart)\n",
      "    - Entropy Sampling    :    600 ±    0 ( 99.0% gespart)\n",
      "    - Margin Sampling     :    600 ±    0 ( 99.0% gespart)\n",
      "    - Least Confidence    :    600 ±    0 ( 99.0% gespart)\n",
      "\n",
      "Random Forest:\n",
      "  Baseline (Random 100%): 0.9690\n",
      "  Ziel-Accuracy: 0.8721\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    766 ±  235 ( 98.7% gespart)\n",
      "    - Entropy Sampling    :    766 ±  235 ( 98.7% gespart)\n",
      "    - Margin Sampling     :    766 ±  235 ( 98.7% gespart)\n",
      "    - Least Confidence    :    766 ±  235 ( 98.7% gespart)\n",
      "\n",
      "ZIEL: 95% der Baseline-Performance\n",
      "------------------------------------------------------------\n",
      "\n",
      "CNN:\n",
      "  Baseline (Random 100%): 0.9959\n",
      "  Ziel-Accuracy: 0.9461\n",
      "  Labels benötigt:\n",
      "    - Margin Sampling     :  1,933 ±  235 ( 96.8% gespart)\n",
      "      -> 20.5% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :  2,433 ±  235 ( 95.9% gespart)\n",
      "    - Entropy Sampling    :  2,600 ±  408 ( 95.7% gespart)\n",
      "    - Least Confidence    :  2,766 ±  235 ( 95.4% gespart)\n",
      "\n",
      "Naive Bayes:\n",
      "  Baseline (Random 100%): 0.5560\n",
      "  Ziel-Accuracy: 0.5282\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    600 ±    0 ( 99.0% gespart)\n",
      "    - Entropy Sampling    :    600 ±    0 ( 99.0% gespart)\n",
      "    - Margin Sampling     :    600 ±    0 ( 99.0% gespart)\n",
      "    - Least Confidence    :    600 ±    0 ( 99.0% gespart)\n",
      "\n",
      "Random Forest:\n",
      "  Baseline (Random 100%): 0.9690\n",
      "  Ziel-Accuracy: 0.9205\n",
      "  Labels benötigt:\n",
      "    - Margin Sampling     :  1,100 ±    0 ( 98.2% gespart)\n",
      "      -> 51.5% weniger Labels als Random Sampling\n",
      "    - Least Confidence    :  1,766 ±  235 ( 97.1% gespart)\n",
      "      -> 22.1% weniger Labels als Random Sampling\n",
      "    - Entropy Sampling    :  2,100 ±    0 ( 96.5% gespart)\n",
      "      -> 7.4% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :  2,266 ±  235 ( 96.2% gespart)\n",
      "\n",
      "ZIEL: 98% der Baseline-Performance\n",
      "------------------------------------------------------------\n",
      "\n",
      "CNN:\n",
      "  Baseline (Random 100%): 0.9959\n",
      "  Ziel-Accuracy: 0.9760\n",
      "  Labels benötigt:\n",
      "    - Margin Sampling     :  2,933 ±  235 ( 95.1% gespart)\n",
      "      -> 31.2% weniger Labels als Random Sampling\n",
      "    - Entropy Sampling    :  3,266 ±  235 ( 94.6% gespart)\n",
      "      -> 23.4% weniger Labels als Random Sampling\n",
      "    - Least Confidence    :  3,266 ±  235 ( 94.6% gespart)\n",
      "      -> 23.4% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :  4,266 ±  235 ( 92.9% gespart)\n",
      "\n",
      "Naive Bayes:\n",
      "  Baseline (Random 100%): 0.5560\n",
      "  Ziel-Accuracy: 0.5449\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    600 ±    0 ( 99.0% gespart)\n",
      "    - Entropy Sampling    :    600 ±    0 ( 99.0% gespart)\n",
      "    - Margin Sampling     :    600 ±    0 ( 99.0% gespart)\n",
      "    - Least Confidence    :    600 ±    0 ( 99.0% gespart)\n",
      "\n",
      "Random Forest:\n",
      "  Baseline (Random 100%): 0.9690\n",
      "  Ziel-Accuracy: 0.9496\n",
      "  Labels benötigt:\n",
      "    - Margin Sampling     :  2,100 ±    0 ( 96.5% gespart)\n",
      "      -> 78.5% weniger Labels als Random Sampling\n",
      "    - Least Confidence    :  3,100 ±  408 ( 94.8% gespart)\n",
      "      -> 68.3% weniger Labels als Random Sampling\n",
      "    - Entropy Sampling    :  4,266 ±  235 ( 92.9% gespart)\n",
      "      -> 56.3% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :  9,766 ±  471 ( 83.7% gespart)\n",
      "\n",
      "\n",
      "BESTE STRATEGIEN (bei 95% Performance):\n",
      "------------------------------------------------------------\n",
      "CNN: Margin Sampling (nur 1,933 Labels = 96.8% Einsparung)\n",
      "Naive Bayes: Random Sampling (nur 600 Labels = 99.0% Einsparung)\n",
      "Random Forest: Margin Sampling (nur 1,100 Labels = 98.2% Einsparung)\n",
      "\n",
      "\n",
      "DURCHSCHNITTLICHE EINSPARUNGEN ÜBER ALLE KLASSIFIKATOREN:\n",
      "------------------------------------------------------------\n",
      "Entropy Sampling: 0.2% weniger Labels als Random Sampling\n",
      "Least Confidence: 2.8% weniger Labels als Random Sampling\n",
      "Margin Sampling: 24.0% weniger Labels als Random Sampling\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[ok] Label-Einsparungs-Bericht gespeichert: reports/mnist_label_savings_report.txt\n",
      "[ok] Label-Einsparungen gespeichert: results/mnist_label_savings.csv\n",
      "\n",
      "============================================================\n",
      "Erstelle Visualisierungen...\n",
      "============================================================\n",
      "00:27:54 [INFO] [ok] Visualisierung mit Signifikanz für CNN erstellt: plots/active_learning_cnn_with_significance.png\n",
      "00:27:54 [INFO] [ok] Visualisierung mit Signifikanz für Naive Bayes erstellt: plots/active_learning_naive_bayes_with_significance.png\n",
      "00:27:55 [INFO] [ok] Visualisierung mit Signifikanz für Random Forest erstellt: plots/active_learning_random_forest_with_significance.png\n",
      "00:27:55 [WARNING] Keine signifikanten Ergebnisse gefunden!\n",
      "00:27:56 [INFO] [ok] Statistische Zusammenfassung erstellt: plots/active_learning_statistical_summary.png\n",
      "00:27:56 [INFO] [ok] Finale Vergleichsvisualisierung erstellt: plots/active_learning_final_comparison.png\n",
      "\n",
      "============================================================\n",
      "BESTE KOMBINATION BEI 100% BUDGET:\n",
      "============================================================\n",
      "Klassifikator: CNN\n",
      "Query-Strategie: Random Sampling\n",
      "Test Accuracy: 0.9959 (±0.0003)\n",
      "F1-Score: 0.9959\n",
      "============================================================\n",
      "\n",
      "TOP 5 KOMBINATIONEN:\n",
      "------------------------------------------------------------\n",
      "1. CNN + Random Sampling: Acc=0.9959, F1=0.9959\n",
      "2. CNN + Entropy Sampling: Acc=0.9959, F1=0.9958\n",
      "3. CNN + Least Confidence: Acc=0.9958, F1=0.9958\n",
      "4. CNN + Margin Sampling: Acc=0.9956, F1=0.9956\n",
      "5. Random Forest + Least Confidence: Acc=0.9699, F1=0.9697\n",
      "00:27:56 [INFO] [ok] Improvement-Analyse erstellt: plots/active_learning_improvement_analysis.png\n",
      "[ok] Alle Visualisierungen erstellt\n",
      "\n",
      "[ok] Ergebnisse gespeichert in: results/mnist_active_learning_results.csv\n",
      "[ok] Statistische Analyse gespeichert in: results/mnist_statistical_analysis.csv\n",
      "[ok] Zusammenfassung gespeichert in: results/mnist_active_learning_summary.xlsx\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT ERFOLGREICH ABGESCHLOSSEN\n",
      "Gesamtanzahl Experimente: 180\n",
      "Datensatzgröße: 60,000 Trainingsbilder\n",
      "Klassifikatoren: 3\n",
      "Query-Strategien: 4\n",
      "Budget-Stufen: 5\n",
      "Wiederholungen pro Experiment: 3\n",
      "\n",
      "Statistische Analyse:\n",
      "- Anzahl Vergleiche: 45\n",
      "- Signifikante Ergebnisse: 0 (0.0%)\n",
      "- Verwendeter Test: Wilcoxon Signed-Rank Test\n",
      "- Effektstärkemaß: Cliff's Delta\n",
      "- Multiple Vergleiche: Bonferroni-Korrektur\n",
      "\n",
      "NEU: Label-Einsparungs-Analyse durchgeführt!\n",
      "- Visualisierung: plots/mnist_label_savings_analysis.png\n",
      "- Bericht: reports/mnist_label_savings_report.txt\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "=================================================================\n",
    "Active Learning für MNIST - Robuste Version mit statistischer Analyse\n",
    "=================================================================\n",
    "Professionelles Skript für MNIST-Experimente mit fairem Vergleich\n",
    "zwischen aktivem Lernen und Random Sampling als Baseline.\n",
    "\n",
    "Verwendet den KOMPLETTEN MNIST-Datensatz (60.000 Trainingsbilder)\n",
    "mit Budget-Stufen von 20%, 40%, 60%, 80% und 100%.\n",
    "\n",
    "Version: 7.2 - Mit Label-Einsparungs-Analyse und Jupyter-Kompatibilität\n",
    "            \n",
    "Klassifikatoren:\n",
    "- Naive Bayes\n",
    "- Random Forest\n",
    "- Logistic Regression\n",
    "- SVM\n",
    "- CNN\n",
    "\n",
    "Query-Strategien:\n",
    "- Random Sampling (Baseline)\n",
    "- Entropy Sampling\n",
    "- Margin Sampling\n",
    "- Least Confidence\n",
    "\n",
    "Statistische Analyse:\n",
    "- Wilcoxon Signed-Rank Test\n",
    "- Cliff's Delta Effektstärke\n",
    "- Bonferroni-Korrektur für multiple Vergleiche\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Matplotlib Backend setzen bevor pyplot importiert wird\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Für Server ohne GUI\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn mit Fehlerbehandlung\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    # Prüfe ob der Style verfügbar ist\n",
    "    try:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    except:\n",
    "        try:\n",
    "            plt.style.use('seaborn-whitegrid')\n",
    "        except:\n",
    "            plt.style.use('ggplot')\n",
    "except ImportError:\n",
    "    print(\"Warnung: Seaborn nicht installiert. Verwende Standard-Matplotlib.\")\n",
    "    sns = None\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "# Statistische Tests\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "import itertools\n",
    "\n",
    "# Excel-Export\n",
    "try:\n",
    "    import openpyxl\n",
    "    EXCEL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warnung: openpyxl nicht installiert. Excel-Export wird deaktiviert.\")\n",
    "    EXCEL_AVAILABLE = False\n",
    "\n",
    "# SSL-Fehler beim Download verhindern\n",
    "import ssl\n",
    "try:\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Reproduzierbarkeit\n",
    "# -------------------------------------------------------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Logging konfigurieren mit UTF-8 Encoding\n",
    "# -------------------------------------------------------------------------------\n",
    "# Erstelle Log-Verzeichnis\n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Logging Setup mit UTF-8 Encoding für Windows\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            os.path.join(log_dir, f\"active_learning_{time.strftime('%Y%m%d_%H%M%S')}.log\"),\n",
    "            encoding='utf-8'\n",
    "        ),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set encoding for stdout to handle Unicode - nur wenn möglich\n",
    "if sys.platform == 'win32':\n",
    "    # Prüfe ob wir in einer Jupyter/IPython Umgebung sind\n",
    "    try:\n",
    "        get_ipython()\n",
    "        # In Jupyter/IPython - keine Änderung nötig\n",
    "        logger.info(\"Jupyter/IPython Umgebung erkannt - UTF-8 Handling bereits aktiv\")\n",
    "    except NameError:\n",
    "        # Normales Python - versuche UTF-8 zu setzen\n",
    "        try:\n",
    "            import io\n",
    "            if hasattr(sys.stdout, 'buffer'):\n",
    "                sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
    "                sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Konnte UTF-8 Encoding nicht setzen: {e}\")\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Konfiguration\n",
    "# -------------------------------------------------------------------------------\n",
    "BUDGET_PERCENTAGES = [0.2, 0.4, 0.6, 0.8, 1.0]  # 20%, 40%, 60%, 80%, 100%\n",
    "BATCH_SIZE = 500  # Größere Batches für effizienteres Training\n",
    "N_RUNS = 3  # Erhöht von 3 auf 5 für bessere statistische Aussagekraft\n",
    "INITIAL_PERCENTAGE = 0.01  # 1% initial labeling\n",
    "SIGNIFICANCE_LEVEL = 0.05  # Für statistische Tests\n",
    "\n",
    "# Erstelle Output-Verzeichnisse\n",
    "output_dirs = [\"plots\", \"results\", \"reports\"]\n",
    "for dir_name in output_dirs:\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "        logger.info(f\"Erstellt Verzeichnis: {dir_name}\")\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 1) MNIST laden - VOLLSTÄNDIGER DATENSATZ\n",
    "# -------------------------------------------------------------------------------\n",
    "def load_mnist_data():\n",
    "    \"\"\"\n",
    "    Lädt den VOLLSTÄNDIGEN MNIST-Datensatz (60.000 Trainingsbilder).\n",
    "    Gibt auch eine flache Version für sklearn-Klassifikatoren zurück.\n",
    "    \"\"\"\n",
    "    logger.info(\"Lade vollständigen MNIST-Datensatz...\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    # Erstelle Datenverzeichnis\n",
    "    data_dir = './data'\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    try:\n",
    "        train_dataset = torchvision.datasets.MNIST(\n",
    "            root=data_dir, train=True, download=True, transform=transform\n",
    "        )\n",
    "        test_dataset = torchvision.datasets.MNIST(\n",
    "            root=data_dir, train=False, download=True, transform=transform\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Laden des MNIST-Datensatzes: {e}\")\n",
    "        logger.info(\"Versuche alternativen Download...\")\n",
    "        \n",
    "        # Alternative: Manuelle Download-URL setzen\n",
    "        try:\n",
    "            torchvision.datasets.MNIST.resources = [\n",
    "                ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz', 'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
    "                ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz', 'd53e105ee54ea40749a09fcbcd1e9432'),\n",
    "                ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz', '9fb629c4189551a2d022fa330f9573f3'),\n",
    "                ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz', 'ec29112dd5afa0611ce80d1b7f02629c')\n",
    "            ]\n",
    "            \n",
    "            train_dataset = torchvision.datasets.MNIST(\n",
    "                root=data_dir, train=True, download=True, transform=transform\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.MNIST(\n",
    "                root=data_dir, train=False, download=True, transform=transform\n",
    "            )\n",
    "        except Exception as e2:\n",
    "            logger.error(f\"Auch alternativer Download fehlgeschlagen: {e2}\")\n",
    "            raise RuntimeError(\"MNIST-Datensatz konnte nicht geladen werden. Bitte überprüfen Sie Ihre Internetverbindung.\")\n",
    "    \n",
    "    # Konvertiere zu numpy arrays mit Fehlerbehandlung\n",
    "    try:\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "        \n",
    "        X_train, y_train = next(iter(train_loader))\n",
    "        X_test, y_test = next(iter(test_loader))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Konvertieren der Daten: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Für CNN (4D: batch, channel, height, width)\n",
    "    X_train_cnn = X_train.numpy()\n",
    "    X_test_cnn = X_test.numpy()\n",
    "    \n",
    "    # Für sklearn (2D: batch, features)\n",
    "    X_train_flat = X_train.view(X_train.size(0), -1).numpy()\n",
    "    X_test_flat = X_test.view(X_test.size(0), -1).numpy()\n",
    "    \n",
    "    y_train = y_train.numpy()\n",
    "    y_test = y_test.numpy()\n",
    "    \n",
    "    # Validierung der Daten\n",
    "    assert X_train_cnn.shape[0] == 60000, f\"Unerwartete Anzahl von Trainingsbildern: {X_train_cnn.shape[0]}\"\n",
    "    assert X_test_cnn.shape[0] == 10000, f\"Unerwartete Anzahl von Testbildern: {X_test_cnn.shape[0]}\"\n",
    "    assert len(np.unique(y_train)) == 10, f\"Unerwartete Anzahl von Klassen: {len(np.unique(y_train))}\"\n",
    "    \n",
    "    logger.info(f\"[ok] Datensatz geladen: {len(X_train):,} Trainingsbilder, {len(X_test):,} Testbilder\")\n",
    "    logger.info(f\"  CNN Format: {X_train_cnn.shape} | Flat Format: {X_train_flat.shape}\")\n",
    "    logger.info(f\"  Klassen: {len(np.unique(y_train))}\")\n",
    "    logger.info(f\"  Speicherbedarf: {(X_train_cnn.nbytes + X_train_flat.nbytes) / 1024**2:.1f} MB\")\n",
    "    \n",
    "    return X_train_cnn, X_train_flat, y_train, X_test_cnn, X_test_flat, y_test\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 2) CNN Modell\n",
    "# -------------------------------------------------------------------------------\n",
    "class OptimizedCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Optimierte CNN-Architektur für MNIST mit besserer Performance.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(OptimizedCNN, self).__init__()\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv Block 1\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Conv Block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64 * 7 * 7, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Device handling mit Fehlerbehandlung\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                self.device = torch.device('cuda')\n",
    "                # Test ob CUDA wirklich funktioniert\n",
    "                test_tensor = torch.zeros(1).cuda()\n",
    "                del test_tensor\n",
    "            except:\n",
    "                logger.warning(\"CUDA verfügbar aber nicht nutzbar. Verwende CPU.\")\n",
    "                self.device = torch.device('cpu')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self, X_np, y_np, epochs=5, lr=1e-3, batch_size=256, verbose=False):\n",
    "        \"\"\"\n",
    "        Trainiert das CNN mit optimierten Hyperparametern.\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "        \n",
    "        # Hyperparameter-Anpassung basierend auf Datensatzgröße\n",
    "        if len(X_np) < 1000:\n",
    "            batch_size = min(32, len(X_np))\n",
    "            lr = lr * 0.1\n",
    "        \n",
    "        optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Create dataset\n",
    "        try:\n",
    "            dataset = torch.utils.data.TensorDataset(\n",
    "                torch.from_numpy(X_np).float(),\n",
    "                torch.from_numpy(y_np).long()\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Erstellen des Datasets: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # DataLoader mit optimierten Settings\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=0,  # Immer 0 für Kompatibilität\n",
    "            pin_memory=(self.device.type == 'cuda'),\n",
    "            drop_last=False\n",
    "        )\n",
    "        \n",
    "        # Training loop mit Fehlerbehandlung\n",
    "        try:\n",
    "            for epoch in range(epochs):\n",
    "                total_loss = 0.0\n",
    "                batch_count = 0\n",
    "                \n",
    "                for xb, yb in loader:\n",
    "                    xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = self(xb)\n",
    "                    loss = loss_fn(outputs, yb)\n",
    "                    \n",
    "                    # Gradient clipping zur Stabilität\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    batch_count += 1\n",
    "                \n",
    "                scheduler.step()\n",
    "                \n",
    "                if verbose and (epoch + 1) % 2 == 0:\n",
    "                    avg_loss = total_loss / max(batch_count, 1)\n",
    "                    logger.info(f\"    Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler während des Trainings: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X_np, batch_size=1024):\n",
    "        \"\"\"\n",
    "        Gibt Wahrscheinlichkeiten für große Datenmengen zurück.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        probs = []\n",
    "        \n",
    "        # Anpassung der Batch-Größe bei wenig Speicher\n",
    "        if self.device.type == 'cuda':\n",
    "            try:\n",
    "                free_memory = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()\n",
    "                if free_memory < 1024**3:  # Weniger als 1GB frei\n",
    "                    batch_size = 256\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                for i in range(0, len(X_np), batch_size):\n",
    "                    batch = torch.from_numpy(X_np[i:i+batch_size]).float().to(self.device)\n",
    "                    logits = self(batch)\n",
    "                    batch_probs = F.softmax(logits, dim=1)\n",
    "                    probs.append(batch_probs.cpu().numpy())\n",
    "                    \n",
    "                    # Speicher freigeben\n",
    "                    del batch, logits, batch_probs\n",
    "                    if self.device.type == 'cuda':\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Fehler bei predict_proba: {e}\")\n",
    "                raise\n",
    "        \n",
    "        return np.vstack(probs) if probs else np.array([])\n",
    "\n",
    "    def predict(self, X_np, batch_size=1024):\n",
    "        \"\"\"\n",
    "        Gibt Vorhersagen zurück.\n",
    "        \"\"\"\n",
    "        probs = self.predict_proba(X_np, batch_size)\n",
    "        return np.argmax(probs, axis=1) if len(probs) > 0 else np.array([])\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 3) Wrapper für sklearn-Klassifikatoren\n",
    "# -------------------------------------------------------------------------------\n",
    "class SklearnWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper-Klasse für sklearn-Klassifikatoren mit CNN-ähnlicher API.\n",
    "    \"\"\"\n",
    "    def __init__(self, classifier, scaler=None):\n",
    "        self.classifier = classifier\n",
    "        self.scaler = scaler\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X_np, y_np, **kwargs):\n",
    "        \"\"\"Trainiert den Klassifikator mit Fehlerbehandlung.\"\"\"\n",
    "        try:\n",
    "            if self.scaler is not None:\n",
    "                X_scaled = self.scaler.fit_transform(X_np)\n",
    "            else:\n",
    "                X_scaled = X_np\n",
    "            \n",
    "            self.classifier.fit(X_scaled, y_np)\n",
    "            self.is_fitted = True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Training des sklearn-Modells: {e}\")\n",
    "            raise\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X_np):\n",
    "        \"\"\"Gibt Wahrscheinlichkeiten zurueck mit Fehlerbehandlung.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Modell wurde noch nicht trainiert!\")\n",
    "        \n",
    "        try:\n",
    "            if self.scaler is not None:\n",
    "                X_scaled = self.scaler.transform(X_np)\n",
    "            else:\n",
    "                X_scaled = X_np\n",
    "                \n",
    "            if hasattr(self.classifier, 'predict_proba'):\n",
    "                return self.classifier.predict_proba(X_scaled)\n",
    "            else:\n",
    "                # Für SVM mit probability=False oder andere Klassifikatoren\n",
    "                if hasattr(self.classifier, 'decision_function'):\n",
    "                    decision = self.classifier.decision_function(X_scaled)\n",
    "                    \n",
    "                    # Multi-class Fall\n",
    "                    if len(decision.shape) == 2:\n",
    "                        # Softmax auf decision values\n",
    "                        exp_decision = np.exp(decision - np.max(decision, axis=1, keepdims=True))\n",
    "                        probs = exp_decision / np.sum(exp_decision, axis=1, keepdims=True)\n",
    "                    else:\n",
    "                        # Binary Fall - konvertiere zu 2-Klassen-Wahrscheinlichkeiten\n",
    "                        probs = np.zeros((len(decision), 2))\n",
    "                        probs[:, 1] = 1 / (1 + np.exp(-decision))\n",
    "                        probs[:, 0] = 1 - probs[:, 1]\n",
    "                    return probs\n",
    "                else:\n",
    "                    # Fallback: One-hot encoding der Vorhersagen\n",
    "                    predictions = self.classifier.predict(X_scaled)\n",
    "                    n_classes = len(np.unique(predictions))\n",
    "                    probs = np.zeros((len(predictions), n_classes))\n",
    "                    for i, pred in enumerate(predictions):\n",
    "                        probs[i, int(pred)] = 1.0\n",
    "                    return probs\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler bei predict_proba: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def predict(self, X_np):\n",
    "        \"\"\"Gibt Vorhersagen zurück mit Fehlerbehandlung.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Modell wurde noch nicht trainiert!\")\n",
    "            \n",
    "        try:\n",
    "            if self.scaler is not None:\n",
    "                X_scaled = self.scaler.transform(X_np)\n",
    "            else:\n",
    "                X_scaled = X_np\n",
    "            return self.classifier.predict(X_scaled)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler bei predict: {e}\")\n",
    "            raise\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 4) Klassifikator-Factory\n",
    "# -------------------------------------------------------------------------------\n",
    "def create_classifier(classifier_name, use_cnn_format=False):\n",
    "    \"\"\"\n",
    "    Erstellt einen Klassifikator basierend auf dem Namen.\n",
    "    \n",
    "    Args:\n",
    "        classifier_name: Name des Klassifikators\n",
    "        use_cnn_format: True für CNN (4D), False für sklearn (2D)\n",
    "    \n",
    "    Returns:\n",
    "        Klassifikator-Objekt mit einheitlicher API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if classifier_name == 'CNN':\n",
    "            return OptimizedCNN()\n",
    "        \n",
    "        elif classifier_name == 'Naive Bayes':\n",
    "            return SklearnWrapper(GaussianNB())\n",
    "        \n",
    "        elif classifier_name == 'Random Forest':\n",
    "            # Angepasste Parameter für bessere Performance\n",
    "            n_jobs = min(os.cpu_count() - 1, -1) if os.cpu_count() else -1\n",
    "            return SklearnWrapper(\n",
    "                RandomForestClassifier(\n",
    "                    n_estimators=100,\n",
    "                    max_depth=None,\n",
    "                    min_samples_split=2,\n",
    "                    min_samples_leaf=1,\n",
    "                    n_jobs=n_jobs,\n",
    "                    random_state=SEED,\n",
    "                    verbose=0\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        elif classifier_name == 'Logistic Regression':\n",
    "            return SklearnWrapper(\n",
    "                LogisticRegression(\n",
    "                    max_iter=1000,\n",
    "                    solver='saga',\n",
    "                    multi_class='multinomial',\n",
    "                    n_jobs=-1,\n",
    "                    random_state=SEED,\n",
    "                    verbose=0,\n",
    "        \t\t    penalty='l2',  \n",
    "        \t        C=0.1          \t\n",
    "                ),\n",
    "                scaler=StandardScaler()\n",
    "            )\n",
    "        \n",
    "        elif classifier_name == 'SVM':\n",
    "            return SklearnWrapper(\n",
    "                SVC(\n",
    "                    kernel='rbf',\n",
    "                    gamma='scale',\n",
    "                    decision_function_shape='ovr',\n",
    "                    probability=True,\n",
    "                    cache_size=500,  # Mehr Cache für bessere Performance\n",
    "                    random_state=SEED,\n",
    "                    verbose=False\n",
    "                ),\n",
    "                scaler=StandardScaler()\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unbekannter Klassifikator: {classifier_name}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Erstellen des Klassifikators {classifier_name}: {e}\")\n",
    "        raise\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 5) Query-Strategien mit Fehlerbehandlung\n",
    "# -------------------------------------------------------------------------------\n",
    "def entropy_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Waehlt Samples mit hoechster Entropie aus.\n",
    "    H(x) = -Σ p(y|x) * log(p(y|x))\n",
    "    \"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        \n",
    "        # Kleine Konstante hinzufügen um log(0) zu vermeiden\n",
    "        epsilon = 1e-10\n",
    "        probs = np.clip(probs, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        # Entropie berechnen\n",
    "        entropies = -np.sum(probs * np.log(probs), axis=1)\n",
    "        \n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        # Indizes mit höchster Entropie\n",
    "        return np.argsort(entropies)[-n_instances:]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Entropy Sampling: {e}\")\n",
    "        # Fallback zu Random Sampling\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def margin_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Wählt Samples mit kleinstem Margin zwischen Top-2 Klassen.\n",
    "    margin = P(y1|x) - P(y2|x)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        \n",
    "        # Sortiere Wahrscheinlichkeiten\n",
    "        sorted_probs = np.sort(probs, axis=1)\n",
    "        \n",
    "        # Berechne Margin\n",
    "        if sorted_probs.shape[1] >= 2:\n",
    "            margins = sorted_probs[:, -1] - sorted_probs[:, -2]\n",
    "        else:\n",
    "            # Falls nur eine Klasse, verwende 1 - max_prob als Margin\n",
    "            margins = 1.0 - sorted_probs[:, -1]\n",
    "        \n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        # Indizes mit kleinstem Margin\n",
    "        return np.argsort(margins)[:n_instances]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Margin Sampling: {e}\")\n",
    "        # Fallback zu Random Sampling\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def least_confidence_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Wählt Samples mit geringster Konfidenz.\n",
    "    confidence = max P(y|x)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        \n",
    "        # Maximum-Wahrscheinlichkeit als Konfidenz\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        \n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        # Indizes mit geringster Konfidenz\n",
    "        return np.argsort(confidences)[:n_instances]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Least Confidence Sampling: {e}\")\n",
    "        # Fallback zu Random Sampling\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def random_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Zufällige Auswahl (Baseline).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        if n_instances <= 0:\n",
    "            return np.array([], dtype=int)\n",
    "            \n",
    "        return np.random.choice(len(X_pool), size=n_instances, replace=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Random Sampling: {e}\")\n",
    "        # Notfall-Fallback\n",
    "        return np.arange(min(n_instances, len(X_pool)))\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 6) Statistische Analyse Funktionen mit Fehlerbehandlung\n",
    "# -------------------------------------------------------------------------------\n",
    "def cliffs_delta(x, y):\n",
    "    \"\"\"\n",
    "    Berechnet Cliff's Delta als nicht-parametrisches Effektstaerkemaß.\n",
    "    \n",
    "    Interpretation:\n",
    "    |d| < 0.147 \"negligible\"\n",
    "    |d| < 0.33  \"small\" \n",
    "    |d| < 0.474 \"medium\"\n",
    "    |d| >= 0.474 \"large\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nx = len(x)\n",
    "        ny = len(y)\n",
    "        \n",
    "        if nx == 0 or ny == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Konvertiere zu numpy arrays falls nötig\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        # Berechne die Anzahl der Paare, wo x[i] > y[j]\n",
    "        greater = 0\n",
    "        less = 0\n",
    "        \n",
    "        # Vektorisierte Berechnung für bessere Performance\n",
    "        for xi in x:\n",
    "            greater += np.sum(xi > y)\n",
    "            less += np.sum(xi < y)\n",
    "        \n",
    "        # Cliff's Delta\n",
    "        d = (greater - less) / (nx * ny)\n",
    "        \n",
    "        # Sicherstellen, dass d im Bereich [-1, 1] liegt\n",
    "        d = np.clip(d, -1.0, 1.0)\n",
    "        \n",
    "        return d\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Cliff's Delta Berechnung: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def interpret_cliffs_delta(d):\n",
    "    \"\"\"\n",
    "    Interpretiert die Effektstärke nach Cliff's Delta.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        abs_d = abs(float(d))\n",
    "        if abs_d < 0.147:\n",
    "            return \"negligible\"\n",
    "        elif abs_d < 0.33:\n",
    "            return \"small\"\n",
    "        elif abs_d < 0.474:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"large\"\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "def perform_statistical_analysis(results_df, metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Fuehrt statistische Analyse durch: Wilcoxon Signed-Rank Test mit Bonferroni-Korrektur.\n",
    "    \"\"\"\n",
    "    statistical_results = []\n",
    "    \n",
    "    try:\n",
    "        classifiers = results_df['classifier'].unique()\n",
    "        strategies = results_df['strategy'].unique()\n",
    "        budget_levels = results_df['budget_pct'].unique()\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            for budget_pct in budget_levels:\n",
    "                # Hole Random Sampling als Baseline\n",
    "                baseline_data = results_df[\n",
    "                    (results_df['classifier'] == classifier) & \n",
    "                    (results_df['strategy'] == 'Random Sampling') & \n",
    "                    (results_df['budget_pct'] == budget_pct)\n",
    "                ][metric].values\n",
    "                \n",
    "                # Vergleiche mit anderen Strategien\n",
    "                for strategy in strategies:\n",
    "                    if strategy == 'Random Sampling':\n",
    "                        continue\n",
    "                        \n",
    "                    strategy_data = results_df[\n",
    "                        (results_df['classifier'] == classifier) & \n",
    "                        (results_df['strategy'] == strategy) & \n",
    "                        (results_df['budget_pct'] == budget_pct)\n",
    "                    ][metric].values\n",
    "                    \n",
    "                    # Mindestens N_RUNS Datenpunkte für statistische Tests\n",
    "                    if len(baseline_data) >= N_RUNS and len(strategy_data) >= N_RUNS:\n",
    "                        # Wilcoxon Signed-Rank Test\n",
    "                        try:\n",
    "                            # Prüfe ob alle Werte gleich sind\n",
    "                            if np.allclose(strategy_data, baseline_data):\n",
    "                                statistic, p_value = 0.0, 1.0\n",
    "                            else:\n",
    "                                statistic, p_value = wilcoxon(\n",
    "                                    strategy_data, baseline_data, \n",
    "                                    alternative='greater',\n",
    "                                    zero_method='zsplit'\n",
    "                                )\n",
    "                        except Exception as e:\n",
    "                            logger.warning(f\"Wilcoxon Test fehlgeschlagen für {classifier}-{strategy}: {e}\")\n",
    "                            statistic, p_value = 0.0, 1.0\n",
    "                        \n",
    "                        # Effektstärke\n",
    "                        effect_size = cliffs_delta(strategy_data, baseline_data)\n",
    "                        effect_interpretation = interpret_cliffs_delta(effect_size)\n",
    "                        \n",
    "                        # Mittelwerte und Standardabweichungen\n",
    "                        baseline_mean = np.mean(baseline_data) if len(baseline_data) > 0 else 0\n",
    "                        baseline_std = np.std(baseline_data) if len(baseline_data) > 0 else 0\n",
    "                        strategy_mean = np.mean(strategy_data) if len(strategy_data) > 0 else 0\n",
    "                        strategy_std = np.std(strategy_data) if len(strategy_data) > 0 else 0\n",
    "                        \n",
    "                        # Verbesserung berechnen mit Division-by-Zero-Schutz\n",
    "                        improvement = strategy_mean - baseline_mean\n",
    "                        improvement_pct = ((improvement / baseline_mean) * 100) if baseline_mean > 0 else 0\n",
    "                        \n",
    "                        statistical_results.append({\n",
    "                            'classifier': classifier,\n",
    "                            'budget_pct': budget_pct,\n",
    "                            'strategy': strategy,\n",
    "                            'baseline_mean': baseline_mean,\n",
    "                            'baseline_std': baseline_std,\n",
    "                            'strategy_mean': strategy_mean,\n",
    "                            'strategy_std': strategy_std,\n",
    "                            'improvement': improvement,\n",
    "                            'improvement_pct': improvement_pct,\n",
    "                            'wilcoxon_statistic': float(statistic),\n",
    "                            'p_value': float(p_value),\n",
    "                            'cliffs_delta': float(effect_size),\n",
    "                            'effect_size': effect_interpretation,\n",
    "                            'n_samples': len(strategy_data)\n",
    "                        })\n",
    "        \n",
    "        # Konvertiere zu DataFrame\n",
    "        stat_df = pd.DataFrame(statistical_results)\n",
    "        \n",
    "        if len(stat_df) > 0:\n",
    "            # Bonferroni-Korrektur für multiple Vergleiche\n",
    "            n_comparisons = len(stat_df)\n",
    "            stat_df['p_value_corrected'] = np.minimum(stat_df['p_value'] * n_comparisons, 1.0)\n",
    "            stat_df['significant'] = stat_df['p_value_corrected'] < SIGNIFICANCE_LEVEL\n",
    "        else:\n",
    "            logger.warning(\"Keine statistischen Ergebnisse generiert!\")\n",
    "            \n",
    "        return stat_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der statistischen Analyse: {e}\")\n",
    "        return pd.DataFrame()  # Leerer DataFrame als Fallback\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 7) Active Learning Hauptfunktion mit Fehlerbehandlung\n",
    "# -------------------------------------------------------------------------------\n",
    "def run_active_learning_experiment(X_train_cnn, X_train_flat, y_train, \n",
    "                                 X_test_cnn, X_test_flat, y_test,\n",
    "                                 classifier_name, strategy_name, strategy_func,\n",
    "                                 budget_percentages, batch_size=500):\n",
    "    \"\"\"\n",
    "    Führt ein Active Learning Experiment durch mit umfassender Fehlerbehandlung.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    n_total = len(y_train)\n",
    "    \n",
    "    # Wähle richtiges Datenformat\n",
    "    use_cnn = (classifier_name == 'CNN')\n",
    "    X_train = X_train_cnn if use_cnn else X_train_flat\n",
    "    X_test = X_test_cnn if use_cnn else X_test_flat\n",
    "    \n",
    "    for budget_pct in budget_percentages:\n",
    "        n_budget = int(budget_pct * n_total)\n",
    "        \n",
    "        logger.info(f\"\\n{classifier_name} + {strategy_name} - Budget: {budget_pct:.0%} ({n_budget:,} Samples)\")\n",
    "        \n",
    "        for run in range(N_RUNS):\n",
    "            logger.info(f\"  Run {run+1}/{N_RUNS}\")\n",
    "            \n",
    "            try:\n",
    "                # Set seed for reproducibility\n",
    "                np.random.seed(SEED + run)\n",
    "                if use_cnn:\n",
    "                    torch.manual_seed(SEED + run)\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.manual_seed(SEED + run)\n",
    "                \n",
    "                # Initialisierung\n",
    "                pool_indices = np.arange(n_total)\n",
    "                labeled_indices = []\n",
    "                \n",
    "                # Initiale zufällige Auswahl\n",
    "                n_initial = max(100, int(INITIAL_PERCENTAGE * n_total))\n",
    "                n_initial = min(n_initial, len(pool_indices))  # Sicherstellen dass genug Samples da sind\n",
    "                \n",
    "                initial_indices = np.random.choice(pool_indices, size=n_initial, replace=False)\n",
    "                labeled_indices = list(initial_indices)\n",
    "                pool_indices = np.setdiff1d(pool_indices, labeled_indices)\n",
    "                \n",
    "                # Tracking\n",
    "                accuracies = []\n",
    "                n_labeled_list = []\n",
    "                query_times = []\n",
    "                train_times = []\n",
    "                \n",
    "                while len(labeled_indices) < n_budget and len(pool_indices) > 0:\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    # Modell erstellen und trainieren\n",
    "                    model = create_classifier(classifier_name, use_cnn)\n",
    "                    \n",
    "                    train_start = time.time()\n",
    "                    \n",
    "                    # Training mit Fehlerbehandlung\n",
    "                    try:\n",
    "                        if use_cnn:\n",
    "                            model.fit(X_train[labeled_indices], y_train[labeled_indices], \n",
    "                                     epochs=5, verbose=False)\n",
    "                        else:\n",
    "                            model.fit(X_train[labeled_indices], y_train[labeled_indices])\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler beim Training in Run {run+1}: {e}\")\n",
    "                        # Skip diesen Durchlauf\n",
    "                        break\n",
    "                    \n",
    "                    train_time = time.time() - train_start\n",
    "                    train_times.append(train_time)\n",
    "                    \n",
    "                    # Evaluation\n",
    "                    try:\n",
    "                        y_pred = model.predict(X_test)\n",
    "                        acc = accuracy_score(y_test, y_pred)\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler bei der Evaluation in Run {run+1}: {e}\")\n",
    "                        acc = 0.0\n",
    "                    \n",
    "                    accuracies.append(acc)\n",
    "                    n_labeled_list.append(len(labeled_indices))\n",
    "                    \n",
    "                    # Nächste Batch auswählen\n",
    "                    n_query = min(batch_size, n_budget - len(labeled_indices), len(pool_indices))\n",
    "                    if n_query <= 0:\n",
    "                        break\n",
    "                    \n",
    "                    # Query mit Zeitmessung und Fehlerbehandlung\n",
    "                    query_start = time.time()\n",
    "                    try:\n",
    "                        query_indices = strategy_func(model, X_train[pool_indices], n_query)\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler bei Query-Strategie {strategy_name}: {e}\")\n",
    "                        # Fallback zu Random Sampling\n",
    "                        query_indices = random_sampling(model, X_train[pool_indices], n_query)\n",
    "                    \n",
    "                    query_time = time.time() - query_start\n",
    "                    query_times.append(query_time)\n",
    "                    \n",
    "                    # Validierung der Query-Indizes\n",
    "                    query_indices = np.asarray(query_indices)\n",
    "                    query_indices = query_indices[query_indices < len(pool_indices)]  # Entferne ungültige Indizes\n",
    "                    \n",
    "                    if len(query_indices) == 0:\n",
    "                        logger.warning(f\"Keine gueltigen Query-Indizes in Run {run+1}\")\n",
    "                        break\n",
    "                    \n",
    "                    selected_indices = pool_indices[query_indices]\n",
    "                    \n",
    "                    # Update\n",
    "                    labeled_indices.extend(selected_indices)\n",
    "                    pool_indices = np.setdiff1d(pool_indices, selected_indices)\n",
    "                    \n",
    "                    # Progress logging - Unicode-Fix: Verwende -> statt →\n",
    "                    if len(labeled_indices) % 5000 == 0 or len(labeled_indices) == n_budget:\n",
    "                        logger.info(f\"    {len(labeled_indices):,} labeled -> Accuracy: {acc:.4f} \"\n",
    "                                  f\"(Train: {train_time:.1f}s, Query: {query_time:.2f}s)\")\n",
    "                    \n",
    "                    # Speicher freigeben bei CNN\n",
    "                    if use_cnn and hasattr(model, 'device') and model.device.type == 'cuda':\n",
    "                        torch.cuda.empty_cache()\n",
    "                \n",
    "                # Finale Evaluation mit mehr Training\n",
    "                if len(labeled_indices) > 0:\n",
    "                    try:\n",
    "                        model = create_classifier(classifier_name, use_cnn)\n",
    "                        \n",
    "                        if use_cnn:\n",
    "                            model.fit(X_train[labeled_indices], y_train[labeled_indices], \n",
    "                                     epochs=10, verbose=False)\n",
    "                        else:\n",
    "                            model.fit(X_train[labeled_indices], y_train[labeled_indices])\n",
    "                        \n",
    "                        y_pred = model.predict(X_test)\n",
    "                        final_acc = accuracy_score(y_test, y_pred)\n",
    "                        final_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler bei finaler Evaluation in Run {run+1}: {e}\")\n",
    "                        final_acc = acc if 'acc' in locals() else 0.0\n",
    "                        final_f1 = 0.0\n",
    "                    \n",
    "                    results.append({\n",
    "                        'classifier': classifier_name,\n",
    "                        'strategy': strategy_name,\n",
    "                        'budget_pct': budget_pct,\n",
    "                        'run': run,\n",
    "                        'n_labeled': len(labeled_indices),\n",
    "                        'accuracy': final_acc,\n",
    "                        'f1_score': final_f1,\n",
    "                        'accuracies': accuracies,\n",
    "                        'n_labeled_list': n_labeled_list,\n",
    "                        'avg_query_time': np.mean(query_times) if query_times else 0,\n",
    "                        'avg_train_time': np.mean(train_times) if train_times else 0\n",
    "                    })\n",
    "                    \n",
    "                    # Unicode-Fix: Verwende -> statt →\n",
    "                    logger.info(f\"    Final: {len(labeled_indices):,} labeled -> \"\n",
    "                              f\"Accuracy: {final_acc:.4f}, F1: {final_f1:.4f}\")\n",
    "                \n",
    "                # Speicher freigeben\n",
    "                if use_cnn and torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Unerwarteter Fehler in Run {run+1}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 8) Visualisierung: Pro Klassifikator mit Signifikanzmarkierungen\n",
    "# -------------------------------------------------------------------------------\n",
    "def plot_per_classifier_with_significance(all_results, stat_results):\n",
    "    \"\"\"\n",
    "    Erstellt eine Visualisierung pro Klassifikator mit Signifikanzmarkierungen.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen mit Fallback\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        # Farben für Strategien\n",
    "        strategy_colors = {\n",
    "            'Random Sampling': '#808080',\n",
    "            'Entropy Sampling': '#1f77b4',\n",
    "            'Margin Sampling': '#ff7f0e',\n",
    "            'Least Confidence': '#2ca02c'\n",
    "        }\n",
    "        \n",
    "        # Klassifikatoren extrahieren\n",
    "        classifiers = sorted(list(set(r['classifier'] for r in all_results)))\n",
    "        \n",
    "        # Eine Figure pro Klassifikator\n",
    "        for classifier in classifiers:\n",
    "            fig, axes = plt.subplots(1, len(BUDGET_PERCENTAGES), figsize=(20, 4))\n",
    "            \n",
    "            # Handle für einzelne Subplot\n",
    "            if len(BUDGET_PERCENTAGES) == 1:\n",
    "                axes = [axes]\n",
    "                \n",
    "            fig.suptitle(f'{classifier} - Active Learning Performance with Statistical Significance', \n",
    "                         fontsize=16, y=1.02)\n",
    "            \n",
    "            for budget_idx, budget_pct in enumerate(BUDGET_PERCENTAGES):\n",
    "                ax = axes[budget_idx]\n",
    "                \n",
    "                # Daten für diesen Klassifikator und Budget\n",
    "                for strategy, color in strategy_colors.items():\n",
    "                    strategy_results = [r for r in all_results \n",
    "                                      if r['classifier'] == classifier \n",
    "                                      and r['strategy'] == strategy \n",
    "                                      and r['budget_pct'] == budget_pct]\n",
    "                    \n",
    "                    if strategy_results:\n",
    "                        # Lernkurven aggregieren\n",
    "                        max_samples = int(budget_pct * 60000)\n",
    "                        x_common = np.linspace(100, max_samples, 100)\n",
    "                        y_interpolated = []\n",
    "                        \n",
    "                        for r in strategy_results:\n",
    "                            if len(r['n_labeled_list']) > 1:\n",
    "                                try:\n",
    "                                    y_interp = np.interp(x_common, r['n_labeled_list'], r['accuracies'])\n",
    "                                    y_interpolated.append(y_interp)\n",
    "                                except:\n",
    "                                    logger.warning(f\"Interpolation fehlgeschlagen für {classifier}-{strategy}\")\n",
    "                        \n",
    "                        if y_interpolated:\n",
    "                            y_mean = np.mean(y_interpolated, axis=0)\n",
    "                            y_std = np.std(y_interpolated, axis=0)\n",
    "                            \n",
    "                            # Überprüfe Signifikanz\n",
    "                            is_significant = False\n",
    "                            effect_size = \"\"\n",
    "                            if strategy != 'Random Sampling' and not stat_results.empty:\n",
    "                                sig_data = stat_results[\n",
    "                                    (stat_results['classifier'] == classifier) & \n",
    "                                    (stat_results['strategy'] == strategy) & \n",
    "                                    (stat_results['budget_pct'] == budget_pct)\n",
    "                                ]\n",
    "                                if not sig_data.empty:\n",
    "                                    is_significant = sig_data.iloc[0]['significant']\n",
    "                                    effect_size = sig_data.iloc[0]['effect_size']\n",
    "                            \n",
    "                            # Label mit Signifikanz\n",
    "                            label = strategy\n",
    "                            if is_significant:\n",
    "                                label += f\" *({effect_size})\"\n",
    "                            \n",
    "                            # Plot mit Konfidenzintervall\n",
    "                            ax.plot(x_common, y_mean, \n",
    "                                   label=label, \n",
    "                                   color=color, \n",
    "                                   linewidth=2.5,\n",
    "                                   linestyle='-' if not is_significant or strategy == 'Random Sampling' else '--',\n",
    "                                   marker='o' if strategy == 'Random Sampling' else None,\n",
    "                                   markevery=10 if strategy == 'Random Sampling' else None,\n",
    "                                   markersize=4)\n",
    "                            \n",
    "                            ax.fill_between(x_common, \n",
    "                                          y_mean - y_std, \n",
    "                                          y_mean + y_std, \n",
    "                                          color=color, \n",
    "                                          alpha=0.2)\n",
    "                \n",
    "                # Achsenbeschriftung\n",
    "                ax.set_xlabel('Number of Labeled Samples', fontsize=11)\n",
    "                ax.set_ylabel('Test Accuracy', fontsize=11)\n",
    "                ax.set_title(f'Budget: {int(budget_pct*100)}%', fontsize=12)\n",
    "                \n",
    "                # Grid und Limits\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                ax.set_ylim([0.75, 1.0])\n",
    "                \n",
    "                # X-Achse formatieren\n",
    "                ax.ticklabel_format(style='plain', axis='x')\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}k'))\n",
    "                \n",
    "                # Legende nur beim ersten Plot\n",
    "                if budget_idx == 0:\n",
    "                    ax.legend(loc='lower right', fontsize=9, framealpha=0.9)\n",
    "            \n",
    "            # Signifikanz-Erklärung\n",
    "            fig.text(0.5, -0.05, \n",
    "                    '* = statistically significant (p < 0.05 with Bonferroni correction); ' +\n",
    "                    'Effect size in parentheses (negligible/small/medium/large)',\n",
    "                    ha='center', fontsize=10, style='italic')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Speichern mit Fehlerbehandlung\n",
    "            filename = f'plots/active_learning_{classifier.lower().replace(\" \", \"_\")}_with_significance.png'\n",
    "            try:\n",
    "                plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "                logger.info(f\"[ok] Visualisierung mit Signifikanz für {classifier} erstellt: {filename}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Fehler beim Speichern der Visualisierung für {classifier}: {e}\")\n",
    "                \n",
    "            plt.close()\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_per_classifier_with_significance: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 9) Visualisierung: Statistische Zusammenfassung\n",
    "# -------------------------------------------------------------------------------\n",
    "def plot_statistical_summary(stat_results):\n",
    "    \"\"\"\n",
    "    Erstellt eine Visualisierung der statistischen Ergebnisse.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        if stat_results.empty:\n",
    "            logger.warning(\"Keine statistischen Ergebnisse zum Visualisieren!\")\n",
    "            return\n",
    "            \n",
    "        # Filtere nur signifikante Ergebnisse\n",
    "        sig_results = stat_results[stat_results['significant']].copy() if 'significant' in stat_results.columns else pd.DataFrame()\n",
    "        \n",
    "        if sig_results.empty:\n",
    "            logger.warning(\"Keine signifikanten Ergebnisse gefunden!\")\n",
    "            # Erstelle trotzdem eine Visualisierung mit allen Ergebnissen\n",
    "            sig_results = stat_results.copy()\n",
    "        \n",
    "        # Figure mit Subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('Statistical Analysis Summary', fontsize=16)\n",
    "        \n",
    "        # 1. Heatmap der p-Werte\n",
    "        try:\n",
    "            ax1 = axes[0, 0]\n",
    "            pivot_p = stat_results.pivot_table(\n",
    "                values='p_value_corrected',\n",
    "                index=['classifier', 'strategy'],\n",
    "                columns='budget_pct',\n",
    "                fill_value=1.0\n",
    "            )\n",
    "            \n",
    "            if sns is not None and not pivot_p.empty:\n",
    "                sns.heatmap(pivot_p, \n",
    "                            annot=True, \n",
    "                            fmt='.3f', \n",
    "                            cmap='RdYlGn_r',\n",
    "                            vmin=0, \n",
    "                            vmax=0.1,\n",
    "                            cbar_kws={'label': 'Corrected p-value'},\n",
    "                            ax=ax1)\n",
    "            else:\n",
    "                ax1.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "                \n",
    "            ax1.set_title('Corrected p-values (Wilcoxon Signed-Rank Test)')\n",
    "            ax1.set_xlabel('Budget (%)')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei p-Wert Heatmap: {e}\")\n",
    "            axes[0, 0].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        # 2. Heatmap der Effektstärken\n",
    "        try:\n",
    "            ax2 = axes[0, 1]\n",
    "            pivot_effect = stat_results.pivot_table(\n",
    "                values='cliffs_delta',\n",
    "                index=['classifier', 'strategy'],\n",
    "                columns='budget_pct',\n",
    "                fill_value=0.0\n",
    "            )\n",
    "            \n",
    "            if sns is not None and not pivot_effect.empty:\n",
    "                sns.heatmap(pivot_effect, \n",
    "                            annot=True, \n",
    "                            fmt='.3f', \n",
    "                            cmap='coolwarm',\n",
    "                            center=0,\n",
    "                            vmin=-1, \n",
    "                            vmax=1,\n",
    "                            cbar_kws={'label': \"Cliff's Delta\"},\n",
    "                            ax=ax2)\n",
    "            else:\n",
    "                ax2.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "                \n",
    "            ax2.set_title(\"Effect Size (Cliff's Delta)\")\n",
    "            ax2.set_xlabel('Budget (%)')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei Effektstärken Heatmap: {e}\")\n",
    "            axes[0, 1].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        # 3. Anzahl signifikanter Verbesserungen pro Strategie\n",
    "        try:\n",
    "            ax3 = axes[1, 0]\n",
    "            if not sig_results.empty and 'strategy' in sig_results.columns:\n",
    "                sig_counts = sig_results.groupby('strategy').size().sort_values(ascending=False)\n",
    "                sig_counts.plot(kind='bar', ax=ax3, color='steelblue')\n",
    "                ax3.set_title('Number of Significant Improvements per Strategy')\n",
    "                ax3.set_xlabel('Strategy')\n",
    "                ax3.set_ylabel('Count')\n",
    "                ax3.grid(axis='y', alpha=0.3)\n",
    "            else:\n",
    "                ax3.text(0.5, 0.5, 'Keine signifikanten Ergebnisse', ha='center', va='center')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei Signifikanz-Barplot: {e}\")\n",
    "            axes[1, 0].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        # 4. Durchschnittliche Effektstärke pro Klassifikator\n",
    "        try:\n",
    "            ax4 = axes[1, 1]\n",
    "            if 'classifier' in stat_results.columns and 'cliffs_delta' in stat_results.columns:\n",
    "                avg_effect = stat_results.groupby('classifier')['cliffs_delta'].agg(['mean', 'std'])\n",
    "                avg_effect['mean'].plot(kind='bar', ax=ax4, yerr=avg_effect['std'], \n",
    "                                       capsize=5, color='darkorange')\n",
    "                ax4.set_title(\"Average Effect Size per Classifier\")\n",
    "                ax4.set_xlabel('Classifier')\n",
    "                ax4.set_ylabel(\"Mean Cliff's Delta\")\n",
    "                ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "                ax4.grid(axis='y', alpha=0.3)\n",
    "            else:\n",
    "                ax4.text(0.5, 0.5, 'Daten nicht verfügbar', ha='center', va='center')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei Effektstärken-Barplot: {e}\")\n",
    "            axes[1, 1].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Speichern\n",
    "        filename = 'plots/active_learning_statistical_summary.png'\n",
    "        try:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"[ok] Statistische Zusammenfassung erstellt: {filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern der statistischen Zusammenfassung: {e}\")\n",
    "            \n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_statistical_summary: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 10) Detaillierte statistische Tabelle\n",
    "# -------------------------------------------------------------------------------\n",
    "def create_statistical_report(stat_results):\n",
    "    \"\"\"\n",
    "    Erstellt einen detaillierten statistischen Bericht.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Sortiere nach Effektstärke\n",
    "        if not stat_results.empty and 'cliffs_delta' in stat_results.columns:\n",
    "            stat_results_sorted = stat_results.sort_values('cliffs_delta', ascending=False)\n",
    "        else:\n",
    "            stat_results_sorted = stat_results\n",
    "        \n",
    "        # Erstelle formatierten Bericht\n",
    "        report = []\n",
    "        report.append(\"\\n\" + \"=\"*100)\n",
    "        report.append(\"DETAILLIERTER STATISTISCHER BERICHT\")\n",
    "        report.append(\"=\"*100)\n",
    "        report.append(f\"Signifikanzniveau: {SIGNIFICANCE_LEVEL} (mit Bonferroni-Korrektur)\")\n",
    "        report.append(f\"Anzahl Runs pro Experiment: {N_RUNS}\")\n",
    "        report.append(f\"Statistischer Test: Wilcoxon Signed-Rank Test\")\n",
    "        report.append(f\"Effektstärkemaß: Cliff's Delta\")\n",
    "        report.append(\"\\n\")\n",
    "        \n",
    "        # Signifikante Ergebnisse\n",
    "        if 'significant' in stat_results_sorted.columns:\n",
    "            sig_results = stat_results_sorted[stat_results_sorted['significant']]\n",
    "        else:\n",
    "            sig_results = pd.DataFrame()\n",
    "        \n",
    "        if not sig_results.empty:\n",
    "            report.append(\"SIGNIFIKANTE VERBESSERUNGEN GEGENÜBER RANDOM SAMPLING:\")\n",
    "            report.append(\"-\"*100)\n",
    "            report.append(f\"{'Klassifikator':<20} {'Strategie':<20} {'Budget':<10} {'Verbesserung':<15} \"\n",
    "                         f\"{'p-Wert':<12} {'Effekt':<15} {'Interpretation':<15}\")\n",
    "            report.append(\"-\"*100)\n",
    "            \n",
    "            for _, row in sig_results.iterrows():\n",
    "                report.append(f\"{row['classifier']:<20} {row['strategy']:<20} \"\n",
    "                             f\"{int(row['budget_pct']*100):>8}% \"\n",
    "                             f\"{row['improvement_pct']:>13.2f}% \"\n",
    "                             f\"{row['p_value_corrected']:>11.4f} \"\n",
    "                             f\"{row['cliffs_delta']:>14.3f} \"\n",
    "                             f\"{row['effect_size']:<15}\")\n",
    "        else:\n",
    "            report.append(\"Keine signifikanten Verbesserungen gefunden!\")\n",
    "        \n",
    "        # Zusammenfassung nach Strategie\n",
    "        report.append(\"\\n\\nZUSAMMENFASSUNG NACH STRATEGIE:\")\n",
    "        report.append(\"-\"*100)\n",
    "        \n",
    "        for strategy in ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "            if 'strategy' in stat_results.columns:\n",
    "                strategy_data = stat_results[stat_results['strategy'] == strategy]\n",
    "                if not strategy_data.empty:\n",
    "                    sig_count = strategy_data['significant'].sum() if 'significant' in strategy_data.columns else 0\n",
    "                    avg_improvement = strategy_data['improvement_pct'].mean() if 'improvement_pct' in strategy_data.columns else 0\n",
    "                    avg_effect = strategy_data['cliffs_delta'].mean() if 'cliffs_delta' in strategy_data.columns else 0\n",
    "                    \n",
    "                    report.append(f\"\\n{strategy}:\")\n",
    "                    report.append(f\"  - Signifikante Verbesserungen: {sig_count}/{len(strategy_data)} \"\n",
    "                                 f\"({sig_count/len(strategy_data)*100:.1f}%)\")\n",
    "                    report.append(f\"  - Durchschnittliche Verbesserung: {avg_improvement:.2f}%\")\n",
    "                    report.append(f\"  - Durchschnittliche Effektstärke: {avg_effect:.3f}\")\n",
    "        \n",
    "        # Zusammenfassung nach Klassifikator\n",
    "        report.append(\"\\n\\nZUSAMMENFASSUNG NACH KLASSIFIKATOR:\")\n",
    "        report.append(\"-\"*100)\n",
    "        \n",
    "        if 'classifier' in stat_results.columns:\n",
    "            for classifier in stat_results['classifier'].unique():\n",
    "                classifier_data = stat_results[stat_results['classifier'] == classifier]\n",
    "                sig_count = classifier_data['significant'].sum() if 'significant' in classifier_data.columns else 0\n",
    "                \n",
    "                report.append(f\"\\n{classifier}:\")\n",
    "                report.append(f\"  - Signifikante Verbesserungen: {sig_count}/{len(classifier_data)} \"\n",
    "                             f\"({sig_count/len(classifier_data)*100:.1f}%)\")\n",
    "                \n",
    "                if sig_count > 0 and 'cliffs_delta' in classifier_data.columns:\n",
    "                    best_strategy = classifier_data.loc[classifier_data['cliffs_delta'].idxmax()]\n",
    "                    report.append(f\"  - Beste Strategie: {best_strategy['strategy']} \"\n",
    "                                 f\"bei {int(best_strategy['budget_pct']*100)}% Budget \"\n",
    "                                 f\"(Effekt: {best_strategy['cliffs_delta']:.3f})\")\n",
    "        \n",
    "        report.append(\"\\n\" + \"=\"*100)\n",
    "        \n",
    "        # Ausgabe\n",
    "        report_text = \"\\n\".join(report)\n",
    "        print(report_text)\n",
    "        \n",
    "        # Speichern\n",
    "        report_filename = 'reports/statistical_report.txt'\n",
    "        try:\n",
    "            with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(report_text)\n",
    "            logger.info(f\"[ok] Statistischer Bericht gespeichert: {report_filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern des Berichts: {e}\")\n",
    "        \n",
    "        return report_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei create_statistical_report: {e}\")\n",
    "        return \"Fehler bei der Berichterstellung\"\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 11) Visualisierung: Finale Vergleichsmatrix\n",
    "# -------------------------------------------------------------------------------\n",
    "def plot_final_comparison(all_results):\n",
    "    \"\"\"\n",
    "    Erstellt eine Visualisierung, die zeigt, welche Kombination aus Klassifikator\n",
    "    und Query-Strategie bei 100% Budget am besten abgeschnitten hat.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        # Nur Ergebnisse mit 100% Budget\n",
    "        final_results = [r for r in all_results if r['budget_pct'] == 1.0]\n",
    "        \n",
    "        if not final_results:\n",
    "            logger.warning(\"Keine Ergebnisse mit 100% Budget gefunden!\")\n",
    "            return\n",
    "        \n",
    "        # Aggregiere Ergebnisse\n",
    "        summary_data = []\n",
    "        classifiers = sorted(list(set(r['classifier'] for r in final_results)))\n",
    "        strategies = ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            for strategy in strategies:\n",
    "                results = [r for r in final_results \n",
    "                          if r['classifier'] == classifier and r['strategy'] == strategy]\n",
    "                \n",
    "                if results:\n",
    "                    mean_acc = np.mean([r['accuracy'] for r in results])\n",
    "                    std_acc = np.std([r['accuracy'] for r in results])\n",
    "                    mean_f1 = np.mean([r['f1_score'] for r in results])\n",
    "                    \n",
    "                    summary_data.append({\n",
    "                        'Classifier': classifier,\n",
    "                        'Strategy': strategy,\n",
    "                        'Accuracy': mean_acc,\n",
    "                        'Accuracy_std': std_acc,\n",
    "                        'F1-Score': mean_f1\n",
    "                    })\n",
    "        \n",
    "        if not summary_data:\n",
    "            logger.warning(\"Keine Daten für finale Vergleichsmatrix!\")\n",
    "            return\n",
    "            \n",
    "        # DataFrame erstellen\n",
    "        df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # Pivot für Heatmap\n",
    "        pivot_acc = df.pivot(index='Classifier', columns='Strategy', values='Accuracy')\n",
    "        pivot_f1 = df.pivot(index='Classifier', columns='Strategy', values='F1-Score')\n",
    "        \n",
    "        # Figure mit zwei Subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Heatmap für Accuracy\n",
    "        if sns is not None and not pivot_acc.empty:\n",
    "            sns.heatmap(pivot_acc, \n",
    "                        annot=True, \n",
    "                        fmt='.4f', \n",
    "                        cmap='RdYlGn', \n",
    "                        vmin=0.95, \n",
    "                        vmax=1.0,\n",
    "                        cbar_kws={'label': 'Test Accuracy'},\n",
    "                        ax=ax1)\n",
    "        else:\n",
    "            ax1.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "            \n",
    "        ax1.set_title('Test Accuracy at 100% Budget', fontsize=14)\n",
    "        ax1.set_xlabel('Query Strategy', fontsize=12)\n",
    "        ax1.set_ylabel('Classifier', fontsize=12)\n",
    "        \n",
    "        # Heatmap für F1-Score\n",
    "        if sns is not None and not pivot_f1.empty:\n",
    "            sns.heatmap(pivot_f1, \n",
    "                        annot=True, \n",
    "                        fmt='.4f', \n",
    "                        cmap='RdYlGn', \n",
    "                        vmin=0.95, \n",
    "                        vmax=1.0,\n",
    "                        cbar_kws={'label': 'F1-Score (Macro)'},\n",
    "                        ax=ax2)\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "            \n",
    "        ax2.set_title('F1-Score at 100% Budget', fontsize=14)\n",
    "        ax2.set_xlabel('Query Strategy', fontsize=12)\n",
    "        ax2.set_ylabel('Classifier', fontsize=12)\n",
    "        \n",
    "        plt.suptitle('Final Performance Comparison - Full Dataset (100% Budget)', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Speichern\n",
    "        filename = 'plots/active_learning_final_comparison.png'\n",
    "        try:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"[ok] Finale Vergleichsvisualisierung erstellt: {filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern der finalen Vergleichsmatrix: {e}\")\n",
    "            \n",
    "        plt.close()\n",
    "        \n",
    "        # Beste Kombination finden\n",
    "        if not df.empty:\n",
    "            best_idx = df['Accuracy'].idxmax()\n",
    "            best_result = df.iloc[best_idx]\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"BESTE KOMBINATION BEI 100% BUDGET:\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"Klassifikator: {best_result['Classifier']}\")\n",
    "            print(f\"Query-Strategie: {best_result['Strategy']}\")\n",
    "            print(f\"Test Accuracy: {best_result['Accuracy']:.4f} (±{best_result['Accuracy_std']:.4f})\")\n",
    "            print(f\"F1-Score: {best_result['F1-Score']:.4f}\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            # Top 5 Kombinationen\n",
    "            print(\"\\nTOP 5 KOMBINATIONEN:\")\n",
    "            print(\"-\"*60)\n",
    "            top5 = df.nlargest(5, 'Accuracy')[['Classifier', 'Strategy', 'Accuracy', 'F1-Score']]\n",
    "            for idx, (_, row) in enumerate(top5.iterrows()):\n",
    "                print(f\"{idx+1}. {row['Classifier']} + {row['Strategy']}: \"\n",
    "                      f\"Acc={row['Accuracy']:.4f}, F1={row['F1-Score']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_final_comparison: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 12) Zusätzliche Analyse: Improvement over Random\n",
    "# -------------------------------------------------------------------------------\n",
    "def plot_improvement_analysis(all_results):\n",
    "    \"\"\"\n",
    "    Zeigt die Verbesserung der Active Learning Strategien gegenüber Random Sampling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        # Berechne Verbesserungen\n",
    "        improvements = []\n",
    "        classifiers = sorted(list(set(r['classifier'] for r in all_results)))\n",
    "        strategies = ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            for strategy in strategies:\n",
    "                for budget_pct in BUDGET_PERCENTAGES:\n",
    "                    # Random Sampling Baseline\n",
    "                    random_results = [r for r in all_results \n",
    "                                    if r['classifier'] == classifier \n",
    "                                    and r['strategy'] == 'Random Sampling' \n",
    "                                    and r['budget_pct'] == budget_pct]\n",
    "                    \n",
    "                    # Active Learning Strategy\n",
    "                    strategy_results = [r for r in all_results \n",
    "                                      if r['classifier'] == classifier \n",
    "                                      and r['strategy'] == strategy \n",
    "                                      and r['budget_pct'] == budget_pct]\n",
    "                    \n",
    "                    if random_results and strategy_results:\n",
    "                        random_acc = np.mean([r['accuracy'] for r in random_results])\n",
    "                        strategy_acc = np.mean([r['accuracy'] for r in strategy_results])\n",
    "                        \n",
    "                        # Prozentuale Verbesserung\n",
    "                        improvement = ((strategy_acc - random_acc) / random_acc) * 100 if random_acc > 0 else 0\n",
    "                        \n",
    "                        improvements.append({\n",
    "                            'Classifier': classifier,\n",
    "                            'Strategy': strategy,\n",
    "                            'Budget': int(budget_pct * 100),\n",
    "                            'Improvement (%)': improvement\n",
    "                        })\n",
    "        \n",
    "        if not improvements:\n",
    "            logger.warning(\"Keine Verbesserungsdaten gefunden!\")\n",
    "            return\n",
    "            \n",
    "        # DataFrame erstellen\n",
    "        imp_df = pd.DataFrame(improvements)\n",
    "        \n",
    "        # Figure\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Gruppierter Barplot\n",
    "        x = np.arange(len(BUDGET_PERCENTAGES))\n",
    "        width = 0.15\n",
    "        \n",
    "        # Erstelle eine eindeutige Farbe für jede Klassifikator-Strategie-Kombination\n",
    "        colors = plt.cm.tab20(np.linspace(0, 1, len(classifiers) * len(strategies)))\n",
    "        color_idx = 0\n",
    "        \n",
    "        for i, classifier in enumerate(classifiers):\n",
    "            for j, strategy in enumerate(strategies):\n",
    "                data = imp_df[(imp_df['Classifier'] == classifier) & \n",
    "                             (imp_df['Strategy'] == strategy)]\n",
    "                \n",
    "                if not data.empty:\n",
    "                    values = []\n",
    "                    for b in BUDGET_PERCENTAGES:\n",
    "                        budget_data = data[data['Budget'] == int(b*100)]\n",
    "                        if not budget_data.empty:\n",
    "                            values.append(budget_data['Improvement (%)'].values[0])\n",
    "                        else:\n",
    "                            values.append(0)\n",
    "                    \n",
    "                    offset = (i * len(strategies) + j - len(classifiers) * len(strategies) / 2) * width\n",
    "                    bars = ax.bar(x + offset, values, width, \n",
    "                                 label=f'{classifier} - {strategy}',\n",
    "                                 color=colors[color_idx])\n",
    "                    color_idx += 1\n",
    "        \n",
    "        # Achsenbeschriftung\n",
    "        ax.set_xlabel('Budget (%)', fontsize=12)\n",
    "        ax.set_ylabel('Improvement over Random Sampling (%)', fontsize=12)\n",
    "        ax.set_title('Active Learning Improvement Analysis', fontsize=14)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f'{int(b*100)}%' for b in BUDGET_PERCENTAGES])\n",
    "        \n",
    "        # Nulllinie\n",
    "        ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Legende\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "        \n",
    "        # Grid\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Speichern\n",
    "        filename = 'plots/active_learning_improvement_analysis.png'\n",
    "        try:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"[ok] Improvement-Analyse erstellt: {filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern der Improvement-Analyse: {e}\")\n",
    "            \n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_improvement_analysis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# 13) Label-Einsparungs-Analyse Funktionen (NEU)\n",
    "# -------------------------------------------------------------------------------\n",
    "def calculate_label_savings(all_results, target_performance_percentages=[0.90, 0.95, 0.98]):\n",
    "    \"\"\"\n",
    "    Berechnet die Label-Einsparung für Active Learning Strategien.\n",
    "    \n",
    "    Args:\n",
    "        all_results: Liste aller Experiment-Ergebnisse\n",
    "        target_performance_percentages: Prozentsätze der Random Sampling 100% Performance\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame mit Label-Einsparungen\n",
    "    \"\"\"\n",
    "    savings_results = []\n",
    "    \n",
    "    # Gruppiere nach Klassifikator\n",
    "    classifiers = sorted(list(set(r['classifier'] for r in all_results)))\n",
    "    \n",
    "    for classifier in classifiers:\n",
    "        # Hole Random Sampling Performance bei 100% Budget als Referenz\n",
    "        random_100_results = [r for r in all_results \n",
    "                            if r['classifier'] == classifier \n",
    "                            and r['strategy'] == 'Random Sampling' \n",
    "                            and r['budget_pct'] == 1.0]\n",
    "        \n",
    "        if not random_100_results:\n",
    "            continue\n",
    "            \n",
    "        # Durchschnittliche Performance bei 100% Budget\n",
    "        random_100_acc = np.mean([r['accuracy'] for r in random_100_results])\n",
    "        \n",
    "        # Für verschiedene Ziel-Performance-Level\n",
    "        for target_pct in target_performance_percentages:\n",
    "            target_accuracy = random_100_acc * target_pct\n",
    "            \n",
    "            # Für jede Strategie\n",
    "            for strategy in ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "                strategy_results = [r for r in all_results \n",
    "                                  if r['classifier'] == classifier \n",
    "                                  and r['strategy'] == strategy]\n",
    "                \n",
    "                if not strategy_results:\n",
    "                    continue\n",
    "                \n",
    "                # Aggregiere Lernkurven über alle Runs\n",
    "                all_curves = []\n",
    "                for r in strategy_results:\n",
    "                    if 'n_labeled_list' in r and 'accuracies' in r:\n",
    "                        all_curves.append((r['n_labeled_list'], r['accuracies']))\n",
    "                \n",
    "                if not all_curves:\n",
    "                    continue\n",
    "                \n",
    "                # Finde minimale Label-Anzahl um Ziel-Accuracy zu erreichen\n",
    "                labels_needed = []\n",
    "                \n",
    "                for n_labeled_list, accuracies in all_curves:\n",
    "                    # Interpoliere um den Punkt zu finden, wo target_accuracy erreicht wird\n",
    "                    if len(accuracies) > 0 and max(accuracies) >= target_accuracy:\n",
    "                        # Finde ersten Punkt, der target_accuracy überschreitet\n",
    "                        for i, acc in enumerate(accuracies):\n",
    "                            if acc >= target_accuracy:\n",
    "                                labels_needed.append(n_labeled_list[i])\n",
    "                                break\n",
    "                    else:\n",
    "                        # Ziel nicht erreicht - verwende Maximum\n",
    "                        labels_needed.append(60000)  # Max dataset size\n",
    "                \n",
    "                if labels_needed:\n",
    "                    avg_labels_needed = np.mean(labels_needed)\n",
    "                    std_labels_needed = np.std(labels_needed)\n",
    "                    \n",
    "                    # Berechne Einsparung gegenüber 100% (60000 Labels)\n",
    "                    savings_pct = ((60000 - avg_labels_needed) / 60000) * 100\n",
    "                    \n",
    "                    # Berechne Einsparung gegenüber Random Sampling\n",
    "                    if strategy != 'Random Sampling':\n",
    "                        random_labels = next((s['avg_labels_needed'] for s in savings_results \n",
    "                                            if s['classifier'] == classifier \n",
    "                                            and s['strategy'] == 'Random Sampling' \n",
    "                                            and s['target_performance'] == int(target_pct*100)), 60000)\n",
    "                        relative_savings_pct = ((random_labels - avg_labels_needed) / random_labels) * 100 if random_labels > 0 else 0\n",
    "                    else:\n",
    "                        relative_savings_pct = 0\n",
    "                    \n",
    "                    savings_results.append({\n",
    "                        'classifier': classifier,\n",
    "                        'strategy': strategy,\n",
    "                        'target_performance': int(target_pct * 100),\n",
    "                        'target_accuracy': target_accuracy,\n",
    "                        'avg_labels_needed': avg_labels_needed,\n",
    "                        'std_labels_needed': std_labels_needed,\n",
    "                        'savings_pct': savings_pct,\n",
    "                        'relative_savings_pct': relative_savings_pct,\n",
    "                        'random_100_acc': random_100_acc\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(savings_results)\n",
    "\n",
    "def plot_label_savings(savings_df, dataset_name=\"MNIST\"):\n",
    "    \"\"\"\n",
    "    Visualisiert die Label-Einsparungen.\n",
    "    \"\"\"\n",
    "    # Style setzen\n",
    "    try:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    except:\n",
    "        plt.style.use('ggplot')\n",
    "    \n",
    "    # Figure mit Subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'{dataset_name} - Label Savings Analysis', fontsize=16)\n",
    "    \n",
    "    # 1. Labels benötigt für verschiedene Performance-Level\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    # Gruppiere nach Klassifikator und Target Performance\n",
    "    for classifier in savings_df['classifier'].unique():\n",
    "        for target in savings_df['target_performance'].unique():\n",
    "            data = savings_df[(savings_df['classifier'] == classifier) & \n",
    "                            (savings_df['target_performance'] == target)]\n",
    "            \n",
    "            if not data.empty:\n",
    "                strategies = data['strategy'].values\n",
    "                labels_needed = data['avg_labels_needed'].values\n",
    "                errors = data['std_labels_needed'].values\n",
    "                \n",
    "                x = np.arange(len(strategies))\n",
    "                width = 0.2\n",
    "                offset = (target - 95) * width / 5  # Offset basierend auf target\n",
    "                \n",
    "                ax1.bar(x + offset, labels_needed, width, \n",
    "                       yerr=errors, capsize=5,\n",
    "                       label=f'{classifier} - {target}% of baseline',\n",
    "                       alpha=0.7)\n",
    "    \n",
    "    ax1.set_xlabel('Strategy')\n",
    "    ax1.set_ylabel('Labels Needed')\n",
    "    ax1.set_title('Labels Required to Reach Target Performance')\n",
    "    ax1.set_xticks(np.arange(len(strategies)))\n",
    "    ax1.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 2. Relative Einsparung gegenüber Random Sampling\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    # Pivot für Heatmap\n",
    "    pivot_savings = savings_df[savings_df['strategy'] != 'Random Sampling'].pivot_table(\n",
    "        values='relative_savings_pct',\n",
    "        index=['classifier', 'strategy'],\n",
    "        columns='target_performance',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    if not pivot_savings.empty and sns is not None:\n",
    "        sns.heatmap(pivot_savings, \n",
    "                    annot=True, \n",
    "                    fmt='.1f', \n",
    "                    cmap='RdYlGn',\n",
    "                    center=0,\n",
    "                    cbar_kws={'label': 'Label Savings (%)'},\n",
    "                    ax=ax2)\n",
    "        ax2.set_title('Label Savings vs Random Sampling (%)')\n",
    "        ax2.set_xlabel('Target Performance (% of baseline)')\n",
    "    \n",
    "    # 3. Absolute Label-Anzahl pro Klassifikator bei 95% Performance\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    data_95 = savings_df[savings_df['target_performance'] == 95]\n",
    "    \n",
    "    classifiers = data_95['classifier'].unique()\n",
    "    strategies = ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']\n",
    "    \n",
    "    x = np.arange(len(classifiers))\n",
    "    width = 0.2\n",
    "    \n",
    "    for i, strategy in enumerate(strategies):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for classifier in classifiers:\n",
    "            row = data_95[(data_95['classifier'] == classifier) & \n",
    "                         (data_95['strategy'] == strategy)]\n",
    "            if not row.empty:\n",
    "                values.append(row['avg_labels_needed'].values[0])\n",
    "                errors.append(row['std_labels_needed'].values[0])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        ax3.bar(x + i*width - 1.5*width, values, width, \n",
    "               yerr=errors, capsize=5,\n",
    "               label=strategy, alpha=0.8)\n",
    "    \n",
    "    ax3.set_xlabel('Classifier')\n",
    "    ax3.set_ylabel('Labels Needed')\n",
    "    ax3.set_title('Labels Needed to Reach 95% of Baseline Performance')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels(classifiers, rotation=45, ha='right')\n",
    "    ax3.legend()\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Referenzlinie bei 60000 (100% der Daten)\n",
    "    ax3.axhline(y=60000, color='red', linestyle='--', alpha=0.5, label='Full Dataset')\n",
    "    \n",
    "    # 4. Zusammenfassungstabelle\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('tight')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Erstelle Zusammenfassungstabelle für 95% Performance\n",
    "    summary_data = []\n",
    "    for classifier in classifiers:\n",
    "        row_data = [classifier]\n",
    "        for strategy in strategies:\n",
    "            data = data_95[(data_95['classifier'] == classifier) & \n",
    "                          (data_95['strategy'] == strategy)]\n",
    "            if not data.empty:\n",
    "                labels = data['avg_labels_needed'].values[0]\n",
    "                savings = data['savings_pct'].values[0]\n",
    "                row_data.append(f'{int(labels):,}\\n({savings:.1f}% saved)')\n",
    "            else:\n",
    "                row_data.append('N/A')\n",
    "        summary_data.append(row_data)\n",
    "    \n",
    "    table = ax4.table(cellText=summary_data,\n",
    "                     colLabels=['Classifier'] + strategies,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1.2, 2)\n",
    "    \n",
    "    # Style the header row\n",
    "    for i in range(len(strategies) + 1):\n",
    "        table[(0, i)].set_facecolor('#40466e')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    ax4.set_title('Summary: Labels Needed for 95% Performance', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Speichern\n",
    "    filename = f'plots/{dataset_name.lower()}_label_savings_analysis.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"[ok] Label-Einsparungs-Analyse erstellt: {filename}\")\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return savings_df\n",
    "\n",
    "def create_label_savings_report(savings_df, dataset_name=\"MNIST\"):\n",
    "    \"\"\"\n",
    "    Erstellt einen detaillierten Bericht über Label-Einsparungen.\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(f\"LABEL-EINSPARUNGS-BERICHT - {dataset_name}\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    # Für jedes Performance-Level\n",
    "    for target_perf in sorted(savings_df['target_performance'].unique()):\n",
    "        report.append(f\"\\nZIEL: {target_perf}% der Baseline-Performance\")\n",
    "        report.append(\"-\"*60)\n",
    "        \n",
    "        target_data = savings_df[savings_df['target_performance'] == target_perf]\n",
    "        \n",
    "        # Nach Klassifikator gruppieren\n",
    "        for classifier in sorted(target_data['classifier'].unique()):\n",
    "            classifier_data = target_data[target_data['classifier'] == classifier]\n",
    "            baseline_acc = classifier_data['random_100_acc'].iloc[0]\n",
    "            target_acc = classifier_data['target_accuracy'].iloc[0]\n",
    "            \n",
    "            report.append(f\"\\n{classifier}:\")\n",
    "            report.append(f\"  Baseline (Random 100%): {baseline_acc:.4f}\")\n",
    "            report.append(f\"  Ziel-Accuracy: {target_acc:.4f}\")\n",
    "            report.append(f\"  Labels benötigt:\")\n",
    "            \n",
    "            # Sortiere nach Labels benötigt\n",
    "            sorted_data = classifier_data.sort_values('avg_labels_needed')\n",
    "            \n",
    "            for _, row in sorted_data.iterrows():\n",
    "                strategy = row['strategy']\n",
    "                labels = row['avg_labels_needed']\n",
    "                std = row['std_labels_needed']\n",
    "                savings = row['savings_pct']\n",
    "                rel_savings = row['relative_savings_pct']\n",
    "                \n",
    "                report.append(f\"    - {strategy:<20}: {int(labels):>6,} ± {int(std):>4} \"\n",
    "                            f\"({savings:>5.1f}% gespart)\")\n",
    "                \n",
    "                if strategy != 'Random Sampling' and rel_savings > 0:\n",
    "                    report.append(f\"      -> {rel_savings:.1f}% weniger Labels als Random Sampling\")\n",
    "    \n",
    "    # Beste Strategien\n",
    "    report.append(\"\\n\\nBESTE STRATEGIEN (bei 95% Performance):\")\n",
    "    report.append(\"-\"*60)\n",
    "    \n",
    "    data_95 = savings_df[savings_df['target_performance'] == 95]\n",
    "    \n",
    "    for classifier in sorted(data_95['classifier'].unique()):\n",
    "        classifier_data = data_95[data_95['classifier'] == classifier]\n",
    "        best_row = classifier_data.loc[classifier_data['avg_labels_needed'].idxmin()]\n",
    "        \n",
    "        report.append(f\"{classifier}: {best_row['strategy']} \"\n",
    "                     f\"(nur {int(best_row['avg_labels_needed']):,} Labels = \"\n",
    "                     f\"{best_row['savings_pct']:.1f}% Einsparung)\")\n",
    "    \n",
    "    # Durchschnittliche Einsparungen\n",
    "    report.append(\"\\n\\nDURCHSCHNITTLICHE EINSPARUNGEN ÜBER ALLE KLASSIFIKATOREN:\")\n",
    "    report.append(\"-\"*60)\n",
    "    \n",
    "    avg_savings = data_95.groupby('strategy')['relative_savings_pct'].mean()\n",
    "    for strategy, savings in avg_savings.items():\n",
    "        if strategy != 'Random Sampling':\n",
    "            report.append(f\"{strategy}: {savings:.1f}% weniger Labels als Random Sampling\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Ausgabe und Speichern\n",
    "    report_text = \"\\n\".join(report)\n",
    "    print(report_text)\n",
    "    \n",
    "    filename = f'reports/{dataset_name.lower()}_label_savings_report.txt'\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    print(f\"\\n[ok] Label-Einsparungs-Bericht gespeichert: {filename}\")\n",
    "    \n",
    "    return report_text\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Hauptprogramm\n",
    "# -------------------------------------------------------------------------------\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Haupteinstiegspunkt für das erweiterte Active Learning Experiment.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ACTIVE LEARNING AUF MNIST - ROBUSTE VERSION MIT STATISTISCHER ANALYSE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # System Info\n",
    "    print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"NumPy Version: {np.__version__}\")\n",
    "    print(f\"Pandas Version: {pd.__version__}\")\n",
    "    print(f\"Scikit-learn Version: {sklearn.__version__}\")\n",
    "    print(f\"SciPy Version: {scipy.__version__}\")\n",
    "    \n",
    "    # Device Info\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"Verwende GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    else:\n",
    "        print(\"Verwende CPU (keine GPU gefunden)\")\n",
    "    \n",
    "    print(f\"\\nExperiment-Konfiguration:\")\n",
    "    print(f\"- Anzahl Runs: {N_RUNS}\")\n",
    "    print(f\"- Budget-Stufen: {[f'{int(b*100)}%' for b in BUDGET_PERCENTAGES]}\")\n",
    "    print(f\"- Batch-Größe: {BATCH_SIZE}\")\n",
    "    print(f\"- Signifikanzniveau: {SIGNIFICANCE_LEVEL}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Daten laden\n",
    "    try:\n",
    "        X_train_cnn, X_train_flat, y_train, X_test_cnn, X_test_flat, y_test = load_mnist_data()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Kritischer Fehler beim Laden der Daten: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    # Klassifikatoren und Strategien definieren\n",
    "    classifiers = ['CNN', 'Naive Bayes', 'Random Forest']\n",
    "    strategies = [\n",
    "        ('Random Sampling', random_sampling),\n",
    "        ('Entropy Sampling', entropy_sampling),\n",
    "        ('Margin Sampling', margin_sampling),\n",
    "        ('Least Confidence', least_confidence_sampling)\n",
    "    ]\n",
    "    \n",
    "    # Experimente durchführen\n",
    "    all_results = []\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    total_experiments = len(classifiers) * len(strategies)\n",
    "    current_experiment = 0\n",
    "    \n",
    "    for classifier_name in classifiers:\n",
    "        for strategy_name, strategy_func in strategies:\n",
    "            current_experiment += 1\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Experiment {current_experiment}/{total_experiments}: {classifier_name} + {strategy_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            experiment_start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                results = run_active_learning_experiment(\n",
    "                    X_train_cnn, X_train_flat, y_train,\n",
    "                    X_test_cnn, X_test_flat, y_test,\n",
    "                    classifier_name, strategy_name, strategy_func,\n",
    "                    BUDGET_PERCENTAGES, BATCH_SIZE\n",
    "                )\n",
    "                all_results.extend(results)\n",
    "                \n",
    "                experiment_time = time.time() - experiment_start_time\n",
    "                print(f\"\\n[ok] {classifier_name} + {strategy_name} abgeschlossen in {experiment_time/60:.1f} Minuten\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Kritischer Fehler bei {classifier_name} + {strategy_name}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    # Gesamtzeit\n",
    "    total_time = time.time() - total_start_time\n",
    "    print(f\"\\n[ok] Alle Experimente abgeschlossen in {total_time/60:.1f} Minuten\")\n",
    "    \n",
    "    # Überprüfe ob Ergebnisse vorhanden sind\n",
    "    if not all_results:\n",
    "        logger.error(\"Keine Experimenteergebnisse vorhanden!\")\n",
    "        return 1\n",
    "    \n",
    "    # Ergebnisse in DataFrame konvertieren für statistische Analyse\n",
    "    try:\n",
    "        results_df = pd.DataFrame([{\n",
    "            'classifier': r['classifier'],\n",
    "            'strategy': r['strategy'],\n",
    "            'budget_pct': r['budget_pct'],\n",
    "            'run': r['run'],\n",
    "            'n_labeled': r['n_labeled'],\n",
    "            'accuracy': r['accuracy'],\n",
    "            'f1_score': r['f1_score'],\n",
    "            'avg_query_time': r.get('avg_query_time', 0),\n",
    "            'avg_train_time': r.get('avg_train_time', 0)\n",
    "        } for r in all_results])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Erstellen des Results DataFrame: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    # Statistische Analyse durchführen\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Führe statistische Analyse durch...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        stat_results = perform_statistical_analysis(results_df)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der statistischen Analyse: {e}\")\n",
    "        stat_results = pd.DataFrame()\n",
    "    \n",
    "    # Statistischen Bericht erstellen\n",
    "    try:\n",
    "        statistical_report = create_statistical_report(stat_results)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Erstellen des statistischen Berichts: {e}\")\n",
    "    \n",
    "    # Label-Einsparungs-Analyse (NEU)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Berechne Label-Einsparungen...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Berechne Label-Einsparungen für verschiedene Performance-Level\n",
    "        savings_df = calculate_label_savings(all_results, target_performance_percentages=[0.90, 0.95, 0.98])\n",
    "        \n",
    "        # Visualisiere Label-Einsparungen\n",
    "        plot_label_savings(savings_df, dataset_name=\"MNIST\")\n",
    "        \n",
    "        # Erstelle detaillierten Bericht\n",
    "        label_savings_report = create_label_savings_report(savings_df, dataset_name=\"MNIST\")\n",
    "        \n",
    "        # Speichere als CSV\n",
    "        savings_csv = 'results/mnist_label_savings.csv'\n",
    "        savings_df.to_csv(savings_csv, index=False)\n",
    "        print(f\"[ok] Label-Einsparungen gespeichert: {savings_csv}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der Label-Einsparungs-Analyse: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # Ergebnisse visualisieren\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Erstelle Visualisierungen...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Pro Klassifikator mit Signifikanz\n",
    "        plot_per_classifier_with_significance(all_results, stat_results)\n",
    "        \n",
    "        # Statistische Zusammenfassung\n",
    "        plot_statistical_summary(stat_results)\n",
    "        \n",
    "        # Finale Vergleichsmatrix\n",
    "        plot_final_comparison(all_results)\n",
    "        \n",
    "        # Improvement Analyse\n",
    "        plot_improvement_analysis(all_results)\n",
    "        \n",
    "        print(\"[ok] Alle Visualisierungen erstellt\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der Visualisierung: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # Ergebnisse speichern\n",
    "    try:\n",
    "        # Detaillierte Ergebnisse\n",
    "        csv_filename = 'results/mnist_active_learning_results.csv'\n",
    "        results_df.to_csv(csv_filename, index=False)\n",
    "        print(f\"\\n[ok] Ergebnisse gespeichert in: {csv_filename}\")\n",
    "        \n",
    "        # Statistische Ergebnisse\n",
    "        if not stat_results.empty:\n",
    "            stat_csv_filename = 'results/mnist_statistical_analysis.csv'\n",
    "            stat_results.to_csv(stat_csv_filename, index=False)\n",
    "            print(f\"[ok] Statistische Analyse gespeichert in: {stat_csv_filename}\")\n",
    "        \n",
    "        # Zusammenfassung als Excel (wenn verfügbar)\n",
    "        if EXCEL_AVAILABLE:\n",
    "            excel_filename = 'results/mnist_active_learning_summary.xlsx'\n",
    "            try:\n",
    "                with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "                    # Raw results\n",
    "                    results_df.to_excel(writer, sheet_name='Raw Results', index=False)\n",
    "                    \n",
    "                    # Statistical analysis\n",
    "                    if not stat_results.empty:\n",
    "                        stat_results.to_excel(writer, sheet_name='Statistical Analysis', index=False)\n",
    "                    \n",
    "                    # Summary by classifier and strategy\n",
    "                    summary = results_df.groupby(['classifier', 'strategy', 'budget_pct'])[['accuracy', 'f1_score']].agg(['mean', 'std'])\n",
    "                    summary.to_excel(writer, sheet_name='Summary Statistics')\n",
    "                    \n",
    "                    # Best combinations at 100% budget\n",
    "                    final_results = results_df[results_df['budget_pct'] == 1.0]\n",
    "                    if not final_results.empty:\n",
    "                        best_combinations = final_results.groupby(['classifier', 'strategy'])[['accuracy', 'f1_score']].mean()\n",
    "                        best_combinations = best_combinations.sort_values('accuracy', ascending=False)\n",
    "                        best_combinations.to_excel(writer, sheet_name='Best Combinations')\n",
    "                    \n",
    "                    # Significant improvements\n",
    "                    if not stat_results.empty and 'significant' in stat_results.columns:\n",
    "                        sig_improvements = stat_results[stat_results['significant']].sort_values('cliffs_delta', ascending=False)\n",
    "                        if not sig_improvements.empty:\n",
    "                            sig_improvements.to_excel(writer, sheet_name='Significant Improvements', index=False)\n",
    "                    \n",
    "                    # Label savings (NEU)\n",
    "                    if 'savings_df' in locals() and not savings_df.empty:\n",
    "                        savings_df.to_excel(writer, sheet_name='Label Savings', index=False)\n",
    "                \n",
    "                print(f\"[ok] Zusammenfassung gespeichert in: {excel_filename}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Fehler beim Excel-Export: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Speichern der Ergebnisse: {e}\")\n",
    "    \n",
    "    # Abschlusszusammenfassung\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPERIMENT ERFOLGREICH ABGESCHLOSSEN\")\n",
    "    print(f\"Gesamtanzahl Experimente: {len(all_results)}\")\n",
    "    print(f\"Datensatzgröße: {len(y_train):,} Trainingsbilder\")\n",
    "    print(f\"Klassifikatoren: {len(classifiers)}\")\n",
    "    print(f\"Query-Strategien: {len(strategies)}\")\n",
    "    print(f\"Budget-Stufen: {len(BUDGET_PERCENTAGES)}\")\n",
    "    print(f\"Wiederholungen pro Experiment: {N_RUNS}\")\n",
    "    \n",
    "    # Statistische Zusammenfassung\n",
    "    if not stat_results.empty:\n",
    "        total_comparisons = len(stat_results)\n",
    "        significant_count = stat_results['significant'].sum() if 'significant' in stat_results.columns else 0\n",
    "        print(f\"\\nStatistische Analyse:\")\n",
    "        print(f\"- Anzahl Vergleiche: {total_comparisons}\")\n",
    "        print(f\"- Signifikante Ergebnisse: {significant_count} ({significant_count/total_comparisons*100:.1f}%)\")\n",
    "        print(f\"- Verwendeter Test: Wilcoxon Signed-Rank Test\")\n",
    "        print(f\"- Effektstärkemaß: Cliff's Delta\")\n",
    "        print(f\"- Multiple Vergleiche: Bonferroni-Korrektur\")\n",
    "    \n",
    "    print(\"\\nNEU: Label-Einsparungs-Analyse durchgeführt!\")\n",
    "    print(\"- Visualisierung: plots/mnist_label_savings_analysis.png\")\n",
    "    print(\"- Bericht: reports/mnist_label_savings_report.txt\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        exit_code = main()\n",
    "        sys.exit(exit_code)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unerwarteter Fehler im Hauptprogramm: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
