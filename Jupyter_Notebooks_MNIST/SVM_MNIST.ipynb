{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbde1127-17d8-47ab-89b5-9ba17d135e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAPIDS cuML verfügbar - primäre GPU-Beschleunigung aktiviert\n",
      "⚠ ThunderSVM benötigt ältere CUDA-Version (9.x/10.x). Aktuelle CUDA-Version inkompatibel.\n",
      "  Tipp: Verwenden Sie RAPIDS cuML stattdessen für moderne GPUs.\n",
      "================================================================================\n",
      "GPU-OPTIMIERTES ACTIVE LEARNING FÜR SVM - BACHELORARBEIT\n",
      "================================================================================\n",
      "Python Version: 3.13.5\n",
      "PyTorch Version: 2.7.1+cu126\n",
      "NumPy Version: 2.2.6\n",
      "Scikit-learn Version: 1.7.1\n",
      "\n",
      "GPU Setup:\n",
      "✓ CUDA verfügbar: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "  VRAM: 7.6 GB\n",
      "\n",
      "GPU Memory Setup:\n",
      "✓ Verwende Standard GPU Memory Management (RMM Pool deaktiviert)\n",
      "  GPU: NVIDIA GeForce RTX 4060 Laptop GPU, 8188 MiB\n",
      "\n",
      "Hinweis: RMM Memory Pool ist deaktiviert (USE_MEMORY_POOL = False)\n",
      "Falls Sie Speicherprobleme haben, können Sie den Pool aktivieren:\n",
      "  Setzen Sie USE_MEMORY_POOL = True in der Konfiguration\n",
      "\n",
      "Für GPU Monitoring installieren Sie:\n",
      "  pip install nvidia-ml-py gpustat\n",
      "  Dann verwenden Sie: gpustat -i 1\n",
      "\n",
      "Experiment-Konfiguration:\n",
      "- Anzahl Runs: 5\n",
      "- Budget-Stufen: ['20%', '40%', '60%', '80%', '100%']\n",
      "- Batch-Größe: 500\n",
      "- GPU Backends: cuML=True, ThunderSVM=False\n",
      "================================================================================\n",
      "13:20:52 [INFO] Lade MNIST-Datensatz...\n",
      "13:20:55 [INFO] ✓ Datensatz geladen: 60,000 Trainingsbilder, 10,000 Testbilder\n",
      "13:20:55 [INFO]   Feature-Dimensionen: 784\n",
      "13:20:55 [INFO]   Klassen: 10\n",
      "13:20:55 [INFO]   Speicherbedarf: 209.4 MB\n",
      "\n",
      "============================================================\n",
      "Strategie: Random Sampling\n",
      "============================================================\n",
      "13:20:55 [INFO] \n",
      "GPU-SVM + Random Sampling - Budget: 20% (12,000 Samples)\n",
      "13:20:55 [INFO]   Run 1/5\n",
      "13:20:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 0.1/8.0 GB)\n",
      "13:21:00 [INFO]   Training abgeschlossen in 4.47s (Backend: cuml)\n",
      "13:21:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:21:07 [INFO]   Training abgeschlossen in 4.62s (Backend: cuml)\n",
      "13:21:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:21:14 [INFO]   Training abgeschlossen in 4.64s (Backend: cuml)\n",
      "13:21:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:21:22 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "13:21:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:21:29 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "13:21:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:21:37 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "13:21:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:21:45 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "13:21:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:21:53 [INFO]   Training abgeschlossen in 5.01s (Backend: cuml)\n",
      "13:21:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:22:01 [INFO]   Training abgeschlossen in 5.45s (Backend: cuml)\n",
      "13:22:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:22:10 [INFO]   Training abgeschlossen in 5.56s (Backend: cuml)\n",
      "13:22:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:22:18 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "13:22:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:22:27 [INFO]   Training abgeschlossen in 6.12s (Backend: cuml)\n",
      "13:22:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:22:37 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "13:22:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:22:46 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "13:22:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:22:56 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "13:22:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:23:05 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "13:23:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:23:15 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "13:23:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:23:24 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "13:23:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:23:34 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "13:23:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:23:44 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "13:23:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:23:54 [INFO]   Training abgeschlossen in 6.74s (Backend: cuml)\n",
      "13:23:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:24:04 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "13:24:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:24:14 [INFO]   Training abgeschlossen in 6.97s (Backend: cuml)\n",
      "13:24:17 [INFO]     12,000 labeled → Accuracy: 0.9398 (Train: 7.0s, Query: 0.02s) | GPU: 2.2/8.0 GB\n",
      "13:24:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:24:24 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "13:24:27 [INFO]     Final: 12,000 labeled → Accuracy: 0.9400, F1: 0.9394\n",
      "13:24:27 [INFO]   Run 2/5\n",
      "13:24:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:24:32 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "13:24:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:24:39 [INFO]   Training abgeschlossen in 4.55s (Backend: cuml)\n",
      "13:24:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:24:47 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "13:24:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:24:54 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "13:24:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:25:02 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "13:25:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:25:09 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "13:25:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:25:17 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "13:25:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:25:25 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "13:25:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:25:33 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "13:25:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:25:42 [INFO]   Training abgeschlossen in 5.59s (Backend: cuml)\n",
      "13:25:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:25:51 [INFO]   Training abgeschlossen in 5.91s (Backend: cuml)\n",
      "13:25:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:26:00 [INFO]   Training abgeschlossen in 5.96s (Backend: cuml)\n",
      "13:26:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:26:09 [INFO]   Training abgeschlossen in 6.05s (Backend: cuml)\n",
      "13:26:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:26:18 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "13:26:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:26:28 [INFO]   Training abgeschlossen in 6.56s (Backend: cuml)\n",
      "13:26:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:26:37 [INFO]   Training abgeschlossen in 6.21s (Backend: cuml)\n",
      "13:26:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:26:47 [INFO]   Training abgeschlossen in 6.40s (Backend: cuml)\n",
      "13:26:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:26:57 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "13:27:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:27:06 [INFO]   Training abgeschlossen in 6.43s (Backend: cuml)\n",
      "13:27:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:27:16 [INFO]   Training abgeschlossen in 6.62s (Backend: cuml)\n",
      "13:27:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:27:26 [INFO]   Training abgeschlossen in 6.60s (Backend: cuml)\n",
      "13:27:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:27:36 [INFO]   Training abgeschlossen in 6.94s (Backend: cuml)\n",
      "13:27:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:27:46 [INFO]   Training abgeschlossen in 6.82s (Backend: cuml)\n",
      "13:27:49 [INFO]     12,000 labeled → Accuracy: 0.9441 (Train: 6.8s, Query: 0.02s) | GPU: 2.2/8.0 GB\n",
      "13:27:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:27:56 [INFO]   Training abgeschlossen in 7.05s (Backend: cuml)\n",
      "13:28:00 [INFO]     Final: 12,000 labeled → Accuracy: 0.9447, F1: 0.9442\n",
      "13:28:00 [INFO]   Run 3/5\n",
      "13:28:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:28:04 [INFO]   Training abgeschlossen in 4.53s (Backend: cuml)\n",
      "13:28:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:28:12 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "13:28:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:28:19 [INFO]   Training abgeschlossen in 4.67s (Backend: cuml)\n",
      "13:28:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:28:26 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "13:28:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:28:34 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "13:28:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:28:42 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "13:28:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:28:49 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "13:28:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:28:58 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "13:29:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:29:06 [INFO]   Training abgeschlossen in 5.35s (Backend: cuml)\n",
      "13:29:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:29:15 [INFO]   Training abgeschlossen in 5.79s (Backend: cuml)\n",
      "13:29:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:29:23 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "13:29:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:29:32 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "13:29:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:29:41 [INFO]   Training abgeschlossen in 6.07s (Backend: cuml)\n",
      "13:29:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:29:51 [INFO]   Training abgeschlossen in 6.20s (Backend: cuml)\n",
      "13:29:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:30:00 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "13:30:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:30:10 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "13:30:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:30:19 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "13:30:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:30:29 [INFO]   Training abgeschlossen in 6.39s (Backend: cuml)\n",
      "13:30:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:30:38 [INFO]   Training abgeschlossen in 6.47s (Backend: cuml)\n",
      "13:30:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:30:48 [INFO]   Training abgeschlossen in 6.49s (Backend: cuml)\n",
      "13:30:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:30:58 [INFO]   Training abgeschlossen in 6.85s (Backend: cuml)\n",
      "13:31:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:31:08 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "13:31:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:31:18 [INFO]   Training abgeschlossen in 6.73s (Backend: cuml)\n",
      "13:31:21 [INFO]     12,000 labeled → Accuracy: 0.9440 (Train: 6.7s, Query: 0.02s) | GPU: 2.2/8.0 GB\n",
      "13:31:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:31:28 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "13:31:31 [INFO]     Final: 12,000 labeled → Accuracy: 0.9445, F1: 0.9440\n",
      "13:31:31 [INFO]   Run 4/5\n",
      "13:31:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:31:36 [INFO]   Training abgeschlossen in 4.55s (Backend: cuml)\n",
      "13:31:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:31:43 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "13:31:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:31:51 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "13:31:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:31:58 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "13:32:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:32:06 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "13:32:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:32:14 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "13:32:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:32:21 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "13:32:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:32:29 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "13:32:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:32:38 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "13:32:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:32:46 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "13:32:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:32:55 [INFO]   Training abgeschlossen in 5.84s (Backend: cuml)\n",
      "13:32:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:33:04 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "13:33:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:33:14 [INFO]   Training abgeschlossen in 6.43s (Backend: cuml)\n",
      "13:33:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:33:23 [INFO]   Training abgeschlossen in 6.16s (Backend: cuml)\n",
      "13:33:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:33:33 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "13:33:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:33:42 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "13:33:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:33:52 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "13:33:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:34:01 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "13:34:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:34:11 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "13:34:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:34:21 [INFO]   Training abgeschlossen in 6.54s (Backend: cuml)\n",
      "13:34:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:34:30 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "13:34:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:34:40 [INFO]   Training abgeschlossen in 6.62s (Backend: cuml)\n",
      "13:34:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:34:50 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "13:34:53 [INFO]     12,000 labeled → Accuracy: 0.9453 (Train: 6.7s, Query: 0.02s) | GPU: 2.2/8.0 GB\n",
      "13:34:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:35:00 [INFO]   Training abgeschlossen in 6.82s (Backend: cuml)\n",
      "13:35:03 [INFO]     Final: 12,000 labeled → Accuracy: 0.9464, F1: 0.9460\n",
      "13:35:04 [INFO]   Run 5/5\n",
      "13:35:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:35:08 [INFO]   Training abgeschlossen in 4.56s (Backend: cuml)\n",
      "13:35:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:35:16 [INFO]   Training abgeschlossen in 4.63s (Backend: cuml)\n",
      "13:35:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:35:23 [INFO]   Training abgeschlossen in 4.64s (Backend: cuml)\n",
      "13:35:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:35:31 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "13:35:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:35:38 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "13:35:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:35:46 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "13:35:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:35:54 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "13:35:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:36:02 [INFO]   Training abgeschlossen in 5.08s (Backend: cuml)\n",
      "13:36:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:36:10 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "13:36:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:36:19 [INFO]   Training abgeschlossen in 5.91s (Backend: cuml)\n",
      "13:36:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:36:28 [INFO]   Training abgeschlossen in 5.70s (Backend: cuml)\n",
      "13:36:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:36:36 [INFO]   Training abgeschlossen in 5.84s (Backend: cuml)\n",
      "13:36:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:36:46 [INFO]   Training abgeschlossen in 6.02s (Backend: cuml)\n",
      "13:36:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:36:55 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "13:36:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:37:04 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "13:37:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:37:14 [INFO]   Training abgeschlossen in 6.48s (Backend: cuml)\n",
      "13:37:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:37:24 [INFO]   Training abgeschlossen in 6.47s (Backend: cuml)\n",
      "13:37:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:37:33 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "13:37:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:37:43 [INFO]   Training abgeschlossen in 6.47s (Backend: cuml)\n",
      "13:37:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:37:53 [INFO]   Training abgeschlossen in 6.54s (Backend: cuml)\n",
      "13:37:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:38:03 [INFO]   Training abgeschlossen in 6.77s (Backend: cuml)\n",
      "13:38:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:38:13 [INFO]   Training abgeschlossen in 6.78s (Backend: cuml)\n",
      "13:38:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:38:23 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "13:38:26 [INFO]     12,000 labeled → Accuracy: 0.9435 (Train: 6.8s, Query: 0.02s) | GPU: 2.2/8.0 GB\n",
      "13:38:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:38:33 [INFO]   Training abgeschlossen in 6.72s (Backend: cuml)\n",
      "13:38:36 [INFO]     Final: 12,000 labeled → Accuracy: 0.9443, F1: 0.9439\n",
      "13:38:36 [INFO] \n",
      "GPU-SVM + Random Sampling - Budget: 40% (24,000 Samples)\n",
      "13:38:36 [INFO]   Run 1/5\n",
      "13:38:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:38:41 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "13:38:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:38:48 [INFO]   Training abgeschlossen in 4.63s (Backend: cuml)\n",
      "13:38:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:38:55 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "13:38:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:39:03 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "13:39:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:39:11 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "13:39:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:39:18 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "13:39:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:39:26 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "13:39:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:39:34 [INFO]   Training abgeschlossen in 5.05s (Backend: cuml)\n",
      "13:39:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:39:43 [INFO]   Training abgeschlossen in 5.37s (Backend: cuml)\n",
      "13:39:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:39:51 [INFO]   Training abgeschlossen in 5.75s (Backend: cuml)\n",
      "13:39:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:40:00 [INFO]   Training abgeschlossen in 5.71s (Backend: cuml)\n",
      "13:40:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:40:09 [INFO]   Training abgeschlossen in 6.06s (Backend: cuml)\n",
      "13:40:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:40:18 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "13:40:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:40:28 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "13:40:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:40:38 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "13:40:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:40:47 [INFO]   Training abgeschlossen in 6.28s (Backend: cuml)\n",
      "13:40:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:40:56 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "13:41:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:41:06 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "13:41:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:41:16 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "13:41:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:41:26 [INFO]   Training abgeschlossen in 6.76s (Backend: cuml)\n",
      "13:41:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:41:36 [INFO]   Training abgeschlossen in 6.78s (Backend: cuml)\n",
      "13:41:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:41:46 [INFO]   Training abgeschlossen in 6.67s (Backend: cuml)\n",
      "13:41:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:41:56 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "13:41:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:42:06 [INFO]   Training abgeschlossen in 6.81s (Backend: cuml)\n",
      "13:42:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:42:16 [INFO]   Training abgeschlossen in 7.06s (Backend: cuml)\n",
      "13:42:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:42:27 [INFO]   Training abgeschlossen in 7.16s (Backend: cuml)\n",
      "13:42:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:42:37 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "13:42:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:42:48 [INFO]   Training abgeschlossen in 7.21s (Backend: cuml)\n",
      "13:42:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:42:58 [INFO]   Training abgeschlossen in 7.30s (Backend: cuml)\n",
      "13:43:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:43:09 [INFO]   Training abgeschlossen in 7.39s (Backend: cuml)\n",
      "13:43:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:43:20 [INFO]   Training abgeschlossen in 7.56s (Backend: cuml)\n",
      "13:43:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:43:31 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "13:43:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:43:42 [INFO]   Training abgeschlossen in 7.64s (Backend: cuml)\n",
      "13:43:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:43:53 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "13:43:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:44:05 [INFO]   Training abgeschlossen in 7.83s (Backend: cuml)\n",
      "13:44:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:44:16 [INFO]   Training abgeschlossen in 7.89s (Backend: cuml)\n",
      "13:44:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:44:28 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "13:44:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:44:39 [INFO]   Training abgeschlossen in 8.15s (Backend: cuml)\n",
      "13:44:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:44:51 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "13:44:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:45:03 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "13:45:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:45:15 [INFO]   Training abgeschlossen in 8.43s (Backend: cuml)\n",
      "13:45:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:45:27 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "13:45:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:45:39 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "13:45:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:45:51 [INFO]   Training abgeschlossen in 8.44s (Backend: cuml)\n",
      "13:45:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:46:03 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "13:46:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:46:16 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "13:46:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:46:28 [INFO]   Training abgeschlossen in 8.83s (Backend: cuml)\n",
      "13:46:32 [INFO]     24,000 labeled → Accuracy: 0.9541 (Train: 8.8s, Query: 0.01s) | GPU: 2.4/8.0 GB\n",
      "13:46:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:46:41 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "13:46:44 [INFO]     Final: 24,000 labeled → Accuracy: 0.9543, F1: 0.9539\n",
      "13:46:44 [INFO]   Run 2/5\n",
      "13:46:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:46:49 [INFO]   Training abgeschlossen in 4.65s (Backend: cuml)\n",
      "13:46:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:46:56 [INFO]   Training abgeschlossen in 4.61s (Backend: cuml)\n",
      "13:46:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:47:04 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "13:47:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:47:11 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "13:47:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:47:19 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "13:47:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:47:27 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "13:47:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:47:35 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "13:47:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:47:42 [INFO]   Training abgeschlossen in 5.03s (Backend: cuml)\n",
      "13:47:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:47:51 [INFO]   Training abgeschlossen in 5.40s (Backend: cuml)\n",
      "13:47:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:47:59 [INFO]   Training abgeschlossen in 5.75s (Backend: cuml)\n",
      "13:48:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:48:08 [INFO]   Training abgeschlossen in 5.72s (Backend: cuml)\n",
      "13:48:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:48:17 [INFO]   Training abgeschlossen in 5.78s (Backend: cuml)\n",
      "13:48:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:48:26 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "13:48:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:48:36 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "13:48:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:48:45 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "13:48:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:48:55 [INFO]   Training abgeschlossen in 6.60s (Backend: cuml)\n",
      "13:48:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:49:04 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "13:49:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:49:14 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "13:49:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:49:24 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "13:49:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:49:34 [INFO]   Training abgeschlossen in 6.86s (Backend: cuml)\n",
      "13:49:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:49:43 [INFO]   Training abgeschlossen in 6.62s (Backend: cuml)\n",
      "13:49:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:49:54 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "13:49:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:50:04 [INFO]   Training abgeschlossen in 6.78s (Backend: cuml)\n",
      "13:50:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:50:14 [INFO]   Training abgeschlossen in 6.76s (Backend: cuml)\n",
      "13:50:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:50:24 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "13:50:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:50:34 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "13:50:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:50:45 [INFO]   Training abgeschlossen in 7.26s (Backend: cuml)\n",
      "13:50:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:50:56 [INFO]   Training abgeschlossen in 7.31s (Backend: cuml)\n",
      "13:50:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:51:06 [INFO]   Training abgeschlossen in 7.35s (Backend: cuml)\n",
      "13:51:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:51:17 [INFO]   Training abgeschlossen in 7.40s (Backend: cuml)\n",
      "13:51:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:51:28 [INFO]   Training abgeschlossen in 7.60s (Backend: cuml)\n",
      "13:51:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:51:39 [INFO]   Training abgeschlossen in 7.74s (Backend: cuml)\n",
      "13:51:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:51:50 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "13:51:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:52:02 [INFO]   Training abgeschlossen in 7.82s (Backend: cuml)\n",
      "13:52:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:52:13 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "13:52:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:52:24 [INFO]   Training abgeschlossen in 7.94s (Backend: cuml)\n",
      "13:52:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:52:36 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "13:52:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:52:48 [INFO]   Training abgeschlossen in 8.22s (Backend: cuml)\n",
      "13:52:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:53:00 [INFO]   Training abgeschlossen in 8.29s (Backend: cuml)\n",
      "13:53:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:53:12 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "13:53:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:53:24 [INFO]   Training abgeschlossen in 8.45s (Backend: cuml)\n",
      "13:53:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:53:36 [INFO]   Training abgeschlossen in 8.83s (Backend: cuml)\n",
      "13:53:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:53:48 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "13:53:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:54:00 [INFO]   Training abgeschlossen in 8.48s (Backend: cuml)\n",
      "13:54:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:54:12 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "13:54:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:54:25 [INFO]   Training abgeschlossen in 8.67s (Backend: cuml)\n",
      "13:54:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:54:37 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "13:54:41 [INFO]     24,000 labeled → Accuracy: 0.9536 (Train: 8.8s, Query: 0.01s) | GPU: 2.4/8.0 GB\n",
      "13:54:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:54:50 [INFO]   Training abgeschlossen in 8.85s (Backend: cuml)\n",
      "13:54:53 [INFO]     Final: 24,000 labeled → Accuracy: 0.9538, F1: 0.9534\n",
      "13:54:54 [INFO]   Run 3/5\n",
      "13:54:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:54:58 [INFO]   Training abgeschlossen in 4.56s (Backend: cuml)\n",
      "13:55:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:55:05 [INFO]   Training abgeschlossen in 4.52s (Backend: cuml)\n",
      "13:55:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:55:13 [INFO]   Training abgeschlossen in 4.67s (Backend: cuml)\n",
      "13:55:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:55:20 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "13:55:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:55:28 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "13:55:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:55:36 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "13:55:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:55:44 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "13:55:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:55:52 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "13:55:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:56:00 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "13:56:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:56:09 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "13:56:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:56:17 [INFO]   Training abgeschlossen in 5.88s (Backend: cuml)\n",
      "13:56:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:56:26 [INFO]   Training abgeschlossen in 5.88s (Backend: cuml)\n",
      "13:56:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:56:36 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "13:56:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:56:45 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "13:56:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:56:55 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "13:56:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:57:04 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "13:57:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:57:13 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "13:57:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:57:23 [INFO]   Training abgeschlossen in 6.43s (Backend: cuml)\n",
      "13:57:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:57:33 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "13:57:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:57:43 [INFO]   Training abgeschlossen in 6.67s (Backend: cuml)\n",
      "13:57:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:57:53 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "13:57:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:58:03 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "13:58:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:58:13 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "13:58:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:58:23 [INFO]   Training abgeschlossen in 6.82s (Backend: cuml)\n",
      "13:58:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:58:33 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "13:58:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:58:44 [INFO]   Training abgeschlossen in 7.15s (Backend: cuml)\n",
      "13:58:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:58:55 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "13:58:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:59:05 [INFO]   Training abgeschlossen in 7.34s (Backend: cuml)\n",
      "13:59:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:59:16 [INFO]   Training abgeschlossen in 7.37s (Backend: cuml)\n",
      "13:59:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:59:27 [INFO]   Training abgeschlossen in 7.48s (Backend: cuml)\n",
      "13:59:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:59:38 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "13:59:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:59:49 [INFO]   Training abgeschlossen in 7.61s (Backend: cuml)\n",
      "13:59:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:00:00 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "14:00:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:00:11 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "14:00:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:00:23 [INFO]   Training abgeschlossen in 7.86s (Backend: cuml)\n",
      "14:00:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:00:34 [INFO]   Training abgeschlossen in 8.11s (Backend: cuml)\n",
      "14:00:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:00:46 [INFO]   Training abgeschlossen in 8.08s (Backend: cuml)\n",
      "14:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:00:57 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "14:01:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:01:09 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "14:01:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:01:21 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "14:01:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:01:33 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "14:01:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:01:46 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "14:01:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:01:58 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "14:02:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:02:10 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "14:02:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:02:22 [INFO]   Training abgeschlossen in 8.48s (Backend: cuml)\n",
      "14:02:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:02:34 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "14:02:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:02:46 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "14:02:50 [INFO]     24,000 labeled → Accuracy: 0.9525 (Train: 8.8s, Query: 0.01s) | GPU: 2.4/8.0 GB\n",
      "14:02:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:02:59 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "14:03:02 [INFO]     Final: 24,000 labeled → Accuracy: 0.9539, F1: 0.9535\n",
      "14:03:03 [INFO]   Run 4/5\n",
      "14:03:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:03:07 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "14:03:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:03:15 [INFO]   Training abgeschlossen in 4.62s (Backend: cuml)\n",
      "14:03:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:03:22 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "14:03:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:03:30 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "14:03:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:03:37 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "14:03:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:03:45 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "14:03:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:03:53 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "14:03:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:04:01 [INFO]   Training abgeschlossen in 5.14s (Backend: cuml)\n",
      "14:04:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:04:09 [INFO]   Training abgeschlossen in 5.39s (Backend: cuml)\n",
      "14:04:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:04:18 [INFO]   Training abgeschlossen in 5.73s (Backend: cuml)\n",
      "14:04:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:04:26 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "14:04:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:04:35 [INFO]   Training abgeschlossen in 5.83s (Backend: cuml)\n",
      "14:04:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:04:45 [INFO]   Training abgeschlossen in 6.63s (Backend: cuml)\n",
      "14:04:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:04:54 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "14:04:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:05:04 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "14:05:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:05:13 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "14:05:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:05:23 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "14:05:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:05:32 [INFO]   Training abgeschlossen in 6.59s (Backend: cuml)\n",
      "14:05:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:05:42 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "14:05:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:05:52 [INFO]   Training abgeschlossen in 6.62s (Backend: cuml)\n",
      "14:05:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:06:02 [INFO]   Training abgeschlossen in 6.76s (Backend: cuml)\n",
      "14:06:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:06:12 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "14:06:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:06:22 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "14:06:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:06:32 [INFO]   Training abgeschlossen in 6.85s (Backend: cuml)\n",
      "14:06:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:06:42 [INFO]   Training abgeschlossen in 7.04s (Backend: cuml)\n",
      "14:06:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:06:53 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "14:06:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:07:03 [INFO]   Training abgeschlossen in 7.17s (Backend: cuml)\n",
      "14:07:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:07:14 [INFO]   Training abgeschlossen in 7.27s (Backend: cuml)\n",
      "14:07:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:07:25 [INFO]   Training abgeschlossen in 7.34s (Backend: cuml)\n",
      "14:07:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:07:35 [INFO]   Training abgeschlossen in 7.47s (Backend: cuml)\n",
      "14:07:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:07:47 [INFO]   Training abgeschlossen in 7.77s (Backend: cuml)\n",
      "14:07:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:07:58 [INFO]   Training abgeschlossen in 7.64s (Backend: cuml)\n",
      "14:08:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:08:09 [INFO]   Training abgeschlossen in 7.74s (Backend: cuml)\n",
      "14:08:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:08:20 [INFO]   Training abgeschlossen in 7.90s (Backend: cuml)\n",
      "14:08:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:08:32 [INFO]   Training abgeschlossen in 7.95s (Backend: cuml)\n",
      "14:08:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:08:43 [INFO]   Training abgeschlossen in 8.11s (Backend: cuml)\n",
      "14:08:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:08:55 [INFO]   Training abgeschlossen in 8.25s (Backend: cuml)\n",
      "14:08:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:09:07 [INFO]   Training abgeschlossen in 8.25s (Backend: cuml)\n",
      "14:09:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:09:19 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "14:09:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:09:31 [INFO]   Training abgeschlossen in 8.43s (Backend: cuml)\n",
      "14:09:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:09:43 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "14:09:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:09:56 [INFO]   Training abgeschlossen in 8.68s (Backend: cuml)\n",
      "14:09:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:10:08 [INFO]   Training abgeschlossen in 8.65s (Backend: cuml)\n",
      "14:10:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:10:20 [INFO]   Training abgeschlossen in 8.53s (Backend: cuml)\n",
      "14:10:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:10:32 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "14:10:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:10:45 [INFO]   Training abgeschlossen in 8.92s (Backend: cuml)\n",
      "14:10:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:10:57 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "14:11:01 [INFO]     24,000 labeled → Accuracy: 0.9557 (Train: 8.8s, Query: 0.01s) | GPU: 2.4/8.0 GB\n",
      "14:11:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:11:10 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "14:11:13 [INFO]     Final: 24,000 labeled → Accuracy: 0.9560, F1: 0.9556\n",
      "14:11:13 [INFO]   Run 5/5\n",
      "14:11:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:11:18 [INFO]   Training abgeschlossen in 4.56s (Backend: cuml)\n",
      "14:11:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:11:25 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "14:11:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:11:33 [INFO]   Training abgeschlossen in 4.62s (Backend: cuml)\n",
      "14:11:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:11:40 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "14:11:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:11:48 [INFO]   Training abgeschlossen in 4.94s (Backend: cuml)\n",
      "14:11:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:11:56 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "14:11:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:12:04 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "14:12:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:12:12 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "14:12:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:12:20 [INFO]   Training abgeschlossen in 5.40s (Backend: cuml)\n",
      "14:12:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:12:28 [INFO]   Training abgeschlossen in 5.59s (Backend: cuml)\n",
      "14:12:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:12:37 [INFO]   Training abgeschlossen in 5.65s (Backend: cuml)\n",
      "14:12:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:12:46 [INFO]   Training abgeschlossen in 6.01s (Backend: cuml)\n",
      "14:12:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:12:55 [INFO]   Training abgeschlossen in 6.19s (Backend: cuml)\n",
      "14:12:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:13:05 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "14:13:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:13:14 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "14:13:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:13:24 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "14:13:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:13:33 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "14:13:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:13:43 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "14:13:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:13:53 [INFO]   Training abgeschlossen in 6.61s (Backend: cuml)\n",
      "14:13:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:14:03 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "14:14:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:14:13 [INFO]   Training abgeschlossen in 6.80s (Backend: cuml)\n",
      "14:14:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:14:22 [INFO]   Training abgeschlossen in 6.62s (Backend: cuml)\n",
      "14:14:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:14:32 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "14:14:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:14:42 [INFO]   Training abgeschlossen in 6.91s (Backend: cuml)\n",
      "14:14:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:14:53 [INFO]   Training abgeschlossen in 7.07s (Backend: cuml)\n",
      "14:14:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:15:03 [INFO]   Training abgeschlossen in 7.14s (Backend: cuml)\n",
      "14:15:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:15:14 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "14:15:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:15:24 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "14:15:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:15:35 [INFO]   Training abgeschlossen in 7.38s (Backend: cuml)\n",
      "14:15:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:15:46 [INFO]   Training abgeschlossen in 7.45s (Backend: cuml)\n",
      "14:15:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:15:57 [INFO]   Training abgeschlossen in 7.79s (Backend: cuml)\n",
      "14:16:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:16:08 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "14:16:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:16:19 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "14:16:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:16:30 [INFO]   Training abgeschlossen in 7.83s (Backend: cuml)\n",
      "14:16:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:16:42 [INFO]   Training abgeschlossen in 7.89s (Backend: cuml)\n",
      "14:16:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:16:53 [INFO]   Training abgeschlossen in 8.15s (Backend: cuml)\n",
      "14:16:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:17:05 [INFO]   Training abgeschlossen in 8.02s (Backend: cuml)\n",
      "14:17:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:17:17 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "14:17:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:17:28 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "14:17:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:17:40 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "14:17:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:17:53 [INFO]   Training abgeschlossen in 8.67s (Backend: cuml)\n",
      "14:17:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:18:05 [INFO]   Training abgeschlossen in 8.55s (Backend: cuml)\n",
      "14:18:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:18:17 [INFO]   Training abgeschlossen in 8.64s (Backend: cuml)\n",
      "14:18:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:18:29 [INFO]   Training abgeschlossen in 8.40s (Backend: cuml)\n",
      "14:18:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:18:41 [INFO]   Training abgeschlossen in 8.45s (Backend: cuml)\n",
      "14:18:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:18:53 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "14:18:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:19:06 [INFO]   Training abgeschlossen in 8.75s (Backend: cuml)\n",
      "14:19:09 [INFO]     24,000 labeled → Accuracy: 0.9541 (Train: 8.8s, Query: 0.01s) | GPU: 2.4/8.0 GB\n",
      "14:19:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:19:18 [INFO]   Training abgeschlossen in 8.74s (Backend: cuml)\n",
      "14:19:22 [INFO]     Final: 24,000 labeled → Accuracy: 0.9537, F1: 0.9533\n",
      "14:19:22 [INFO] \n",
      "GPU-SVM + Random Sampling - Budget: 60% (36,000 Samples)\n",
      "14:19:22 [INFO]   Run 1/5\n",
      "14:19:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:19:26 [INFO]   Training abgeschlossen in 4.51s (Backend: cuml)\n",
      "14:19:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:19:34 [INFO]   Training abgeschlossen in 4.56s (Backend: cuml)\n",
      "14:19:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:19:41 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "14:19:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:19:49 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "14:19:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:19:56 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "14:19:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:20:04 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "14:20:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:20:12 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "14:20:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:20:20 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "14:20:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:20:28 [INFO]   Training abgeschlossen in 5.38s (Backend: cuml)\n",
      "14:20:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:20:37 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "14:20:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:20:46 [INFO]   Training abgeschlossen in 5.70s (Backend: cuml)\n",
      "14:20:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:20:55 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "14:20:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:21:04 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "14:21:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:21:13 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "14:21:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:21:23 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "14:21:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:21:32 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "14:21:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:21:42 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "14:21:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:21:52 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "14:21:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:22:01 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "14:22:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:22:11 [INFO]   Training abgeschlossen in 6.54s (Backend: cuml)\n",
      "14:22:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:22:21 [INFO]   Training abgeschlossen in 6.80s (Backend: cuml)\n",
      "14:22:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:22:31 [INFO]   Training abgeschlossen in 6.63s (Backend: cuml)\n",
      "14:22:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:22:41 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "14:22:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:22:51 [INFO]   Training abgeschlossen in 6.85s (Backend: cuml)\n",
      "14:22:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:23:01 [INFO]   Training abgeschlossen in 7.02s (Backend: cuml)\n",
      "14:23:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:23:12 [INFO]   Training abgeschlossen in 7.07s (Backend: cuml)\n",
      "14:23:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:23:23 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "14:23:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:23:33 [INFO]   Training abgeschlossen in 7.26s (Backend: cuml)\n",
      "14:23:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:23:44 [INFO]   Training abgeschlossen in 7.36s (Backend: cuml)\n",
      "14:23:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:23:54 [INFO]   Training abgeschlossen in 7.41s (Backend: cuml)\n",
      "14:23:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:24:06 [INFO]   Training abgeschlossen in 7.79s (Backend: cuml)\n",
      "14:24:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:24:17 [INFO]   Training abgeschlossen in 7.61s (Backend: cuml)\n",
      "14:24:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:24:28 [INFO]   Training abgeschlossen in 7.69s (Backend: cuml)\n",
      "14:24:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:24:39 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "14:24:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:24:50 [INFO]   Training abgeschlossen in 7.86s (Backend: cuml)\n",
      "14:24:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:25:02 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "14:25:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:25:14 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "14:25:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:25:25 [INFO]   Training abgeschlossen in 8.15s (Backend: cuml)\n",
      "14:25:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:25:37 [INFO]   Training abgeschlossen in 8.22s (Backend: cuml)\n",
      "14:25:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:25:49 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "14:25:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:26:01 [INFO]   Training abgeschlossen in 8.53s (Backend: cuml)\n",
      "14:26:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:26:13 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "14:26:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:26:26 [INFO]   Training abgeschlossen in 8.65s (Backend: cuml)\n",
      "14:26:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:26:38 [INFO]   Training abgeschlossen in 8.40s (Backend: cuml)\n",
      "14:26:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:26:50 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "14:26:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:27:02 [INFO]   Training abgeschlossen in 8.62s (Backend: cuml)\n",
      "14:27:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:27:14 [INFO]   Training abgeschlossen in 8.87s (Backend: cuml)\n",
      "14:27:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:27:27 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "14:27:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:27:39 [INFO]   Training abgeschlossen in 8.90s (Backend: cuml)\n",
      "14:27:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:27:52 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "14:27:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:28:05 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "14:28:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:28:18 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "14:28:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:28:31 [INFO]   Training abgeschlossen in 9.28s (Backend: cuml)\n",
      "14:28:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:28:44 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "14:28:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:28:57 [INFO]   Training abgeschlossen in 9.54s (Backend: cuml)\n",
      "14:29:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:29:11 [INFO]   Training abgeschlossen in 9.83s (Backend: cuml)\n",
      "14:29:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:29:25 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "14:29:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:29:38 [INFO]   Training abgeschlossen in 9.77s (Backend: cuml)\n",
      "14:29:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:29:52 [INFO]   Training abgeschlossen in 9.94s (Backend: cuml)\n",
      "14:29:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:30:06 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "14:30:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:30:20 [INFO]   Training abgeschlossen in 10.23s (Backend: cuml)\n",
      "14:30:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:30:34 [INFO]   Training abgeschlossen in 10.43s (Backend: cuml)\n",
      "14:30:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:30:48 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "14:30:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:31:03 [INFO]   Training abgeschlossen in 10.72s (Backend: cuml)\n",
      "14:31:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:31:18 [INFO]   Training abgeschlossen in 10.73s (Backend: cuml)\n",
      "14:31:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:31:32 [INFO]   Training abgeschlossen in 10.75s (Backend: cuml)\n",
      "14:31:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:31:47 [INFO]   Training abgeschlossen in 10.93s (Backend: cuml)\n",
      "14:31:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:32:02 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "14:32:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:32:17 [INFO]   Training abgeschlossen in 11.24s (Backend: cuml)\n",
      "14:32:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:32:32 [INFO]   Training abgeschlossen in 11.07s (Backend: cuml)\n",
      "14:32:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:32:47 [INFO]   Training abgeschlossen in 11.20s (Backend: cuml)\n",
      "14:32:51 [INFO]     36,000 labeled → Accuracy: 0.9607 (Train: 11.2s, Query: 0.01s) | GPU: 2.6/8.0 GB\n",
      "14:32:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:33:03 [INFO]   Training abgeschlossen in 11.34s (Backend: cuml)\n",
      "14:33:06 [INFO]     Final: 36,000 labeled → Accuracy: 0.9603, F1: 0.9600\n",
      "14:33:06 [INFO]   Run 2/5\n",
      "14:33:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:33:11 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "14:33:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:33:19 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "14:33:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:33:26 [INFO]   Training abgeschlossen in 4.61s (Backend: cuml)\n",
      "14:33:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:33:33 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "14:33:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:33:41 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "14:33:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:33:49 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "14:33:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:33:57 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "14:33:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:34:05 [INFO]   Training abgeschlossen in 5.14s (Backend: cuml)\n",
      "14:34:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:34:14 [INFO]   Training abgeschlossen in 5.84s (Backend: cuml)\n",
      "14:34:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:34:22 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "14:34:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:34:31 [INFO]   Training abgeschlossen in 5.83s (Backend: cuml)\n",
      "14:34:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:34:40 [INFO]   Training abgeschlossen in 5.78s (Backend: cuml)\n",
      "14:34:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:34:49 [INFO]   Training abgeschlossen in 5.98s (Backend: cuml)\n",
      "14:34:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:34:58 [INFO]   Training abgeschlossen in 6.54s (Backend: cuml)\n",
      "14:35:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:35:08 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "14:35:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:35:18 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "14:35:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:35:27 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "14:35:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:35:37 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "14:35:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:35:46 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "14:35:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:35:56 [INFO]   Training abgeschlossen in 6.60s (Backend: cuml)\n",
      "14:35:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:36:06 [INFO]   Training abgeschlossen in 6.59s (Backend: cuml)\n",
      "14:36:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:36:16 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "14:36:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:36:26 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "14:36:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:36:36 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "14:36:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:36:46 [INFO]   Training abgeschlossen in 6.89s (Backend: cuml)\n",
      "14:36:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:36:56 [INFO]   Training abgeschlossen in 7.04s (Backend: cuml)\n",
      "14:37:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:37:07 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "14:37:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:37:18 [INFO]   Training abgeschlossen in 7.48s (Backend: cuml)\n",
      "14:37:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:37:29 [INFO]   Training abgeschlossen in 7.41s (Backend: cuml)\n",
      "14:37:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:37:39 [INFO]   Training abgeschlossen in 7.42s (Backend: cuml)\n",
      "14:37:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:37:50 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "14:37:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:38:01 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "14:38:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:38:13 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "14:38:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:38:24 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "14:38:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:38:35 [INFO]   Training abgeschlossen in 7.98s (Backend: cuml)\n",
      "14:38:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:38:47 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "14:38:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:38:59 [INFO]   Training abgeschlossen in 8.15s (Backend: cuml)\n",
      "14:39:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:39:10 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "14:39:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:39:22 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "14:39:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:39:34 [INFO]   Training abgeschlossen in 8.37s (Backend: cuml)\n",
      "14:39:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:39:46 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "14:39:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:39:58 [INFO]   Training abgeschlossen in 8.57s (Backend: cuml)\n",
      "14:40:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:40:11 [INFO]   Training abgeschlossen in 8.69s (Backend: cuml)\n",
      "14:40:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:40:23 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "14:40:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:40:35 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "14:40:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:40:47 [INFO]   Training abgeschlossen in 8.60s (Backend: cuml)\n",
      "14:40:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:41:00 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "14:41:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:41:12 [INFO]   Training abgeschlossen in 8.81s (Backend: cuml)\n",
      "14:41:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:41:25 [INFO]   Training abgeschlossen in 8.96s (Backend: cuml)\n",
      "14:41:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:41:37 [INFO]   Training abgeschlossen in 9.05s (Backend: cuml)\n",
      "14:41:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:41:50 [INFO]   Training abgeschlossen in 9.34s (Backend: cuml)\n",
      "14:41:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:42:03 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "14:42:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:42:17 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "14:42:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:42:30 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "14:42:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:42:43 [INFO]   Training abgeschlossen in 9.50s (Backend: cuml)\n",
      "14:42:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:42:56 [INFO]   Training abgeschlossen in 9.62s (Backend: cuml)\n",
      "14:43:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:43:10 [INFO]   Training abgeschlossen in 9.76s (Backend: cuml)\n",
      "14:43:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:43:24 [INFO]   Training abgeschlossen in 9.99s (Backend: cuml)\n",
      "14:43:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:43:37 [INFO]   Training abgeschlossen in 9.93s (Backend: cuml)\n",
      "14:43:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:43:51 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "14:43:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:44:05 [INFO]   Training abgeschlossen in 10.30s (Backend: cuml)\n",
      "14:44:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:44:20 [INFO]   Training abgeschlossen in 10.73s (Backend: cuml)\n",
      "14:44:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:44:34 [INFO]   Training abgeschlossen in 10.47s (Backend: cuml)\n",
      "14:44:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:44:49 [INFO]   Training abgeschlossen in 10.68s (Backend: cuml)\n",
      "14:44:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:45:04 [INFO]   Training abgeschlossen in 10.68s (Backend: cuml)\n",
      "14:45:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:45:19 [INFO]   Training abgeschlossen in 11.29s (Backend: cuml)\n",
      "14:45:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:45:34 [INFO]   Training abgeschlossen in 11.04s (Backend: cuml)\n",
      "14:45:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:45:49 [INFO]   Training abgeschlossen in 11.02s (Backend: cuml)\n",
      "14:45:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:46:04 [INFO]   Training abgeschlossen in 11.07s (Backend: cuml)\n",
      "14:46:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:46:19 [INFO]   Training abgeschlossen in 11.32s (Backend: cuml)\n",
      "14:46:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:46:34 [INFO]   Training abgeschlossen in 11.31s (Backend: cuml)\n",
      "14:46:38 [INFO]     36,000 labeled → Accuracy: 0.9597 (Train: 11.3s, Query: 0.01s) | GPU: 2.6/8.0 GB\n",
      "14:46:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:46:49 [INFO]   Training abgeschlossen in 11.27s (Backend: cuml)\n",
      "14:46:53 [INFO]     Final: 36,000 labeled → Accuracy: 0.9595, F1: 0.9592\n",
      "14:46:53 [INFO]   Run 3/5\n",
      "14:46:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:46:58 [INFO]   Training abgeschlossen in 4.53s (Backend: cuml)\n",
      "14:47:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:47:05 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "14:47:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:47:13 [INFO]   Training abgeschlossen in 4.55s (Backend: cuml)\n",
      "14:47:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:47:20 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "14:47:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:47:28 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "14:47:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:47:36 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "14:47:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:47:43 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "14:47:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:47:51 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "14:47:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:48:00 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "14:48:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:48:08 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "14:48:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:48:17 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "14:48:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:48:27 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "14:48:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:48:36 [INFO]   Training abgeschlossen in 6.04s (Backend: cuml)\n",
      "14:48:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:48:45 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "14:48:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:48:55 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "14:48:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:49:04 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "14:49:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:49:13 [INFO]   Training abgeschlossen in 6.39s (Backend: cuml)\n",
      "14:49:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:49:23 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "14:49:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:49:33 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "14:49:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:49:43 [INFO]   Training abgeschlossen in 6.57s (Backend: cuml)\n",
      "14:49:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:49:52 [INFO]   Training abgeschlossen in 6.61s (Backend: cuml)\n",
      "14:49:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:50:02 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "14:50:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:50:12 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "14:50:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:50:23 [INFO]   Training abgeschlossen in 7.04s (Backend: cuml)\n",
      "14:50:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:50:33 [INFO]   Training abgeschlossen in 6.98s (Backend: cuml)\n",
      "14:50:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:50:43 [INFO]   Training abgeschlossen in 7.04s (Backend: cuml)\n",
      "14:50:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:50:54 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "14:50:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:51:04 [INFO]   Training abgeschlossen in 7.27s (Backend: cuml)\n",
      "14:51:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:51:18 [INFO]   Training abgeschlossen in 10.76s (Backend: cuml)\n",
      "14:51:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:51:41 [INFO]   Training abgeschlossen in 11.28s (Backend: cuml)\n",
      "14:51:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:52:03 [INFO]   Training abgeschlossen in 11.49s (Backend: cuml)\n",
      "14:52:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:52:25 [INFO]   Training abgeschlossen in 11.72s (Backend: cuml)\n",
      "14:52:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:52:48 [INFO]   Training abgeschlossen in 11.88s (Backend: cuml)\n",
      "14:52:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:53:11 [INFO]   Training abgeschlossen in 12.03s (Backend: cuml)\n",
      "14:53:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:53:34 [INFO]   Training abgeschlossen in 12.26s (Backend: cuml)\n",
      "14:53:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:53:57 [INFO]   Training abgeschlossen in 12.40s (Backend: cuml)\n",
      "14:54:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:54:21 [INFO]   Training abgeschlossen in 12.64s (Backend: cuml)\n",
      "14:54:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:54:44 [INFO]   Training abgeschlossen in 12.82s (Backend: cuml)\n",
      "14:54:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:55:08 [INFO]   Training abgeschlossen in 13.21s (Backend: cuml)\n",
      "14:55:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:55:32 [INFO]   Training abgeschlossen in 13.28s (Backend: cuml)\n",
      "14:55:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:55:57 [INFO]   Training abgeschlossen in 13.53s (Backend: cuml)\n",
      "14:56:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:56:21 [INFO]   Training abgeschlossen in 13.64s (Backend: cuml)\n",
      "14:56:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:56:46 [INFO]   Training abgeschlossen in 13.81s (Backend: cuml)\n",
      "14:56:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:57:11 [INFO]   Training abgeschlossen in 13.77s (Backend: cuml)\n",
      "14:57:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:57:36 [INFO]   Training abgeschlossen in 13.91s (Backend: cuml)\n",
      "14:57:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:58:01 [INFO]   Training abgeschlossen in 14.27s (Backend: cuml)\n",
      "14:58:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:58:26 [INFO]   Training abgeschlossen in 14.35s (Backend: cuml)\n",
      "14:58:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:58:51 [INFO]   Training abgeschlossen in 14.58s (Backend: cuml)\n",
      "14:59:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:59:17 [INFO]   Training abgeschlossen in 14.83s (Backend: cuml)\n",
      "14:59:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:59:43 [INFO]   Training abgeschlossen in 15.03s (Backend: cuml)\n",
      "14:59:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:00:10 [INFO]   Training abgeschlossen in 15.44s (Backend: cuml)\n",
      "15:00:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:00:36 [INFO]   Training abgeschlossen in 15.44s (Backend: cuml)\n",
      "15:00:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:01:03 [INFO]   Training abgeschlossen in 15.75s (Backend: cuml)\n",
      "15:01:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:01:30 [INFO]   Training abgeschlossen in 15.93s (Backend: cuml)\n",
      "15:01:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:01:57 [INFO]   Training abgeschlossen in 16.22s (Backend: cuml)\n",
      "15:02:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:02:25 [INFO]   Training abgeschlossen in 16.23s (Backend: cuml)\n",
      "15:02:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:02:53 [INFO]   Training abgeschlossen in 16.60s (Backend: cuml)\n",
      "15:03:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:03:20 [INFO]   Training abgeschlossen in 16.62s (Backend: cuml)\n",
      "15:03:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:03:49 [INFO]   Training abgeschlossen in 17.11s (Backend: cuml)\n",
      "15:04:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:04:17 [INFO]   Training abgeschlossen in 17.14s (Backend: cuml)\n",
      "15:04:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:04:46 [INFO]   Training abgeschlossen in 17.55s (Backend: cuml)\n",
      "15:04:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:05:15 [INFO]   Training abgeschlossen in 17.65s (Backend: cuml)\n",
      "15:05:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:05:44 [INFO]   Training abgeschlossen in 17.89s (Backend: cuml)\n",
      "15:05:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:06:13 [INFO]   Training abgeschlossen in 17.98s (Backend: cuml)\n",
      "15:06:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:06:43 [INFO]   Training abgeschlossen in 18.32s (Backend: cuml)\n",
      "15:06:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:07:12 [INFO]   Training abgeschlossen in 18.35s (Backend: cuml)\n",
      "15:07:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:07:42 [INFO]   Training abgeschlossen in 18.76s (Backend: cuml)\n",
      "15:07:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:08:12 [INFO]   Training abgeschlossen in 18.94s (Backend: cuml)\n",
      "15:08:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:08:43 [INFO]   Training abgeschlossen in 19.26s (Backend: cuml)\n",
      "15:08:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:09:13 [INFO]   Training abgeschlossen in 19.26s (Backend: cuml)\n",
      "15:09:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:09:44 [INFO]   Training abgeschlossen in 19.56s (Backend: cuml)\n",
      "15:09:55 [INFO]     36,000 labeled → Accuracy: 0.9581 (Train: 19.6s, Query: 0.01s) | GPU: 2.6/8.0 GB\n",
      "15:09:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:10:15 [INFO]   Training abgeschlossen in 19.72s (Backend: cuml)\n",
      "15:10:26 [INFO]     Final: 36,000 labeled → Accuracy: 0.9585, F1: 0.9581\n",
      "15:10:26 [INFO]   Run 4/5\n",
      "15:10:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:10:31 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "15:10:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:10:46 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "15:10:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:11:02 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "15:11:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:11:17 [INFO]   Training abgeschlossen in 5.25s (Backend: cuml)\n",
      "15:11:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:11:32 [INFO]   Training abgeschlossen in 5.46s (Backend: cuml)\n",
      "15:11:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:11:48 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "15:11:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:12:04 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "15:12:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:12:21 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "15:12:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:12:38 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "15:12:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:12:55 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "15:13:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:13:13 [INFO]   Training abgeschlossen in 7.43s (Backend: cuml)\n",
      "15:13:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:13:31 [INFO]   Training abgeschlossen in 7.45s (Backend: cuml)\n",
      "15:13:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:13:49 [INFO]   Training abgeschlossen in 8.08s (Backend: cuml)\n",
      "15:13:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:14:08 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "15:14:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:14:27 [INFO]   Training abgeschlossen in 8.44s (Backend: cuml)\n",
      "15:14:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:14:46 [INFO]   Training abgeschlossen in 8.75s (Backend: cuml)\n",
      "15:14:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:15:05 [INFO]   Training abgeschlossen in 8.85s (Backend: cuml)\n",
      "15:15:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:15:25 [INFO]   Training abgeschlossen in 8.87s (Backend: cuml)\n",
      "15:15:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:15:44 [INFO]   Training abgeschlossen in 9.06s (Backend: cuml)\n",
      "15:15:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:16:04 [INFO]   Training abgeschlossen in 9.39s (Backend: cuml)\n",
      "15:16:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:16:24 [INFO]   Training abgeschlossen in 9.59s (Backend: cuml)\n",
      "15:16:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:16:44 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "15:16:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:17:05 [INFO]   Training abgeschlossen in 9.82s (Backend: cuml)\n",
      "15:17:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:17:25 [INFO]   Training abgeschlossen in 10.02s (Backend: cuml)\n",
      "15:17:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:17:46 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "15:17:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:18:07 [INFO]   Training abgeschlossen in 10.45s (Backend: cuml)\n",
      "15:18:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:18:29 [INFO]   Training abgeschlossen in 10.73s (Backend: cuml)\n",
      "15:18:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:18:51 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "15:19:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:19:12 [INFO]   Training abgeschlossen in 11.06s (Backend: cuml)\n",
      "15:19:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:19:34 [INFO]   Training abgeschlossen in 11.28s (Backend: cuml)\n",
      "15:19:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:19:57 [INFO]   Training abgeschlossen in 11.39s (Backend: cuml)\n",
      "15:20:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:20:19 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "15:20:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:20:41 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "15:20:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:21:04 [INFO]   Training abgeschlossen in 11.98s (Backend: cuml)\n",
      "15:21:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:21:27 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "15:21:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:21:50 [INFO]   Training abgeschlossen in 12.37s (Backend: cuml)\n",
      "15:22:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:22:14 [INFO]   Training abgeschlossen in 12.60s (Backend: cuml)\n",
      "15:22:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:22:37 [INFO]   Training abgeschlossen in 12.81s (Backend: cuml)\n",
      "15:22:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:23:01 [INFO]   Training abgeschlossen in 12.99s (Backend: cuml)\n",
      "15:23:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:23:26 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "15:23:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:23:50 [INFO]   Training abgeschlossen in 13.34s (Backend: cuml)\n",
      "15:24:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:24:14 [INFO]   Training abgeschlossen in 13.65s (Backend: cuml)\n",
      "15:24:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:24:39 [INFO]   Training abgeschlossen in 13.78s (Backend: cuml)\n",
      "15:24:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:25:04 [INFO]   Training abgeschlossen in 13.88s (Backend: cuml)\n",
      "15:25:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:25:29 [INFO]   Training abgeschlossen in 13.93s (Backend: cuml)\n",
      "15:25:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:25:54 [INFO]   Training abgeschlossen in 14.18s (Backend: cuml)\n",
      "15:26:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:26:19 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "15:26:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:26:45 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "15:26:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:27:11 [INFO]   Training abgeschlossen in 15.00s (Backend: cuml)\n",
      "15:27:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:27:37 [INFO]   Training abgeschlossen in 15.10s (Backend: cuml)\n",
      "15:27:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:28:04 [INFO]   Training abgeschlossen in 15.49s (Backend: cuml)\n",
      "15:28:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:28:30 [INFO]   Training abgeschlossen in 15.43s (Backend: cuml)\n",
      "15:28:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:28:57 [INFO]   Training abgeschlossen in 15.69s (Backend: cuml)\n",
      "15:29:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:29:24 [INFO]   Training abgeschlossen in 15.85s (Backend: cuml)\n",
      "15:29:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:29:51 [INFO]   Training abgeschlossen in 16.07s (Backend: cuml)\n",
      "15:30:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:30:18 [INFO]   Training abgeschlossen in 16.30s (Backend: cuml)\n",
      "15:30:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:30:46 [INFO]   Training abgeschlossen in 16.46s (Backend: cuml)\n",
      "15:30:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:31:14 [INFO]   Training abgeschlossen in 16.73s (Backend: cuml)\n",
      "15:31:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:31:42 [INFO]   Training abgeschlossen in 17.02s (Backend: cuml)\n",
      "15:31:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:32:10 [INFO]   Training abgeschlossen in 17.21s (Backend: cuml)\n",
      "15:32:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:32:39 [INFO]   Training abgeschlossen in 17.46s (Backend: cuml)\n",
      "15:32:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:33:08 [INFO]   Training abgeschlossen in 17.67s (Backend: cuml)\n",
      "15:33:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:33:37 [INFO]   Training abgeschlossen in 17.92s (Backend: cuml)\n",
      "15:33:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:34:06 [INFO]   Training abgeschlossen in 17.99s (Backend: cuml)\n",
      "15:34:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:34:35 [INFO]   Training abgeschlossen in 18.18s (Backend: cuml)\n",
      "15:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:35:05 [INFO]   Training abgeschlossen in 18.35s (Backend: cuml)\n",
      "15:35:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:35:35 [INFO]   Training abgeschlossen in 18.70s (Backend: cuml)\n",
      "15:35:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:36:05 [INFO]   Training abgeschlossen in 18.81s (Backend: cuml)\n",
      "15:36:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:36:35 [INFO]   Training abgeschlossen in 19.07s (Backend: cuml)\n",
      "15:36:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:37:06 [INFO]   Training abgeschlossen in 19.29s (Backend: cuml)\n",
      "15:37:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:37:36 [INFO]   Training abgeschlossen in 19.41s (Backend: cuml)\n",
      "15:37:47 [INFO]     36,000 labeled → Accuracy: 0.9611 (Train: 19.4s, Query: 0.01s) | GPU: 2.6/8.0 GB\n",
      "15:37:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:38:07 [INFO]   Training abgeschlossen in 19.68s (Backend: cuml)\n",
      "15:38:18 [INFO]     Final: 36,000 labeled → Accuracy: 0.9623, F1: 0.9620\n",
      "15:38:19 [INFO]   Run 5/5\n",
      "15:38:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:38:23 [INFO]   Training abgeschlossen in 4.67s (Backend: cuml)\n",
      "15:38:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:38:38 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "15:38:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:38:53 [INFO]   Training abgeschlossen in 5.03s (Backend: cuml)\n",
      "15:39:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:39:09 [INFO]   Training abgeschlossen in 5.25s (Backend: cuml)\n",
      "15:39:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:39:24 [INFO]   Training abgeschlossen in 5.46s (Backend: cuml)\n",
      "15:39:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:39:40 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "15:39:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:39:56 [INFO]   Training abgeschlossen in 5.70s (Backend: cuml)\n",
      "15:40:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:40:12 [INFO]   Training abgeschlossen in 6.09s (Backend: cuml)\n",
      "15:40:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:40:29 [INFO]   Training abgeschlossen in 6.62s (Backend: cuml)\n",
      "15:40:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:40:47 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "15:40:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:41:04 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "15:41:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:41:22 [INFO]   Training abgeschlossen in 7.61s (Backend: cuml)\n",
      "15:41:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:41:41 [INFO]   Training abgeschlossen in 7.82s (Backend: cuml)\n",
      "15:41:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:41:59 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "15:42:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:42:18 [INFO]   Training abgeschlossen in 8.43s (Backend: cuml)\n",
      "15:42:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:42:37 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "15:42:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:42:56 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "15:43:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:43:16 [INFO]   Training abgeschlossen in 8.92s (Backend: cuml)\n",
      "15:43:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:43:35 [INFO]   Training abgeschlossen in 9.11s (Backend: cuml)\n",
      "15:43:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:43:55 [INFO]   Training abgeschlossen in 9.26s (Backend: cuml)\n",
      "15:44:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:44:15 [INFO]   Training abgeschlossen in 9.57s (Backend: cuml)\n",
      "15:44:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:44:35 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "15:44:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:44:56 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "15:45:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:45:17 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "15:45:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:45:38 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "15:45:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:45:59 [INFO]   Training abgeschlossen in 10.44s (Backend: cuml)\n",
      "15:46:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:46:20 [INFO]   Training abgeschlossen in 10.83s (Backend: cuml)\n",
      "15:46:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:46:42 [INFO]   Training abgeschlossen in 10.94s (Backend: cuml)\n",
      "15:46:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:47:04 [INFO]   Training abgeschlossen in 11.10s (Backend: cuml)\n",
      "15:47:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:47:26 [INFO]   Training abgeschlossen in 11.31s (Backend: cuml)\n",
      "15:47:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:47:48 [INFO]   Training abgeschlossen in 11.48s (Backend: cuml)\n",
      "15:47:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:48:10 [INFO]   Training abgeschlossen in 11.64s (Backend: cuml)\n",
      "15:48:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:48:33 [INFO]   Training abgeschlossen in 11.83s (Backend: cuml)\n",
      "15:48:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:48:55 [INFO]   Training abgeschlossen in 12.02s (Backend: cuml)\n",
      "15:49:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:49:19 [INFO]   Training abgeschlossen in 12.34s (Backend: cuml)\n",
      "15:49:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:49:42 [INFO]   Training abgeschlossen in 12.42s (Backend: cuml)\n",
      "15:49:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:50:05 [INFO]   Training abgeschlossen in 12.60s (Backend: cuml)\n",
      "15:50:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:50:29 [INFO]   Training abgeschlossen in 12.84s (Backend: cuml)\n",
      "15:50:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:50:53 [INFO]   Training abgeschlossen in 13.12s (Backend: cuml)\n",
      "15:51:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:51:17 [INFO]   Training abgeschlossen in 13.24s (Backend: cuml)\n",
      "15:51:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:51:41 [INFO]   Training abgeschlossen in 13.51s (Backend: cuml)\n",
      "15:51:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:52:06 [INFO]   Training abgeschlossen in 13.69s (Backend: cuml)\n",
      "15:52:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:52:31 [INFO]   Training abgeschlossen in 13.88s (Backend: cuml)\n",
      "15:52:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:52:56 [INFO]   Training abgeschlossen in 13.92s (Backend: cuml)\n",
      "15:53:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:53:21 [INFO]   Training abgeschlossen in 13.99s (Backend: cuml)\n",
      "15:53:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:53:46 [INFO]   Training abgeschlossen in 14.29s (Backend: cuml)\n",
      "15:53:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:54:12 [INFO]   Training abgeschlossen in 14.40s (Backend: cuml)\n",
      "15:54:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:54:37 [INFO]   Training abgeschlossen in 14.80s (Backend: cuml)\n",
      "15:54:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:55:03 [INFO]   Training abgeschlossen in 14.78s (Backend: cuml)\n",
      "15:55:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:55:29 [INFO]   Training abgeschlossen in 15.17s (Backend: cuml)\n",
      "15:55:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:55:56 [INFO]   Training abgeschlossen in 15.56s (Backend: cuml)\n",
      "15:56:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:56:23 [INFO]   Training abgeschlossen in 15.72s (Backend: cuml)\n",
      "15:56:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:56:50 [INFO]   Training abgeschlossen in 15.72s (Backend: cuml)\n",
      "15:57:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:57:17 [INFO]   Training abgeschlossen in 16.19s (Backend: cuml)\n",
      "15:57:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:57:45 [INFO]   Training abgeschlossen in 16.18s (Backend: cuml)\n",
      "15:57:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:58:12 [INFO]   Training abgeschlossen in 16.62s (Backend: cuml)\n",
      "15:58:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:58:40 [INFO]   Training abgeschlossen in 16.59s (Backend: cuml)\n",
      "15:58:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:59:09 [INFO]   Training abgeschlossen in 17.05s (Backend: cuml)\n",
      "15:59:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:59:37 [INFO]   Training abgeschlossen in 17.10s (Backend: cuml)\n",
      "15:59:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:00:06 [INFO]   Training abgeschlossen in 17.63s (Backend: cuml)\n",
      "16:00:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:00:34 [INFO]   Training abgeschlossen in 17.50s (Backend: cuml)\n",
      "16:00:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:01:03 [INFO]   Training abgeschlossen in 17.59s (Backend: cuml)\n",
      "16:01:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:01:32 [INFO]   Training abgeschlossen in 17.76s (Backend: cuml)\n",
      "16:01:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:02:01 [INFO]   Training abgeschlossen in 18.00s (Backend: cuml)\n",
      "16:02:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:02:31 [INFO]   Training abgeschlossen in 18.18s (Backend: cuml)\n",
      "16:02:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:03:00 [INFO]   Training abgeschlossen in 18.50s (Backend: cuml)\n",
      "16:03:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:03:30 [INFO]   Training abgeschlossen in 18.72s (Backend: cuml)\n",
      "16:03:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:04:01 [INFO]   Training abgeschlossen in 18.94s (Backend: cuml)\n",
      "16:04:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:04:31 [INFO]   Training abgeschlossen in 19.09s (Backend: cuml)\n",
      "16:04:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:05:01 [INFO]   Training abgeschlossen in 19.23s (Backend: cuml)\n",
      "16:05:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:05:32 [INFO]   Training abgeschlossen in 19.46s (Backend: cuml)\n",
      "16:05:43 [INFO]     36,000 labeled → Accuracy: 0.9607 (Train: 19.5s, Query: 0.01s) | GPU: 2.6/8.0 GB\n",
      "16:05:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:06:03 [INFO]   Training abgeschlossen in 19.63s (Backend: cuml)\n",
      "16:06:14 [INFO]     Final: 36,000 labeled → Accuracy: 0.9613, F1: 0.9610\n",
      "16:06:14 [INFO] \n",
      "GPU-SVM + Random Sampling - Budget: 80% (48,000 Samples)\n",
      "16:06:14 [INFO]   Run 1/5\n",
      "16:06:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:06:19 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "16:06:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:06:34 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "16:06:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:06:49 [INFO]   Training abgeschlossen in 5.08s (Backend: cuml)\n",
      "16:06:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:07:05 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "16:07:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:07:20 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "16:07:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:07:36 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "16:07:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:07:52 [INFO]   Training abgeschlossen in 5.65s (Backend: cuml)\n",
      "16:08:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:08:09 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "16:08:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:08:26 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "16:08:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:08:43 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "16:08:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:09:01 [INFO]   Training abgeschlossen in 7.44s (Backend: cuml)\n",
      "16:09:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:09:19 [INFO]   Training abgeschlossen in 7.70s (Backend: cuml)\n",
      "16:09:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:09:38 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "16:09:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:09:56 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "16:10:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:10:15 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "16:10:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:10:35 [INFO]   Training abgeschlossen in 8.66s (Backend: cuml)\n",
      "16:10:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:10:54 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "16:11:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:11:14 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "16:11:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:11:33 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "16:11:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:11:53 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "16:12:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:12:14 [INFO]   Training abgeschlossen in 9.55s (Backend: cuml)\n",
      "16:12:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:12:34 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "16:12:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:12:54 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "16:13:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:13:15 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "16:13:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:13:36 [INFO]   Training abgeschlossen in 10.25s (Backend: cuml)\n",
      "16:13:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:13:57 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "16:14:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:14:19 [INFO]   Training abgeschlossen in 10.83s (Backend: cuml)\n",
      "16:14:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:14:40 [INFO]   Training abgeschlossen in 10.83s (Backend: cuml)\n",
      "16:14:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:15:02 [INFO]   Training abgeschlossen in 11.05s (Backend: cuml)\n",
      "16:15:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:15:24 [INFO]   Training abgeschlossen in 11.22s (Backend: cuml)\n",
      "16:15:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:15:46 [INFO]   Training abgeschlossen in 11.41s (Backend: cuml)\n",
      "16:15:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:16:08 [INFO]   Training abgeschlossen in 11.69s (Backend: cuml)\n",
      "16:16:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:16:31 [INFO]   Training abgeschlossen in 11.86s (Backend: cuml)\n",
      "16:16:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:16:54 [INFO]   Training abgeschlossen in 12.15s (Backend: cuml)\n",
      "16:17:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:17:17 [INFO]   Training abgeschlossen in 12.25s (Backend: cuml)\n",
      "16:17:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:17:40 [INFO]   Training abgeschlossen in 12.42s (Backend: cuml)\n",
      "16:17:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:18:04 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "16:18:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:18:27 [INFO]   Training abgeschlossen in 12.70s (Backend: cuml)\n",
      "16:18:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:18:51 [INFO]   Training abgeschlossen in 13.02s (Backend: cuml)\n",
      "16:19:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:19:15 [INFO]   Training abgeschlossen in 13.12s (Backend: cuml)\n",
      "16:19:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:19:39 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "16:19:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:20:04 [INFO]   Training abgeschlossen in 13.56s (Backend: cuml)\n",
      "16:20:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:20:28 [INFO]   Training abgeschlossen in 13.79s (Backend: cuml)\n",
      "16:20:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:20:53 [INFO]   Training abgeschlossen in 13.77s (Backend: cuml)\n",
      "16:21:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:21:18 [INFO]   Training abgeschlossen in 13.92s (Backend: cuml)\n",
      "16:21:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:21:43 [INFO]   Training abgeschlossen in 14.23s (Backend: cuml)\n",
      "16:21:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:22:09 [INFO]   Training abgeschlossen in 14.56s (Backend: cuml)\n",
      "16:22:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:22:35 [INFO]   Training abgeschlossen in 14.77s (Backend: cuml)\n",
      "16:22:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:23:01 [INFO]   Training abgeschlossen in 14.86s (Backend: cuml)\n",
      "16:23:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:23:27 [INFO]   Training abgeschlossen in 15.15s (Backend: cuml)\n",
      "16:23:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:23:53 [INFO]   Training abgeschlossen in 15.46s (Backend: cuml)\n",
      "16:24:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:24:20 [INFO]   Training abgeschlossen in 15.52s (Backend: cuml)\n",
      "16:24:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:24:47 [INFO]   Training abgeschlossen in 15.62s (Backend: cuml)\n",
      "16:24:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:25:14 [INFO]   Training abgeschlossen in 15.90s (Backend: cuml)\n",
      "16:25:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:25:41 [INFO]   Training abgeschlossen in 16.16s (Backend: cuml)\n",
      "16:25:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:26:08 [INFO]   Training abgeschlossen in 16.26s (Backend: cuml)\n",
      "16:26:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:26:36 [INFO]   Training abgeschlossen in 16.45s (Backend: cuml)\n",
      "16:26:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:27:04 [INFO]   Training abgeschlossen in 16.72s (Backend: cuml)\n",
      "16:27:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:27:32 [INFO]   Training abgeschlossen in 16.88s (Backend: cuml)\n",
      "16:27:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:28:00 [INFO]   Training abgeschlossen in 17.14s (Backend: cuml)\n",
      "16:28:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:28:28 [INFO]   Training abgeschlossen in 17.29s (Backend: cuml)\n",
      "16:28:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:28:57 [INFO]   Training abgeschlossen in 17.62s (Backend: cuml)\n",
      "16:29:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:29:26 [INFO]   Training abgeschlossen in 17.74s (Backend: cuml)\n",
      "16:29:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:29:55 [INFO]   Training abgeschlossen in 18.03s (Backend: cuml)\n",
      "16:30:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:30:25 [INFO]   Training abgeschlossen in 18.17s (Backend: cuml)\n",
      "16:30:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:30:54 [INFO]   Training abgeschlossen in 18.40s (Backend: cuml)\n",
      "16:31:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:31:24 [INFO]   Training abgeschlossen in 18.61s (Backend: cuml)\n",
      "16:31:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:31:54 [INFO]   Training abgeschlossen in 18.82s (Backend: cuml)\n",
      "16:32:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:32:24 [INFO]   Training abgeschlossen in 19.03s (Backend: cuml)\n",
      "16:32:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:32:55 [INFO]   Training abgeschlossen in 19.35s (Backend: cuml)\n",
      "16:33:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:33:26 [INFO]   Training abgeschlossen in 19.44s (Backend: cuml)\n",
      "16:33:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:33:57 [INFO]   Training abgeschlossen in 19.81s (Backend: cuml)\n",
      "16:34:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:34:28 [INFO]   Training abgeschlossen in 19.93s (Backend: cuml)\n",
      "16:34:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:34:59 [INFO]   Training abgeschlossen in 20.11s (Backend: cuml)\n",
      "16:35:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:35:31 [INFO]   Training abgeschlossen in 20.47s (Backend: cuml)\n",
      "16:35:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:36:03 [INFO]   Training abgeschlossen in 20.52s (Backend: cuml)\n",
      "16:36:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:36:35 [INFO]   Training abgeschlossen in 20.81s (Backend: cuml)\n",
      "16:36:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:37:07 [INFO]   Training abgeschlossen in 20.98s (Backend: cuml)\n",
      "16:37:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:37:40 [INFO]   Training abgeschlossen in 21.26s (Backend: cuml)\n",
      "16:37:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:38:13 [INFO]   Training abgeschlossen in 21.56s (Backend: cuml)\n",
      "16:38:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:38:46 [INFO]   Training abgeschlossen in 21.72s (Backend: cuml)\n",
      "16:38:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:39:20 [INFO]   Training abgeschlossen in 22.10s (Backend: cuml)\n",
      "16:39:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:39:53 [INFO]   Training abgeschlossen in 22.09s (Backend: cuml)\n",
      "16:40:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:40:27 [INFO]   Training abgeschlossen in 22.24s (Backend: cuml)\n",
      "16:40:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:41:01 [INFO]   Training abgeschlossen in 22.54s (Backend: cuml)\n",
      "16:41:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:41:35 [INFO]   Training abgeschlossen in 22.74s (Backend: cuml)\n",
      "16:41:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:42:09 [INFO]   Training abgeschlossen in 23.00s (Backend: cuml)\n",
      "16:42:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:42:44 [INFO]   Training abgeschlossen in 23.11s (Backend: cuml)\n",
      "16:42:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:43:18 [INFO]   Training abgeschlossen in 23.34s (Backend: cuml)\n",
      "16:43:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:43:54 [INFO]   Training abgeschlossen in 23.71s (Backend: cuml)\n",
      "16:44:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:44:29 [INFO]   Training abgeschlossen in 23.84s (Backend: cuml)\n",
      "16:44:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:45:05 [INFO]   Training abgeschlossen in 24.16s (Backend: cuml)\n",
      "16:45:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:45:40 [INFO]   Training abgeschlossen in 24.19s (Backend: cuml)\n",
      "16:45:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:46:16 [INFO]   Training abgeschlossen in 24.40s (Backend: cuml)\n",
      "16:46:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:46:53 [INFO]   Training abgeschlossen in 24.81s (Backend: cuml)\n",
      "16:47:04 [INFO]     48,000 labeled → Accuracy: 0.9625 (Train: 24.8s, Query: 0.00s) | GPU: 2.7/8.0 GB\n",
      "16:47:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:47:29 [INFO]   Training abgeschlossen in 25.00s (Backend: cuml)\n",
      "16:47:41 [INFO]     Final: 48,000 labeled → Accuracy: 0.9625, F1: 0.9622\n",
      "16:47:41 [INFO]   Run 2/5\n",
      "16:47:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:47:46 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "16:47:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:48:00 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "16:48:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:48:16 [INFO]   Training abgeschlossen in 5.04s (Backend: cuml)\n",
      "16:48:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:48:31 [INFO]   Training abgeschlossen in 5.25s (Backend: cuml)\n",
      "16:48:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:48:47 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "16:48:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:49:02 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "16:49:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:49:18 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "16:49:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:49:35 [INFO]   Training abgeschlossen in 6.08s (Backend: cuml)\n",
      "16:49:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:49:52 [INFO]   Training abgeschlossen in 6.76s (Backend: cuml)\n",
      "16:50:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:50:09 [INFO]   Training abgeschlossen in 6.99s (Backend: cuml)\n",
      "16:50:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:50:26 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "16:50:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:50:44 [INFO]   Training abgeschlossen in 7.59s (Backend: cuml)\n",
      "16:50:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:51:03 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "16:51:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:51:21 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "16:51:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:51:40 [INFO]   Training abgeschlossen in 8.45s (Backend: cuml)\n",
      "16:51:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:51:59 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "16:52:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:52:18 [INFO]   Training abgeschlossen in 8.65s (Backend: cuml)\n",
      "16:52:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:52:38 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "16:52:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:52:58 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "16:53:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:53:17 [INFO]   Training abgeschlossen in 9.28s (Backend: cuml)\n",
      "16:53:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:53:38 [INFO]   Training abgeschlossen in 9.83s (Backend: cuml)\n",
      "16:53:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:53:58 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "16:54:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:54:19 [INFO]   Training abgeschlossen in 9.85s (Backend: cuml)\n",
      "16:54:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:54:40 [INFO]   Training abgeschlossen in 10.23s (Backend: cuml)\n",
      "16:54:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:55:01 [INFO]   Training abgeschlossen in 10.44s (Backend: cuml)\n",
      "16:55:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:55:22 [INFO]   Training abgeschlossen in 10.63s (Backend: cuml)\n",
      "16:55:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:55:44 [INFO]   Training abgeschlossen in 10.86s (Backend: cuml)\n",
      "16:55:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:56:06 [INFO]   Training abgeschlossen in 11.12s (Backend: cuml)\n",
      "16:56:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:56:28 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "16:56:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:56:49 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "16:57:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:57:12 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "16:57:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:57:34 [INFO]   Training abgeschlossen in 11.56s (Backend: cuml)\n",
      "16:57:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:57:56 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "16:58:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:58:19 [INFO]   Training abgeschlossen in 11.99s (Backend: cuml)\n",
      "16:58:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:58:42 [INFO]   Training abgeschlossen in 12.20s (Backend: cuml)\n",
      "16:58:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:59:05 [INFO]   Training abgeschlossen in 12.42s (Backend: cuml)\n",
      "16:59:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:59:29 [INFO]   Training abgeschlossen in 12.59s (Backend: cuml)\n",
      "16:59:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:59:52 [INFO]   Training abgeschlossen in 12.79s (Backend: cuml)\n",
      "17:00:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:00:16 [INFO]   Training abgeschlossen in 12.87s (Backend: cuml)\n",
      "17:00:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:00:40 [INFO]   Training abgeschlossen in 13.10s (Backend: cuml)\n",
      "17:00:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:01:04 [INFO]   Training abgeschlossen in 13.32s (Backend: cuml)\n",
      "17:01:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:01:29 [INFO]   Training abgeschlossen in 13.51s (Backend: cuml)\n",
      "17:01:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:01:53 [INFO]   Training abgeschlossen in 13.85s (Backend: cuml)\n",
      "17:02:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:02:18 [INFO]   Training abgeschlossen in 13.64s (Backend: cuml)\n",
      "17:02:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:02:43 [INFO]   Training abgeschlossen in 14.02s (Backend: cuml)\n",
      "17:02:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:03:08 [INFO]   Training abgeschlossen in 14.12s (Backend: cuml)\n",
      "17:03:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:03:33 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "17:03:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:03:59 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "17:04:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:04:25 [INFO]   Training abgeschlossen in 14.79s (Backend: cuml)\n",
      "17:04:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:04:51 [INFO]   Training abgeschlossen in 15.06s (Backend: cuml)\n",
      "17:05:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:05:17 [INFO]   Training abgeschlossen in 15.47s (Backend: cuml)\n",
      "17:05:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:05:44 [INFO]   Training abgeschlossen in 15.52s (Backend: cuml)\n",
      "17:05:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:06:10 [INFO]   Training abgeschlossen in 15.62s (Backend: cuml)\n",
      "17:06:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:06:37 [INFO]   Training abgeschlossen in 15.95s (Backend: cuml)\n",
      "17:06:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:07:05 [INFO]   Training abgeschlossen in 16.17s (Backend: cuml)\n",
      "17:07:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:07:32 [INFO]   Training abgeschlossen in 16.24s (Backend: cuml)\n",
      "17:07:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:07:59 [INFO]   Training abgeschlossen in 16.36s (Backend: cuml)\n",
      "17:08:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:08:27 [INFO]   Training abgeschlossen in 16.63s (Backend: cuml)\n",
      "17:08:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:08:55 [INFO]   Training abgeschlossen in 16.90s (Backend: cuml)\n",
      "17:09:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:09:24 [INFO]   Training abgeschlossen in 17.18s (Backend: cuml)\n",
      "17:09:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:09:52 [INFO]   Training abgeschlossen in 17.36s (Backend: cuml)\n",
      "17:10:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:10:21 [INFO]   Training abgeschlossen in 18.00s (Backend: cuml)\n",
      "17:10:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:10:51 [INFO]   Training abgeschlossen in 18.08s (Backend: cuml)\n",
      "17:11:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:11:20 [INFO]   Training abgeschlossen in 18.39s (Backend: cuml)\n",
      "17:11:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:11:50 [INFO]   Training abgeschlossen in 18.33s (Backend: cuml)\n",
      "17:12:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:12:20 [INFO]   Training abgeschlossen in 18.70s (Backend: cuml)\n",
      "17:12:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:12:50 [INFO]   Training abgeschlossen in 18.71s (Backend: cuml)\n",
      "17:13:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:13:20 [INFO]   Training abgeschlossen in 18.91s (Backend: cuml)\n",
      "17:13:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:13:51 [INFO]   Training abgeschlossen in 19.22s (Backend: cuml)\n",
      "17:14:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:14:21 [INFO]   Training abgeschlossen in 19.42s (Backend: cuml)\n",
      "17:14:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:14:53 [INFO]   Training abgeschlossen in 19.87s (Backend: cuml)\n",
      "17:15:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:15:24 [INFO]   Training abgeschlossen in 19.91s (Backend: cuml)\n",
      "17:15:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:15:56 [INFO]   Training abgeschlossen in 20.45s (Backend: cuml)\n",
      "17:16:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:16:27 [INFO]   Training abgeschlossen in 20.30s (Backend: cuml)\n",
      "17:16:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:16:59 [INFO]   Training abgeschlossen in 20.57s (Backend: cuml)\n",
      "17:17:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:17:31 [INFO]   Training abgeschlossen in 20.66s (Backend: cuml)\n",
      "17:17:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:18:04 [INFO]   Training abgeschlossen in 20.85s (Backend: cuml)\n",
      "17:18:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:18:36 [INFO]   Training abgeschlossen in 21.18s (Backend: cuml)\n",
      "17:18:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:19:09 [INFO]   Training abgeschlossen in 21.28s (Backend: cuml)\n",
      "17:19:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:19:42 [INFO]   Training abgeschlossen in 21.58s (Backend: cuml)\n",
      "17:19:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:20:15 [INFO]   Training abgeschlossen in 21.96s (Backend: cuml)\n",
      "17:20:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:20:49 [INFO]   Training abgeschlossen in 21.89s (Backend: cuml)\n",
      "17:21:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:21:22 [INFO]   Training abgeschlossen in 22.22s (Backend: cuml)\n",
      "17:21:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:21:56 [INFO]   Training abgeschlossen in 22.56s (Backend: cuml)\n",
      "17:22:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:22:30 [INFO]   Training abgeschlossen in 22.64s (Backend: cuml)\n",
      "17:22:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:23:05 [INFO]   Training abgeschlossen in 22.97s (Backend: cuml)\n",
      "17:23:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:23:39 [INFO]   Training abgeschlossen in 23.06s (Backend: cuml)\n",
      "17:23:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:24:14 [INFO]   Training abgeschlossen in 23.33s (Backend: cuml)\n",
      "17:24:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:24:49 [INFO]   Training abgeschlossen in 23.50s (Backend: cuml)\n",
      "17:25:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:25:24 [INFO]   Training abgeschlossen in 23.76s (Backend: cuml)\n",
      "17:25:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:26:00 [INFO]   Training abgeschlossen in 23.97s (Backend: cuml)\n",
      "17:26:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:26:36 [INFO]   Training abgeschlossen in 24.22s (Backend: cuml)\n",
      "17:26:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:27:11 [INFO]   Training abgeschlossen in 24.21s (Backend: cuml)\n",
      "17:27:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:27:47 [INFO]   Training abgeschlossen in 24.49s (Backend: cuml)\n",
      "17:27:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:28:24 [INFO]   Training abgeschlossen in 24.83s (Backend: cuml)\n",
      "17:28:35 [INFO]     48,000 labeled → Accuracy: 0.9637 (Train: 24.8s, Query: 0.00s) | GPU: 2.7/8.0 GB\n",
      "17:28:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:29:00 [INFO]   Training abgeschlossen in 24.88s (Backend: cuml)\n",
      "17:29:12 [INFO]     Final: 48,000 labeled → Accuracy: 0.9635, F1: 0.9632\n",
      "17:29:12 [INFO]   Run 3/5\n",
      "17:29:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:29:17 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "17:29:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "17:29:32 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "17:29:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "17:29:47 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "17:29:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "17:30:02 [INFO]   Training abgeschlossen in 5.35s (Backend: cuml)\n",
      "17:30:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "17:30:18 [INFO]   Training abgeschlossen in 5.39s (Backend: cuml)\n",
      "17:30:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "17:30:34 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "17:30:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "17:30:50 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "17:31:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:31:06 [INFO]   Training abgeschlossen in 6.05s (Backend: cuml)\n",
      "17:31:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:31:23 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "17:31:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:31:40 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "17:31:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:31:58 [INFO]   Training abgeschlossen in 7.34s (Backend: cuml)\n",
      "17:32:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:32:16 [INFO]   Training abgeschlossen in 7.56s (Backend: cuml)\n",
      "17:32:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:32:34 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "17:32:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:32:53 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "17:33:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:33:12 [INFO]   Training abgeschlossen in 8.44s (Backend: cuml)\n",
      "17:33:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:33:31 [INFO]   Training abgeschlossen in 8.64s (Backend: cuml)\n",
      "17:33:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:33:50 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "17:34:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:34:10 [INFO]   Training abgeschlossen in 8.92s (Backend: cuml)\n",
      "17:34:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:34:29 [INFO]   Training abgeschlossen in 9.12s (Backend: cuml)\n",
      "17:34:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:34:49 [INFO]   Training abgeschlossen in 9.28s (Backend: cuml)\n",
      "17:35:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:35:09 [INFO]   Training abgeschlossen in 9.52s (Backend: cuml)\n",
      "17:35:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:35:30 [INFO]   Training abgeschlossen in 9.79s (Backend: cuml)\n",
      "17:35:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:35:50 [INFO]   Training abgeschlossen in 9.85s (Backend: cuml)\n",
      "17:36:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:36:11 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "17:36:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:36:32 [INFO]   Training abgeschlossen in 10.25s (Backend: cuml)\n",
      "17:36:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:36:53 [INFO]   Training abgeschlossen in 10.46s (Backend: cuml)\n",
      "17:37:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:37:14 [INFO]   Training abgeschlossen in 10.89s (Backend: cuml)\n",
      "17:37:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:37:36 [INFO]   Training abgeschlossen in 10.89s (Backend: cuml)\n",
      "17:37:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:37:57 [INFO]   Training abgeschlossen in 11.07s (Backend: cuml)\n",
      "17:38:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:38:20 [INFO]   Training abgeschlossen in 11.33s (Backend: cuml)\n",
      "17:38:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:38:42 [INFO]   Training abgeschlossen in 11.47s (Backend: cuml)\n",
      "17:38:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:39:04 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "17:39:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:39:27 [INFO]   Training abgeschlossen in 11.89s (Backend: cuml)\n",
      "17:39:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:39:50 [INFO]   Training abgeschlossen in 12.04s (Backend: cuml)\n",
      "17:40:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:40:13 [INFO]   Training abgeschlossen in 12.29s (Backend: cuml)\n",
      "17:40:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:40:36 [INFO]   Training abgeschlossen in 12.41s (Backend: cuml)\n",
      "17:40:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:41:00 [INFO]   Training abgeschlossen in 12.67s (Backend: cuml)\n",
      "17:41:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:41:23 [INFO]   Training abgeschlossen in 12.76s (Backend: cuml)\n",
      "17:41:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:41:47 [INFO]   Training abgeschlossen in 12.99s (Backend: cuml)\n",
      "17:41:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:42:11 [INFO]   Training abgeschlossen in 13.30s (Backend: cuml)\n",
      "17:42:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:42:36 [INFO]   Training abgeschlossen in 13.41s (Backend: cuml)\n",
      "17:42:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:43:00 [INFO]   Training abgeschlossen in 13.75s (Backend: cuml)\n",
      "17:43:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:43:25 [INFO]   Training abgeschlossen in 13.92s (Backend: cuml)\n",
      "17:43:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:43:50 [INFO]   Training abgeschlossen in 13.85s (Backend: cuml)\n",
      "17:44:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:44:15 [INFO]   Training abgeschlossen in 14.11s (Backend: cuml)\n",
      "17:44:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:44:40 [INFO]   Training abgeschlossen in 14.25s (Backend: cuml)\n",
      "17:44:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:45:06 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "17:45:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:45:31 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "17:45:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:45:57 [INFO]   Training abgeschlossen in 14.96s (Backend: cuml)\n",
      "17:46:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:46:23 [INFO]   Training abgeschlossen in 14.99s (Backend: cuml)\n",
      "17:46:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:46:50 [INFO]   Training abgeschlossen in 15.57s (Backend: cuml)\n",
      "17:47:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:47:16 [INFO]   Training abgeschlossen in 15.45s (Backend: cuml)\n",
      "17:47:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:47:43 [INFO]   Training abgeschlossen in 15.67s (Backend: cuml)\n",
      "17:47:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:48:10 [INFO]   Training abgeschlossen in 15.85s (Backend: cuml)\n",
      "17:48:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:48:37 [INFO]   Training abgeschlossen in 16.10s (Backend: cuml)\n",
      "17:48:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:49:05 [INFO]   Training abgeschlossen in 16.34s (Backend: cuml)\n",
      "17:49:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:49:32 [INFO]   Training abgeschlossen in 16.54s (Backend: cuml)\n",
      "17:49:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:50:00 [INFO]   Training abgeschlossen in 16.70s (Backend: cuml)\n",
      "17:50:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:50:28 [INFO]   Training abgeschlossen in 16.97s (Backend: cuml)\n",
      "17:50:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:50:57 [INFO]   Training abgeschlossen in 17.15s (Backend: cuml)\n",
      "17:51:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:51:25 [INFO]   Training abgeschlossen in 17.34s (Backend: cuml)\n",
      "17:51:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:51:54 [INFO]   Training abgeschlossen in 17.55s (Backend: cuml)\n",
      "17:52:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:52:23 [INFO]   Training abgeschlossen in 17.80s (Backend: cuml)\n",
      "17:52:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:52:52 [INFO]   Training abgeschlossen in 17.97s (Backend: cuml)\n",
      "17:53:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:53:22 [INFO]   Training abgeschlossen in 18.24s (Backend: cuml)\n",
      "17:53:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:53:51 [INFO]   Training abgeschlossen in 18.48s (Backend: cuml)\n",
      "17:54:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:54:21 [INFO]   Training abgeschlossen in 18.67s (Backend: cuml)\n",
      "17:54:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:54:52 [INFO]   Training abgeschlossen in 18.86s (Backend: cuml)\n",
      "17:55:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:55:22 [INFO]   Training abgeschlossen in 19.14s (Backend: cuml)\n",
      "17:55:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:55:53 [INFO]   Training abgeschlossen in 19.30s (Backend: cuml)\n",
      "17:56:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:56:23 [INFO]   Training abgeschlossen in 19.67s (Backend: cuml)\n",
      "17:56:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:56:55 [INFO]   Training abgeschlossen in 19.79s (Backend: cuml)\n",
      "17:57:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:57:26 [INFO]   Training abgeschlossen in 20.14s (Backend: cuml)\n",
      "17:57:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:57:58 [INFO]   Training abgeschlossen in 20.26s (Backend: cuml)\n",
      "17:58:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:58:29 [INFO]   Training abgeschlossen in 20.48s (Backend: cuml)\n",
      "17:58:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:59:02 [INFO]   Training abgeschlossen in 20.89s (Backend: cuml)\n",
      "17:59:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:59:34 [INFO]   Training abgeschlossen in 20.87s (Backend: cuml)\n",
      "17:59:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:00:06 [INFO]   Training abgeschlossen in 21.27s (Backend: cuml)\n",
      "18:00:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:00:39 [INFO]   Training abgeschlossen in 21.22s (Backend: cuml)\n",
      "18:00:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:01:12 [INFO]   Training abgeschlossen in 21.58s (Backend: cuml)\n",
      "18:01:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:01:45 [INFO]   Training abgeschlossen in 21.86s (Backend: cuml)\n",
      "18:01:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:02:19 [INFO]   Training abgeschlossen in 22.07s (Backend: cuml)\n",
      "18:02:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:02:52 [INFO]   Training abgeschlossen in 22.32s (Backend: cuml)\n",
      "18:03:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:03:26 [INFO]   Training abgeschlossen in 22.38s (Backend: cuml)\n",
      "18:03:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:04:00 [INFO]   Training abgeschlossen in 22.66s (Backend: cuml)\n",
      "18:04:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:04:35 [INFO]   Training abgeschlossen in 22.82s (Backend: cuml)\n",
      "18:04:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:05:09 [INFO]   Training abgeschlossen in 23.09s (Backend: cuml)\n",
      "18:05:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:05:44 [INFO]   Training abgeschlossen in 23.42s (Backend: cuml)\n",
      "18:05:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:06:19 [INFO]   Training abgeschlossen in 23.37s (Backend: cuml)\n",
      "18:06:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:06:54 [INFO]   Training abgeschlossen in 23.78s (Backend: cuml)\n",
      "18:07:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:07:30 [INFO]   Training abgeschlossen in 24.01s (Backend: cuml)\n",
      "18:07:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:08:06 [INFO]   Training abgeschlossen in 24.22s (Backend: cuml)\n",
      "18:08:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:08:42 [INFO]   Training abgeschlossen in 24.36s (Backend: cuml)\n",
      "18:08:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:09:18 [INFO]   Training abgeschlossen in 24.55s (Backend: cuml)\n",
      "18:09:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:09:54 [INFO]   Training abgeschlossen in 24.84s (Backend: cuml)\n",
      "18:10:06 [INFO]     48,000 labeled → Accuracy: 0.9637 (Train: 24.9s, Query: 0.00s) | GPU: 2.7/8.0 GB\n",
      "18:10:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:10:31 [INFO]   Training abgeschlossen in 25.22s (Backend: cuml)\n",
      "18:10:42 [INFO]     Final: 48,000 labeled → Accuracy: 0.9633, F1: 0.9630\n",
      "18:10:43 [INFO]   Run 4/5\n",
      "18:10:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:10:48 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "18:10:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:11:03 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "18:11:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:11:18 [INFO]   Training abgeschlossen in 5.13s (Backend: cuml)\n",
      "18:11:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:11:33 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "18:11:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:11:49 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "18:11:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:12:05 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "18:12:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:12:21 [INFO]   Training abgeschlossen in 5.71s (Backend: cuml)\n",
      "18:12:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:12:37 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "18:12:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:12:54 [INFO]   Training abgeschlossen in 6.74s (Backend: cuml)\n",
      "18:13:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:13:12 [INFO]   Training abgeschlossen in 7.26s (Backend: cuml)\n",
      "18:13:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:13:29 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "18:13:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:13:47 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "18:13:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:14:06 [INFO]   Training abgeschlossen in 7.89s (Backend: cuml)\n",
      "18:14:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:14:25 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "18:14:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:14:43 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "18:14:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:15:02 [INFO]   Training abgeschlossen in 8.55s (Backend: cuml)\n",
      "18:15:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:15:22 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "18:15:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:15:41 [INFO]   Training abgeschlossen in 8.92s (Backend: cuml)\n",
      "18:15:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:16:01 [INFO]   Training abgeschlossen in 9.09s (Backend: cuml)\n",
      "18:16:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:16:20 [INFO]   Training abgeschlossen in 9.33s (Backend: cuml)\n",
      "18:16:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:16:40 [INFO]   Training abgeschlossen in 9.48s (Backend: cuml)\n",
      "18:16:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:17:01 [INFO]   Training abgeschlossen in 9.70s (Backend: cuml)\n",
      "18:17:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:17:21 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "18:17:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:17:42 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "18:17:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:18:03 [INFO]   Training abgeschlossen in 10.37s (Backend: cuml)\n",
      "18:18:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:18:24 [INFO]   Training abgeschlossen in 10.47s (Backend: cuml)\n",
      "18:18:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:18:46 [INFO]   Training abgeschlossen in 10.75s (Backend: cuml)\n",
      "18:18:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:19:07 [INFO]   Training abgeschlossen in 11.06s (Backend: cuml)\n",
      "18:19:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:19:29 [INFO]   Training abgeschlossen in 11.03s (Backend: cuml)\n",
      "18:19:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:19:51 [INFO]   Training abgeschlossen in 11.30s (Backend: cuml)\n",
      "18:20:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:20:13 [INFO]   Training abgeschlossen in 11.52s (Backend: cuml)\n",
      "18:20:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:20:36 [INFO]   Training abgeschlossen in 11.66s (Backend: cuml)\n",
      "18:20:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:20:59 [INFO]   Training abgeschlossen in 11.91s (Backend: cuml)\n",
      "18:21:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:21:21 [INFO]   Training abgeschlossen in 12.02s (Backend: cuml)\n",
      "18:21:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:21:44 [INFO]   Training abgeschlossen in 12.19s (Backend: cuml)\n",
      "18:21:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:22:08 [INFO]   Training abgeschlossen in 12.51s (Backend: cuml)\n",
      "18:22:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:22:31 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "18:22:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:22:55 [INFO]   Training abgeschlossen in 12.96s (Backend: cuml)\n",
      "18:23:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:23:19 [INFO]   Training abgeschlossen in 13.00s (Backend: cuml)\n",
      "18:23:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:23:43 [INFO]   Training abgeschlossen in 13.20s (Backend: cuml)\n",
      "18:23:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:24:07 [INFO]   Training abgeschlossen in 13.38s (Backend: cuml)\n",
      "18:24:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:24:32 [INFO]   Training abgeschlossen in 13.63s (Backend: cuml)\n",
      "18:24:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:24:56 [INFO]   Training abgeschlossen in 13.97s (Backend: cuml)\n",
      "18:25:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:25:21 [INFO]   Training abgeschlossen in 13.77s (Backend: cuml)\n",
      "18:25:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:25:46 [INFO]   Training abgeschlossen in 14.08s (Backend: cuml)\n",
      "18:25:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:26:11 [INFO]   Training abgeschlossen in 14.19s (Backend: cuml)\n",
      "18:26:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:26:37 [INFO]   Training abgeschlossen in 14.37s (Backend: cuml)\n",
      "18:26:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:27:02 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "18:27:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:27:28 [INFO]   Training abgeschlossen in 14.75s (Backend: cuml)\n",
      "18:27:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:27:54 [INFO]   Training abgeschlossen in 15.14s (Backend: cuml)\n",
      "18:28:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:28:21 [INFO]   Training abgeschlossen in 15.52s (Backend: cuml)\n",
      "18:28:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:28:47 [INFO]   Training abgeschlossen in 15.52s (Backend: cuml)\n",
      "18:28:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:29:14 [INFO]   Training abgeschlossen in 15.70s (Backend: cuml)\n",
      "18:29:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:29:41 [INFO]   Training abgeschlossen in 16.11s (Backend: cuml)\n",
      "18:29:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:30:08 [INFO]   Training abgeschlossen in 16.11s (Backend: cuml)\n",
      "18:30:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:30:36 [INFO]   Training abgeschlossen in 16.44s (Backend: cuml)\n",
      "18:30:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:31:03 [INFO]   Training abgeschlossen in 16.50s (Backend: cuml)\n",
      "18:31:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:31:31 [INFO]   Training abgeschlossen in 16.96s (Backend: cuml)\n",
      "18:31:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:32:00 [INFO]   Training abgeschlossen in 17.02s (Backend: cuml)\n",
      "18:32:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:32:28 [INFO]   Training abgeschlossen in 17.31s (Backend: cuml)\n",
      "18:32:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:32:57 [INFO]   Training abgeschlossen in 17.44s (Backend: cuml)\n",
      "18:33:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:33:26 [INFO]   Training abgeschlossen in 17.85s (Backend: cuml)\n",
      "18:33:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:33:55 [INFO]   Training abgeschlossen in 17.85s (Backend: cuml)\n",
      "18:34:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:34:24 [INFO]   Training abgeschlossen in 18.28s (Backend: cuml)\n",
      "18:34:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:34:54 [INFO]   Training abgeschlossen in 18.19s (Backend: cuml)\n",
      "18:35:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:35:24 [INFO]   Training abgeschlossen in 18.57s (Backend: cuml)\n",
      "18:35:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:35:53 [INFO]   Training abgeschlossen in 18.68s (Backend: cuml)\n",
      "18:36:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:36:24 [INFO]   Training abgeschlossen in 19.07s (Backend: cuml)\n",
      "18:36:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:36:54 [INFO]   Training abgeschlossen in 19.08s (Backend: cuml)\n",
      "18:37:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:37:25 [INFO]   Training abgeschlossen in 19.32s (Backend: cuml)\n",
      "18:37:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:37:56 [INFO]   Training abgeschlossen in 19.59s (Backend: cuml)\n",
      "18:38:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:38:27 [INFO]   Training abgeschlossen in 19.81s (Backend: cuml)\n",
      "18:38:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:38:58 [INFO]   Training abgeschlossen in 20.09s (Backend: cuml)\n",
      "18:39:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:39:30 [INFO]   Training abgeschlossen in 20.14s (Backend: cuml)\n",
      "18:39:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:40:02 [INFO]   Training abgeschlossen in 20.60s (Backend: cuml)\n",
      "18:40:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:40:34 [INFO]   Training abgeschlossen in 20.81s (Backend: cuml)\n",
      "18:40:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:41:06 [INFO]   Training abgeschlossen in 20.90s (Backend: cuml)\n",
      "18:41:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:41:39 [INFO]   Training abgeschlossen in 21.12s (Backend: cuml)\n",
      "18:41:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:42:11 [INFO]   Training abgeschlossen in 21.38s (Backend: cuml)\n",
      "18:42:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:42:45 [INFO]   Training abgeschlossen in 21.68s (Backend: cuml)\n",
      "18:42:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:43:18 [INFO]   Training abgeschlossen in 21.78s (Backend: cuml)\n",
      "18:43:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:43:51 [INFO]   Training abgeschlossen in 22.06s (Backend: cuml)\n",
      "18:44:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:44:25 [INFO]   Training abgeschlossen in 22.24s (Backend: cuml)\n",
      "18:44:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:44:59 [INFO]   Training abgeschlossen in 22.53s (Backend: cuml)\n",
      "18:45:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:45:33 [INFO]   Training abgeschlossen in 22.68s (Backend: cuml)\n",
      "18:45:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:46:07 [INFO]   Training abgeschlossen in 22.92s (Backend: cuml)\n",
      "18:46:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:46:42 [INFO]   Training abgeschlossen in 23.16s (Backend: cuml)\n",
      "18:46:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:47:17 [INFO]   Training abgeschlossen in 23.33s (Backend: cuml)\n",
      "18:47:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:47:52 [INFO]   Training abgeschlossen in 23.44s (Backend: cuml)\n",
      "18:48:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:48:27 [INFO]   Training abgeschlossen in 23.67s (Backend: cuml)\n",
      "18:48:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:49:03 [INFO]   Training abgeschlossen in 23.88s (Backend: cuml)\n",
      "18:49:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:49:38 [INFO]   Training abgeschlossen in 24.13s (Backend: cuml)\n",
      "18:49:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:50:14 [INFO]   Training abgeschlossen in 24.40s (Backend: cuml)\n",
      "18:50:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:50:50 [INFO]   Training abgeschlossen in 24.54s (Backend: cuml)\n",
      "18:51:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:51:27 [INFO]   Training abgeschlossen in 24.89s (Backend: cuml)\n",
      "18:51:38 [INFO]     48,000 labeled → Accuracy: 0.9641 (Train: 24.9s, Query: 0.00s) | GPU: 2.7/8.0 GB\n",
      "18:51:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:52:04 [INFO]   Training abgeschlossen in 25.05s (Backend: cuml)\n",
      "18:52:15 [INFO]     Final: 48,000 labeled → Accuracy: 0.9642, F1: 0.9639\n",
      "18:52:15 [INFO]   Run 5/5\n",
      "18:52:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:52:20 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "18:52:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:52:35 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "18:52:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:52:50 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "18:53:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:53:05 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "18:53:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:53:21 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "18:53:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:53:37 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "18:53:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:53:53 [INFO]   Training abgeschlossen in 5.73s (Backend: cuml)\n",
      "18:54:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:54:10 [INFO]   Training abgeschlossen in 6.33s (Backend: cuml)\n",
      "18:54:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:54:27 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "18:54:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:54:44 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "18:54:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:55:02 [INFO]   Training abgeschlossen in 7.45s (Backend: cuml)\n",
      "18:55:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:55:20 [INFO]   Training abgeschlossen in 7.54s (Backend: cuml)\n",
      "18:55:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:55:38 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "18:55:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:55:57 [INFO]   Training abgeschlossen in 8.20s (Backend: cuml)\n",
      "18:56:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:56:16 [INFO]   Training abgeschlossen in 8.65s (Backend: cuml)\n",
      "18:56:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:56:35 [INFO]   Training abgeschlossen in 8.65s (Backend: cuml)\n",
      "18:56:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:56:54 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "18:57:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:57:13 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "18:57:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:57:33 [INFO]   Training abgeschlossen in 9.19s (Backend: cuml)\n",
      "18:57:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:57:53 [INFO]   Training abgeschlossen in 9.29s (Backend: cuml)\n",
      "18:58:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:58:13 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "18:58:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:58:33 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "18:58:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:58:54 [INFO]   Training abgeschlossen in 9.99s (Backend: cuml)\n",
      "18:59:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:59:15 [INFO]   Training abgeschlossen in 10.02s (Backend: cuml)\n",
      "18:59:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:59:36 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "18:59:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:59:57 [INFO]   Training abgeschlossen in 10.65s (Backend: cuml)\n",
      "19:00:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:00:18 [INFO]   Training abgeschlossen in 10.73s (Backend: cuml)\n",
      "19:00:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:00:40 [INFO]   Training abgeschlossen in 10.95s (Backend: cuml)\n",
      "19:00:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:01:02 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "19:01:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:01:24 [INFO]   Training abgeschlossen in 11.26s (Backend: cuml)\n",
      "19:01:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:01:46 [INFO]   Training abgeschlossen in 11.52s (Backend: cuml)\n",
      "19:01:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:02:08 [INFO]   Training abgeschlossen in 11.67s (Backend: cuml)\n",
      "19:02:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:02:31 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "19:02:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:02:54 [INFO]   Training abgeschlossen in 12.16s (Backend: cuml)\n",
      "19:03:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:03:17 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "19:03:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:03:40 [INFO]   Training abgeschlossen in 12.42s (Backend: cuml)\n",
      "19:03:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:04:04 [INFO]   Training abgeschlossen in 12.61s (Backend: cuml)\n",
      "19:04:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:04:28 [INFO]   Training abgeschlossen in 12.80s (Backend: cuml)\n",
      "19:04:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:04:52 [INFO]   Training abgeschlossen in 13.17s (Backend: cuml)\n",
      "19:05:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:05:16 [INFO]   Training abgeschlossen in 13.19s (Backend: cuml)\n",
      "19:05:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:05:40 [INFO]   Training abgeschlossen in 13.57s (Backend: cuml)\n",
      "19:05:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:06:05 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "19:06:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:06:29 [INFO]   Training abgeschlossen in 13.84s (Backend: cuml)\n",
      "19:06:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:06:54 [INFO]   Training abgeschlossen in 13.82s (Backend: cuml)\n",
      "19:07:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:07:19 [INFO]   Training abgeschlossen in 13.94s (Backend: cuml)\n",
      "19:07:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:07:44 [INFO]   Training abgeschlossen in 14.22s (Backend: cuml)\n",
      "19:07:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:08:10 [INFO]   Training abgeschlossen in 14.36s (Backend: cuml)\n",
      "19:08:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:08:35 [INFO]   Training abgeschlossen in 14.72s (Backend: cuml)\n",
      "19:08:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:09:01 [INFO]   Training abgeschlossen in 14.85s (Backend: cuml)\n",
      "19:09:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:09:27 [INFO]   Training abgeschlossen in 15.10s (Backend: cuml)\n",
      "19:09:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:09:54 [INFO]   Training abgeschlossen in 15.57s (Backend: cuml)\n",
      "19:10:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:10:20 [INFO]   Training abgeschlossen in 15.47s (Backend: cuml)\n",
      "19:10:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:10:47 [INFO]   Training abgeschlossen in 15.65s (Backend: cuml)\n",
      "19:10:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:11:14 [INFO]   Training abgeschlossen in 15.90s (Backend: cuml)\n",
      "19:11:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:11:41 [INFO]   Training abgeschlossen in 16.21s (Backend: cuml)\n",
      "19:11:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:12:09 [INFO]   Training abgeschlossen in 16.28s (Backend: cuml)\n",
      "19:12:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:12:36 [INFO]   Training abgeschlossen in 16.66s (Backend: cuml)\n",
      "19:12:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:13:04 [INFO]   Training abgeschlossen in 16.84s (Backend: cuml)\n",
      "19:13:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:13:33 [INFO]   Training abgeschlossen in 17.04s (Backend: cuml)\n",
      "19:13:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:14:01 [INFO]   Training abgeschlossen in 17.10s (Backend: cuml)\n",
      "19:14:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:14:29 [INFO]   Training abgeschlossen in 17.47s (Backend: cuml)\n",
      "19:14:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:14:58 [INFO]   Training abgeschlossen in 17.64s (Backend: cuml)\n",
      "19:15:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:15:28 [INFO]   Training abgeschlossen in 17.99s (Backend: cuml)\n",
      "19:15:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:15:57 [INFO]   Training abgeschlossen in 18.12s (Backend: cuml)\n",
      "19:16:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:16:26 [INFO]   Training abgeschlossen in 18.35s (Backend: cuml)\n",
      "19:16:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:16:56 [INFO]   Training abgeschlossen in 18.52s (Backend: cuml)\n",
      "19:17:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:17:26 [INFO]   Training abgeschlossen in 18.71s (Backend: cuml)\n",
      "19:17:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:17:56 [INFO]   Training abgeschlossen in 19.03s (Backend: cuml)\n",
      "19:18:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:18:27 [INFO]   Training abgeschlossen in 19.11s (Backend: cuml)\n",
      "19:18:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:18:57 [INFO]   Training abgeschlossen in 19.51s (Backend: cuml)\n",
      "19:19:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:19:28 [INFO]   Training abgeschlossen in 19.57s (Backend: cuml)\n",
      "19:19:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:20:00 [INFO]   Training abgeschlossen in 19.94s (Backend: cuml)\n",
      "19:20:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:20:31 [INFO]   Training abgeschlossen in 20.00s (Backend: cuml)\n",
      "19:20:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:21:03 [INFO]   Training abgeschlossen in 20.40s (Backend: cuml)\n",
      "19:21:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:21:34 [INFO]   Training abgeschlossen in 20.42s (Backend: cuml)\n",
      "19:21:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:22:06 [INFO]   Training abgeschlossen in 20.76s (Backend: cuml)\n",
      "19:22:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:22:39 [INFO]   Training abgeschlossen in 20.83s (Backend: cuml)\n",
      "19:22:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:23:11 [INFO]   Training abgeschlossen in 20.94s (Backend: cuml)\n",
      "19:23:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:23:44 [INFO]   Training abgeschlossen in 21.33s (Backend: cuml)\n",
      "19:23:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:24:17 [INFO]   Training abgeschlossen in 21.45s (Backend: cuml)\n",
      "19:24:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:24:50 [INFO]   Training abgeschlossen in 21.79s (Backend: cuml)\n",
      "19:25:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:25:23 [INFO]   Training abgeschlossen in 21.95s (Backend: cuml)\n",
      "19:25:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:25:57 [INFO]   Training abgeschlossen in 22.10s (Backend: cuml)\n",
      "19:26:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:26:30 [INFO]   Training abgeschlossen in 22.41s (Backend: cuml)\n",
      "19:26:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:27:04 [INFO]   Training abgeschlossen in 22.48s (Backend: cuml)\n",
      "19:27:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:27:39 [INFO]   Training abgeschlossen in 22.83s (Backend: cuml)\n",
      "19:27:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:28:13 [INFO]   Training abgeschlossen in 22.92s (Backend: cuml)\n",
      "19:28:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:28:48 [INFO]   Training abgeschlossen in 23.25s (Backend: cuml)\n",
      "19:28:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:29:23 [INFO]   Training abgeschlossen in 23.58s (Backend: cuml)\n",
      "19:29:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:29:58 [INFO]   Training abgeschlossen in 23.70s (Backend: cuml)\n",
      "19:30:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:30:33 [INFO]   Training abgeschlossen in 23.91s (Backend: cuml)\n",
      "19:30:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:31:09 [INFO]   Training abgeschlossen in 24.06s (Backend: cuml)\n",
      "19:31:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:31:45 [INFO]   Training abgeschlossen in 24.22s (Backend: cuml)\n",
      "19:31:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:32:21 [INFO]   Training abgeschlossen in 24.63s (Backend: cuml)\n",
      "19:32:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:32:57 [INFO]   Training abgeschlossen in 24.73s (Backend: cuml)\n",
      "19:33:09 [INFO]     48,000 labeled → Accuracy: 0.9625 (Train: 24.8s, Query: 0.00s) | GPU: 2.7/8.0 GB\n",
      "19:33:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:33:34 [INFO]   Training abgeschlossen in 24.96s (Backend: cuml)\n",
      "19:33:45 [INFO]     Final: 48,000 labeled → Accuracy: 0.9630, F1: 0.9627\n",
      "19:33:45 [INFO] \n",
      "GPU-SVM + Random Sampling - Budget: 100% (60,000 Samples)\n",
      "19:33:45 [INFO]   Run 1/5\n",
      "19:33:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:33:50 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "19:34:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:34:05 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "19:34:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:34:21 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "19:34:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:34:36 [INFO]   Training abgeschlossen in 5.25s (Backend: cuml)\n",
      "19:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:34:51 [INFO]   Training abgeschlossen in 5.45s (Backend: cuml)\n",
      "19:35:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:35:07 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "19:35:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:35:23 [INFO]   Training abgeschlossen in 5.81s (Backend: cuml)\n",
      "19:35:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:35:40 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "19:35:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:35:57 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "19:36:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:36:14 [INFO]   Training abgeschlossen in 7.15s (Backend: cuml)\n",
      "19:36:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:36:32 [INFO]   Training abgeschlossen in 7.43s (Backend: cuml)\n",
      "19:36:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:36:50 [INFO]   Training abgeschlossen in 7.49s (Backend: cuml)\n",
      "19:37:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:37:08 [INFO]   Training abgeschlossen in 8.07s (Backend: cuml)\n",
      "19:37:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:37:27 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "19:37:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:37:46 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "19:37:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:38:05 [INFO]   Training abgeschlossen in 9.04s (Backend: cuml)\n",
      "19:38:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:38:25 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "19:38:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:38:44 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "19:38:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:39:04 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "19:39:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:39:23 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "19:39:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:39:44 [INFO]   Training abgeschlossen in 9.57s (Backend: cuml)\n",
      "19:39:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:40:04 [INFO]   Training abgeschlossen in 9.83s (Backend: cuml)\n",
      "19:40:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:40:24 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "19:40:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:40:45 [INFO]   Training abgeschlossen in 10.00s (Backend: cuml)\n",
      "19:40:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:41:06 [INFO]   Training abgeschlossen in 10.39s (Backend: cuml)\n",
      "19:41:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:41:27 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "19:41:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:41:48 [INFO]   Training abgeschlossen in 10.79s (Backend: cuml)\n",
      "19:41:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:42:10 [INFO]   Training abgeschlossen in 10.93s (Backend: cuml)\n",
      "19:42:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:42:32 [INFO]   Training abgeschlossen in 11.14s (Backend: cuml)\n",
      "19:42:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:42:54 [INFO]   Training abgeschlossen in 11.36s (Backend: cuml)\n",
      "19:43:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:43:16 [INFO]   Training abgeschlossen in 11.52s (Backend: cuml)\n",
      "19:43:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:43:38 [INFO]   Training abgeschlossen in 11.64s (Backend: cuml)\n",
      "19:43:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:44:01 [INFO]   Training abgeschlossen in 11.86s (Backend: cuml)\n",
      "19:44:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:44:24 [INFO]   Training abgeschlossen in 12.09s (Backend: cuml)\n",
      "19:44:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:44:47 [INFO]   Training abgeschlossen in 12.38s (Backend: cuml)\n",
      "19:44:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:45:10 [INFO]   Training abgeschlossen in 12.39s (Backend: cuml)\n",
      "19:45:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:45:34 [INFO]   Training abgeschlossen in 12.62s (Backend: cuml)\n",
      "19:45:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:45:57 [INFO]   Training abgeschlossen in 12.81s (Backend: cuml)\n",
      "19:46:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:46:21 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "19:46:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:46:45 [INFO]   Training abgeschlossen in 13.34s (Backend: cuml)\n",
      "19:46:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:47:10 [INFO]   Training abgeschlossen in 13.44s (Backend: cuml)\n",
      "19:47:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:47:34 [INFO]   Training abgeschlossen in 13.72s (Backend: cuml)\n",
      "19:47:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:47:59 [INFO]   Training abgeschlossen in 13.93s (Backend: cuml)\n",
      "19:48:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:48:24 [INFO]   Training abgeschlossen in 13.76s (Backend: cuml)\n",
      "19:48:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:48:49 [INFO]   Training abgeschlossen in 14.00s (Backend: cuml)\n",
      "19:49:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:49:14 [INFO]   Training abgeschlossen in 14.20s (Backend: cuml)\n",
      "19:49:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:49:40 [INFO]   Training abgeschlossen in 14.63s (Backend: cuml)\n",
      "19:49:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:50:05 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "19:50:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:50:31 [INFO]   Training abgeschlossen in 14.99s (Backend: cuml)\n",
      "19:50:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:50:58 [INFO]   Training abgeschlossen in 15.12s (Backend: cuml)\n",
      "19:51:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:51:24 [INFO]   Training abgeschlossen in 15.72s (Backend: cuml)\n",
      "19:51:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:51:51 [INFO]   Training abgeschlossen in 15.47s (Backend: cuml)\n",
      "19:52:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:52:18 [INFO]   Training abgeschlossen in 15.78s (Backend: cuml)\n",
      "19:52:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:52:45 [INFO]   Training abgeschlossen in 15.93s (Backend: cuml)\n",
      "19:52:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:53:12 [INFO]   Training abgeschlossen in 16.22s (Backend: cuml)\n",
      "19:53:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:53:40 [INFO]   Training abgeschlossen in 16.28s (Backend: cuml)\n",
      "19:53:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:54:07 [INFO]   Training abgeschlossen in 16.64s (Backend: cuml)\n",
      "19:54:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:54:35 [INFO]   Training abgeschlossen in 16.78s (Backend: cuml)\n",
      "19:54:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:55:03 [INFO]   Training abgeschlossen in 17.01s (Backend: cuml)\n",
      "19:55:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:55:32 [INFO]   Training abgeschlossen in 17.22s (Backend: cuml)\n",
      "19:55:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:56:00 [INFO]   Training abgeschlossen in 17.49s (Backend: cuml)\n",
      "19:56:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:56:29 [INFO]   Training abgeschlossen in 17.77s (Backend: cuml)\n",
      "19:56:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:56:58 [INFO]   Training abgeschlossen in 17.89s (Backend: cuml)\n",
      "19:57:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:57:28 [INFO]   Training abgeschlossen in 18.02s (Backend: cuml)\n",
      "19:57:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:57:57 [INFO]   Training abgeschlossen in 18.25s (Backend: cuml)\n",
      "19:58:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:58:27 [INFO]   Training abgeschlossen in 18.50s (Backend: cuml)\n",
      "19:58:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:58:57 [INFO]   Training abgeschlossen in 18.72s (Backend: cuml)\n",
      "19:59:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:59:27 [INFO]   Training abgeschlossen in 18.82s (Backend: cuml)\n",
      "19:59:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:59:57 [INFO]   Training abgeschlossen in 19.27s (Backend: cuml)\n",
      "20:00:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:00:28 [INFO]   Training abgeschlossen in 19.29s (Backend: cuml)\n",
      "20:00:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:00:59 [INFO]   Training abgeschlossen in 19.70s (Backend: cuml)\n",
      "20:01:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:01:30 [INFO]   Training abgeschlossen in 19.73s (Backend: cuml)\n",
      "20:01:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:02:01 [INFO]   Training abgeschlossen in 20.05s (Backend: cuml)\n",
      "20:02:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:02:33 [INFO]   Training abgeschlossen in 20.15s (Backend: cuml)\n",
      "20:02:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:03:05 [INFO]   Training abgeschlossen in 20.44s (Backend: cuml)\n",
      "20:03:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:03:37 [INFO]   Training abgeschlossen in 20.69s (Backend: cuml)\n",
      "20:03:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:04:09 [INFO]   Training abgeschlossen in 20.78s (Backend: cuml)\n",
      "20:04:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:04:41 [INFO]   Training abgeschlossen in 21.10s (Backend: cuml)\n",
      "20:04:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:05:14 [INFO]   Training abgeschlossen in 21.21s (Backend: cuml)\n",
      "20:05:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:05:47 [INFO]   Training abgeschlossen in 21.41s (Backend: cuml)\n",
      "20:05:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:06:20 [INFO]   Training abgeschlossen in 21.73s (Backend: cuml)\n",
      "20:06:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:06:53 [INFO]   Training abgeschlossen in 21.97s (Backend: cuml)\n",
      "20:07:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:07:27 [INFO]   Training abgeschlossen in 22.26s (Backend: cuml)\n",
      "20:07:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:08:01 [INFO]   Training abgeschlossen in 22.36s (Backend: cuml)\n",
      "20:08:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:08:35 [INFO]   Training abgeschlossen in 22.71s (Backend: cuml)\n",
      "20:08:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:09:09 [INFO]   Training abgeschlossen in 22.76s (Backend: cuml)\n",
      "20:09:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:09:43 [INFO]   Training abgeschlossen in 22.97s (Backend: cuml)\n",
      "20:09:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:10:18 [INFO]   Training abgeschlossen in 23.19s (Backend: cuml)\n",
      "20:10:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:10:53 [INFO]   Training abgeschlossen in 23.42s (Backend: cuml)\n",
      "20:11:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:11:28 [INFO]   Training abgeschlossen in 23.69s (Backend: cuml)\n",
      "20:11:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:12:04 [INFO]   Training abgeschlossen in 24.04s (Backend: cuml)\n",
      "20:12:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:12:39 [INFO]   Training abgeschlossen in 24.05s (Backend: cuml)\n",
      "20:12:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:13:15 [INFO]   Training abgeschlossen in 24.35s (Backend: cuml)\n",
      "20:13:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:13:51 [INFO]   Training abgeschlossen in 24.48s (Backend: cuml)\n",
      "20:14:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:14:27 [INFO]   Training abgeschlossen in 24.69s (Backend: cuml)\n",
      "20:14:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:15:04 [INFO]   Training abgeschlossen in 25.00s (Backend: cuml)\n",
      "20:15:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:15:40 [INFO]   Training abgeschlossen in 25.04s (Backend: cuml)\n",
      "20:15:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:16:17 [INFO]   Training abgeschlossen in 25.35s (Backend: cuml)\n",
      "20:16:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:16:55 [INFO]   Training abgeschlossen in 25.83s (Backend: cuml)\n",
      "20:17:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:17:44 [INFO]   Training abgeschlossen in 37.59s (Backend: cuml)\n",
      "20:17:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:18:36 [INFO]   Training abgeschlossen in 40.13s (Backend: cuml)\n",
      "20:18:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:19:26 [INFO]   Training abgeschlossen in 38.94s (Backend: cuml)\n",
      "20:19:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:20:18 [INFO]   Training abgeschlossen in 39.39s (Backend: cuml)\n",
      "20:20:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:21:09 [INFO]   Training abgeschlossen in 39.69s (Backend: cuml)\n",
      "20:21:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:22:01 [INFO]   Training abgeschlossen in 40.02s (Backend: cuml)\n",
      "20:22:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:22:51 [INFO]   Training abgeschlossen in 39.06s (Backend: cuml)\n",
      "20:23:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:23:41 [INFO]   Training abgeschlossen in 38.10s (Backend: cuml)\n",
      "20:23:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:24:33 [INFO]   Training abgeschlossen in 39.75s (Backend: cuml)\n",
      "20:24:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:25:25 [INFO]   Training abgeschlossen in 40.91s (Backend: cuml)\n",
      "20:25:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:26:19 [INFO]   Training abgeschlossen in 41.57s (Backend: cuml)\n",
      "20:26:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:27:09 [INFO]   Training abgeschlossen in 38.95s (Backend: cuml)\n",
      "20:27:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:28:04 [INFO]   Training abgeschlossen in 42.35s (Backend: cuml)\n",
      "20:28:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:28:56 [INFO]   Training abgeschlossen in 40.23s (Backend: cuml)\n",
      "20:29:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:29:50 [INFO]   Training abgeschlossen in 43.03s (Backend: cuml)\n",
      "20:30:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:30:45 [INFO]   Training abgeschlossen in 42.62s (Backend: cuml)\n",
      "20:30:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:31:39 [INFO]   Training abgeschlossen in 42.47s (Backend: cuml)\n",
      "20:31:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:32:33 [INFO]   Training abgeschlossen in 41.51s (Backend: cuml)\n",
      "20:32:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:33:26 [INFO]   Training abgeschlossen in 41.31s (Backend: cuml)\n",
      "20:33:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:34:22 [INFO]   Training abgeschlossen in 44.11s (Backend: cuml)\n",
      "20:34:33 [INFO]     60,000 labeled → Accuracy: 0.9658 (Train: 44.1s, Query: 0.00s) | GPU: 2.8/8.0 GB\n",
      "20:34:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:35:16 [INFO]   Training abgeschlossen in 42.86s (Backend: cuml)\n",
      "20:35:28 [INFO]     Final: 60,000 labeled → Accuracy: 0.9664, F1: 0.9661\n",
      "20:35:28 [INFO]   Run 2/5\n",
      "20:35:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:35:33 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "20:35:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:35:48 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "20:35:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:36:03 [INFO]   Training abgeschlossen in 5.02s (Backend: cuml)\n",
      "20:36:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:36:18 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "20:36:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:36:34 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "20:36:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:36:50 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "20:37:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:37:06 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "20:37:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:37:22 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "20:37:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:37:39 [INFO]   Training abgeschlossen in 6.65s (Backend: cuml)\n",
      "20:37:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:37:57 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "20:38:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:38:14 [INFO]   Training abgeschlossen in 7.26s (Backend: cuml)\n",
      "20:38:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:38:32 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "20:38:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:38:51 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "20:39:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:39:09 [INFO]   Training abgeschlossen in 8.25s (Backend: cuml)\n",
      "20:39:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:39:28 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "20:39:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:39:47 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "20:39:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:40:06 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "20:40:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:40:25 [INFO]   Training abgeschlossen in 8.92s (Backend: cuml)\n",
      "20:40:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:40:45 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "20:40:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:41:05 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "20:41:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:41:25 [INFO]   Training abgeschlossen in 9.51s (Backend: cuml)\n",
      "20:41:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:41:45 [INFO]   Training abgeschlossen in 9.80s (Backend: cuml)\n",
      "20:41:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:42:06 [INFO]   Training abgeschlossen in 9.87s (Backend: cuml)\n",
      "20:42:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:42:26 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "20:42:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:42:47 [INFO]   Training abgeschlossen in 10.36s (Backend: cuml)\n",
      "20:42:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:43:08 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "20:43:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:43:30 [INFO]   Training abgeschlossen in 10.92s (Backend: cuml)\n",
      "20:43:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:43:52 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "20:44:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:44:14 [INFO]   Training abgeschlossen in 11.09s (Backend: cuml)\n",
      "20:44:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:44:36 [INFO]   Training abgeschlossen in 11.39s (Backend: cuml)\n",
      "20:44:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:44:58 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "20:45:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:45:20 [INFO]   Training abgeschlossen in 11.64s (Backend: cuml)\n",
      "20:45:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:45:43 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "20:45:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:46:06 [INFO]   Training abgeschlossen in 12.04s (Backend: cuml)\n",
      "20:46:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:46:29 [INFO]   Training abgeschlossen in 12.27s (Backend: cuml)\n",
      "20:46:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:46:52 [INFO]   Training abgeschlossen in 12.46s (Backend: cuml)\n",
      "20:47:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:47:15 [INFO]   Training abgeschlossen in 12.66s (Backend: cuml)\n",
      "20:47:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:47:39 [INFO]   Training abgeschlossen in 12.81s (Backend: cuml)\n",
      "20:47:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:48:03 [INFO]   Training abgeschlossen in 13.04s (Backend: cuml)\n",
      "20:48:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:48:27 [INFO]   Training abgeschlossen in 13.34s (Backend: cuml)\n",
      "20:48:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:48:52 [INFO]   Training abgeschlossen in 13.38s (Backend: cuml)\n",
      "20:49:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:49:16 [INFO]   Training abgeschlossen in 13.82s (Backend: cuml)\n",
      "20:49:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:49:41 [INFO]   Training abgeschlossen in 13.79s (Backend: cuml)\n",
      "20:49:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:50:06 [INFO]   Training abgeschlossen in 13.73s (Backend: cuml)\n",
      "20:50:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:50:31 [INFO]   Training abgeschlossen in 13.98s (Backend: cuml)\n",
      "20:50:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:50:56 [INFO]   Training abgeschlossen in 14.15s (Backend: cuml)\n",
      "20:51:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:51:21 [INFO]   Training abgeschlossen in 14.42s (Backend: cuml)\n",
      "20:51:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:51:47 [INFO]   Training abgeschlossen in 14.56s (Backend: cuml)\n",
      "20:51:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:52:13 [INFO]   Training abgeschlossen in 14.95s (Backend: cuml)\n",
      "20:52:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:52:39 [INFO]   Training abgeschlossen in 15.00s (Backend: cuml)\n",
      "20:52:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:53:05 [INFO]   Training abgeschlossen in 15.61s (Backend: cuml)\n",
      "20:53:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:53:32 [INFO]   Training abgeschlossen in 15.48s (Backend: cuml)\n",
      "20:53:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:53:59 [INFO]   Training abgeschlossen in 15.83s (Backend: cuml)\n",
      "20:54:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:54:26 [INFO]   Training abgeschlossen in 15.95s (Backend: cuml)\n",
      "20:54:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:54:53 [INFO]   Training abgeschlossen in 16.17s (Backend: cuml)\n",
      "20:55:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:55:20 [INFO]   Training abgeschlossen in 16.25s (Backend: cuml)\n",
      "20:55:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:55:48 [INFO]   Training abgeschlossen in 16.55s (Backend: cuml)\n",
      "20:55:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:56:16 [INFO]   Training abgeschlossen in 16.85s (Backend: cuml)\n",
      "20:56:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:56:44 [INFO]   Training abgeschlossen in 16.90s (Backend: cuml)\n",
      "20:56:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:57:13 [INFO]   Training abgeschlossen in 17.19s (Backend: cuml)\n",
      "20:57:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:57:41 [INFO]   Training abgeschlossen in 17.41s (Backend: cuml)\n",
      "20:57:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:58:10 [INFO]   Training abgeschlossen in 17.65s (Backend: cuml)\n",
      "20:58:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:58:39 [INFO]   Training abgeschlossen in 17.97s (Backend: cuml)\n",
      "20:58:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:59:09 [INFO]   Training abgeschlossen in 18.20s (Backend: cuml)\n",
      "20:59:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:59:38 [INFO]   Training abgeschlossen in 18.30s (Backend: cuml)\n",
      "20:59:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:00:08 [INFO]   Training abgeschlossen in 18.52s (Backend: cuml)\n",
      "21:00:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:00:38 [INFO]   Training abgeschlossen in 18.77s (Backend: cuml)\n",
      "21:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:01:08 [INFO]   Training abgeschlossen in 19.01s (Backend: cuml)\n",
      "21:01:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:01:39 [INFO]   Training abgeschlossen in 19.14s (Backend: cuml)\n",
      "21:01:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:02:10 [INFO]   Training abgeschlossen in 19.40s (Backend: cuml)\n",
      "21:02:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:02:40 [INFO]   Training abgeschlossen in 19.54s (Backend: cuml)\n",
      "21:02:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:03:11 [INFO]   Training abgeschlossen in 19.74s (Backend: cuml)\n",
      "21:03:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:03:43 [INFO]   Training abgeschlossen in 19.97s (Backend: cuml)\n",
      "21:03:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:04:14 [INFO]   Training abgeschlossen in 20.25s (Backend: cuml)\n",
      "21:04:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:04:46 [INFO]   Training abgeschlossen in 20.54s (Backend: cuml)\n",
      "21:04:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:05:18 [INFO]   Training abgeschlossen in 20.59s (Backend: cuml)\n",
      "21:05:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:05:50 [INFO]   Training abgeschlossen in 20.87s (Backend: cuml)\n",
      "21:06:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:06:23 [INFO]   Training abgeschlossen in 20.98s (Backend: cuml)\n",
      "21:06:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:06:55 [INFO]   Training abgeschlossen in 21.22s (Backend: cuml)\n",
      "21:07:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:07:28 [INFO]   Training abgeschlossen in 21.42s (Backend: cuml)\n",
      "21:07:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:08:01 [INFO]   Training abgeschlossen in 21.63s (Backend: cuml)\n",
      "21:08:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:08:34 [INFO]   Training abgeschlossen in 21.89s (Backend: cuml)\n",
      "21:08:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:09:08 [INFO]   Training abgeschlossen in 22.21s (Backend: cuml)\n",
      "21:09:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:09:42 [INFO]   Training abgeschlossen in 22.34s (Backend: cuml)\n",
      "21:09:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:10:16 [INFO]   Training abgeschlossen in 22.54s (Backend: cuml)\n",
      "21:10:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:10:50 [INFO]   Training abgeschlossen in 23.06s (Backend: cuml)\n",
      "21:11:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:11:25 [INFO]   Training abgeschlossen in 23.14s (Backend: cuml)\n",
      "21:11:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:12:00 [INFO]   Training abgeschlossen in 23.32s (Backend: cuml)\n",
      "21:12:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:12:35 [INFO]   Training abgeschlossen in 23.45s (Backend: cuml)\n",
      "21:12:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:13:10 [INFO]   Training abgeschlossen in 23.62s (Backend: cuml)\n",
      "21:13:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:13:45 [INFO]   Training abgeschlossen in 23.84s (Backend: cuml)\n",
      "21:13:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:14:21 [INFO]   Training abgeschlossen in 24.15s (Backend: cuml)\n",
      "21:14:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:14:57 [INFO]   Training abgeschlossen in 24.30s (Backend: cuml)\n",
      "21:15:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:15:33 [INFO]   Training abgeschlossen in 24.42s (Backend: cuml)\n",
      "21:15:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:16:09 [INFO]   Training abgeschlossen in 24.72s (Backend: cuml)\n",
      "21:16:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:16:45 [INFO]   Training abgeschlossen in 24.92s (Backend: cuml)\n",
      "21:16:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:17:22 [INFO]   Training abgeschlossen in 25.03s (Backend: cuml)\n",
      "21:17:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:17:59 [INFO]   Training abgeschlossen in 25.31s (Backend: cuml)\n",
      "21:18:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:18:36 [INFO]   Training abgeschlossen in 25.71s (Backend: cuml)\n",
      "21:18:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:19:25 [INFO]   Training abgeschlossen in 36.67s (Backend: cuml)\n",
      "21:19:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:20:18 [INFO]   Training abgeschlossen in 41.94s (Backend: cuml)\n",
      "21:20:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:21:08 [INFO]   Training abgeschlossen in 38.34s (Backend: cuml)\n",
      "21:21:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:21:58 [INFO]   Training abgeschlossen in 38.17s (Backend: cuml)\n",
      "21:22:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:22:47 [INFO]   Training abgeschlossen in 37.55s (Backend: cuml)\n",
      "21:22:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:23:39 [INFO]   Training abgeschlossen in 40.26s (Backend: cuml)\n",
      "21:23:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:24:31 [INFO]   Training abgeschlossen in 40.01s (Backend: cuml)\n",
      "21:24:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:25:23 [INFO]   Training abgeschlossen in 40.54s (Backend: cuml)\n",
      "21:25:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:26:15 [INFO]   Training abgeschlossen in 40.00s (Backend: cuml)\n",
      "21:26:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:27:10 [INFO]   Training abgeschlossen in 42.99s (Backend: cuml)\n",
      "21:27:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:28:02 [INFO]   Training abgeschlossen in 40.40s (Backend: cuml)\n",
      "21:28:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:28:56 [INFO]   Training abgeschlossen in 42.76s (Backend: cuml)\n",
      "21:29:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:29:49 [INFO]   Training abgeschlossen in 41.12s (Backend: cuml)\n",
      "21:30:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:30:44 [INFO]   Training abgeschlossen in 42.88s (Backend: cuml)\n",
      "21:30:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:31:37 [INFO]   Training abgeschlossen in 41.64s (Backend: cuml)\n",
      "21:31:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:32:30 [INFO]   Training abgeschlossen in 40.78s (Backend: cuml)\n",
      "21:32:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:33:24 [INFO]   Training abgeschlossen in 42.29s (Backend: cuml)\n",
      "21:33:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:34:19 [INFO]   Training abgeschlossen in 42.71s (Backend: cuml)\n",
      "21:34:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:35:16 [INFO]   Training abgeschlossen in 44.68s (Backend: cuml)\n",
      "21:35:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:36:11 [INFO]   Training abgeschlossen in 43.26s (Backend: cuml)\n",
      "21:36:22 [INFO]     60,000 labeled → Accuracy: 0.9659 (Train: 43.3s, Query: 0.00s) | GPU: 2.8/8.0 GB\n",
      "21:36:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:37:06 [INFO]   Training abgeschlossen in 43.35s (Backend: cuml)\n",
      "21:37:18 [INFO]     Final: 60,000 labeled → Accuracy: 0.9659, F1: 0.9656\n",
      "21:37:18 [INFO]   Run 3/5\n",
      "21:37:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:37:23 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "21:37:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:37:38 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "21:37:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:37:53 [INFO]   Training abgeschlossen in 5.06s (Backend: cuml)\n",
      "21:38:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:38:09 [INFO]   Training abgeschlossen in 5.34s (Backend: cuml)\n",
      "21:38:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:38:24 [INFO]   Training abgeschlossen in 5.45s (Backend: cuml)\n",
      "21:38:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:38:40 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "21:38:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:38:56 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "21:39:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:39:13 [INFO]   Training abgeschlossen in 6.13s (Backend: cuml)\n",
      "21:39:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:39:30 [INFO]   Training abgeschlossen in 6.91s (Backend: cuml)\n",
      "21:39:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:39:48 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "21:39:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:40:05 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "21:40:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:40:23 [INFO]   Training abgeschlossen in 7.63s (Backend: cuml)\n",
      "21:40:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:40:42 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "21:40:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:41:01 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "21:41:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:41:20 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "21:41:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:41:39 [INFO]   Training abgeschlossen in 8.73s (Backend: cuml)\n",
      "21:41:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:41:58 [INFO]   Training abgeschlossen in 8.83s (Backend: cuml)\n",
      "21:42:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:42:18 [INFO]   Training abgeschlossen in 8.92s (Backend: cuml)\n",
      "21:42:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:42:37 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "21:42:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:42:57 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "21:43:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:43:17 [INFO]   Training abgeschlossen in 9.56s (Backend: cuml)\n",
      "21:43:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:43:38 [INFO]   Training abgeschlossen in 9.74s (Backend: cuml)\n",
      "21:43:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:43:58 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "21:44:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:44:19 [INFO]   Training abgeschlossen in 10.07s (Backend: cuml)\n",
      "21:44:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:44:40 [INFO]   Training abgeschlossen in 10.41s (Backend: cuml)\n",
      "21:44:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:45:01 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "21:45:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:45:23 [INFO]   Training abgeschlossen in 11.03s (Backend: cuml)\n",
      "21:45:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:45:45 [INFO]   Training abgeschlossen in 11.12s (Backend: cuml)\n",
      "21:45:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:46:07 [INFO]   Training abgeschlossen in 11.20s (Backend: cuml)\n",
      "21:46:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:46:29 [INFO]   Training abgeschlossen in 11.40s (Backend: cuml)\n",
      "21:46:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:46:51 [INFO]   Training abgeschlossen in 11.54s (Backend: cuml)\n",
      "21:47:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:47:14 [INFO]   Training abgeschlossen in 11.81s (Backend: cuml)\n",
      "21:47:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:47:36 [INFO]   Training abgeschlossen in 11.88s (Backend: cuml)\n",
      "21:47:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:47:59 [INFO]   Training abgeschlossen in 12.11s (Backend: cuml)\n",
      "21:48:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:48:22 [INFO]   Training abgeschlossen in 12.30s (Backend: cuml)\n",
      "21:48:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:48:46 [INFO]   Training abgeschlossen in 12.43s (Backend: cuml)\n",
      "21:48:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:49:09 [INFO]   Training abgeschlossen in 12.84s (Backend: cuml)\n",
      "21:49:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:49:33 [INFO]   Training abgeschlossen in 12.85s (Backend: cuml)\n",
      "21:49:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:49:57 [INFO]   Training abgeschlossen in 13.12s (Backend: cuml)\n",
      "21:50:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:50:21 [INFO]   Training abgeschlossen in 13.24s (Backend: cuml)\n",
      "21:50:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:50:46 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "21:50:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:51:10 [INFO]   Training abgeschlossen in 13.65s (Backend: cuml)\n",
      "21:51:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:51:35 [INFO]   Training abgeschlossen in 13.80s (Backend: cuml)\n",
      "21:51:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:52:00 [INFO]   Training abgeschlossen in 13.76s (Backend: cuml)\n",
      "21:52:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:52:25 [INFO]   Training abgeschlossen in 13.87s (Backend: cuml)\n",
      "21:52:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:52:50 [INFO]   Training abgeschlossen in 14.08s (Backend: cuml)\n",
      "21:53:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:53:15 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "21:53:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:53:40 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "21:53:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:54:06 [INFO]   Training abgeschlossen in 15.00s (Backend: cuml)\n",
      "21:54:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:54:32 [INFO]   Training abgeschlossen in 14.97s (Backend: cuml)\n",
      "21:54:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:54:59 [INFO]   Training abgeschlossen in 15.53s (Backend: cuml)\n",
      "21:55:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:55:25 [INFO]   Training abgeschlossen in 15.43s (Backend: cuml)\n",
      "21:55:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:55:52 [INFO]   Training abgeschlossen in 15.69s (Backend: cuml)\n",
      "21:56:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:56:19 [INFO]   Training abgeschlossen in 15.87s (Backend: cuml)\n",
      "21:56:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:56:46 [INFO]   Training abgeschlossen in 16.29s (Backend: cuml)\n",
      "21:56:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:57:14 [INFO]   Training abgeschlossen in 16.29s (Backend: cuml)\n",
      "21:57:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:57:41 [INFO]   Training abgeschlossen in 16.54s (Backend: cuml)\n",
      "21:57:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:58:09 [INFO]   Training abgeschlossen in 16.78s (Backend: cuml)\n",
      "21:58:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:58:37 [INFO]   Training abgeschlossen in 17.15s (Backend: cuml)\n",
      "21:58:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:59:05 [INFO]   Training abgeschlossen in 17.12s (Backend: cuml)\n",
      "21:59:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:59:34 [INFO]   Training abgeschlossen in 17.52s (Backend: cuml)\n",
      "21:59:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:00:03 [INFO]   Training abgeschlossen in 17.59s (Backend: cuml)\n",
      "22:00:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:00:32 [INFO]   Training abgeschlossen in 17.95s (Backend: cuml)\n",
      "22:00:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:01:01 [INFO]   Training abgeschlossen in 17.98s (Backend: cuml)\n",
      "22:01:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:01:31 [INFO]   Training abgeschlossen in 18.35s (Backend: cuml)\n",
      "22:01:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:02:00 [INFO]   Training abgeschlossen in 18.40s (Backend: cuml)\n",
      "22:02:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:02:31 [INFO]   Training abgeschlossen in 18.86s (Backend: cuml)\n",
      "22:02:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:03:01 [INFO]   Training abgeschlossen in 18.82s (Backend: cuml)\n",
      "22:03:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:03:31 [INFO]   Training abgeschlossen in 19.11s (Backend: cuml)\n",
      "22:03:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:04:02 [INFO]   Training abgeschlossen in 19.26s (Backend: cuml)\n",
      "22:04:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:04:32 [INFO]   Training abgeschlossen in 19.57s (Backend: cuml)\n",
      "22:04:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:05:03 [INFO]   Training abgeschlossen in 19.74s (Backend: cuml)\n",
      "22:05:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:05:35 [INFO]   Training abgeschlossen in 19.95s (Backend: cuml)\n",
      "22:05:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:06:06 [INFO]   Training abgeschlossen in 20.32s (Backend: cuml)\n",
      "22:06:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:06:38 [INFO]   Training abgeschlossen in 20.49s (Backend: cuml)\n",
      "22:06:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:07:11 [INFO]   Training abgeschlossen in 20.77s (Backend: cuml)\n",
      "22:07:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:07:43 [INFO]   Training abgeschlossen in 20.95s (Backend: cuml)\n",
      "22:07:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:08:15 [INFO]   Training abgeschlossen in 21.16s (Backend: cuml)\n",
      "22:08:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:08:48 [INFO]   Training abgeschlossen in 21.19s (Backend: cuml)\n",
      "22:08:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:09:21 [INFO]   Training abgeschlossen in 21.50s (Backend: cuml)\n",
      "22:09:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:09:54 [INFO]   Training abgeschlossen in 21.88s (Backend: cuml)\n",
      "22:10:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:10:28 [INFO]   Training abgeschlossen in 22.00s (Backend: cuml)\n",
      "22:10:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:11:01 [INFO]   Training abgeschlossen in 22.27s (Backend: cuml)\n",
      "22:11:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:11:35 [INFO]   Training abgeschlossen in 22.23s (Backend: cuml)\n",
      "22:11:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:12:09 [INFO]   Training abgeschlossen in 22.53s (Backend: cuml)\n",
      "22:12:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:12:43 [INFO]   Training abgeschlossen in 22.72s (Backend: cuml)\n",
      "22:12:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:13:18 [INFO]   Training abgeschlossen in 22.92s (Backend: cuml)\n",
      "22:13:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:13:52 [INFO]   Training abgeschlossen in 23.38s (Backend: cuml)\n",
      "22:14:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:14:27 [INFO]   Training abgeschlossen in 23.38s (Backend: cuml)\n",
      "22:14:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:15:03 [INFO]   Training abgeschlossen in 23.79s (Backend: cuml)\n",
      "22:15:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:15:38 [INFO]   Training abgeschlossen in 24.06s (Backend: cuml)\n",
      "22:15:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:16:14 [INFO]   Training abgeschlossen in 24.10s (Backend: cuml)\n",
      "22:16:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:16:50 [INFO]   Training abgeschlossen in 24.32s (Backend: cuml)\n",
      "22:17:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:17:26 [INFO]   Training abgeschlossen in 24.66s (Backend: cuml)\n",
      "22:17:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:18:02 [INFO]   Training abgeschlossen in 24.73s (Backend: cuml)\n",
      "22:18:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:18:39 [INFO]   Training abgeschlossen in 24.97s (Backend: cuml)\n",
      "22:18:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:19:16 [INFO]   Training abgeschlossen in 25.24s (Backend: cuml)\n",
      "22:19:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:19:53 [INFO]   Training abgeschlossen in 25.38s (Backend: cuml)\n",
      "22:20:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:20:30 [INFO]   Training abgeschlossen in 25.71s (Backend: cuml)\n",
      "22:20:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:21:19 [INFO]   Training abgeschlossen in 37.17s (Backend: cuml)\n",
      "22:21:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:22:09 [INFO]   Training abgeschlossen in 38.21s (Backend: cuml)\n",
      "22:22:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:22:59 [INFO]   Training abgeschlossen in 38.01s (Backend: cuml)\n",
      "22:23:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:23:50 [INFO]   Training abgeschlossen in 40.00s (Backend: cuml)\n",
      "22:24:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:24:40 [INFO]   Training abgeschlossen in 37.90s (Backend: cuml)\n",
      "22:24:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:25:31 [INFO]   Training abgeschlossen in 39.61s (Backend: cuml)\n",
      "22:25:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:26:23 [INFO]   Training abgeschlossen in 39.90s (Backend: cuml)\n",
      "22:26:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:27:16 [INFO]   Training abgeschlossen in 41.37s (Backend: cuml)\n",
      "22:27:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:28:06 [INFO]   Training abgeschlossen in 38.92s (Backend: cuml)\n",
      "22:28:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:29:00 [INFO]   Training abgeschlossen in 41.97s (Backend: cuml)\n",
      "22:29:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:29:55 [INFO]   Training abgeschlossen in 43.19s (Backend: cuml)\n",
      "22:30:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:30:48 [INFO]   Training abgeschlossen in 41.23s (Backend: cuml)\n",
      "22:31:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:31:41 [INFO]   Training abgeschlossen in 41.37s (Backend: cuml)\n",
      "22:31:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:32:35 [INFO]   Training abgeschlossen in 41.89s (Backend: cuml)\n",
      "22:32:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:33:30 [INFO]   Training abgeschlossen in 42.77s (Backend: cuml)\n",
      "22:33:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:34:24 [INFO]   Training abgeschlossen in 42.61s (Backend: cuml)\n",
      "22:34:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:35:21 [INFO]   Training abgeschlossen in 45.18s (Backend: cuml)\n",
      "22:35:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:36:16 [INFO]   Training abgeschlossen in 42.52s (Backend: cuml)\n",
      "22:36:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:37:11 [INFO]   Training abgeschlossen in 43.81s (Backend: cuml)\n",
      "22:37:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:38:06 [INFO]   Training abgeschlossen in 42.96s (Backend: cuml)\n",
      "22:38:18 [INFO]     60,000 labeled → Accuracy: 0.9658 (Train: 43.0s, Query: 0.00s) | GPU: 2.8/8.0 GB\n",
      "22:38:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:39:02 [INFO]   Training abgeschlossen in 44.33s (Backend: cuml)\n",
      "22:39:14 [INFO]     Final: 60,000 labeled → Accuracy: 0.9660, F1: 0.9657\n",
      "22:39:14 [INFO]   Run 4/5\n",
      "22:39:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:39:19 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "22:39:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:39:34 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "22:39:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:39:49 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "22:39:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:40:05 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "22:40:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:40:20 [INFO]   Training abgeschlossen in 5.42s (Backend: cuml)\n",
      "22:40:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:40:36 [INFO]   Training abgeschlossen in 5.59s (Backend: cuml)\n",
      "22:40:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:40:52 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "22:41:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:41:09 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "22:41:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:41:26 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "22:41:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:41:43 [INFO]   Training abgeschlossen in 7.04s (Backend: cuml)\n",
      "22:41:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:42:01 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "22:42:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:42:19 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "22:42:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:42:37 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "22:42:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:42:56 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "22:43:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:43:15 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "22:43:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:43:34 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "22:43:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:43:53 [INFO]   Training abgeschlossen in 8.73s (Backend: cuml)\n",
      "22:44:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:44:12 [INFO]   Training abgeschlossen in 8.89s (Backend: cuml)\n",
      "22:44:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:44:32 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "22:44:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:44:52 [INFO]   Training abgeschlossen in 9.35s (Backend: cuml)\n",
      "22:45:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:45:12 [INFO]   Training abgeschlossen in 9.51s (Backend: cuml)\n",
      "22:45:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:45:32 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "22:45:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:45:53 [INFO]   Training abgeschlossen in 10.00s (Backend: cuml)\n",
      "22:46:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:46:13 [INFO]   Training abgeschlossen in 10.05s (Backend: cuml)\n",
      "22:46:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:46:34 [INFO]   Training abgeschlossen in 10.25s (Backend: cuml)\n",
      "22:46:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:46:56 [INFO]   Training abgeschlossen in 10.67s (Backend: cuml)\n",
      "22:47:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:47:17 [INFO]   Training abgeschlossen in 10.79s (Backend: cuml)\n",
      "22:47:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:47:39 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "22:47:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:48:00 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "22:48:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:48:22 [INFO]   Training abgeschlossen in 11.24s (Backend: cuml)\n",
      "22:48:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:48:45 [INFO]   Training abgeschlossen in 11.50s (Backend: cuml)\n",
      "22:48:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:49:07 [INFO]   Training abgeschlossen in 11.74s (Backend: cuml)\n",
      "22:49:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:49:30 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "22:49:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:49:52 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "22:50:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:50:15 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "22:50:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:50:39 [INFO]   Training abgeschlossen in 12.50s (Backend: cuml)\n",
      "22:50:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:51:02 [INFO]   Training abgeschlossen in 12.58s (Backend: cuml)\n",
      "22:51:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:51:26 [INFO]   Training abgeschlossen in 12.76s (Backend: cuml)\n",
      "22:51:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:51:50 [INFO]   Training abgeschlossen in 12.99s (Backend: cuml)\n",
      "22:52:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:52:14 [INFO]   Training abgeschlossen in 13.19s (Backend: cuml)\n",
      "22:52:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:52:38 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "22:52:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:53:03 [INFO]   Training abgeschlossen in 13.63s (Backend: cuml)\n",
      "22:53:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:53:27 [INFO]   Training abgeschlossen in 13.90s (Backend: cuml)\n",
      "22:53:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:53:52 [INFO]   Training abgeschlossen in 13.75s (Backend: cuml)\n",
      "22:54:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:54:17 [INFO]   Training abgeschlossen in 14.00s (Backend: cuml)\n",
      "22:54:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:54:42 [INFO]   Training abgeschlossen in 14.26s (Backend: cuml)\n",
      "22:54:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:55:08 [INFO]   Training abgeschlossen in 14.45s (Backend: cuml)\n",
      "22:55:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:55:34 [INFO]   Training abgeschlossen in 14.82s (Backend: cuml)\n",
      "22:55:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:56:00 [INFO]   Training abgeschlossen in 14.96s (Backend: cuml)\n",
      "22:56:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:56:26 [INFO]   Training abgeschlossen in 15.23s (Backend: cuml)\n",
      "22:56:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:56:53 [INFO]   Training abgeschlossen in 15.54s (Backend: cuml)\n",
      "22:57:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:57:19 [INFO]   Training abgeschlossen in 15.56s (Backend: cuml)\n",
      "22:57:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:57:46 [INFO]   Training abgeschlossen in 15.74s (Backend: cuml)\n",
      "22:57:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:58:13 [INFO]   Training abgeschlossen in 16.01s (Backend: cuml)\n",
      "22:58:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:58:41 [INFO]   Training abgeschlossen in 16.16s (Backend: cuml)\n",
      "22:58:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:59:08 [INFO]   Training abgeschlossen in 16.28s (Backend: cuml)\n",
      "22:59:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:59:36 [INFO]   Training abgeschlossen in 16.49s (Backend: cuml)\n",
      "22:59:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:00:04 [INFO]   Training abgeschlossen in 16.76s (Backend: cuml)\n",
      "23:00:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:00:32 [INFO]   Training abgeschlossen in 16.95s (Backend: cuml)\n",
      "23:00:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:01:00 [INFO]   Training abgeschlossen in 17.11s (Backend: cuml)\n",
      "23:01:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:01:29 [INFO]   Training abgeschlossen in 17.38s (Backend: cuml)\n",
      "23:01:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:01:57 [INFO]   Training abgeschlossen in 17.60s (Backend: cuml)\n",
      "23:02:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:02:26 [INFO]   Training abgeschlossen in 17.85s (Backend: cuml)\n",
      "23:02:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:02:56 [INFO]   Training abgeschlossen in 18.02s (Backend: cuml)\n",
      "23:03:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:03:25 [INFO]   Training abgeschlossen in 18.19s (Backend: cuml)\n",
      "23:03:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:03:55 [INFO]   Training abgeschlossen in 18.42s (Backend: cuml)\n",
      "23:04:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:04:25 [INFO]   Training abgeschlossen in 18.64s (Backend: cuml)\n",
      "23:04:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:04:55 [INFO]   Training abgeschlossen in 18.93s (Backend: cuml)\n",
      "23:05:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:05:25 [INFO]   Training abgeschlossen in 19.08s (Backend: cuml)\n",
      "23:05:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:05:56 [INFO]   Training abgeschlossen in 19.49s (Backend: cuml)\n",
      "23:06:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:06:27 [INFO]   Training abgeschlossen in 19.52s (Backend: cuml)\n",
      "23:06:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:06:58 [INFO]   Training abgeschlossen in 19.87s (Backend: cuml)\n",
      "23:07:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:07:29 [INFO]   Training abgeschlossen in 19.90s (Backend: cuml)\n",
      "23:07:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:08:01 [INFO]   Training abgeschlossen in 20.30s (Backend: cuml)\n",
      "23:08:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:08:33 [INFO]   Training abgeschlossen in 20.55s (Backend: cuml)\n",
      "23:08:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:09:05 [INFO]   Training abgeschlossen in 20.62s (Backend: cuml)\n",
      "23:09:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:09:37 [INFO]   Training abgeschlossen in 20.85s (Backend: cuml)\n",
      "23:09:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:10:09 [INFO]   Training abgeschlossen in 21.09s (Backend: cuml)\n",
      "23:10:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:10:42 [INFO]   Training abgeschlossen in 21.35s (Backend: cuml)\n",
      "23:10:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:11:15 [INFO]   Training abgeschlossen in 21.47s (Backend: cuml)\n",
      "23:11:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:11:48 [INFO]   Training abgeschlossen in 21.89s (Backend: cuml)\n",
      "23:12:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:12:22 [INFO]   Training abgeschlossen in 21.99s (Backend: cuml)\n",
      "23:12:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:12:55 [INFO]   Training abgeschlossen in 22.17s (Backend: cuml)\n",
      "23:13:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:13:29 [INFO]   Training abgeschlossen in 22.40s (Backend: cuml)\n",
      "23:13:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:14:03 [INFO]   Training abgeschlossen in 22.63s (Backend: cuml)\n",
      "23:14:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:14:38 [INFO]   Training abgeschlossen in 22.90s (Backend: cuml)\n",
      "23:14:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:15:12 [INFO]   Training abgeschlossen in 22.99s (Backend: cuml)\n",
      "23:15:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:15:47 [INFO]   Training abgeschlossen in 23.21s (Backend: cuml)\n",
      "23:15:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:16:22 [INFO]   Training abgeschlossen in 23.50s (Backend: cuml)\n",
      "23:16:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:16:57 [INFO]   Training abgeschlossen in 23.68s (Backend: cuml)\n",
      "23:17:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:17:33 [INFO]   Training abgeschlossen in 24.02s (Backend: cuml)\n",
      "23:17:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:18:08 [INFO]   Training abgeschlossen in 24.05s (Backend: cuml)\n",
      "23:18:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:18:44 [INFO]   Training abgeschlossen in 24.33s (Backend: cuml)\n",
      "23:18:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:19:20 [INFO]   Training abgeschlossen in 24.61s (Backend: cuml)\n",
      "23:19:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:19:57 [INFO]   Training abgeschlossen in 24.73s (Backend: cuml)\n",
      "23:20:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:20:33 [INFO]   Training abgeschlossen in 25.01s (Backend: cuml)\n",
      "23:20:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:21:10 [INFO]   Training abgeschlossen in 25.22s (Backend: cuml)\n",
      "23:21:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:21:47 [INFO]   Training abgeschlossen in 25.34s (Backend: cuml)\n",
      "23:21:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:22:24 [INFO]   Training abgeschlossen in 25.79s (Backend: cuml)\n",
      "23:22:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:23:14 [INFO]   Training abgeschlossen in 38.41s (Backend: cuml)\n",
      "23:23:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:24:05 [INFO]   Training abgeschlossen in 39.16s (Backend: cuml)\n",
      "23:24:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:24:56 [INFO]   Training abgeschlossen in 38.85s (Backend: cuml)\n",
      "23:25:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:25:47 [INFO]   Training abgeschlossen in 39.39s (Backend: cuml)\n",
      "23:25:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:26:37 [INFO]   Training abgeschlossen in 38.21s (Backend: cuml)\n",
      "23:26:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:27:28 [INFO]   Training abgeschlossen in 39.81s (Backend: cuml)\n",
      "23:27:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:28:19 [INFO]   Training abgeschlossen in 39.35s (Backend: cuml)\n",
      "23:28:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:29:11 [INFO]   Training abgeschlossen in 39.76s (Backend: cuml)\n",
      "23:29:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:30:05 [INFO]   Training abgeschlossen in 42.40s (Backend: cuml)\n",
      "23:30:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:30:58 [INFO]   Training abgeschlossen in 41.57s (Backend: cuml)\n",
      "23:31:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:31:50 [INFO]   Training abgeschlossen in 40.33s (Backend: cuml)\n",
      "23:32:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:32:45 [INFO]   Training abgeschlossen in 42.77s (Backend: cuml)\n",
      "23:32:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:33:38 [INFO]   Training abgeschlossen in 41.22s (Backend: cuml)\n",
      "23:33:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:34:33 [INFO]   Training abgeschlossen in 43.07s (Backend: cuml)\n",
      "23:34:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:35:27 [INFO]   Training abgeschlossen in 42.45s (Backend: cuml)\n",
      "23:35:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:36:23 [INFO]   Training abgeschlossen in 43.74s (Backend: cuml)\n",
      "23:36:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:37:15 [INFO]   Training abgeschlossen in 40.55s (Backend: cuml)\n",
      "23:37:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:38:10 [INFO]   Training abgeschlossen in 43.66s (Backend: cuml)\n",
      "23:38:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:39:07 [INFO]   Training abgeschlossen in 44.54s (Backend: cuml)\n",
      "23:39:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:40:03 [INFO]   Training abgeschlossen in 44.14s (Backend: cuml)\n",
      "23:40:15 [INFO]     60,000 labeled → Accuracy: 0.9658 (Train: 44.2s, Query: 0.00s) | GPU: 2.8/8.0 GB\n",
      "23:40:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:40:57 [INFO]   Training abgeschlossen in 42.37s (Backend: cuml)\n",
      "23:41:09 [INFO]     Final: 60,000 labeled → Accuracy: 0.9663, F1: 0.9660\n",
      "23:41:09 [INFO]   Run 5/5\n",
      "23:41:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:41:14 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "23:41:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:41:29 [INFO]   Training abgeschlossen in 4.94s (Backend: cuml)\n",
      "23:41:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:41:44 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "23:41:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:42:00 [INFO]   Training abgeschlossen in 5.34s (Backend: cuml)\n",
      "23:42:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:42:15 [INFO]   Training abgeschlossen in 5.46s (Backend: cuml)\n",
      "23:42:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:42:31 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "23:42:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:42:47 [INFO]   Training abgeschlossen in 5.70s (Backend: cuml)\n",
      "23:42:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:43:03 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "23:43:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:43:20 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "23:43:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:43:38 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "23:43:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:43:56 [INFO]   Training abgeschlossen in 7.49s (Backend: cuml)\n",
      "23:44:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:44:14 [INFO]   Training abgeschlossen in 7.61s (Backend: cuml)\n",
      "23:44:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:44:32 [INFO]   Training abgeschlossen in 7.86s (Backend: cuml)\n",
      "23:44:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:44:51 [INFO]   Training abgeschlossen in 8.29s (Backend: cuml)\n",
      "23:45:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:45:10 [INFO]   Training abgeschlossen in 8.47s (Backend: cuml)\n",
      "23:45:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:45:29 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "23:45:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:45:48 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "23:45:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:46:07 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "23:46:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:46:27 [INFO]   Training abgeschlossen in 9.06s (Backend: cuml)\n",
      "23:46:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:46:46 [INFO]   Training abgeschlossen in 9.28s (Backend: cuml)\n",
      "23:46:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:47:07 [INFO]   Training abgeschlossen in 9.82s (Backend: cuml)\n",
      "23:47:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:47:27 [INFO]   Training abgeschlossen in 9.75s (Backend: cuml)\n",
      "23:47:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:47:48 [INFO]   Training abgeschlossen in 9.88s (Backend: cuml)\n",
      "23:47:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:48:09 [INFO]   Training abgeschlossen in 10.23s (Backend: cuml)\n",
      "23:48:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:48:30 [INFO]   Training abgeschlossen in 10.38s (Backend: cuml)\n",
      "23:48:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:48:51 [INFO]   Training abgeschlossen in 10.61s (Backend: cuml)\n",
      "23:49:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:49:12 [INFO]   Training abgeschlossen in 10.81s (Backend: cuml)\n",
      "23:49:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:49:34 [INFO]   Training abgeschlossen in 10.92s (Backend: cuml)\n",
      "23:49:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:49:56 [INFO]   Training abgeschlossen in 11.37s (Backend: cuml)\n",
      "23:50:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:50:18 [INFO]   Training abgeschlossen in 11.34s (Backend: cuml)\n",
      "23:50:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:50:40 [INFO]   Training abgeschlossen in 11.48s (Backend: cuml)\n",
      "23:50:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:51:03 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "23:51:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:51:26 [INFO]   Training abgeschlossen in 11.90s (Backend: cuml)\n",
      "23:51:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:51:48 [INFO]   Training abgeschlossen in 12.04s (Backend: cuml)\n",
      "23:51:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:52:12 [INFO]   Training abgeschlossen in 12.27s (Backend: cuml)\n",
      "23:52:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:52:35 [INFO]   Training abgeschlossen in 12.41s (Backend: cuml)\n",
      "23:52:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:52:59 [INFO]   Training abgeschlossen in 12.80s (Backend: cuml)\n",
      "23:53:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:53:22 [INFO]   Training abgeschlossen in 12.85s (Backend: cuml)\n",
      "23:53:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:53:46 [INFO]   Training abgeschlossen in 13.13s (Backend: cuml)\n",
      "23:53:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:54:10 [INFO]   Training abgeschlossen in 13.25s (Backend: cuml)\n",
      "23:54:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:54:35 [INFO]   Training abgeschlossen in 13.45s (Backend: cuml)\n",
      "23:54:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:54:59 [INFO]   Training abgeschlossen in 13.74s (Backend: cuml)\n",
      "23:55:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:55:24 [INFO]   Training abgeschlossen in 13.91s (Backend: cuml)\n",
      "23:55:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:55:49 [INFO]   Training abgeschlossen in 13.93s (Backend: cuml)\n",
      "23:56:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:56:14 [INFO]   Training abgeschlossen in 14.02s (Backend: cuml)\n",
      "23:56:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:56:39 [INFO]   Training abgeschlossen in 14.23s (Backend: cuml)\n",
      "23:56:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:57:04 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "23:57:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:57:30 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "23:57:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:57:56 [INFO]   Training abgeschlossen in 14.94s (Backend: cuml)\n",
      "23:58:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:58:22 [INFO]   Training abgeschlossen in 15.09s (Backend: cuml)\n",
      "23:58:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:58:49 [INFO]   Training abgeschlossen in 15.68s (Backend: cuml)\n",
      "23:59:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:59:16 [INFO]   Training abgeschlossen in 15.56s (Backend: cuml)\n",
      "23:59:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:59:43 [INFO]   Training abgeschlossen in 15.84s (Backend: cuml)\n",
      "23:59:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:00:10 [INFO]   Training abgeschlossen in 15.92s (Backend: cuml)\n",
      "00:00:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:00:37 [INFO]   Training abgeschlossen in 16.28s (Backend: cuml)\n",
      "00:00:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:01:04 [INFO]   Training abgeschlossen in 16.42s (Backend: cuml)\n",
      "00:01:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:01:32 [INFO]   Training abgeschlossen in 16.64s (Backend: cuml)\n",
      "00:01:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:02:00 [INFO]   Training abgeschlossen in 16.73s (Backend: cuml)\n",
      "00:02:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:02:28 [INFO]   Training abgeschlossen in 17.07s (Backend: cuml)\n",
      "00:02:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:02:57 [INFO]   Training abgeschlossen in 17.25s (Backend: cuml)\n",
      "00:03:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:03:25 [INFO]   Training abgeschlossen in 17.52s (Backend: cuml)\n",
      "00:03:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:03:54 [INFO]   Training abgeschlossen in 17.69s (Backend: cuml)\n",
      "00:04:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:04:23 [INFO]   Training abgeschlossen in 17.88s (Backend: cuml)\n",
      "00:04:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:04:53 [INFO]   Training abgeschlossen in 18.02s (Backend: cuml)\n",
      "00:05:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:05:22 [INFO]   Training abgeschlossen in 18.41s (Backend: cuml)\n",
      "00:05:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:05:52 [INFO]   Training abgeschlossen in 18.51s (Backend: cuml)\n",
      "00:06:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:06:22 [INFO]   Training abgeschlossen in 18.86s (Backend: cuml)\n",
      "00:06:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:06:52 [INFO]   Training abgeschlossen in 18.98s (Backend: cuml)\n",
      "00:07:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:07:23 [INFO]   Training abgeschlossen in 19.27s (Backend: cuml)\n",
      "00:07:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:07:53 [INFO]   Training abgeschlossen in 19.31s (Backend: cuml)\n",
      "00:08:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:08:24 [INFO]   Training abgeschlossen in 19.54s (Backend: cuml)\n",
      "00:08:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:08:55 [INFO]   Training abgeschlossen in 19.78s (Backend: cuml)\n",
      "00:09:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:09:27 [INFO]   Training abgeschlossen in 20.07s (Backend: cuml)\n",
      "00:09:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:09:58 [INFO]   Training abgeschlossen in 20.14s (Backend: cuml)\n",
      "00:10:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:10:30 [INFO]   Training abgeschlossen in 20.46s (Backend: cuml)\n",
      "00:10:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:11:02 [INFO]   Training abgeschlossen in 20.80s (Backend: cuml)\n",
      "00:11:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:11:35 [INFO]   Training abgeschlossen in 20.80s (Backend: cuml)\n",
      "00:11:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:12:07 [INFO]   Training abgeschlossen in 21.12s (Backend: cuml)\n",
      "00:12:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:12:40 [INFO]   Training abgeschlossen in 21.38s (Backend: cuml)\n",
      "00:12:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:13:13 [INFO]   Training abgeschlossen in 21.63s (Backend: cuml)\n",
      "00:13:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:13:46 [INFO]   Training abgeschlossen in 21.86s (Backend: cuml)\n",
      "00:13:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:14:19 [INFO]   Training abgeschlossen in 22.01s (Backend: cuml)\n",
      "00:14:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:14:53 [INFO]   Training abgeschlossen in 22.35s (Backend: cuml)\n",
      "00:15:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:15:27 [INFO]   Training abgeschlossen in 22.44s (Backend: cuml)\n",
      "00:15:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:16:01 [INFO]   Training abgeschlossen in 22.71s (Backend: cuml)\n",
      "00:16:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:16:36 [INFO]   Training abgeschlossen in 22.86s (Backend: cuml)\n",
      "00:16:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:17:10 [INFO]   Training abgeschlossen in 23.04s (Backend: cuml)\n",
      "00:17:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:17:45 [INFO]   Training abgeschlossen in 23.58s (Backend: cuml)\n",
      "00:17:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:18:20 [INFO]   Training abgeschlossen in 23.43s (Backend: cuml)\n",
      "00:18:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:18:56 [INFO]   Training abgeschlossen in 23.96s (Backend: cuml)\n",
      "00:19:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:19:31 [INFO]   Training abgeschlossen in 24.04s (Backend: cuml)\n",
      "00:19:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:20:07 [INFO]   Training abgeschlossen in 24.25s (Backend: cuml)\n",
      "00:20:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:20:44 [INFO]   Training abgeschlossen in 24.71s (Backend: cuml)\n",
      "00:20:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:21:20 [INFO]   Training abgeschlossen in 24.52s (Backend: cuml)\n",
      "00:21:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:21:56 [INFO]   Training abgeschlossen in 24.97s (Backend: cuml)\n",
      "00:22:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:22:33 [INFO]   Training abgeschlossen in 25.20s (Backend: cuml)\n",
      "00:22:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:23:10 [INFO]   Training abgeschlossen in 25.36s (Backend: cuml)\n",
      "00:23:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:23:47 [INFO]   Training abgeschlossen in 25.66s (Backend: cuml)\n",
      "00:23:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:24:25 [INFO]   Training abgeschlossen in 25.78s (Backend: cuml)\n",
      "00:24:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:25:13 [INFO]   Training abgeschlossen in 36.72s (Backend: cuml)\n",
      "00:25:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:26:05 [INFO]   Training abgeschlossen in 40.31s (Backend: cuml)\n",
      "00:26:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:26:54 [INFO]   Training abgeschlossen in 37.53s (Backend: cuml)\n",
      "00:27:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:27:45 [INFO]   Training abgeschlossen in 39.49s (Backend: cuml)\n",
      "00:27:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:28:38 [INFO]   Training abgeschlossen in 40.80s (Backend: cuml)\n",
      "00:28:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:29:29 [INFO]   Training abgeschlossen in 39.56s (Backend: cuml)\n",
      "00:29:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:30:21 [INFO]   Training abgeschlossen in 39.83s (Backend: cuml)\n",
      "00:30:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:31:12 [INFO]   Training abgeschlossen in 39.14s (Backend: cuml)\n",
      "00:31:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:32:03 [INFO]   Training abgeschlossen in 39.50s (Backend: cuml)\n",
      "00:32:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:32:57 [INFO]   Training abgeschlossen in 41.95s (Backend: cuml)\n",
      "00:33:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:33:50 [INFO]   Training abgeschlossen in 41.47s (Backend: cuml)\n",
      "00:34:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:34:44 [INFO]   Training abgeschlossen in 42.49s (Backend: cuml)\n",
      "00:34:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:35:37 [INFO]   Training abgeschlossen in 41.32s (Backend: cuml)\n",
      "00:35:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:36:33 [INFO]   Training abgeschlossen in 43.93s (Backend: cuml)\n",
      "00:36:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:37:27 [INFO]   Training abgeschlossen in 41.82s (Backend: cuml)\n",
      "00:37:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:38:20 [INFO]   Training abgeschlossen in 41.17s (Backend: cuml)\n",
      "00:38:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:39:13 [INFO]   Training abgeschlossen in 41.22s (Backend: cuml)\n",
      "00:39:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:40:09 [INFO]   Training abgeschlossen in 43.94s (Backend: cuml)\n",
      "00:40:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:41:04 [INFO]   Training abgeschlossen in 43.74s (Backend: cuml)\n",
      "00:41:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:42:00 [INFO]   Training abgeschlossen in 43.88s (Backend: cuml)\n",
      "00:42:12 [INFO]     60,000 labeled → Accuracy: 0.9665 (Train: 43.9s, Query: 0.00s) | GPU: 2.8/8.0 GB\n",
      "00:42:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "00:42:57 [INFO]   Training abgeschlossen in 44.91s (Backend: cuml)\n",
      "00:43:09 [INFO]     Final: 60,000 labeled → Accuracy: 0.9664, F1: 0.9661\n",
      "\n",
      "============================================================\n",
      "Strategie: Entropy Sampling\n",
      "============================================================\n",
      "00:43:09 [INFO] \n",
      "GPU-SVM + Entropy Sampling - Budget: 20% (12,000 Samples)\n",
      "00:43:09 [INFO]   Run 1/5\n",
      "00:43:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 0.1/8.0 GB)\n",
      "00:43:14 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "00:44:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "00:44:25 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "00:45:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "00:45:37 [INFO]   Training abgeschlossen in 5.05s (Backend: cuml)\n",
      "00:46:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "00:46:49 [INFO]   Training abgeschlossen in 5.18s (Backend: cuml)\n",
      "00:47:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:48:02 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "00:49:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:49:15 [INFO]   Training abgeschlossen in 5.79s (Backend: cuml)\n",
      "00:50:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:50:28 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "00:51:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:51:41 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "00:52:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:52:55 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "00:54:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:54:09 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "00:55:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:55:23 [INFO]   Training abgeschlossen in 7.73s (Backend: cuml)\n",
      "00:56:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:56:37 [INFO]   Training abgeschlossen in 7.92s (Backend: cuml)\n",
      "00:57:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:57:51 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "00:58:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:59:05 [INFO]   Training abgeschlossen in 8.37s (Backend: cuml)\n",
      "01:00:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:00:19 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "01:01:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:01:33 [INFO]   Training abgeschlossen in 8.83s (Backend: cuml)\n",
      "01:02:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:02:47 [INFO]   Training abgeschlossen in 9.15s (Backend: cuml)\n",
      "01:03:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:04:00 [INFO]   Training abgeschlossen in 9.22s (Backend: cuml)\n",
      "01:05:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:05:13 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "01:06:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:06:27 [INFO]   Training abgeschlossen in 9.81s (Backend: cuml)\n",
      "01:07:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:07:40 [INFO]   Training abgeschlossen in 9.87s (Backend: cuml)\n",
      "01:08:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:08:53 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "01:09:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:10:05 [INFO]   Training abgeschlossen in 10.27s (Backend: cuml)\n",
      "01:11:08 [INFO]     12,000 labeled → Accuracy: 0.9659 (Train: 10.3s, Query: 51.93s) | GPU: 2.6/8.0 GB\n",
      "01:11:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:11:19 [INFO]   Training abgeschlossen in 10.51s (Backend: cuml)\n",
      "01:11:29 [INFO]     Final: 12,000 labeled → Accuracy: 0.9658, F1: 0.9655\n",
      "01:11:30 [INFO]   Run 2/5\n",
      "01:11:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:11:34 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "01:12:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:12:46 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "01:13:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:13:57 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "01:15:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:15:09 [INFO]   Training abgeschlossen in 5.21s (Backend: cuml)\n",
      "01:16:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:16:22 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "01:17:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:17:34 [INFO]   Training abgeschlossen in 5.77s (Backend: cuml)\n",
      "01:18:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:18:47 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "01:19:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:20:01 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "01:21:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:21:14 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "01:22:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:22:28 [INFO]   Training abgeschlossen in 7.27s (Backend: cuml)\n",
      "01:23:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:23:43 [INFO]   Training abgeschlossen in 7.83s (Backend: cuml)\n",
      "01:24:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:24:57 [INFO]   Training abgeschlossen in 7.92s (Backend: cuml)\n",
      "01:26:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:26:11 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "01:27:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:27:25 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "01:28:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:28:39 [INFO]   Training abgeschlossen in 8.55s (Backend: cuml)\n",
      "01:29:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:29:53 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "01:30:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:31:06 [INFO]   Training abgeschlossen in 9.01s (Backend: cuml)\n",
      "01:32:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:32:20 [INFO]   Training abgeschlossen in 9.31s (Backend: cuml)\n",
      "01:33:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:33:34 [INFO]   Training abgeschlossen in 9.48s (Backend: cuml)\n",
      "01:34:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:34:47 [INFO]   Training abgeschlossen in 9.66s (Backend: cuml)\n",
      "01:35:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:36:00 [INFO]   Training abgeschlossen in 10.12s (Backend: cuml)\n",
      "01:37:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:37:13 [INFO]   Training abgeschlossen in 10.17s (Backend: cuml)\n",
      "01:38:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:38:26 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "01:39:27 [INFO]     12,000 labeled → Accuracy: 0.9670 (Train: 10.4s, Query: 50.92s) | GPU: 2.6/8.0 GB\n",
      "01:39:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:39:38 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "01:39:49 [INFO]     Final: 12,000 labeled → Accuracy: 0.9674, F1: 0.9671\n",
      "01:39:49 [INFO]   Run 3/5\n",
      "01:39:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:39:54 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "01:41:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:41:06 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "01:42:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:42:17 [INFO]   Training abgeschlossen in 5.03s (Backend: cuml)\n",
      "01:43:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:43:29 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "01:44:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:44:42 [INFO]   Training abgeschlossen in 5.51s (Backend: cuml)\n",
      "01:45:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:45:54 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "01:47:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:47:07 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "01:48:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:48:20 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "01:49:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:49:34 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "01:50:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:50:48 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "01:51:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:52:02 [INFO]   Training abgeschlossen in 7.82s (Backend: cuml)\n",
      "01:53:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:53:16 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "01:54:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:54:30 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "01:55:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:55:44 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "01:56:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:56:58 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "01:58:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:58:12 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "01:59:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:59:25 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "02:00:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:00:39 [INFO]   Training abgeschlossen in 9.37s (Backend: cuml)\n",
      "02:01:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:01:52 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "02:02:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:03:06 [INFO]   Training abgeschlossen in 9.61s (Backend: cuml)\n",
      "02:04:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:04:19 [INFO]   Training abgeschlossen in 9.90s (Backend: cuml)\n",
      "02:05:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:05:31 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "02:06:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:06:45 [INFO]   Training abgeschlossen in 10.27s (Backend: cuml)\n",
      "02:07:48 [INFO]     12,000 labeled → Accuracy: 0.9658 (Train: 10.3s, Query: 51.93s) | GPU: 2.6/8.0 GB\n",
      "02:07:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:07:59 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "02:08:09 [INFO]     Final: 12,000 labeled → Accuracy: 0.9657, F1: 0.9654\n",
      "02:08:10 [INFO]   Run 4/5\n",
      "02:08:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:08:14 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "02:09:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:09:26 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "02:10:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:10:38 [INFO]   Training abgeschlossen in 5.01s (Backend: cuml)\n",
      "02:11:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:11:50 [INFO]   Training abgeschlossen in 5.28s (Backend: cuml)\n",
      "02:12:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:13:02 [INFO]   Training abgeschlossen in 5.45s (Backend: cuml)\n",
      "02:14:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:14:15 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "02:15:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:15:28 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "02:16:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:16:41 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "02:17:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:17:55 [INFO]   Training abgeschlossen in 6.74s (Backend: cuml)\n",
      "02:19:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:19:09 [INFO]   Training abgeschlossen in 7.14s (Backend: cuml)\n",
      "02:20:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:20:23 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "02:21:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:21:37 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "02:22:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:22:51 [INFO]   Training abgeschlossen in 7.98s (Backend: cuml)\n",
      "02:23:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:24:05 [INFO]   Training abgeschlossen in 8.37s (Backend: cuml)\n",
      "02:25:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:25:19 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "02:26:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:26:32 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "02:27:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:27:46 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "02:28:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:28:59 [INFO]   Training abgeschlossen in 9.16s (Backend: cuml)\n",
      "02:30:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:30:12 [INFO]   Training abgeschlossen in 9.37s (Backend: cuml)\n",
      "02:31:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:31:25 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "02:32:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:32:38 [INFO]   Training abgeschlossen in 10.03s (Backend: cuml)\n",
      "02:33:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:33:51 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "02:34:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:35:04 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "02:36:05 [INFO]     12,000 labeled → Accuracy: 0.9668 (Train: 10.3s, Query: 50.88s) | GPU: 2.6/8.0 GB\n",
      "02:36:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:36:16 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "02:36:27 [INFO]     Final: 12,000 labeled → Accuracy: 0.9658, F1: 0.9654\n",
      "02:36:27 [INFO]   Run 5/5\n",
      "02:36:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:36:32 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "02:37:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:37:44 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "02:38:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:38:55 [INFO]   Training abgeschlossen in 5.04s (Backend: cuml)\n",
      "02:40:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:40:07 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "02:41:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:41:20 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "02:42:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:42:33 [INFO]   Training abgeschlossen in 5.65s (Backend: cuml)\n",
      "02:43:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:43:46 [INFO]   Training abgeschlossen in 6.06s (Backend: cuml)\n",
      "02:44:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:44:59 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "02:46:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:46:13 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "02:47:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:47:26 [INFO]   Training abgeschlossen in 7.17s (Backend: cuml)\n",
      "02:48:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:48:41 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "02:49:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:49:56 [INFO]   Training abgeschlossen in 7.94s (Backend: cuml)\n",
      "02:51:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:51:10 [INFO]   Training abgeschlossen in 8.20s (Backend: cuml)\n",
      "02:52:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:52:24 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "02:53:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:53:38 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "02:54:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:54:52 [INFO]   Training abgeschlossen in 8.71s (Backend: cuml)\n",
      "02:55:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:56:05 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "02:57:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:57:19 [INFO]   Training abgeschlossen in 9.34s (Backend: cuml)\n",
      "02:58:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:58:33 [INFO]   Training abgeschlossen in 9.50s (Backend: cuml)\n",
      "02:59:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:59:46 [INFO]   Training abgeschlossen in 9.63s (Backend: cuml)\n",
      "03:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:00:59 [INFO]   Training abgeschlossen in 9.94s (Backend: cuml)\n",
      "03:02:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:02:12 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "03:03:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:03:26 [INFO]   Training abgeschlossen in 10.37s (Backend: cuml)\n",
      "03:04:29 [INFO]     12,000 labeled → Accuracy: 0.9659 (Train: 10.4s, Query: 51.99s) | GPU: 2.6/8.0 GB\n",
      "03:04:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:04:39 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "03:04:50 [INFO]     Final: 12,000 labeled → Accuracy: 0.9668, F1: 0.9665\n",
      "03:04:50 [INFO] \n",
      "GPU-SVM + Entropy Sampling - Budget: 40% (24,000 Samples)\n",
      "03:04:50 [INFO]   Run 1/5\n",
      "03:04:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:04:55 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "03:06:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:06:07 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "03:07:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:07:19 [INFO]   Training abgeschlossen in 5.06s (Backend: cuml)\n",
      "03:08:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:08:31 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "03:09:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:09:44 [INFO]   Training abgeschlossen in 5.43s (Backend: cuml)\n",
      "03:10:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:10:57 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "03:12:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:12:10 [INFO]   Training abgeschlossen in 5.88s (Backend: cuml)\n",
      "03:13:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:13:23 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "03:14:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:14:37 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "03:15:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:15:51 [INFO]   Training abgeschlossen in 7.15s (Backend: cuml)\n",
      "03:16:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:17:04 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "03:18:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:18:19 [INFO]   Training abgeschlossen in 7.94s (Backend: cuml)\n",
      "03:19:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:19:32 [INFO]   Training abgeschlossen in 8.06s (Backend: cuml)\n",
      "03:20:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:20:46 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "03:21:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:22:00 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "03:23:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:23:14 [INFO]   Training abgeschlossen in 8.69s (Backend: cuml)\n",
      "03:24:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:24:27 [INFO]   Training abgeschlossen in 8.94s (Backend: cuml)\n",
      "03:25:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:25:41 [INFO]   Training abgeschlossen in 9.22s (Backend: cuml)\n",
      "03:26:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:26:54 [INFO]   Training abgeschlossen in 9.50s (Backend: cuml)\n",
      "03:27:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:28:07 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "03:29:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:29:20 [INFO]   Training abgeschlossen in 9.87s (Backend: cuml)\n",
      "03:30:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:30:33 [INFO]   Training abgeschlossen in 10.20s (Backend: cuml)\n",
      "03:31:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:31:46 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "03:32:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:32:59 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "03:34:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:34:12 [INFO]   Training abgeschlossen in 10.70s (Backend: cuml)\n",
      "03:35:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:35:26 [INFO]   Training abgeschlossen in 11.12s (Backend: cuml)\n",
      "03:36:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:36:39 [INFO]   Training abgeschlossen in 11.22s (Backend: cuml)\n",
      "03:37:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:37:51 [INFO]   Training abgeschlossen in 11.41s (Backend: cuml)\n",
      "03:38:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:39:03 [INFO]   Training abgeschlossen in 11.56s (Backend: cuml)\n",
      "03:40:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:40:14 [INFO]   Training abgeschlossen in 11.84s (Backend: cuml)\n",
      "03:41:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:41:24 [INFO]   Training abgeschlossen in 11.93s (Backend: cuml)\n",
      "03:42:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:42:35 [INFO]   Training abgeschlossen in 12.15s (Backend: cuml)\n",
      "03:43:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:43:45 [INFO]   Training abgeschlossen in 12.38s (Backend: cuml)\n",
      "03:44:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:44:56 [INFO]   Training abgeschlossen in 12.84s (Backend: cuml)\n",
      "03:45:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:46:06 [INFO]   Training abgeschlossen in 12.88s (Backend: cuml)\n",
      "03:47:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:47:15 [INFO]   Training abgeschlossen in 13.04s (Backend: cuml)\n",
      "03:48:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:48:25 [INFO]   Training abgeschlossen in 13.23s (Backend: cuml)\n",
      "03:49:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:49:34 [INFO]   Training abgeschlossen in 13.47s (Backend: cuml)\n",
      "03:50:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:50:44 [INFO]   Training abgeschlossen in 13.82s (Backend: cuml)\n",
      "03:51:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:51:53 [INFO]   Training abgeschlossen in 13.86s (Backend: cuml)\n",
      "03:52:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:53:03 [INFO]   Training abgeschlossen in 14.11s (Backend: cuml)\n",
      "03:53:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:54:12 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "03:55:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:55:21 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "03:56:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:56:28 [INFO]   Training abgeschlossen in 14.58s (Backend: cuml)\n",
      "03:57:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:57:36 [INFO]   Training abgeschlossen in 14.69s (Backend: cuml)\n",
      "03:58:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:58:43 [INFO]   Training abgeschlossen in 14.86s (Backend: cuml)\n",
      "03:59:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:59:49 [INFO]   Training abgeschlossen in 15.07s (Backend: cuml)\n",
      "04:00:40 [INFO]     24,000 labeled → Accuracy: 0.9663 (Train: 15.1s, Query: 39.97s) | GPU: 2.7/8.0 GB\n",
      "04:00:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:00:56 [INFO]   Training abgeschlossen in 15.28s (Backend: cuml)\n",
      "04:01:07 [INFO]     Final: 24,000 labeled → Accuracy: 0.9666, F1: 0.9664\n",
      "04:01:07 [INFO]   Run 2/5\n",
      "04:01:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:01:12 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "04:02:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "04:02:24 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "04:03:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "04:03:35 [INFO]   Training abgeschlossen in 5.04s (Backend: cuml)\n",
      "04:04:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "04:04:47 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "04:05:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:06:00 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "04:07:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:07:12 [INFO]   Training abgeschlossen in 5.75s (Backend: cuml)\n",
      "04:08:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:08:25 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "04:09:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:09:39 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "04:10:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:10:52 [INFO]   Training abgeschlossen in 6.85s (Backend: cuml)\n",
      "04:11:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:12:06 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "04:13:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:13:21 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "04:14:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:14:35 [INFO]   Training abgeschlossen in 8.06s (Backend: cuml)\n",
      "04:15:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:15:49 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "04:16:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:17:03 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "04:18:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:18:17 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "04:19:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:19:30 [INFO]   Training abgeschlossen in 8.83s (Backend: cuml)\n",
      "04:20:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:20:44 [INFO]   Training abgeschlossen in 9.04s (Backend: cuml)\n",
      "04:21:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:21:58 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "04:23:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:23:11 [INFO]   Training abgeschlossen in 9.56s (Backend: cuml)\n",
      "04:24:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:24:24 [INFO]   Training abgeschlossen in 9.72s (Backend: cuml)\n",
      "04:25:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:25:37 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "04:26:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:26:50 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "04:27:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:28:03 [INFO]   Training abgeschlossen in 10.36s (Backend: cuml)\n",
      "04:29:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:29:16 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "04:30:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:30:28 [INFO]   Training abgeschlossen in 10.74s (Backend: cuml)\n",
      "04:31:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:31:40 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "04:32:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:32:52 [INFO]   Training abgeschlossen in 11.23s (Backend: cuml)\n",
      "04:33:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:34:04 [INFO]   Training abgeschlossen in 11.42s (Backend: cuml)\n",
      "04:35:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:35:15 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "04:36:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:36:26 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "04:37:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:37:37 [INFO]   Training abgeschlossen in 12.11s (Backend: cuml)\n",
      "04:38:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:38:48 [INFO]   Training abgeschlossen in 12.24s (Backend: cuml)\n",
      "04:39:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:39:58 [INFO]   Training abgeschlossen in 12.46s (Backend: cuml)\n",
      "04:40:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:41:09 [INFO]   Training abgeschlossen in 12.68s (Backend: cuml)\n",
      "04:42:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:42:19 [INFO]   Training abgeschlossen in 12.96s (Backend: cuml)\n",
      "04:43:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:43:29 [INFO]   Training abgeschlossen in 13.23s (Backend: cuml)\n",
      "04:44:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:44:38 [INFO]   Training abgeschlossen in 13.29s (Backend: cuml)\n",
      "04:45:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:45:48 [INFO]   Training abgeschlossen in 13.50s (Backend: cuml)\n",
      "04:46:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:46:56 [INFO]   Training abgeschlossen in 13.67s (Backend: cuml)\n",
      "04:47:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:48:06 [INFO]   Training abgeschlossen in 13.98s (Backend: cuml)\n",
      "04:49:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:49:15 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "04:50:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:50:23 [INFO]   Training abgeschlossen in 14.39s (Backend: cuml)\n",
      "04:51:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:51:31 [INFO]   Training abgeschlossen in 14.56s (Backend: cuml)\n",
      "04:52:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:52:38 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "04:53:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:53:46 [INFO]   Training abgeschlossen in 14.70s (Backend: cuml)\n",
      "04:54:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:54:53 [INFO]   Training abgeschlossen in 14.99s (Backend: cuml)\n",
      "04:55:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:55:59 [INFO]   Training abgeschlossen in 15.20s (Backend: cuml)\n",
      "04:56:50 [INFO]     24,000 labeled → Accuracy: 0.9665 (Train: 15.2s, Query: 39.56s) | GPU: 2.7/8.0 GB\n",
      "04:56:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:57:06 [INFO]   Training abgeschlossen in 15.35s (Backend: cuml)\n",
      "04:57:17 [INFO]     Final: 24,000 labeled → Accuracy: 0.9665, F1: 0.9662\n",
      "04:57:17 [INFO]   Run 3/5\n",
      "04:57:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:57:22 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "04:58:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "04:58:34 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "04:59:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "04:59:46 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "05:00:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "05:00:58 [INFO]   Training abgeschlossen in 5.21s (Backend: cuml)\n",
      "05:02:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:02:11 [INFO]   Training abgeschlossen in 5.52s (Backend: cuml)\n",
      "05:03:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:03:23 [INFO]   Training abgeschlossen in 5.65s (Backend: cuml)\n",
      "05:04:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:04:36 [INFO]   Training abgeschlossen in 5.88s (Backend: cuml)\n",
      "05:05:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:05:49 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "05:06:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:07:03 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "05:08:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:08:17 [INFO]   Training abgeschlossen in 7.36s (Backend: cuml)\n",
      "05:09:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:09:31 [INFO]   Training abgeschlossen in 7.69s (Backend: cuml)\n",
      "05:10:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:10:45 [INFO]   Training abgeschlossen in 7.91s (Backend: cuml)\n",
      "05:11:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:11:59 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "05:13:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:13:13 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "05:14:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:14:26 [INFO]   Training abgeschlossen in 8.53s (Backend: cuml)\n",
      "05:15:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:15:40 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "05:16:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:16:54 [INFO]   Training abgeschlossen in 9.06s (Backend: cuml)\n",
      "05:17:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:18:07 [INFO]   Training abgeschlossen in 9.22s (Backend: cuml)\n",
      "05:19:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:19:20 [INFO]   Training abgeschlossen in 9.42s (Backend: cuml)\n",
      "05:20:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:20:34 [INFO]   Training abgeschlossen in 9.75s (Backend: cuml)\n",
      "05:21:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:21:46 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "05:22:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:22:59 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "05:24:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:24:13 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "05:25:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:25:27 [INFO]   Training abgeschlossen in 10.60s (Backend: cuml)\n",
      "05:26:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:26:40 [INFO]   Training abgeschlossen in 10.72s (Backend: cuml)\n",
      "05:27:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:27:52 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "05:28:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:29:04 [INFO]   Training abgeschlossen in 11.28s (Backend: cuml)\n",
      "05:30:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:30:17 [INFO]   Training abgeschlossen in 11.44s (Backend: cuml)\n",
      "05:31:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:31:29 [INFO]   Training abgeschlossen in 11.58s (Backend: cuml)\n",
      "05:32:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:32:41 [INFO]   Training abgeschlossen in 11.74s (Backend: cuml)\n",
      "05:33:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:33:52 [INFO]   Training abgeschlossen in 12.05s (Backend: cuml)\n",
      "05:34:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:35:04 [INFO]   Training abgeschlossen in 12.32s (Backend: cuml)\n",
      "05:36:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:36:14 [INFO]   Training abgeschlossen in 12.46s (Backend: cuml)\n",
      "05:37:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:37:26 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "05:38:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:38:36 [INFO]   Training abgeschlossen in 12.99s (Backend: cuml)\n",
      "05:39:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:39:46 [INFO]   Training abgeschlossen in 13.10s (Backend: cuml)\n",
      "05:40:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:40:56 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "05:41:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:42:06 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "05:43:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:43:16 [INFO]   Training abgeschlossen in 13.64s (Backend: cuml)\n",
      "05:44:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:44:24 [INFO]   Training abgeschlossen in 13.90s (Backend: cuml)\n",
      "05:45:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:45:33 [INFO]   Training abgeschlossen in 14.36s (Backend: cuml)\n",
      "05:46:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:46:42 [INFO]   Training abgeschlossen in 14.45s (Backend: cuml)\n",
      "05:47:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:47:50 [INFO]   Training abgeschlossen in 14.59s (Backend: cuml)\n",
      "05:48:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:48:57 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "05:49:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:50:04 [INFO]   Training abgeschlossen in 14.65s (Backend: cuml)\n",
      "05:50:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:51:11 [INFO]   Training abgeschlossen in 14.89s (Backend: cuml)\n",
      "05:52:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:52:17 [INFO]   Training abgeschlossen in 15.15s (Backend: cuml)\n",
      "05:53:09 [INFO]     24,000 labeled → Accuracy: 0.9662 (Train: 15.2s, Query: 39.98s) | GPU: 2.7/8.0 GB\n",
      "05:53:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:53:24 [INFO]   Training abgeschlossen in 15.40s (Backend: cuml)\n",
      "05:53:36 [INFO]     Final: 24,000 labeled → Accuracy: 0.9659, F1: 0.9656\n",
      "05:53:36 [INFO]   Run 4/5\n",
      "05:53:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:53:41 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "05:54:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "05:54:52 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "05:55:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "05:56:04 [INFO]   Training abgeschlossen in 5.05s (Backend: cuml)\n",
      "05:57:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "05:57:16 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "05:58:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:58:28 [INFO]   Training abgeschlossen in 5.51s (Backend: cuml)\n",
      "05:59:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:59:41 [INFO]   Training abgeschlossen in 5.71s (Backend: cuml)\n",
      "06:00:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:00:54 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "06:02:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:02:07 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "06:03:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:03:21 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "06:04:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:04:35 [INFO]   Training abgeschlossen in 7.31s (Backend: cuml)\n",
      "06:05:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:05:49 [INFO]   Training abgeschlossen in 7.79s (Backend: cuml)\n",
      "06:06:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:07:03 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "06:08:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:08:17 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "06:09:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:09:31 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "06:10:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:10:44 [INFO]   Training abgeschlossen in 8.53s (Backend: cuml)\n",
      "06:11:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:11:58 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "06:13:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:13:12 [INFO]   Training abgeschlossen in 8.96s (Backend: cuml)\n",
      "06:14:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:14:25 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "06:15:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:15:38 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "06:16:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:16:51 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "06:17:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:18:04 [INFO]   Training abgeschlossen in 9.88s (Backend: cuml)\n",
      "06:19:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:19:17 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "06:20:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:20:31 [INFO]   Training abgeschlossen in 10.43s (Backend: cuml)\n",
      "06:21:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:21:44 [INFO]   Training abgeschlossen in 10.59s (Backend: cuml)\n",
      "06:22:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:22:56 [INFO]   Training abgeschlossen in 10.78s (Backend: cuml)\n",
      "06:23:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:24:08 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "06:25:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:25:21 [INFO]   Training abgeschlossen in 11.31s (Backend: cuml)\n",
      "06:26:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:26:32 [INFO]   Training abgeschlossen in 11.38s (Backend: cuml)\n",
      "06:27:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:27:45 [INFO]   Training abgeschlossen in 11.57s (Backend: cuml)\n",
      "06:28:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:28:57 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "06:29:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:30:09 [INFO]   Training abgeschlossen in 12.07s (Backend: cuml)\n",
      "06:31:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:31:21 [INFO]   Training abgeschlossen in 12.20s (Backend: cuml)\n",
      "06:32:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:32:32 [INFO]   Training abgeschlossen in 12.40s (Backend: cuml)\n",
      "06:33:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:33:42 [INFO]   Training abgeschlossen in 12.76s (Backend: cuml)\n",
      "06:34:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:34:53 [INFO]   Training abgeschlossen in 12.91s (Backend: cuml)\n",
      "06:35:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:36:03 [INFO]   Training abgeschlossen in 13.03s (Backend: cuml)\n",
      "06:37:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:37:13 [INFO]   Training abgeschlossen in 13.26s (Backend: cuml)\n",
      "06:38:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:38:24 [INFO]   Training abgeschlossen in 13.51s (Backend: cuml)\n",
      "06:39:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:39:34 [INFO]   Training abgeschlossen in 13.80s (Backend: cuml)\n",
      "06:40:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:40:44 [INFO]   Training abgeschlossen in 13.95s (Backend: cuml)\n",
      "06:41:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:41:53 [INFO]   Training abgeschlossen in 14.20s (Backend: cuml)\n",
      "06:42:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:43:03 [INFO]   Training abgeschlossen in 14.38s (Backend: cuml)\n",
      "06:43:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:44:12 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "06:45:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:45:19 [INFO]   Training abgeschlossen in 14.59s (Backend: cuml)\n",
      "06:46:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:46:26 [INFO]   Training abgeschlossen in 14.68s (Backend: cuml)\n",
      "06:47:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:47:33 [INFO]   Training abgeschlossen in 14.89s (Backend: cuml)\n",
      "06:48:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:48:39 [INFO]   Training abgeschlossen in 15.02s (Backend: cuml)\n",
      "06:49:30 [INFO]     24,000 labeled → Accuracy: 0.9670 (Train: 15.0s, Query: 39.65s) | GPU: 2.7/8.0 GB\n",
      "06:49:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:49:46 [INFO]   Training abgeschlossen in 15.31s (Backend: cuml)\n",
      "06:49:57 [INFO]     Final: 24,000 labeled → Accuracy: 0.9672, F1: 0.9669\n",
      "06:49:57 [INFO]   Run 5/5\n",
      "06:49:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:50:02 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "06:51:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "06:51:14 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "06:52:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "06:52:25 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "06:53:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "06:53:37 [INFO]   Training abgeschlossen in 5.18s (Backend: cuml)\n",
      "06:54:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:54:50 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "06:55:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:56:03 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "06:57:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:57:16 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "06:58:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:58:29 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "06:59:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:59:43 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "07:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:00:57 [INFO]   Training abgeschlossen in 7.15s (Backend: cuml)\n",
      "07:02:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:02:11 [INFO]   Training abgeschlossen in 7.89s (Backend: cuml)\n",
      "07:03:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:03:25 [INFO]   Training abgeschlossen in 7.97s (Backend: cuml)\n",
      "07:04:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:04:39 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "07:05:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:05:53 [INFO]   Training abgeschlossen in 8.48s (Backend: cuml)\n",
      "07:06:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:07:07 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "07:08:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:08:21 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "07:09:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:09:35 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "07:10:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:10:48 [INFO]   Training abgeschlossen in 9.33s (Backend: cuml)\n",
      "07:11:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:12:02 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "07:13:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:13:15 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "07:14:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:14:28 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "07:15:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:15:41 [INFO]   Training abgeschlossen in 10.15s (Backend: cuml)\n",
      "07:16:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:16:54 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "07:17:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:18:07 [INFO]   Training abgeschlossen in 10.63s (Backend: cuml)\n",
      "07:19:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:19:19 [INFO]   Training abgeschlossen in 10.94s (Backend: cuml)\n",
      "07:20:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:20:32 [INFO]   Training abgeschlossen in 11.07s (Backend: cuml)\n",
      "07:21:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:21:43 [INFO]   Training abgeschlossen in 11.27s (Backend: cuml)\n",
      "07:22:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:22:56 [INFO]   Training abgeschlossen in 11.47s (Backend: cuml)\n",
      "07:23:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:24:09 [INFO]   Training abgeschlossen in 11.64s (Backend: cuml)\n",
      "07:25:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:25:20 [INFO]   Training abgeschlossen in 11.84s (Backend: cuml)\n",
      "07:26:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:26:31 [INFO]   Training abgeschlossen in 12.02s (Backend: cuml)\n",
      "07:27:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:27:43 [INFO]   Training abgeschlossen in 12.34s (Backend: cuml)\n",
      "07:28:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:28:54 [INFO]   Training abgeschlossen in 12.43s (Backend: cuml)\n",
      "07:29:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:30:06 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "07:31:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:31:16 [INFO]   Training abgeschlossen in 12.90s (Backend: cuml)\n",
      "07:32:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:32:27 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "07:33:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:33:37 [INFO]   Training abgeschlossen in 13.29s (Backend: cuml)\n",
      "07:34:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:34:48 [INFO]   Training abgeschlossen in 13.51s (Backend: cuml)\n",
      "07:35:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:35:58 [INFO]   Training abgeschlossen in 13.72s (Backend: cuml)\n",
      "07:36:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:37:08 [INFO]   Training abgeschlossen in 13.95s (Backend: cuml)\n",
      "07:38:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:38:17 [INFO]   Training abgeschlossen in 14.24s (Backend: cuml)\n",
      "07:39:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:39:27 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "07:40:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:40:36 [INFO]   Training abgeschlossen in 14.57s (Backend: cuml)\n",
      "07:41:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:41:43 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "07:42:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:42:51 [INFO]   Training abgeschlossen in 14.75s (Backend: cuml)\n",
      "07:43:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:43:58 [INFO]   Training abgeschlossen in 15.07s (Backend: cuml)\n",
      "07:44:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:45:04 [INFO]   Training abgeschlossen in 15.13s (Backend: cuml)\n",
      "07:45:55 [INFO]     24,000 labeled → Accuracy: 0.9674 (Train: 15.1s, Query: 39.61s) | GPU: 2.7/8.0 GB\n",
      "07:45:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:46:11 [INFO]   Training abgeschlossen in 15.34s (Backend: cuml)\n",
      "07:46:22 [INFO]     Final: 24,000 labeled → Accuracy: 0.9677, F1: 0.9674\n",
      "07:46:22 [INFO] \n",
      "GPU-SVM + Entropy Sampling - Budget: 60% (36,000 Samples)\n",
      "07:46:22 [INFO]   Run 1/5\n",
      "07:46:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:46:27 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "07:47:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "07:47:39 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "07:48:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "07:48:51 [INFO]   Training abgeschlossen in 5.07s (Backend: cuml)\n",
      "07:49:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "07:50:03 [INFO]   Training abgeschlossen in 5.07s (Backend: cuml)\n",
      "07:51:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:51:15 [INFO]   Training abgeschlossen in 5.40s (Backend: cuml)\n",
      "07:52:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:52:28 [INFO]   Training abgeschlossen in 5.71s (Backend: cuml)\n",
      "07:53:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:53:41 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "07:54:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:54:55 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "07:56:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:56:09 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "07:57:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:57:22 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "07:58:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:58:36 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "07:59:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:59:50 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "08:00:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:01:05 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "08:02:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:02:18 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "08:03:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:03:32 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "08:04:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:04:46 [INFO]   Training abgeschlossen in 8.84s (Backend: cuml)\n",
      "08:05:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:06:00 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "08:07:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:07:13 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "08:08:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:08:26 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "08:09:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:09:40 [INFO]   Training abgeschlossen in 9.66s (Backend: cuml)\n",
      "08:10:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:10:53 [INFO]   Training abgeschlossen in 9.91s (Backend: cuml)\n",
      "08:11:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:12:06 [INFO]   Training abgeschlossen in 10.10s (Backend: cuml)\n",
      "08:13:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:13:18 [INFO]   Training abgeschlossen in 10.32s (Backend: cuml)\n",
      "08:14:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:14:31 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "08:15:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:15:43 [INFO]   Training abgeschlossen in 10.73s (Backend: cuml)\n",
      "08:16:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:16:55 [INFO]   Training abgeschlossen in 11.10s (Backend: cuml)\n",
      "08:17:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:18:07 [INFO]   Training abgeschlossen in 11.21s (Backend: cuml)\n",
      "08:19:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:19:18 [INFO]   Training abgeschlossen in 11.47s (Backend: cuml)\n",
      "08:20:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:20:31 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "08:21:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:21:43 [INFO]   Training abgeschlossen in 11.94s (Backend: cuml)\n",
      "08:22:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:22:55 [INFO]   Training abgeschlossen in 11.98s (Backend: cuml)\n",
      "08:23:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:24:07 [INFO]   Training abgeschlossen in 12.19s (Backend: cuml)\n",
      "08:25:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:25:18 [INFO]   Training abgeschlossen in 12.37s (Backend: cuml)\n",
      "08:26:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:26:28 [INFO]   Training abgeschlossen in 12.67s (Backend: cuml)\n",
      "08:27:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:27:39 [INFO]   Training abgeschlossen in 12.85s (Backend: cuml)\n",
      "08:28:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:28:49 [INFO]   Training abgeschlossen in 13.04s (Backend: cuml)\n",
      "08:29:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:29:59 [INFO]   Training abgeschlossen in 13.24s (Backend: cuml)\n",
      "08:30:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:31:10 [INFO]   Training abgeschlossen in 13.61s (Backend: cuml)\n",
      "08:32:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:32:19 [INFO]   Training abgeschlossen in 13.69s (Backend: cuml)\n",
      "08:33:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:33:29 [INFO]   Training abgeschlossen in 13.85s (Backend: cuml)\n",
      "08:34:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:34:38 [INFO]   Training abgeschlossen in 14.10s (Backend: cuml)\n",
      "08:35:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:35:48 [INFO]   Training abgeschlossen in 14.33s (Backend: cuml)\n",
      "08:36:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:36:57 [INFO]   Training abgeschlossen in 14.75s (Backend: cuml)\n",
      "08:37:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:38:04 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "08:38:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:39:11 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "08:40:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:40:18 [INFO]   Training abgeschlossen in 14.89s (Backend: cuml)\n",
      "08:41:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:41:24 [INFO]   Training abgeschlossen in 15.10s (Backend: cuml)\n",
      "08:42:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:42:31 [INFO]   Training abgeschlossen in 15.43s (Backend: cuml)\n",
      "08:43:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:43:37 [INFO]   Training abgeschlossen in 15.67s (Backend: cuml)\n",
      "08:44:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:44:43 [INFO]   Training abgeschlossen in 15.68s (Backend: cuml)\n",
      "08:45:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:45:48 [INFO]   Training abgeschlossen in 16.10s (Backend: cuml)\n",
      "08:46:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:46:53 [INFO]   Training abgeschlossen in 16.07s (Backend: cuml)\n",
      "08:47:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:47:58 [INFO]   Training abgeschlossen in 16.36s (Backend: cuml)\n",
      "08:48:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:49:03 [INFO]   Training abgeschlossen in 16.58s (Backend: cuml)\n",
      "08:49:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:50:07 [INFO]   Training abgeschlossen in 16.85s (Backend: cuml)\n",
      "08:50:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:51:13 [INFO]   Training abgeschlossen in 17.30s (Backend: cuml)\n",
      "08:51:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:52:16 [INFO]   Training abgeschlossen in 17.26s (Backend: cuml)\n",
      "08:53:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:53:20 [INFO]   Training abgeschlossen in 17.44s (Backend: cuml)\n",
      "08:54:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:54:24 [INFO]   Training abgeschlossen in 17.67s (Backend: cuml)\n",
      "08:55:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:55:28 [INFO]   Training abgeschlossen in 17.85s (Backend: cuml)\n",
      "08:56:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:56:30 [INFO]   Training abgeschlossen in 18.07s (Backend: cuml)\n",
      "08:57:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:57:33 [INFO]   Training abgeschlossen in 18.42s (Backend: cuml)\n",
      "08:58:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:58:35 [INFO]   Training abgeschlossen in 18.53s (Backend: cuml)\n",
      "08:59:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:59:37 [INFO]   Training abgeschlossen in 18.88s (Backend: cuml)\n",
      "09:00:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:00:39 [INFO]   Training abgeschlossen in 19.09s (Backend: cuml)\n",
      "09:01:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:01:40 [INFO]   Training abgeschlossen in 19.33s (Backend: cuml)\n",
      "09:02:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:02:41 [INFO]   Training abgeschlossen in 19.46s (Backend: cuml)\n",
      "09:03:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:03:42 [INFO]   Training abgeschlossen in 19.62s (Backend: cuml)\n",
      "09:04:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:04:42 [INFO]   Training abgeschlossen in 19.84s (Backend: cuml)\n",
      "09:05:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:05:42 [INFO]   Training abgeschlossen in 20.04s (Backend: cuml)\n",
      "09:06:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:06:42 [INFO]   Training abgeschlossen in 20.28s (Backend: cuml)\n",
      "09:07:21 [INFO]     36,000 labeled → Accuracy: 0.9650 (Train: 20.3s, Query: 27.28s) | GPU: 2.8/8.0 GB\n",
      "09:07:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:07:41 [INFO]   Training abgeschlossen in 20.43s (Backend: cuml)\n",
      "09:07:53 [INFO]     Final: 36,000 labeled → Accuracy: 0.9654, F1: 0.9652\n",
      "09:07:53 [INFO]   Run 2/5\n",
      "09:07:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:07:58 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "09:09:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "09:09:09 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "09:10:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "09:10:21 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "09:11:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "09:11:33 [INFO]   Training abgeschlossen in 5.24s (Backend: cuml)\n",
      "09:12:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:12:45 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "09:13:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:13:58 [INFO]   Training abgeschlossen in 5.76s (Backend: cuml)\n",
      "09:15:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:15:11 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "09:16:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:16:24 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "09:17:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:17:38 [INFO]   Training abgeschlossen in 6.78s (Backend: cuml)\n",
      "09:18:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:18:52 [INFO]   Training abgeschlossen in 7.17s (Backend: cuml)\n",
      "09:19:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:20:06 [INFO]   Training abgeschlossen in 7.79s (Backend: cuml)\n",
      "09:21:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:21:20 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "09:22:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:22:34 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "09:23:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:23:48 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "09:24:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:25:02 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "09:26:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:26:16 [INFO]   Training abgeschlossen in 8.83s (Backend: cuml)\n",
      "09:27:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:27:30 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "09:28:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:28:43 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "09:29:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:29:57 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "09:31:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:31:10 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "09:32:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:32:23 [INFO]   Training abgeschlossen in 9.88s (Backend: cuml)\n",
      "09:33:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:33:36 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "09:34:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:34:49 [INFO]   Training abgeschlossen in 10.38s (Backend: cuml)\n",
      "09:35:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:36:01 [INFO]   Training abgeschlossen in 10.64s (Backend: cuml)\n",
      "09:37:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:37:14 [INFO]   Training abgeschlossen in 10.78s (Backend: cuml)\n",
      "09:38:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:38:26 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "09:39:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:39:37 [INFO]   Training abgeschlossen in 11.27s (Backend: cuml)\n",
      "09:40:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:40:49 [INFO]   Training abgeschlossen in 11.45s (Backend: cuml)\n",
      "09:41:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:42:01 [INFO]   Training abgeschlossen in 11.55s (Backend: cuml)\n",
      "09:43:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:43:12 [INFO]   Training abgeschlossen in 11.76s (Backend: cuml)\n",
      "09:44:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:44:23 [INFO]   Training abgeschlossen in 12.03s (Backend: cuml)\n",
      "09:45:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:45:33 [INFO]   Training abgeschlossen in 12.32s (Backend: cuml)\n",
      "09:46:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:46:44 [INFO]   Training abgeschlossen in 12.42s (Backend: cuml)\n",
      "09:47:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:47:54 [INFO]   Training abgeschlossen in 12.67s (Backend: cuml)\n",
      "09:48:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:49:04 [INFO]   Training abgeschlossen in 12.86s (Backend: cuml)\n",
      "09:50:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:50:14 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "09:51:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:51:23 [INFO]   Training abgeschlossen in 13.24s (Backend: cuml)\n",
      "09:52:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:52:33 [INFO]   Training abgeschlossen in 13.45s (Backend: cuml)\n",
      "09:53:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:53:42 [INFO]   Training abgeschlossen in 13.61s (Backend: cuml)\n",
      "09:54:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:54:52 [INFO]   Training abgeschlossen in 13.86s (Backend: cuml)\n",
      "09:55:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:56:02 [INFO]   Training abgeschlossen in 14.26s (Backend: cuml)\n",
      "09:56:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:57:11 [INFO]   Training abgeschlossen in 14.35s (Backend: cuml)\n",
      "09:58:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:58:20 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "09:59:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:59:27 [INFO]   Training abgeschlossen in 14.43s (Backend: cuml)\n",
      "10:00:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:00:35 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "10:01:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:01:42 [INFO]   Training abgeschlossen in 14.99s (Backend: cuml)\n",
      "10:02:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:02:48 [INFO]   Training abgeschlossen in 15.28s (Backend: cuml)\n",
      "10:03:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:03:55 [INFO]   Training abgeschlossen in 15.36s (Backend: cuml)\n",
      "10:04:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:05:00 [INFO]   Training abgeschlossen in 15.58s (Backend: cuml)\n",
      "10:05:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:06:06 [INFO]   Training abgeschlossen in 15.69s (Backend: cuml)\n",
      "10:06:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:07:12 [INFO]   Training abgeschlossen in 16.15s (Backend: cuml)\n",
      "10:08:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:08:17 [INFO]   Training abgeschlossen in 16.16s (Backend: cuml)\n",
      "10:09:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:09:22 [INFO]   Training abgeschlossen in 16.48s (Backend: cuml)\n",
      "10:10:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:10:27 [INFO]   Training abgeschlossen in 16.74s (Backend: cuml)\n",
      "10:11:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:11:31 [INFO]   Training abgeschlossen in 16.92s (Backend: cuml)\n",
      "10:12:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:12:36 [INFO]   Training abgeschlossen in 17.05s (Backend: cuml)\n",
      "10:13:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:13:39 [INFO]   Training abgeschlossen in 17.15s (Backend: cuml)\n",
      "10:14:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:14:43 [INFO]   Training abgeschlossen in 17.41s (Backend: cuml)\n",
      "10:15:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:15:47 [INFO]   Training abgeschlossen in 17.70s (Backend: cuml)\n",
      "10:16:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:16:49 [INFO]   Training abgeschlossen in 17.87s (Backend: cuml)\n",
      "10:17:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:17:52 [INFO]   Training abgeschlossen in 18.12s (Backend: cuml)\n",
      "10:18:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:18:55 [INFO]   Training abgeschlossen in 18.40s (Backend: cuml)\n",
      "10:19:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:19:57 [INFO]   Training abgeschlossen in 18.63s (Backend: cuml)\n",
      "10:20:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:20:59 [INFO]   Training abgeschlossen in 18.81s (Backend: cuml)\n",
      "10:21:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:22:01 [INFO]   Training abgeschlossen in 19.14s (Backend: cuml)\n",
      "10:22:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:23:02 [INFO]   Training abgeschlossen in 19.28s (Backend: cuml)\n",
      "10:23:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:24:03 [INFO]   Training abgeschlossen in 19.63s (Backend: cuml)\n",
      "10:24:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:25:05 [INFO]   Training abgeschlossen in 19.85s (Backend: cuml)\n",
      "10:25:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:26:05 [INFO]   Training abgeschlossen in 19.89s (Backend: cuml)\n",
      "10:26:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:27:05 [INFO]   Training abgeschlossen in 19.97s (Backend: cuml)\n",
      "10:27:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:28:05 [INFO]   Training abgeschlossen in 20.47s (Backend: cuml)\n",
      "10:28:44 [INFO]     36,000 labeled → Accuracy: 0.9662 (Train: 20.5s, Query: 27.36s) | GPU: 2.8/8.0 GB\n",
      "10:28:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:29:05 [INFO]   Training abgeschlossen in 20.42s (Backend: cuml)\n",
      "10:29:16 [INFO]     Final: 36,000 labeled → Accuracy: 0.9657, F1: 0.9655\n",
      "10:29:16 [INFO]   Run 3/5\n",
      "10:29:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:29:21 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "10:30:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:30:33 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "10:31:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:31:44 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "10:32:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:32:56 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "10:34:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:34:09 [INFO]   Training abgeschlossen in 5.45s (Backend: cuml)\n",
      "10:35:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:35:21 [INFO]   Training abgeschlossen in 5.74s (Backend: cuml)\n",
      "10:36:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:36:34 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "10:37:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:37:47 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "10:38:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:39:00 [INFO]   Training abgeschlossen in 6.77s (Backend: cuml)\n",
      "10:40:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:40:14 [INFO]   Training abgeschlossen in 7.21s (Backend: cuml)\n",
      "10:41:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:41:28 [INFO]   Training abgeschlossen in 7.78s (Backend: cuml)\n",
      "10:42:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:42:42 [INFO]   Training abgeschlossen in 7.86s (Backend: cuml)\n",
      "10:43:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:43:56 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "10:45:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:45:10 [INFO]   Training abgeschlossen in 8.28s (Backend: cuml)\n",
      "10:46:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:46:24 [INFO]   Training abgeschlossen in 8.47s (Backend: cuml)\n",
      "10:47:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:47:37 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "10:48:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:48:51 [INFO]   Training abgeschlossen in 9.04s (Backend: cuml)\n",
      "10:49:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:50:04 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "10:51:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:51:18 [INFO]   Training abgeschlossen in 9.33s (Backend: cuml)\n",
      "10:52:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:52:31 [INFO]   Training abgeschlossen in 9.76s (Backend: cuml)\n",
      "10:53:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:53:44 [INFO]   Training abgeschlossen in 9.85s (Backend: cuml)\n",
      "10:54:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:54:57 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "10:55:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:56:09 [INFO]   Training abgeschlossen in 10.27s (Backend: cuml)\n",
      "10:57:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:57:23 [INFO]   Training abgeschlossen in 10.56s (Backend: cuml)\n",
      "10:58:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:58:36 [INFO]   Training abgeschlossen in 10.69s (Backend: cuml)\n",
      "10:59:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:59:49 [INFO]   Training abgeschlossen in 10.91s (Backend: cuml)\n",
      "11:00:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:01:01 [INFO]   Training abgeschlossen in 11.18s (Backend: cuml)\n",
      "11:02:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:02:14 [INFO]   Training abgeschlossen in 11.45s (Backend: cuml)\n",
      "11:03:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:03:26 [INFO]   Training abgeschlossen in 11.54s (Backend: cuml)\n",
      "11:04:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:04:37 [INFO]   Training abgeschlossen in 11.76s (Backend: cuml)\n",
      "11:05:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:05:48 [INFO]   Training abgeschlossen in 11.97s (Backend: cuml)\n",
      "11:06:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:07:00 [INFO]   Training abgeschlossen in 12.36s (Backend: cuml)\n",
      "11:07:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:08:12 [INFO]   Training abgeschlossen in 12.48s (Backend: cuml)\n",
      "11:09:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:09:23 [INFO]   Training abgeschlossen in 12.68s (Backend: cuml)\n",
      "11:10:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:10:33 [INFO]   Training abgeschlossen in 12.94s (Backend: cuml)\n",
      "11:11:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:11:43 [INFO]   Training abgeschlossen in 13.18s (Backend: cuml)\n",
      "11:12:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:12:52 [INFO]   Training abgeschlossen in 13.28s (Backend: cuml)\n",
      "11:13:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:14:02 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "11:14:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:15:11 [INFO]   Training abgeschlossen in 13.68s (Backend: cuml)\n",
      "11:16:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:16:19 [INFO]   Training abgeschlossen in 13.96s (Backend: cuml)\n",
      "11:17:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:17:28 [INFO]   Training abgeschlossen in 14.08s (Backend: cuml)\n",
      "11:18:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:18:37 [INFO]   Training abgeschlossen in 14.27s (Backend: cuml)\n",
      "11:19:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:19:45 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "11:20:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:20:52 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "11:21:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:21:59 [INFO]   Training abgeschlossen in 14.70s (Backend: cuml)\n",
      "11:22:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:23:06 [INFO]   Training abgeschlossen in 14.85s (Backend: cuml)\n",
      "11:23:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:24:12 [INFO]   Training abgeschlossen in 15.11s (Backend: cuml)\n",
      "11:25:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:25:18 [INFO]   Training abgeschlossen in 15.22s (Backend: cuml)\n",
      "11:26:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:26:24 [INFO]   Training abgeschlossen in 15.49s (Backend: cuml)\n",
      "11:27:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:27:30 [INFO]   Training abgeschlossen in 15.81s (Backend: cuml)\n",
      "11:28:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:28:36 [INFO]   Training abgeschlossen in 16.21s (Backend: cuml)\n",
      "11:29:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:29:41 [INFO]   Training abgeschlossen in 16.28s (Backend: cuml)\n",
      "11:30:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:30:46 [INFO]   Training abgeschlossen in 16.29s (Backend: cuml)\n",
      "11:31:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:31:50 [INFO]   Training abgeschlossen in 16.61s (Backend: cuml)\n",
      "11:32:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:32:55 [INFO]   Training abgeschlossen in 16.83s (Backend: cuml)\n",
      "11:33:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:33:59 [INFO]   Training abgeschlossen in 16.99s (Backend: cuml)\n",
      "11:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:35:03 [INFO]   Training abgeschlossen in 17.36s (Backend: cuml)\n",
      "11:35:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:36:07 [INFO]   Training abgeschlossen in 17.58s (Backend: cuml)\n",
      "11:36:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:37:10 [INFO]   Training abgeschlossen in 17.70s (Backend: cuml)\n",
      "11:37:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:38:13 [INFO]   Training abgeschlossen in 17.85s (Backend: cuml)\n",
      "11:38:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:39:16 [INFO]   Training abgeschlossen in 18.03s (Backend: cuml)\n",
      "11:40:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:40:18 [INFO]   Training abgeschlossen in 18.28s (Backend: cuml)\n",
      "11:41:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:41:21 [INFO]   Training abgeschlossen in 18.46s (Backend: cuml)\n",
      "11:42:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:42:22 [INFO]   Training abgeschlossen in 18.67s (Backend: cuml)\n",
      "11:43:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:43:24 [INFO]   Training abgeschlossen in 18.99s (Backend: cuml)\n",
      "11:44:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:44:25 [INFO]   Training abgeschlossen in 19.23s (Backend: cuml)\n",
      "11:45:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:45:26 [INFO]   Training abgeschlossen in 19.56s (Backend: cuml)\n",
      "11:46:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:46:27 [INFO]   Training abgeschlossen in 19.67s (Backend: cuml)\n",
      "11:47:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:47:28 [INFO]   Training abgeschlossen in 19.97s (Backend: cuml)\n",
      "11:48:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:48:28 [INFO]   Training abgeschlossen in 19.99s (Backend: cuml)\n",
      "11:49:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:49:27 [INFO]   Training abgeschlossen in 20.17s (Backend: cuml)\n",
      "11:50:06 [INFO]     36,000 labeled → Accuracy: 0.9658 (Train: 20.2s, Query: 27.37s) | GPU: 2.8/8.0 GB\n",
      "11:50:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:50:27 [INFO]   Training abgeschlossen in 20.46s (Backend: cuml)\n",
      "11:50:38 [INFO]     Final: 36,000 labeled → Accuracy: 0.9658, F1: 0.9656\n",
      "11:50:38 [INFO]   Run 4/5\n",
      "11:50:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:50:43 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "11:51:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "11:51:55 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "11:53:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "11:53:06 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "11:54:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "11:54:18 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "11:55:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:55:31 [INFO]   Training abgeschlossen in 5.46s (Backend: cuml)\n",
      "11:56:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:56:43 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "11:57:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:57:56 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "11:59:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:59:10 [INFO]   Training abgeschlossen in 6.15s (Backend: cuml)\n",
      "12:00:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:00:23 [INFO]   Training abgeschlossen in 6.81s (Backend: cuml)\n",
      "12:01:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:01:37 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "12:02:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:02:51 [INFO]   Training abgeschlossen in 7.73s (Backend: cuml)\n",
      "12:03:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:04:05 [INFO]   Training abgeschlossen in 7.78s (Backend: cuml)\n",
      "12:05:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:05:19 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "12:06:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:06:33 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "12:07:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:07:46 [INFO]   Training abgeschlossen in 8.45s (Backend: cuml)\n",
      "12:08:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:09:00 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "12:10:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:10:13 [INFO]   Training abgeschlossen in 8.94s (Backend: cuml)\n",
      "12:11:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:11:27 [INFO]   Training abgeschlossen in 9.14s (Backend: cuml)\n",
      "12:12:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:12:40 [INFO]   Training abgeschlossen in 9.42s (Backend: cuml)\n",
      "12:13:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:13:53 [INFO]   Training abgeschlossen in 9.59s (Backend: cuml)\n",
      "12:14:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:15:07 [INFO]   Training abgeschlossen in 9.82s (Backend: cuml)\n",
      "12:16:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:16:20 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "12:17:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:17:34 [INFO]   Training abgeschlossen in 10.25s (Backend: cuml)\n",
      "12:18:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:18:46 [INFO]   Training abgeschlossen in 10.47s (Backend: cuml)\n",
      "12:19:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:19:59 [INFO]   Training abgeschlossen in 10.65s (Backend: cuml)\n",
      "12:21:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:21:12 [INFO]   Training abgeschlossen in 11.03s (Backend: cuml)\n",
      "12:22:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:22:25 [INFO]   Training abgeschlossen in 11.12s (Backend: cuml)\n",
      "12:23:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:23:38 [INFO]   Training abgeschlossen in 11.31s (Backend: cuml)\n",
      "12:24:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:24:50 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "12:25:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:26:02 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "12:27:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:27:13 [INFO]   Training abgeschlossen in 11.95s (Backend: cuml)\n",
      "12:28:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:28:24 [INFO]   Training abgeschlossen in 12.15s (Backend: cuml)\n",
      "12:29:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:29:35 [INFO]   Training abgeschlossen in 12.44s (Backend: cuml)\n",
      "12:30:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:30:46 [INFO]   Training abgeschlossen in 12.67s (Backend: cuml)\n",
      "12:31:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:31:56 [INFO]   Training abgeschlossen in 12.86s (Backend: cuml)\n",
      "12:32:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:33:06 [INFO]   Training abgeschlossen in 13.05s (Backend: cuml)\n",
      "12:34:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:34:15 [INFO]   Training abgeschlossen in 13.18s (Backend: cuml)\n",
      "12:35:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:35:24 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "12:36:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:36:33 [INFO]   Training abgeschlossen in 13.64s (Backend: cuml)\n",
      "12:37:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:37:42 [INFO]   Training abgeschlossen in 13.87s (Backend: cuml)\n",
      "12:38:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:38:50 [INFO]   Training abgeschlossen in 14.07s (Backend: cuml)\n",
      "12:39:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:39:59 [INFO]   Training abgeschlossen in 14.30s (Backend: cuml)\n",
      "12:40:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:41:07 [INFO]   Training abgeschlossen in 14.53s (Backend: cuml)\n",
      "12:42:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:42:14 [INFO]   Training abgeschlossen in 14.39s (Backend: cuml)\n",
      "12:43:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:43:22 [INFO]   Training abgeschlossen in 14.65s (Backend: cuml)\n",
      "12:44:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:44:30 [INFO]   Training abgeschlossen in 14.80s (Backend: cuml)\n",
      "12:45:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:45:37 [INFO]   Training abgeschlossen in 15.13s (Backend: cuml)\n",
      "12:46:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:46:45 [INFO]   Training abgeschlossen in 15.36s (Backend: cuml)\n",
      "12:47:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:47:51 [INFO]   Training abgeschlossen in 15.43s (Backend: cuml)\n",
      "12:48:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:48:58 [INFO]   Training abgeschlossen in 15.67s (Backend: cuml)\n",
      "12:49:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:50:04 [INFO]   Training abgeschlossen in 16.06s (Backend: cuml)\n",
      "12:50:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:51:10 [INFO]   Training abgeschlossen in 16.02s (Backend: cuml)\n",
      "12:51:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:52:14 [INFO]   Training abgeschlossen in 16.27s (Backend: cuml)\n",
      "12:53:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:53:19 [INFO]   Training abgeschlossen in 16.52s (Backend: cuml)\n",
      "12:54:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:54:23 [INFO]   Training abgeschlossen in 16.72s (Backend: cuml)\n",
      "12:55:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:55:27 [INFO]   Training abgeschlossen in 16.91s (Backend: cuml)\n",
      "12:56:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:56:31 [INFO]   Training abgeschlossen in 17.18s (Backend: cuml)\n",
      "12:57:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:57:34 [INFO]   Training abgeschlossen in 17.36s (Backend: cuml)\n",
      "12:58:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:58:37 [INFO]   Training abgeschlossen in 17.62s (Backend: cuml)\n",
      "12:59:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:59:40 [INFO]   Training abgeschlossen in 17.89s (Backend: cuml)\n",
      "13:00:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:00:43 [INFO]   Training abgeschlossen in 18.05s (Backend: cuml)\n",
      "13:01:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:01:46 [INFO]   Training abgeschlossen in 18.36s (Backend: cuml)\n",
      "13:02:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:02:48 [INFO]   Training abgeschlossen in 18.61s (Backend: cuml)\n",
      "13:03:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:03:50 [INFO]   Training abgeschlossen in 18.71s (Backend: cuml)\n",
      "13:04:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:04:51 [INFO]   Training abgeschlossen in 18.88s (Backend: cuml)\n",
      "13:05:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:05:52 [INFO]   Training abgeschlossen in 19.04s (Backend: cuml)\n",
      "13:06:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:06:53 [INFO]   Training abgeschlossen in 19.46s (Backend: cuml)\n",
      "13:07:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:07:54 [INFO]   Training abgeschlossen in 19.69s (Backend: cuml)\n",
      "13:08:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:08:55 [INFO]   Training abgeschlossen in 19.84s (Backend: cuml)\n",
      "13:09:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:09:55 [INFO]   Training abgeschlossen in 20.00s (Backend: cuml)\n",
      "13:10:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:10:54 [INFO]   Training abgeschlossen in 20.18s (Backend: cuml)\n",
      "13:11:33 [INFO]     36,000 labeled → Accuracy: 0.9673 (Train: 20.2s, Query: 27.33s) | GPU: 2.8/8.0 GB\n",
      "13:11:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:11:54 [INFO]   Training abgeschlossen in 20.53s (Backend: cuml)\n",
      "13:12:05 [INFO]     Final: 36,000 labeled → Accuracy: 0.9669, F1: 0.9666\n",
      "13:12:05 [INFO]   Run 5/5\n",
      "13:12:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:12:10 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "13:13:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:13:22 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "13:14:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:14:33 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "13:15:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:15:45 [INFO]   Training abgeschlossen in 5.20s (Backend: cuml)\n",
      "13:16:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:16:58 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "13:18:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:18:11 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "13:19:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:19:24 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "13:20:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:20:37 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "13:21:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:21:51 [INFO]   Training abgeschlossen in 6.91s (Backend: cuml)\n",
      "13:22:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:23:04 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "13:24:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:24:18 [INFO]   Training abgeschlossen in 7.84s (Backend: cuml)\n",
      "13:25:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:25:33 [INFO]   Training abgeschlossen in 7.91s (Backend: cuml)\n",
      "13:26:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:26:47 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "13:27:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:28:00 [INFO]   Training abgeschlossen in 8.31s (Backend: cuml)\n",
      "13:29:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:29:14 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "13:30:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:30:28 [INFO]   Training abgeschlossen in 8.69s (Backend: cuml)\n",
      "13:31:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:31:41 [INFO]   Training abgeschlossen in 8.93s (Backend: cuml)\n",
      "13:32:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:32:55 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "13:33:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:34:08 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "13:35:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:35:21 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "13:36:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:36:35 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "13:37:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:37:48 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "13:38:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:39:00 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "13:40:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:40:13 [INFO]   Training abgeschlossen in 10.59s (Backend: cuml)\n",
      "13:41:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:41:25 [INFO]   Training abgeschlossen in 10.79s (Backend: cuml)\n",
      "13:42:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:42:37 [INFO]   Training abgeschlossen in 10.98s (Backend: cuml)\n",
      "13:43:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:43:49 [INFO]   Training abgeschlossen in 11.17s (Backend: cuml)\n",
      "13:44:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:45:01 [INFO]   Training abgeschlossen in 11.55s (Backend: cuml)\n",
      "13:46:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:46:13 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "13:47:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:47:24 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "13:48:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:48:35 [INFO]   Training abgeschlossen in 11.97s (Backend: cuml)\n",
      "13:49:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:49:45 [INFO]   Training abgeschlossen in 12.22s (Backend: cuml)\n",
      "13:50:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:50:56 [INFO]   Training abgeschlossen in 12.40s (Backend: cuml)\n",
      "13:51:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:52:06 [INFO]   Training abgeschlossen in 12.61s (Backend: cuml)\n",
      "13:53:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:53:16 [INFO]   Training abgeschlossen in 12.84s (Backend: cuml)\n",
      "13:54:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:54:27 [INFO]   Training abgeschlossen in 13.05s (Backend: cuml)\n",
      "13:55:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:55:37 [INFO]   Training abgeschlossen in 13.26s (Backend: cuml)\n",
      "13:56:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:56:46 [INFO]   Training abgeschlossen in 13.45s (Backend: cuml)\n",
      "13:57:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:57:55 [INFO]   Training abgeschlossen in 13.71s (Backend: cuml)\n",
      "13:58:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:59:04 [INFO]   Training abgeschlossen in 13.96s (Backend: cuml)\n",
      "13:59:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:00:13 [INFO]   Training abgeschlossen in 14.04s (Backend: cuml)\n",
      "14:01:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:01:21 [INFO]   Training abgeschlossen in 14.29s (Backend: cuml)\n",
      "14:02:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:02:29 [INFO]   Training abgeschlossen in 14.57s (Backend: cuml)\n",
      "14:03:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:03:36 [INFO]   Training abgeschlossen in 14.51s (Backend: cuml)\n",
      "14:04:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:04:43 [INFO]   Training abgeschlossen in 14.84s (Backend: cuml)\n",
      "14:05:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:05:50 [INFO]   Training abgeschlossen in 14.82s (Backend: cuml)\n",
      "14:06:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:06:57 [INFO]   Training abgeschlossen in 15.04s (Backend: cuml)\n",
      "14:07:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:08:03 [INFO]   Training abgeschlossen in 15.22s (Backend: cuml)\n",
      "14:08:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:09:09 [INFO]   Training abgeschlossen in 15.47s (Backend: cuml)\n",
      "14:09:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:10:15 [INFO]   Training abgeschlossen in 15.81s (Backend: cuml)\n",
      "14:11:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:11:21 [INFO]   Training abgeschlossen in 16.09s (Backend: cuml)\n",
      "14:12:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:12:26 [INFO]   Training abgeschlossen in 16.02s (Backend: cuml)\n",
      "14:13:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:13:31 [INFO]   Training abgeschlossen in 16.32s (Backend: cuml)\n",
      "14:14:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:14:36 [INFO]   Training abgeschlossen in 16.71s (Backend: cuml)\n",
      "14:15:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:15:41 [INFO]   Training abgeschlossen in 16.78s (Backend: cuml)\n",
      "14:16:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:16:46 [INFO]   Training abgeschlossen in 16.90s (Backend: cuml)\n",
      "14:17:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:17:51 [INFO]   Training abgeschlossen in 17.20s (Backend: cuml)\n",
      "14:18:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:18:55 [INFO]   Training abgeschlossen in 17.40s (Backend: cuml)\n",
      "14:19:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:20:00 [INFO]   Training abgeschlossen in 17.74s (Backend: cuml)\n",
      "14:20:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:21:04 [INFO]   Training abgeschlossen in 18.00s (Backend: cuml)\n",
      "14:21:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:22:06 [INFO]   Training abgeschlossen in 18.14s (Backend: cuml)\n",
      "14:22:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:23:09 [INFO]   Training abgeschlossen in 18.29s (Backend: cuml)\n",
      "14:23:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:24:11 [INFO]   Training abgeschlossen in 18.46s (Backend: cuml)\n",
      "14:24:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:25:13 [INFO]   Training abgeschlossen in 18.65s (Backend: cuml)\n",
      "14:25:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:26:14 [INFO]   Training abgeschlossen in 18.85s (Backend: cuml)\n",
      "14:26:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:27:15 [INFO]   Training abgeschlossen in 19.06s (Backend: cuml)\n",
      "14:27:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:28:16 [INFO]   Training abgeschlossen in 19.45s (Backend: cuml)\n",
      "14:28:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:29:16 [INFO]   Training abgeschlossen in 19.56s (Backend: cuml)\n",
      "14:29:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:30:17 [INFO]   Training abgeschlossen in 19.77s (Backend: cuml)\n",
      "14:30:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:31:17 [INFO]   Training abgeschlossen in 19.95s (Backend: cuml)\n",
      "14:31:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:32:16 [INFO]   Training abgeschlossen in 20.14s (Backend: cuml)\n",
      "14:32:55 [INFO]     36,000 labeled → Accuracy: 0.9665 (Train: 20.2s, Query: 27.31s) | GPU: 2.8/8.0 GB\n",
      "14:32:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:33:16 [INFO]   Training abgeschlossen in 20.34s (Backend: cuml)\n",
      "14:33:27 [INFO]     Final: 36,000 labeled → Accuracy: 0.9664, F1: 0.9662\n",
      "14:33:27 [INFO] \n",
      "GPU-SVM + Entropy Sampling - Budget: 80% (48,000 Samples)\n",
      "14:33:27 [INFO]   Run 1/5\n",
      "14:33:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:33:32 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "14:34:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:34:43 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "14:35:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:35:56 [INFO]   Training abgeschlossen in 5.03s (Backend: cuml)\n",
      "14:37:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:37:08 [INFO]   Training abgeschlossen in 5.08s (Backend: cuml)\n",
      "14:38:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:38:20 [INFO]   Training abgeschlossen in 5.44s (Backend: cuml)\n",
      "14:39:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:39:33 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "14:40:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:40:46 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "14:41:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:42:00 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "14:43:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:43:13 [INFO]   Training abgeschlossen in 6.80s (Backend: cuml)\n",
      "14:44:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:44:27 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "14:45:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:45:41 [INFO]   Training abgeschlossen in 7.66s (Backend: cuml)\n",
      "14:46:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:46:55 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "14:48:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:48:09 [INFO]   Training abgeschlossen in 8.10s (Backend: cuml)\n",
      "14:49:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:49:22 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "14:50:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:50:36 [INFO]   Training abgeschlossen in 8.58s (Backend: cuml)\n",
      "14:51:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:51:50 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "14:52:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:53:03 [INFO]   Training abgeschlossen in 8.88s (Backend: cuml)\n",
      "14:54:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:54:16 [INFO]   Training abgeschlossen in 9.16s (Backend: cuml)\n",
      "14:55:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:55:30 [INFO]   Training abgeschlossen in 9.39s (Backend: cuml)\n",
      "14:56:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:56:43 [INFO]   Training abgeschlossen in 9.58s (Backend: cuml)\n",
      "14:57:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:57:56 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "14:58:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:59:08 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "15:00:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:00:21 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "15:01:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:01:33 [INFO]   Training abgeschlossen in 10.48s (Backend: cuml)\n",
      "15:02:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:02:46 [INFO]   Training abgeschlossen in 10.71s (Backend: cuml)\n",
      "15:03:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:03:58 [INFO]   Training abgeschlossen in 10.86s (Backend: cuml)\n",
      "15:04:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:05:09 [INFO]   Training abgeschlossen in 11.12s (Backend: cuml)\n",
      "15:06:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:06:21 [INFO]   Training abgeschlossen in 11.32s (Backend: cuml)\n",
      "15:07:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:07:32 [INFO]   Training abgeschlossen in 11.50s (Backend: cuml)\n",
      "15:08:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:08:43 [INFO]   Training abgeschlossen in 11.70s (Backend: cuml)\n",
      "15:09:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:09:54 [INFO]   Training abgeschlossen in 11.89s (Backend: cuml)\n",
      "15:10:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:11:05 [INFO]   Training abgeschlossen in 12.11s (Backend: cuml)\n",
      "15:12:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:12:17 [INFO]   Training abgeschlossen in 12.38s (Backend: cuml)\n",
      "15:13:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:13:28 [INFO]   Training abgeschlossen in 12.53s (Backend: cuml)\n",
      "15:14:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:14:39 [INFO]   Training abgeschlossen in 12.85s (Backend: cuml)\n",
      "15:15:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:15:48 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "15:16:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:16:57 [INFO]   Training abgeschlossen in 13.18s (Backend: cuml)\n",
      "15:17:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:18:07 [INFO]   Training abgeschlossen in 13.38s (Backend: cuml)\n",
      "15:19:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:19:16 [INFO]   Training abgeschlossen in 13.73s (Backend: cuml)\n",
      "15:20:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:20:24 [INFO]   Training abgeschlossen in 14.05s (Backend: cuml)\n",
      "15:21:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:21:33 [INFO]   Training abgeschlossen in 14.16s (Backend: cuml)\n",
      "15:22:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:22:42 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "15:23:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:23:50 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "15:24:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:24:57 [INFO]   Training abgeschlossen in 14.64s (Backend: cuml)\n",
      "15:25:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:26:04 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "15:26:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:27:11 [INFO]   Training abgeschlossen in 14.90s (Backend: cuml)\n",
      "15:28:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:28:18 [INFO]   Training abgeschlossen in 15.13s (Backend: cuml)\n",
      "15:29:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:29:24 [INFO]   Training abgeschlossen in 15.31s (Backend: cuml)\n",
      "15:30:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:30:30 [INFO]   Training abgeschlossen in 15.57s (Backend: cuml)\n",
      "15:31:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:31:35 [INFO]   Training abgeschlossen in 15.69s (Backend: cuml)\n",
      "15:32:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:32:41 [INFO]   Training abgeschlossen in 16.06s (Backend: cuml)\n",
      "15:33:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:33:47 [INFO]   Training abgeschlossen in 16.06s (Backend: cuml)\n",
      "15:34:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:34:52 [INFO]   Training abgeschlossen in 16.31s (Backend: cuml)\n",
      "15:35:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:35:56 [INFO]   Training abgeschlossen in 16.48s (Backend: cuml)\n",
      "15:36:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:37:00 [INFO]   Training abgeschlossen in 16.66s (Backend: cuml)\n",
      "15:37:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:38:04 [INFO]   Training abgeschlossen in 16.89s (Backend: cuml)\n",
      "15:38:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:39:08 [INFO]   Training abgeschlossen in 17.06s (Backend: cuml)\n",
      "15:39:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:40:11 [INFO]   Training abgeschlossen in 17.32s (Backend: cuml)\n",
      "15:40:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:41:14 [INFO]   Training abgeschlossen in 17.61s (Backend: cuml)\n",
      "15:41:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:42:17 [INFO]   Training abgeschlossen in 17.79s (Backend: cuml)\n",
      "15:43:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:43:20 [INFO]   Training abgeschlossen in 17.97s (Backend: cuml)\n",
      "15:44:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:44:22 [INFO]   Training abgeschlossen in 18.18s (Backend: cuml)\n",
      "15:45:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:45:24 [INFO]   Training abgeschlossen in 18.36s (Backend: cuml)\n",
      "15:46:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:46:25 [INFO]   Training abgeschlossen in 18.61s (Backend: cuml)\n",
      "15:47:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:47:27 [INFO]   Training abgeschlossen in 18.79s (Backend: cuml)\n",
      "15:48:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:48:27 [INFO]   Training abgeschlossen in 19.03s (Backend: cuml)\n",
      "15:49:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:49:28 [INFO]   Training abgeschlossen in 19.37s (Backend: cuml)\n",
      "15:50:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:50:29 [INFO]   Training abgeschlossen in 19.51s (Backend: cuml)\n",
      "15:51:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:51:29 [INFO]   Training abgeschlossen in 19.73s (Backend: cuml)\n",
      "15:52:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:52:29 [INFO]   Training abgeschlossen in 19.94s (Backend: cuml)\n",
      "15:53:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:53:28 [INFO]   Training abgeschlossen in 20.17s (Backend: cuml)\n",
      "15:54:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:54:28 [INFO]   Training abgeschlossen in 20.33s (Backend: cuml)\n",
      "15:55:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:55:26 [INFO]   Training abgeschlossen in 20.62s (Backend: cuml)\n",
      "15:56:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:56:25 [INFO]   Training abgeschlossen in 20.78s (Backend: cuml)\n",
      "15:57:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:57:23 [INFO]   Training abgeschlossen in 21.03s (Backend: cuml)\n",
      "15:58:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:58:22 [INFO]   Training abgeschlossen in 21.26s (Backend: cuml)\n",
      "15:58:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:59:19 [INFO]   Training abgeschlossen in 21.34s (Backend: cuml)\n",
      "15:59:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:00:17 [INFO]   Training abgeschlossen in 21.55s (Backend: cuml)\n",
      "16:00:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:01:14 [INFO]   Training abgeschlossen in 21.74s (Backend: cuml)\n",
      "16:01:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:02:10 [INFO]   Training abgeschlossen in 21.97s (Backend: cuml)\n",
      "16:02:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:03:07 [INFO]   Training abgeschlossen in 22.25s (Backend: cuml)\n",
      "16:03:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:04:03 [INFO]   Training abgeschlossen in 22.46s (Backend: cuml)\n",
      "16:04:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:04:59 [INFO]   Training abgeschlossen in 22.74s (Backend: cuml)\n",
      "16:05:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:05:54 [INFO]   Training abgeschlossen in 22.88s (Backend: cuml)\n",
      "16:06:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:06:49 [INFO]   Training abgeschlossen in 22.95s (Backend: cuml)\n",
      "16:07:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:07:44 [INFO]   Training abgeschlossen in 23.20s (Backend: cuml)\n",
      "16:08:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:08:38 [INFO]   Training abgeschlossen in 23.46s (Backend: cuml)\n",
      "16:09:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:09:33 [INFO]   Training abgeschlossen in 23.59s (Backend: cuml)\n",
      "16:10:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:10:26 [INFO]   Training abgeschlossen in 23.87s (Backend: cuml)\n",
      "16:10:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:11:20 [INFO]   Training abgeschlossen in 24.13s (Backend: cuml)\n",
      "16:11:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:12:13 [INFO]   Training abgeschlossen in 24.45s (Backend: cuml)\n",
      "16:12:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:13:06 [INFO]   Training abgeschlossen in 24.48s (Backend: cuml)\n",
      "16:13:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:13:58 [INFO]   Training abgeschlossen in 24.65s (Backend: cuml)\n",
      "16:14:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:14:50 [INFO]   Training abgeschlossen in 24.86s (Backend: cuml)\n",
      "16:15:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:15:42 [INFO]   Training abgeschlossen in 25.07s (Backend: cuml)\n",
      "16:16:08 [INFO]     48,000 labeled → Accuracy: 0.9659 (Train: 25.1s, Query: 14.30s) | GPU: 2.8/8.0 GB\n",
      "16:16:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:16:33 [INFO]   Training abgeschlossen in 25.34s (Backend: cuml)\n",
      "16:16:45 [INFO]     Final: 48,000 labeled → Accuracy: 0.9663, F1: 0.9661\n",
      "16:16:45 [INFO]   Run 2/5\n",
      "16:16:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:16:50 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "16:17:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:18:01 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "16:19:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:19:13 [INFO]   Training abgeschlossen in 5.04s (Backend: cuml)\n",
      "16:20:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:20:25 [INFO]   Training abgeschlossen in 5.20s (Backend: cuml)\n",
      "16:21:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:21:38 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "16:22:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:22:50 [INFO]   Training abgeschlossen in 5.71s (Backend: cuml)\n",
      "16:23:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:24:03 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "16:25:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:25:16 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "16:26:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:26:30 [INFO]   Training abgeschlossen in 6.74s (Backend: cuml)\n",
      "16:27:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:27:45 [INFO]   Training abgeschlossen in 7.29s (Backend: cuml)\n",
      "16:28:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:28:59 [INFO]   Training abgeschlossen in 7.69s (Backend: cuml)\n",
      "16:30:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:30:13 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "16:31:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:31:27 [INFO]   Training abgeschlossen in 8.08s (Backend: cuml)\n",
      "16:32:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:32:41 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "16:33:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:33:56 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "16:35:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:35:09 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "16:36:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:36:23 [INFO]   Training abgeschlossen in 8.94s (Backend: cuml)\n",
      "16:37:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:37:37 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "16:38:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:38:50 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "16:39:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:40:04 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "16:41:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:41:17 [INFO]   Training abgeschlossen in 10.02s (Backend: cuml)\n",
      "16:42:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:42:30 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "16:43:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:43:43 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "16:44:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:44:55 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "16:45:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:46:08 [INFO]   Training abgeschlossen in 10.73s (Backend: cuml)\n",
      "16:47:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:47:20 [INFO]   Training abgeschlossen in 10.91s (Backend: cuml)\n",
      "16:48:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:48:32 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "16:49:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:49:44 [INFO]   Training abgeschlossen in 11.41s (Backend: cuml)\n",
      "16:50:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:50:56 [INFO]   Training abgeschlossen in 11.54s (Backend: cuml)\n",
      "16:51:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:52:07 [INFO]   Training abgeschlossen in 11.76s (Backend: cuml)\n",
      "16:53:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:53:18 [INFO]   Training abgeschlossen in 11.94s (Backend: cuml)\n",
      "16:54:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:54:29 [INFO]   Training abgeschlossen in 12.18s (Backend: cuml)\n",
      "16:55:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:55:40 [INFO]   Training abgeschlossen in 12.43s (Backend: cuml)\n",
      "16:56:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:56:50 [INFO]   Training abgeschlossen in 12.62s (Backend: cuml)\n",
      "16:57:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:58:00 [INFO]   Training abgeschlossen in 12.87s (Backend: cuml)\n",
      "16:58:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:59:11 [INFO]   Training abgeschlossen in 13.12s (Backend: cuml)\n",
      "17:00:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:00:20 [INFO]   Training abgeschlossen in 13.23s (Backend: cuml)\n",
      "17:01:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:01:29 [INFO]   Training abgeschlossen in 13.48s (Backend: cuml)\n",
      "17:02:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:02:39 [INFO]   Training abgeschlossen in 13.68s (Backend: cuml)\n",
      "17:03:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:03:48 [INFO]   Training abgeschlossen in 13.87s (Backend: cuml)\n",
      "17:04:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:04:56 [INFO]   Training abgeschlossen in 14.11s (Backend: cuml)\n",
      "17:05:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:06:05 [INFO]   Training abgeschlossen in 14.30s (Backend: cuml)\n",
      "17:06:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:07:13 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "17:08:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:08:20 [INFO]   Training abgeschlossen in 14.45s (Backend: cuml)\n",
      "17:09:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:09:27 [INFO]   Training abgeschlossen in 14.64s (Backend: cuml)\n",
      "17:10:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:10:34 [INFO]   Training abgeschlossen in 14.94s (Backend: cuml)\n",
      "17:11:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:11:41 [INFO]   Training abgeschlossen in 15.04s (Backend: cuml)\n",
      "17:12:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:12:47 [INFO]   Training abgeschlossen in 15.23s (Backend: cuml)\n",
      "17:13:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:13:53 [INFO]   Training abgeschlossen in 15.42s (Backend: cuml)\n",
      "17:14:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:15:00 [INFO]   Training abgeschlossen in 15.65s (Backend: cuml)\n",
      "17:15:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:16:05 [INFO]   Training abgeschlossen in 16.06s (Backend: cuml)\n",
      "17:16:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:17:11 [INFO]   Training abgeschlossen in 16.31s (Backend: cuml)\n",
      "17:17:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:18:16 [INFO]   Training abgeschlossen in 16.61s (Backend: cuml)\n",
      "17:19:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:19:21 [INFO]   Training abgeschlossen in 16.48s (Backend: cuml)\n",
      "17:20:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:20:25 [INFO]   Training abgeschlossen in 16.83s (Backend: cuml)\n",
      "17:21:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:21:29 [INFO]   Training abgeschlossen in 16.95s (Backend: cuml)\n",
      "17:22:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:22:33 [INFO]   Training abgeschlossen in 17.24s (Backend: cuml)\n",
      "17:23:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:23:37 [INFO]   Training abgeschlossen in 17.70s (Backend: cuml)\n",
      "17:24:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:24:41 [INFO]   Training abgeschlossen in 17.82s (Backend: cuml)\n",
      "17:25:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:25:44 [INFO]   Training abgeschlossen in 18.00s (Backend: cuml)\n",
      "17:26:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:26:47 [INFO]   Training abgeschlossen in 18.10s (Backend: cuml)\n",
      "17:27:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:27:49 [INFO]   Training abgeschlossen in 18.44s (Backend: cuml)\n",
      "17:28:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:28:52 [INFO]   Training abgeschlossen in 18.54s (Backend: cuml)\n",
      "17:29:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:29:54 [INFO]   Training abgeschlossen in 18.81s (Backend: cuml)\n",
      "17:30:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:30:55 [INFO]   Training abgeschlossen in 18.96s (Backend: cuml)\n",
      "17:31:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:31:56 [INFO]   Training abgeschlossen in 19.18s (Backend: cuml)\n",
      "17:32:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:32:57 [INFO]   Training abgeschlossen in 19.41s (Backend: cuml)\n",
      "17:33:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:33:58 [INFO]   Training abgeschlossen in 19.56s (Backend: cuml)\n",
      "17:34:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:34:59 [INFO]   Training abgeschlossen in 19.83s (Backend: cuml)\n",
      "17:35:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:35:59 [INFO]   Training abgeschlossen in 19.98s (Backend: cuml)\n",
      "17:36:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:36:58 [INFO]   Training abgeschlossen in 20.29s (Backend: cuml)\n",
      "17:37:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:37:58 [INFO]   Training abgeschlossen in 20.36s (Backend: cuml)\n",
      "17:38:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:38:57 [INFO]   Training abgeschlossen in 20.61s (Backend: cuml)\n",
      "17:39:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:39:56 [INFO]   Training abgeschlossen in 20.79s (Backend: cuml)\n",
      "17:40:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:40:54 [INFO]   Training abgeschlossen in 21.02s (Backend: cuml)\n",
      "17:41:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:41:52 [INFO]   Training abgeschlossen in 21.18s (Backend: cuml)\n",
      "17:42:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:42:50 [INFO]   Training abgeschlossen in 21.46s (Backend: cuml)\n",
      "17:43:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:43:47 [INFO]   Training abgeschlossen in 21.66s (Backend: cuml)\n",
      "17:44:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:44:44 [INFO]   Training abgeschlossen in 21.81s (Backend: cuml)\n",
      "17:45:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:45:41 [INFO]   Training abgeschlossen in 21.93s (Backend: cuml)\n",
      "17:46:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:46:38 [INFO]   Training abgeschlossen in 22.25s (Backend: cuml)\n",
      "17:47:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:47:34 [INFO]   Training abgeschlossen in 22.48s (Backend: cuml)\n",
      "17:48:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:48:30 [INFO]   Training abgeschlossen in 22.68s (Backend: cuml)\n",
      "17:49:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:49:25 [INFO]   Training abgeschlossen in 22.79s (Backend: cuml)\n",
      "17:49:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:50:20 [INFO]   Training abgeschlossen in 22.98s (Backend: cuml)\n",
      "17:50:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:51:15 [INFO]   Training abgeschlossen in 23.28s (Backend: cuml)\n",
      "17:51:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:52:09 [INFO]   Training abgeschlossen in 23.61s (Backend: cuml)\n",
      "17:52:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:53:04 [INFO]   Training abgeschlossen in 23.77s (Backend: cuml)\n",
      "17:53:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:53:58 [INFO]   Training abgeschlossen in 24.00s (Backend: cuml)\n",
      "17:54:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:54:51 [INFO]   Training abgeschlossen in 24.16s (Backend: cuml)\n",
      "17:55:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:55:45 [INFO]   Training abgeschlossen in 24.47s (Backend: cuml)\n",
      "17:56:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:56:38 [INFO]   Training abgeschlossen in 24.79s (Backend: cuml)\n",
      "17:57:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:57:30 [INFO]   Training abgeschlossen in 24.69s (Backend: cuml)\n",
      "17:57:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:58:23 [INFO]   Training abgeschlossen in 24.95s (Backend: cuml)\n",
      "17:58:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:59:14 [INFO]   Training abgeschlossen in 25.23s (Backend: cuml)\n",
      "17:59:40 [INFO]     48,000 labeled → Accuracy: 0.9666 (Train: 25.3s, Query: 14.32s) | GPU: 2.8/8.0 GB\n",
      "17:59:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:00:06 [INFO]   Training abgeschlossen in 25.47s (Backend: cuml)\n",
      "18:00:17 [INFO]     Final: 48,000 labeled → Accuracy: 0.9665, F1: 0.9663\n",
      "18:00:18 [INFO]   Run 3/5\n",
      "18:00:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:00:23 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "18:01:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:01:34 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "18:02:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:02:45 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "18:03:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:03:57 [INFO]   Training abgeschlossen in 5.08s (Backend: cuml)\n",
      "18:05:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:05:10 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "18:06:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:06:23 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "18:07:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:07:36 [INFO]   Training abgeschlossen in 5.89s (Backend: cuml)\n",
      "18:08:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:08:48 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "18:09:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:10:02 [INFO]   Training abgeschlossen in 6.85s (Backend: cuml)\n",
      "18:11:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:11:16 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "18:12:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:12:31 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "18:13:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:13:45 [INFO]   Training abgeschlossen in 7.95s (Backend: cuml)\n",
      "18:14:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:14:59 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "18:16:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:16:13 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "18:17:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:17:27 [INFO]   Training abgeschlossen in 8.58s (Backend: cuml)\n",
      "18:18:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:18:41 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "18:19:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:19:54 [INFO]   Training abgeschlossen in 8.93s (Backend: cuml)\n",
      "18:20:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:21:08 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "18:22:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:22:22 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "18:23:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:23:35 [INFO]   Training abgeschlossen in 9.58s (Backend: cuml)\n",
      "18:24:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:24:48 [INFO]   Training abgeschlossen in 9.80s (Backend: cuml)\n",
      "18:25:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:26:01 [INFO]   Training abgeschlossen in 10.21s (Backend: cuml)\n",
      "18:27:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:27:14 [INFO]   Training abgeschlossen in 10.32s (Backend: cuml)\n",
      "18:28:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:28:26 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "18:29:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:29:39 [INFO]   Training abgeschlossen in 10.70s (Backend: cuml)\n",
      "18:30:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:30:51 [INFO]   Training abgeschlossen in 11.04s (Backend: cuml)\n",
      "18:31:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:32:03 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "18:33:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:33:15 [INFO]   Training abgeschlossen in 11.38s (Backend: cuml)\n",
      "18:34:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:34:27 [INFO]   Training abgeschlossen in 11.64s (Backend: cuml)\n",
      "18:35:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:35:38 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "18:36:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:36:49 [INFO]   Training abgeschlossen in 11.99s (Backend: cuml)\n",
      "18:37:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:38:00 [INFO]   Training abgeschlossen in 12.16s (Backend: cuml)\n",
      "18:38:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:39:10 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "18:40:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:40:21 [INFO]   Training abgeschlossen in 12.70s (Backend: cuml)\n",
      "18:41:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:41:31 [INFO]   Training abgeschlossen in 12.84s (Backend: cuml)\n",
      "18:42:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:42:41 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "18:43:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:43:51 [INFO]   Training abgeschlossen in 13.29s (Backend: cuml)\n",
      "18:44:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:45:00 [INFO]   Training abgeschlossen in 13.39s (Backend: cuml)\n",
      "18:45:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:46:09 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "18:47:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:47:17 [INFO]   Training abgeschlossen in 13.86s (Backend: cuml)\n",
      "18:48:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:48:26 [INFO]   Training abgeschlossen in 14.03s (Backend: cuml)\n",
      "18:49:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:49:35 [INFO]   Training abgeschlossen in 14.42s (Backend: cuml)\n",
      "18:50:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:50:42 [INFO]   Training abgeschlossen in 14.53s (Backend: cuml)\n",
      "18:51:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:51:49 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "18:52:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:52:57 [INFO]   Training abgeschlossen in 14.71s (Backend: cuml)\n",
      "18:53:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:54:03 [INFO]   Training abgeschlossen in 14.81s (Backend: cuml)\n",
      "18:54:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:55:10 [INFO]   Training abgeschlossen in 15.16s (Backend: cuml)\n",
      "18:56:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:56:17 [INFO]   Training abgeschlossen in 15.31s (Backend: cuml)\n",
      "18:57:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:57:23 [INFO]   Training abgeschlossen in 15.54s (Backend: cuml)\n",
      "18:58:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:58:29 [INFO]   Training abgeschlossen in 15.67s (Backend: cuml)\n",
      "18:59:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:59:35 [INFO]   Training abgeschlossen in 16.12s (Backend: cuml)\n",
      "19:00:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:00:40 [INFO]   Training abgeschlossen in 16.08s (Backend: cuml)\n",
      "19:01:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:01:45 [INFO]   Training abgeschlossen in 16.40s (Backend: cuml)\n",
      "19:02:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:02:50 [INFO]   Training abgeschlossen in 16.65s (Backend: cuml)\n",
      "19:03:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:03:54 [INFO]   Training abgeschlossen in 16.71s (Backend: cuml)\n",
      "19:04:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:04:58 [INFO]   Training abgeschlossen in 16.95s (Backend: cuml)\n",
      "19:05:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:06:02 [INFO]   Training abgeschlossen in 17.12s (Backend: cuml)\n",
      "19:06:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:07:06 [INFO]   Training abgeschlossen in 17.37s (Backend: cuml)\n",
      "19:07:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:08:09 [INFO]   Training abgeschlossen in 17.67s (Backend: cuml)\n",
      "19:08:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:09:12 [INFO]   Training abgeschlossen in 17.80s (Backend: cuml)\n",
      "19:09:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:10:15 [INFO]   Training abgeschlossen in 18.07s (Backend: cuml)\n",
      "19:10:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:11:17 [INFO]   Training abgeschlossen in 18.36s (Backend: cuml)\n",
      "19:12:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:12:20 [INFO]   Training abgeschlossen in 18.61s (Backend: cuml)\n",
      "19:13:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:13:21 [INFO]   Training abgeschlossen in 18.69s (Backend: cuml)\n",
      "19:14:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:14:23 [INFO]   Training abgeschlossen in 18.90s (Backend: cuml)\n",
      "19:15:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:15:24 [INFO]   Training abgeschlossen in 19.06s (Backend: cuml)\n",
      "19:16:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:16:25 [INFO]   Training abgeschlossen in 19.38s (Backend: cuml)\n",
      "19:17:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:17:26 [INFO]   Training abgeschlossen in 19.72s (Backend: cuml)\n",
      "19:18:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:18:26 [INFO]   Training abgeschlossen in 19.84s (Backend: cuml)\n",
      "19:19:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:19:26 [INFO]   Training abgeschlossen in 20.07s (Backend: cuml)\n",
      "19:20:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:20:26 [INFO]   Training abgeschlossen in 20.30s (Backend: cuml)\n",
      "19:21:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:21:25 [INFO]   Training abgeschlossen in 20.44s (Backend: cuml)\n",
      "19:22:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:22:25 [INFO]   Training abgeschlossen in 20.78s (Backend: cuml)\n",
      "19:23:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:23:23 [INFO]   Training abgeschlossen in 21.01s (Backend: cuml)\n",
      "19:24:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:24:22 [INFO]   Training abgeschlossen in 21.22s (Backend: cuml)\n",
      "19:24:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:25:21 [INFO]   Training abgeschlossen in 21.31s (Backend: cuml)\n",
      "19:25:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:26:18 [INFO]   Training abgeschlossen in 21.48s (Backend: cuml)\n",
      "19:26:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:27:16 [INFO]   Training abgeschlossen in 21.76s (Backend: cuml)\n",
      "19:27:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:28:13 [INFO]   Training abgeschlossen in 21.83s (Backend: cuml)\n",
      "19:28:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:29:10 [INFO]   Training abgeschlossen in 22.15s (Backend: cuml)\n",
      "19:29:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:30:07 [INFO]   Training abgeschlossen in 22.31s (Backend: cuml)\n",
      "19:30:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:31:03 [INFO]   Training abgeschlossen in 22.55s (Backend: cuml)\n",
      "19:31:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:31:59 [INFO]   Training abgeschlossen in 22.83s (Backend: cuml)\n",
      "19:32:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:32:55 [INFO]   Training abgeschlossen in 23.04s (Backend: cuml)\n",
      "19:33:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:33:50 [INFO]   Training abgeschlossen in 23.35s (Backend: cuml)\n",
      "19:34:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:34:45 [INFO]   Training abgeschlossen in 23.27s (Backend: cuml)\n",
      "19:35:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:35:40 [INFO]   Training abgeschlossen in 23.61s (Backend: cuml)\n",
      "19:36:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:36:34 [INFO]   Training abgeschlossen in 23.78s (Backend: cuml)\n",
      "19:37:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:37:28 [INFO]   Training abgeschlossen in 23.94s (Backend: cuml)\n",
      "19:37:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:38:21 [INFO]   Training abgeschlossen in 24.08s (Backend: cuml)\n",
      "19:38:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:39:15 [INFO]   Training abgeschlossen in 24.38s (Backend: cuml)\n",
      "19:39:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:40:07 [INFO]   Training abgeschlossen in 24.52s (Backend: cuml)\n",
      "19:40:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:41:00 [INFO]   Training abgeschlossen in 24.67s (Backend: cuml)\n",
      "19:41:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:41:52 [INFO]   Training abgeschlossen in 24.94s (Backend: cuml)\n",
      "19:42:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:42:44 [INFO]   Training abgeschlossen in 25.15s (Backend: cuml)\n",
      "19:43:10 [INFO]     48,000 labeled → Accuracy: 0.9649 (Train: 25.2s, Query: 14.29s) | GPU: 2.8/8.0 GB\n",
      "19:43:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:43:35 [INFO]   Training abgeschlossen in 25.43s (Backend: cuml)\n",
      "19:43:47 [INFO]     Final: 48,000 labeled → Accuracy: 0.9653, F1: 0.9651\n",
      "19:43:47 [INFO]   Run 4/5\n",
      "19:43:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:43:52 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "19:44:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:45:03 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "19:46:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:46:15 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "19:47:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:47:27 [INFO]   Training abgeschlossen in 5.23s (Backend: cuml)\n",
      "19:48:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:48:40 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "19:49:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:49:53 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "19:51:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:51:06 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "19:52:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:52:19 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "19:53:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:53:33 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "19:54:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:54:47 [INFO]   Training abgeschlossen in 7.15s (Backend: cuml)\n",
      "19:55:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:56:01 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "19:57:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:57:15 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "19:58:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:58:29 [INFO]   Training abgeschlossen in 7.98s (Backend: cuml)\n",
      "19:59:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:59:43 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "20:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:00:57 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "20:02:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:02:11 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "20:03:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:03:24 [INFO]   Training abgeschlossen in 8.96s (Backend: cuml)\n",
      "20:04:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:04:38 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "20:05:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:05:51 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "20:06:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:07:05 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "20:08:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:08:18 [INFO]   Training abgeschlossen in 9.95s (Backend: cuml)\n",
      "20:09:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:09:31 [INFO]   Training abgeschlossen in 10.04s (Backend: cuml)\n",
      "20:10:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:10:44 [INFO]   Training abgeschlossen in 10.24s (Backend: cuml)\n",
      "20:11:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:11:56 [INFO]   Training abgeschlossen in 10.46s (Backend: cuml)\n",
      "20:12:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:13:09 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "20:14:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:14:23 [INFO]   Training abgeschlossen in 10.95s (Backend: cuml)\n",
      "20:15:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:15:36 [INFO]   Training abgeschlossen in 11.18s (Backend: cuml)\n",
      "20:16:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:16:47 [INFO]   Training abgeschlossen in 11.38s (Backend: cuml)\n",
      "20:17:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:18:00 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "20:19:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:19:12 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "20:20:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:20:24 [INFO]   Training abgeschlossen in 11.98s (Backend: cuml)\n",
      "20:21:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:21:36 [INFO]   Training abgeschlossen in 12.26s (Backend: cuml)\n",
      "20:22:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:22:48 [INFO]   Training abgeschlossen in 12.37s (Backend: cuml)\n",
      "20:23:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:23:59 [INFO]   Training abgeschlossen in 12.62s (Backend: cuml)\n",
      "20:24:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:25:11 [INFO]   Training abgeschlossen in 12.83s (Backend: cuml)\n",
      "20:26:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:26:21 [INFO]   Training abgeschlossen in 13.15s (Backend: cuml)\n",
      "20:27:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:27:32 [INFO]   Training abgeschlossen in 13.19s (Backend: cuml)\n",
      "20:28:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:28:42 [INFO]   Training abgeschlossen in 13.42s (Backend: cuml)\n",
      "20:29:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:29:53 [INFO]   Training abgeschlossen in 13.69s (Backend: cuml)\n",
      "20:30:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:31:03 [INFO]   Training abgeschlossen in 13.93s (Backend: cuml)\n",
      "20:31:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:32:12 [INFO]   Training abgeschlossen in 14.13s (Backend: cuml)\n",
      "20:33:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:33:22 [INFO]   Training abgeschlossen in 14.39s (Backend: cuml)\n",
      "20:34:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:34:31 [INFO]   Training abgeschlossen in 14.58s (Backend: cuml)\n",
      "20:35:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:35:39 [INFO]   Training abgeschlossen in 14.51s (Backend: cuml)\n",
      "20:36:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:36:46 [INFO]   Training abgeschlossen in 14.72s (Backend: cuml)\n",
      "20:37:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:37:53 [INFO]   Training abgeschlossen in 14.80s (Backend: cuml)\n",
      "20:38:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:39:00 [INFO]   Training abgeschlossen in 15.04s (Backend: cuml)\n",
      "20:39:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:40:06 [INFO]   Training abgeschlossen in 15.20s (Backend: cuml)\n",
      "20:40:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:41:12 [INFO]   Training abgeschlossen in 15.43s (Backend: cuml)\n",
      "20:42:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:42:18 [INFO]   Training abgeschlossen in 15.69s (Backend: cuml)\n",
      "20:43:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:43:24 [INFO]   Training abgeschlossen in 16.19s (Backend: cuml)\n",
      "20:44:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:44:30 [INFO]   Training abgeschlossen in 16.04s (Backend: cuml)\n",
      "20:45:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:45:36 [INFO]   Training abgeschlossen in 16.25s (Backend: cuml)\n",
      "20:46:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:46:40 [INFO]   Training abgeschlossen in 16.56s (Backend: cuml)\n",
      "20:47:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:47:45 [INFO]   Training abgeschlossen in 16.66s (Backend: cuml)\n",
      "20:48:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:48:51 [INFO]   Training abgeschlossen in 16.99s (Backend: cuml)\n",
      "20:49:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:49:54 [INFO]   Training abgeschlossen in 17.14s (Backend: cuml)\n",
      "20:50:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:50:58 [INFO]   Training abgeschlossen in 17.41s (Backend: cuml)\n",
      "20:51:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:52:02 [INFO]   Training abgeschlossen in 17.66s (Backend: cuml)\n",
      "20:52:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:53:05 [INFO]   Training abgeschlossen in 17.85s (Backend: cuml)\n",
      "20:53:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:54:08 [INFO]   Training abgeschlossen in 18.02s (Backend: cuml)\n",
      "20:54:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:55:10 [INFO]   Training abgeschlossen in 18.29s (Backend: cuml)\n",
      "20:55:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:56:12 [INFO]   Training abgeschlossen in 18.44s (Backend: cuml)\n",
      "20:56:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:57:14 [INFO]   Training abgeschlossen in 18.65s (Backend: cuml)\n",
      "20:57:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:58:16 [INFO]   Training abgeschlossen in 18.89s (Backend: cuml)\n",
      "20:58:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:59:17 [INFO]   Training abgeschlossen in 19.08s (Backend: cuml)\n",
      "20:59:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:00:18 [INFO]   Training abgeschlossen in 19.42s (Backend: cuml)\n",
      "21:00:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:01:18 [INFO]   Training abgeschlossen in 19.75s (Backend: cuml)\n",
      "21:01:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:02:19 [INFO]   Training abgeschlossen in 19.86s (Backend: cuml)\n",
      "21:02:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:03:19 [INFO]   Training abgeschlossen in 19.98s (Backend: cuml)\n",
      "21:03:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:04:18 [INFO]   Training abgeschlossen in 20.22s (Backend: cuml)\n",
      "21:04:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:05:18 [INFO]   Training abgeschlossen in 20.40s (Backend: cuml)\n",
      "21:05:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:06:16 [INFO]   Training abgeschlossen in 20.54s (Backend: cuml)\n",
      "21:06:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:07:15 [INFO]   Training abgeschlossen in 20.77s (Backend: cuml)\n",
      "21:07:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:08:13 [INFO]   Training abgeschlossen in 21.08s (Backend: cuml)\n",
      "21:08:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:09:11 [INFO]   Training abgeschlossen in 21.18s (Backend: cuml)\n",
      "21:09:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:10:09 [INFO]   Training abgeschlossen in 21.43s (Backend: cuml)\n",
      "21:10:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:11:07 [INFO]   Training abgeschlossen in 21.59s (Backend: cuml)\n",
      "21:11:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:12:04 [INFO]   Training abgeschlossen in 21.81s (Backend: cuml)\n",
      "21:12:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:13:01 [INFO]   Training abgeschlossen in 22.04s (Backend: cuml)\n",
      "21:13:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:13:57 [INFO]   Training abgeschlossen in 22.25s (Backend: cuml)\n",
      "21:14:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:14:54 [INFO]   Training abgeschlossen in 22.49s (Backend: cuml)\n",
      "21:15:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:15:50 [INFO]   Training abgeschlossen in 22.73s (Backend: cuml)\n",
      "21:16:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:16:45 [INFO]   Training abgeschlossen in 22.85s (Backend: cuml)\n",
      "21:17:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:17:40 [INFO]   Training abgeschlossen in 23.07s (Backend: cuml)\n",
      "21:18:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:18:35 [INFO]   Training abgeschlossen in 23.26s (Backend: cuml)\n",
      "21:19:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:19:30 [INFO]   Training abgeschlossen in 23.51s (Backend: cuml)\n",
      "21:20:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:20:24 [INFO]   Training abgeschlossen in 23.70s (Backend: cuml)\n",
      "21:20:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:21:18 [INFO]   Training abgeschlossen in 23.84s (Backend: cuml)\n",
      "21:21:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:22:11 [INFO]   Training abgeschlossen in 24.09s (Backend: cuml)\n",
      "21:22:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:23:04 [INFO]   Training abgeschlossen in 24.48s (Backend: cuml)\n",
      "21:23:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:23:57 [INFO]   Training abgeschlossen in 24.61s (Backend: cuml)\n",
      "21:24:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:24:50 [INFO]   Training abgeschlossen in 24.79s (Backend: cuml)\n",
      "21:25:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:25:42 [INFO]   Training abgeschlossen in 25.02s (Backend: cuml)\n",
      "21:26:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:26:34 [INFO]   Training abgeschlossen in 25.21s (Backend: cuml)\n",
      "21:26:59 [INFO]     48,000 labeled → Accuracy: 0.9668 (Train: 25.2s, Query: 14.31s) | GPU: 2.8/8.0 GB\n",
      "21:27:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:27:25 [INFO]   Training abgeschlossen in 25.37s (Backend: cuml)\n",
      "21:27:37 [INFO]     Final: 48,000 labeled → Accuracy: 0.9672, F1: 0.9670\n",
      "21:27:37 [INFO]   Run 5/5\n",
      "21:27:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:27:42 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "21:28:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:28:53 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "21:30:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:30:05 [INFO]   Training abgeschlossen in 4.94s (Backend: cuml)\n",
      "21:31:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:31:17 [INFO]   Training abgeschlossen in 5.14s (Backend: cuml)\n",
      "21:32:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:32:30 [INFO]   Training abgeschlossen in 5.45s (Backend: cuml)\n",
      "21:33:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:33:43 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "21:34:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:34:56 [INFO]   Training abgeschlossen in 6.04s (Backend: cuml)\n",
      "21:36:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:36:10 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "21:37:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:37:23 [INFO]   Training abgeschlossen in 6.92s (Backend: cuml)\n",
      "21:38:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:38:37 [INFO]   Training abgeschlossen in 7.34s (Backend: cuml)\n",
      "21:39:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:39:52 [INFO]   Training abgeschlossen in 7.56s (Backend: cuml)\n",
      "21:40:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:41:06 [INFO]   Training abgeschlossen in 8.06s (Backend: cuml)\n",
      "21:42:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:42:21 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "21:43:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:43:36 [INFO]   Training abgeschlossen in 8.31s (Backend: cuml)\n",
      "21:44:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:44:51 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "21:45:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:46:05 [INFO]   Training abgeschlossen in 8.71s (Backend: cuml)\n",
      "21:47:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:47:20 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "21:48:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:48:35 [INFO]   Training abgeschlossen in 9.16s (Backend: cuml)\n",
      "21:49:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:49:48 [INFO]   Training abgeschlossen in 9.38s (Backend: cuml)\n",
      "21:50:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:51:02 [INFO]   Training abgeschlossen in 9.63s (Backend: cuml)\n",
      "21:52:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:52:15 [INFO]   Training abgeschlossen in 9.88s (Backend: cuml)\n",
      "21:53:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:53:28 [INFO]   Training abgeschlossen in 10.05s (Backend: cuml)\n",
      "21:54:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:54:42 [INFO]   Training abgeschlossen in 10.41s (Backend: cuml)\n",
      "21:55:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:55:55 [INFO]   Training abgeschlossen in 10.48s (Backend: cuml)\n",
      "21:56:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:57:07 [INFO]   Training abgeschlossen in 10.69s (Backend: cuml)\n",
      "21:58:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:58:19 [INFO]   Training abgeschlossen in 10.94s (Backend: cuml)\n",
      "21:59:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:59:31 [INFO]   Training abgeschlossen in 11.27s (Backend: cuml)\n",
      "22:00:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:00:44 [INFO]   Training abgeschlossen in 11.43s (Backend: cuml)\n",
      "22:01:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:01:55 [INFO]   Training abgeschlossen in 11.58s (Backend: cuml)\n",
      "22:02:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:03:07 [INFO]   Training abgeschlossen in 11.83s (Backend: cuml)\n",
      "22:04:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:04:18 [INFO]   Training abgeschlossen in 12.07s (Backend: cuml)\n",
      "22:05:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:05:29 [INFO]   Training abgeschlossen in 12.27s (Backend: cuml)\n",
      "22:06:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:06:39 [INFO]   Training abgeschlossen in 12.45s (Backend: cuml)\n",
      "22:07:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:07:50 [INFO]   Training abgeschlossen in 12.66s (Backend: cuml)\n",
      "22:08:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:09:01 [INFO]   Training abgeschlossen in 12.94s (Backend: cuml)\n",
      "22:09:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:10:12 [INFO]   Training abgeschlossen in 13.12s (Backend: cuml)\n",
      "22:11:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:11:21 [INFO]   Training abgeschlossen in 13.23s (Backend: cuml)\n",
      "22:12:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:12:31 [INFO]   Training abgeschlossen in 13.43s (Backend: cuml)\n",
      "22:13:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:13:40 [INFO]   Training abgeschlossen in 13.84s (Backend: cuml)\n",
      "22:14:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:14:49 [INFO]   Training abgeschlossen in 13.92s (Backend: cuml)\n",
      "22:15:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:15:58 [INFO]   Training abgeschlossen in 14.12s (Backend: cuml)\n",
      "22:16:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:17:06 [INFO]   Training abgeschlossen in 14.33s (Backend: cuml)\n",
      "22:18:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:18:15 [INFO]   Training abgeschlossen in 14.62s (Backend: cuml)\n",
      "22:19:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:19:22 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "22:20:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:20:29 [INFO]   Training abgeschlossen in 14.73s (Backend: cuml)\n",
      "22:21:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:21:37 [INFO]   Training abgeschlossen in 14.84s (Backend: cuml)\n",
      "22:22:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:22:43 [INFO]   Training abgeschlossen in 15.13s (Backend: cuml)\n",
      "22:23:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:23:50 [INFO]   Training abgeschlossen in 15.29s (Backend: cuml)\n",
      "22:24:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:24:56 [INFO]   Training abgeschlossen in 15.51s (Backend: cuml)\n",
      "22:25:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:26:02 [INFO]   Training abgeschlossen in 15.84s (Backend: cuml)\n",
      "22:26:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:27:08 [INFO]   Training abgeschlossen in 16.36s (Backend: cuml)\n",
      "22:27:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:28:13 [INFO]   Training abgeschlossen in 16.19s (Backend: cuml)\n",
      "22:29:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:29:18 [INFO]   Training abgeschlossen in 16.27s (Backend: cuml)\n",
      "22:30:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:30:23 [INFO]   Training abgeschlossen in 16.52s (Backend: cuml)\n",
      "22:31:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:31:27 [INFO]   Training abgeschlossen in 16.72s (Backend: cuml)\n",
      "22:32:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:32:32 [INFO]   Training abgeschlossen in 17.00s (Backend: cuml)\n",
      "22:33:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:33:36 [INFO]   Training abgeschlossen in 17.18s (Backend: cuml)\n",
      "22:34:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:34:39 [INFO]   Training abgeschlossen in 17.53s (Backend: cuml)\n",
      "22:35:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:35:43 [INFO]   Training abgeschlossen in 17.86s (Backend: cuml)\n",
      "22:36:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:36:46 [INFO]   Training abgeschlossen in 18.21s (Backend: cuml)\n",
      "22:37:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:37:49 [INFO]   Training abgeschlossen in 18.06s (Backend: cuml)\n",
      "22:38:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:38:51 [INFO]   Training abgeschlossen in 18.40s (Backend: cuml)\n",
      "22:39:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:39:54 [INFO]   Training abgeschlossen in 18.54s (Backend: cuml)\n",
      "22:40:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:40:56 [INFO]   Training abgeschlossen in 18.78s (Backend: cuml)\n",
      "22:41:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:41:58 [INFO]   Training abgeschlossen in 18.87s (Backend: cuml)\n",
      "22:42:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:42:59 [INFO]   Training abgeschlossen in 19.24s (Backend: cuml)\n",
      "22:43:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:44:00 [INFO]   Training abgeschlossen in 19.54s (Backend: cuml)\n",
      "22:44:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:45:01 [INFO]   Training abgeschlossen in 19.68s (Backend: cuml)\n",
      "22:45:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:46:01 [INFO]   Training abgeschlossen in 19.99s (Backend: cuml)\n",
      "22:46:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:47:02 [INFO]   Training abgeschlossen in 20.17s (Backend: cuml)\n",
      "22:47:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:48:02 [INFO]   Training abgeschlossen in 20.54s (Backend: cuml)\n",
      "22:48:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:49:01 [INFO]   Training abgeschlossen in 20.76s (Backend: cuml)\n",
      "22:49:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:50:01 [INFO]   Training abgeschlossen in 20.94s (Backend: cuml)\n",
      "22:50:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:51:00 [INFO]   Training abgeschlossen in 21.11s (Backend: cuml)\n",
      "22:51:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:51:58 [INFO]   Training abgeschlossen in 21.28s (Backend: cuml)\n",
      "22:52:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:52:56 [INFO]   Training abgeschlossen in 21.31s (Backend: cuml)\n",
      "22:53:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:53:54 [INFO]   Training abgeschlossen in 21.60s (Backend: cuml)\n",
      "22:54:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:54:52 [INFO]   Training abgeschlossen in 21.86s (Backend: cuml)\n",
      "22:55:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:55:49 [INFO]   Training abgeschlossen in 21.89s (Backend: cuml)\n",
      "22:56:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:56:46 [INFO]   Training abgeschlossen in 22.23s (Backend: cuml)\n",
      "22:57:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:57:43 [INFO]   Training abgeschlossen in 22.44s (Backend: cuml)\n",
      "22:58:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:58:40 [INFO]   Training abgeschlossen in 22.67s (Backend: cuml)\n",
      "22:59:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:59:36 [INFO]   Training abgeschlossen in 23.01s (Backend: cuml)\n",
      "23:00:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:00:32 [INFO]   Training abgeschlossen in 23.12s (Backend: cuml)\n",
      "23:01:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:01:27 [INFO]   Training abgeschlossen in 23.22s (Backend: cuml)\n",
      "23:01:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:02:22 [INFO]   Training abgeschlossen in 23.52s (Backend: cuml)\n",
      "23:02:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:03:17 [INFO]   Training abgeschlossen in 23.82s (Backend: cuml)\n",
      "23:03:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:04:12 [INFO]   Training abgeschlossen in 23.98s (Backend: cuml)\n",
      "23:04:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:05:06 [INFO]   Training abgeschlossen in 24.02s (Backend: cuml)\n",
      "23:05:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:05:59 [INFO]   Training abgeschlossen in 24.15s (Backend: cuml)\n",
      "23:06:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:06:52 [INFO]   Training abgeschlossen in 24.47s (Backend: cuml)\n",
      "23:07:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:07:45 [INFO]   Training abgeschlossen in 24.60s (Backend: cuml)\n",
      "23:08:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:08:38 [INFO]   Training abgeschlossen in 24.83s (Backend: cuml)\n",
      "23:09:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:09:30 [INFO]   Training abgeschlossen in 25.07s (Backend: cuml)\n",
      "23:09:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:10:22 [INFO]   Training abgeschlossen in 25.13s (Backend: cuml)\n",
      "23:10:47 [INFO]     48,000 labeled → Accuracy: 0.9662 (Train: 25.1s, Query: 14.21s) | GPU: 2.8/8.0 GB\n",
      "23:10:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:11:13 [INFO]   Training abgeschlossen in 25.37s (Backend: cuml)\n",
      "23:11:25 [INFO]     Final: 48,000 labeled → Accuracy: 0.9663, F1: 0.9661\n",
      "23:11:25 [INFO] \n",
      "GPU-SVM + Entropy Sampling - Budget: 100% (60,000 Samples)\n",
      "23:11:25 [INFO]   Run 1/5\n",
      "23:11:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:11:30 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "23:12:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:12:42 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "23:13:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:13:54 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "23:15:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:15:06 [INFO]   Training abgeschlossen in 5.08s (Backend: cuml)\n",
      "23:16:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:16:19 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "23:17:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:17:32 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "23:18:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:18:45 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "23:19:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:19:58 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "23:21:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:21:13 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "23:22:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:22:27 [INFO]   Training abgeschlossen in 7.16s (Backend: cuml)\n",
      "23:23:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:23:41 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "23:24:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:24:55 [INFO]   Training abgeschlossen in 7.95s (Backend: cuml)\n",
      "23:26:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:26:09 [INFO]   Training abgeschlossen in 8.06s (Backend: cuml)\n",
      "23:27:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:27:23 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "23:28:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:28:38 [INFO]   Training abgeschlossen in 8.60s (Backend: cuml)\n",
      "23:29:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:29:51 [INFO]   Training abgeschlossen in 8.68s (Backend: cuml)\n",
      "23:30:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:31:05 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "23:32:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:32:18 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "23:33:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:33:32 [INFO]   Training abgeschlossen in 9.52s (Backend: cuml)\n",
      "23:34:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:34:45 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "23:35:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:35:58 [INFO]   Training abgeschlossen in 9.83s (Backend: cuml)\n",
      "23:37:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:37:12 [INFO]   Training abgeschlossen in 10.21s (Backend: cuml)\n",
      "23:38:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:38:25 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "23:39:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:39:37 [INFO]   Training abgeschlossen in 10.51s (Backend: cuml)\n",
      "23:40:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:40:49 [INFO]   Training abgeschlossen in 10.71s (Backend: cuml)\n",
      "23:41:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:42:02 [INFO]   Training abgeschlossen in 11.12s (Backend: cuml)\n",
      "23:43:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:43:14 [INFO]   Training abgeschlossen in 11.14s (Backend: cuml)\n",
      "23:44:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:44:26 [INFO]   Training abgeschlossen in 11.38s (Backend: cuml)\n",
      "23:45:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:45:37 [INFO]   Training abgeschlossen in 11.66s (Backend: cuml)\n",
      "23:46:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:46:49 [INFO]   Training abgeschlossen in 11.83s (Backend: cuml)\n",
      "23:47:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:48:00 [INFO]   Training abgeschlossen in 11.93s (Backend: cuml)\n",
      "23:48:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:49:10 [INFO]   Training abgeschlossen in 12.22s (Backend: cuml)\n",
      "23:50:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:50:21 [INFO]   Training abgeschlossen in 12.47s (Backend: cuml)\n",
      "23:51:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:51:31 [INFO]   Training abgeschlossen in 12.67s (Backend: cuml)\n",
      "23:52:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:52:41 [INFO]   Training abgeschlossen in 12.87s (Backend: cuml)\n",
      "23:53:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:53:51 [INFO]   Training abgeschlossen in 13.00s (Backend: cuml)\n",
      "23:54:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:55:01 [INFO]   Training abgeschlossen in 13.20s (Backend: cuml)\n",
      "23:55:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:56:10 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "23:57:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:57:19 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "23:58:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:58:28 [INFO]   Training abgeschlossen in 13.81s (Backend: cuml)\n",
      "23:59:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:59:36 [INFO]   Training abgeschlossen in 14.03s (Backend: cuml)\n",
      "00:00:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:00:45 [INFO]   Training abgeschlossen in 14.27s (Backend: cuml)\n",
      "00:01:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:01:53 [INFO]   Training abgeschlossen in 14.69s (Backend: cuml)\n",
      "00:02:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:03:00 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "00:03:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:04:07 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "00:04:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:05:14 [INFO]   Training abgeschlossen in 14.82s (Backend: cuml)\n",
      "00:06:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:06:21 [INFO]   Training abgeschlossen in 15.02s (Backend: cuml)\n",
      "00:07:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:07:27 [INFO]   Training abgeschlossen in 15.48s (Backend: cuml)\n",
      "00:08:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:08:34 [INFO]   Training abgeschlossen in 15.62s (Backend: cuml)\n",
      "00:09:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:09:39 [INFO]   Training abgeschlossen in 15.69s (Backend: cuml)\n",
      "00:10:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:10:45 [INFO]   Training abgeschlossen in 16.08s (Backend: cuml)\n",
      "00:11:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:11:50 [INFO]   Training abgeschlossen in 16.05s (Backend: cuml)\n",
      "00:12:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:12:55 [INFO]   Training abgeschlossen in 16.27s (Backend: cuml)\n",
      "00:13:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:14:00 [INFO]   Training abgeschlossen in 16.47s (Backend: cuml)\n",
      "00:14:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:15:04 [INFO]   Training abgeschlossen in 16.83s (Backend: cuml)\n",
      "00:15:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:16:08 [INFO]   Training abgeschlossen in 16.99s (Backend: cuml)\n",
      "00:16:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:17:12 [INFO]   Training abgeschlossen in 17.22s (Backend: cuml)\n",
      "00:17:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:18:16 [INFO]   Training abgeschlossen in 17.38s (Backend: cuml)\n",
      "00:19:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:19:19 [INFO]   Training abgeschlossen in 17.58s (Backend: cuml)\n",
      "00:20:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:20:22 [INFO]   Training abgeschlossen in 17.96s (Backend: cuml)\n",
      "00:21:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:21:24 [INFO]   Training abgeschlossen in 18.10s (Backend: cuml)\n",
      "00:22:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:22:27 [INFO]   Training abgeschlossen in 18.33s (Backend: cuml)\n",
      "00:23:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:23:29 [INFO]   Training abgeschlossen in 18.55s (Backend: cuml)\n",
      "00:24:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:24:31 [INFO]   Training abgeschlossen in 18.75s (Backend: cuml)\n",
      "00:25:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:25:33 [INFO]   Training abgeschlossen in 19.05s (Backend: cuml)\n",
      "00:26:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:26:34 [INFO]   Training abgeschlossen in 19.25s (Backend: cuml)\n",
      "00:27:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:27:35 [INFO]   Training abgeschlossen in 19.52s (Backend: cuml)\n",
      "00:28:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:28:36 [INFO]   Training abgeschlossen in 19.55s (Backend: cuml)\n",
      "00:29:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:29:36 [INFO]   Training abgeschlossen in 19.88s (Backend: cuml)\n",
      "00:30:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:30:36 [INFO]   Training abgeschlossen in 19.95s (Backend: cuml)\n",
      "00:31:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:31:36 [INFO]   Training abgeschlossen in 20.28s (Backend: cuml)\n",
      "00:32:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:32:35 [INFO]   Training abgeschlossen in 20.44s (Backend: cuml)\n",
      "00:33:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:33:34 [INFO]   Training abgeschlossen in 20.64s (Backend: cuml)\n",
      "00:34:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:34:33 [INFO]   Training abgeschlossen in 20.80s (Backend: cuml)\n",
      "00:35:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:35:31 [INFO]   Training abgeschlossen in 21.06s (Backend: cuml)\n",
      "00:36:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:36:29 [INFO]   Training abgeschlossen in 21.33s (Backend: cuml)\n",
      "00:37:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:37:27 [INFO]   Training abgeschlossen in 21.55s (Backend: cuml)\n",
      "00:38:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:38:25 [INFO]   Training abgeschlossen in 21.73s (Backend: cuml)\n",
      "00:39:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:39:22 [INFO]   Training abgeschlossen in 21.95s (Backend: cuml)\n",
      "00:39:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:40:19 [INFO]   Training abgeschlossen in 22.20s (Backend: cuml)\n",
      "00:40:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:41:16 [INFO]   Training abgeschlossen in 22.34s (Backend: cuml)\n",
      "00:41:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:42:12 [INFO]   Training abgeschlossen in 22.55s (Backend: cuml)\n",
      "00:42:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:43:08 [INFO]   Training abgeschlossen in 22.82s (Backend: cuml)\n",
      "00:43:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:44:04 [INFO]   Training abgeschlossen in 23.00s (Backend: cuml)\n",
      "00:44:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:44:59 [INFO]   Training abgeschlossen in 23.16s (Backend: cuml)\n",
      "00:45:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:45:54 [INFO]   Training abgeschlossen in 23.43s (Backend: cuml)\n",
      "00:46:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:46:49 [INFO]   Training abgeschlossen in 23.56s (Backend: cuml)\n",
      "00:47:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:47:43 [INFO]   Training abgeschlossen in 23.70s (Backend: cuml)\n",
      "00:48:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:48:37 [INFO]   Training abgeschlossen in 23.91s (Backend: cuml)\n",
      "00:49:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:49:31 [INFO]   Training abgeschlossen in 24.31s (Backend: cuml)\n",
      "00:50:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:50:24 [INFO]   Training abgeschlossen in 24.44s (Backend: cuml)\n",
      "00:50:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:51:17 [INFO]   Training abgeschlossen in 24.67s (Backend: cuml)\n",
      "00:51:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:52:10 [INFO]   Training abgeschlossen in 24.88s (Backend: cuml)\n",
      "00:52:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:53:02 [INFO]   Training abgeschlossen in 25.11s (Backend: cuml)\n",
      "00:53:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:53:54 [INFO]   Training abgeschlossen in 25.37s (Backend: cuml)\n",
      "00:54:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:54:46 [INFO]   Training abgeschlossen in 25.62s (Backend: cuml)\n",
      "00:55:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:55:37 [INFO]   Training abgeschlossen in 25.83s (Backend: cuml)\n",
      "00:56:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:56:28 [INFO]   Training abgeschlossen in 26.05s (Backend: cuml)\n",
      "00:56:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:57:19 [INFO]   Training abgeschlossen in 26.18s (Backend: cuml)\n",
      "00:57:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:58:22 [INFO]   Training abgeschlossen in 39.90s (Backend: cuml)\n",
      "00:58:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:59:25 [INFO]   Training abgeschlossen in 39.55s (Backend: cuml)\n",
      "00:59:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:00:28 [INFO]   Training abgeschlossen in 40.96s (Backend: cuml)\n",
      "01:00:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:01:31 [INFO]   Training abgeschlossen in 40.31s (Backend: cuml)\n",
      "01:01:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:02:34 [INFO]   Training abgeschlossen in 41.33s (Backend: cuml)\n",
      "01:02:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:03:34 [INFO]   Training abgeschlossen in 39.28s (Backend: cuml)\n",
      "01:03:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:04:36 [INFO]   Training abgeschlossen in 42.03s (Backend: cuml)\n",
      "01:04:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:05:36 [INFO]   Training abgeschlossen in 40.11s (Backend: cuml)\n",
      "01:05:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:06:36 [INFO]   Training abgeschlossen in 40.80s (Backend: cuml)\n",
      "01:06:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:07:39 [INFO]   Training abgeschlossen in 43.57s (Backend: cuml)\n",
      "01:07:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:08:39 [INFO]   Training abgeschlossen in 41.87s (Backend: cuml)\n",
      "01:08:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:09:37 [INFO]   Training abgeschlossen in 40.95s (Backend: cuml)\n",
      "01:09:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:10:36 [INFO]   Training abgeschlossen in 42.15s (Backend: cuml)\n",
      "01:10:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:11:35 [INFO]   Training abgeschlossen in 42.17s (Backend: cuml)\n",
      "01:11:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:12:37 [INFO]   Training abgeschlossen in 45.20s (Backend: cuml)\n",
      "01:12:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:13:34 [INFO]   Training abgeschlossen in 41.70s (Backend: cuml)\n",
      "01:13:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:14:31 [INFO]   Training abgeschlossen in 42.71s (Backend: cuml)\n",
      "01:14:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:15:27 [INFO]   Training abgeschlossen in 41.98s (Backend: cuml)\n",
      "01:15:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:16:25 [INFO]   Training abgeschlossen in 44.12s (Backend: cuml)\n",
      "01:16:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:17:22 [INFO]   Training abgeschlossen in 43.12s (Backend: cuml)\n",
      "01:17:34 [INFO]     60,000 labeled → Accuracy: 0.9668 (Train: 43.1s, Query: 0.67s) | GPU: 2.8/8.0 GB\n",
      "01:17:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:18:20 [INFO]   Training abgeschlossen in 45.54s (Backend: cuml)\n",
      "01:18:31 [INFO]     Final: 60,000 labeled → Accuracy: 0.9667, F1: 0.9664\n",
      "01:18:31 [INFO]   Run 2/5\n",
      "01:18:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:18:36 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "01:19:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:19:48 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "01:20:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:20:59 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "01:22:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:22:11 [INFO]   Training abgeschlossen in 5.17s (Backend: cuml)\n",
      "01:23:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:23:24 [INFO]   Training abgeschlossen in 5.53s (Backend: cuml)\n",
      "01:24:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:24:36 [INFO]   Training abgeschlossen in 5.72s (Backend: cuml)\n",
      "01:25:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:25:50 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "01:26:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:27:03 [INFO]   Training abgeschlossen in 6.43s (Backend: cuml)\n",
      "01:28:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:28:17 [INFO]   Training abgeschlossen in 6.72s (Backend: cuml)\n",
      "01:29:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:29:31 [INFO]   Training abgeschlossen in 7.15s (Backend: cuml)\n",
      "01:30:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:30:45 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "01:31:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:32:00 [INFO]   Training abgeschlossen in 7.83s (Backend: cuml)\n",
      "01:33:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:33:14 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "01:34:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:34:28 [INFO]   Training abgeschlossen in 8.37s (Backend: cuml)\n",
      "01:35:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:35:42 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "01:36:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:36:56 [INFO]   Training abgeschlossen in 8.89s (Backend: cuml)\n",
      "01:38:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:38:10 [INFO]   Training abgeschlossen in 9.08s (Backend: cuml)\n",
      "01:39:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:39:24 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "01:40:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:40:37 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "01:41:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:41:51 [INFO]   Training abgeschlossen in 9.60s (Backend: cuml)\n",
      "01:42:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:43:04 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "01:44:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:44:17 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "01:45:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:45:30 [INFO]   Training abgeschlossen in 10.32s (Backend: cuml)\n",
      "01:46:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:46:43 [INFO]   Training abgeschlossen in 10.54s (Backend: cuml)\n",
      "01:47:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:47:55 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "01:48:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:49:08 [INFO]   Training abgeschlossen in 10.89s (Backend: cuml)\n",
      "01:50:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:50:20 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "01:51:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:51:32 [INFO]   Training abgeschlossen in 11.35s (Backend: cuml)\n",
      "01:52:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:52:43 [INFO]   Training abgeschlossen in 11.54s (Backend: cuml)\n",
      "01:53:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:53:54 [INFO]   Training abgeschlossen in 11.70s (Backend: cuml)\n",
      "01:54:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:55:06 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "01:56:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:56:17 [INFO]   Training abgeschlossen in 12.24s (Backend: cuml)\n",
      "01:57:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:57:27 [INFO]   Training abgeschlossen in 12.39s (Backend: cuml)\n",
      "01:58:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:58:39 [INFO]   Training abgeschlossen in 12.62s (Backend: cuml)\n",
      "01:59:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:59:49 [INFO]   Training abgeschlossen in 13.03s (Backend: cuml)\n",
      "02:00:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:01:00 [INFO]   Training abgeschlossen in 13.08s (Backend: cuml)\n",
      "02:01:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:02:11 [INFO]   Training abgeschlossen in 13.29s (Backend: cuml)\n",
      "02:03:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:03:21 [INFO]   Training abgeschlossen in 13.45s (Backend: cuml)\n",
      "02:04:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:04:31 [INFO]   Training abgeschlossen in 13.80s (Backend: cuml)\n",
      "02:05:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:05:42 [INFO]   Training abgeschlossen in 13.93s (Backend: cuml)\n",
      "02:06:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:06:50 [INFO]   Training abgeschlossen in 14.02s (Backend: cuml)\n",
      "02:07:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:07:59 [INFO]   Training abgeschlossen in 14.28s (Backend: cuml)\n",
      "02:08:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:09:07 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "02:10:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:10:15 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "02:11:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:11:22 [INFO]   Training abgeschlossen in 14.69s (Backend: cuml)\n",
      "02:12:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:12:29 [INFO]   Training abgeschlossen in 14.84s (Backend: cuml)\n",
      "02:13:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:13:36 [INFO]   Training abgeschlossen in 15.05s (Backend: cuml)\n",
      "02:14:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:14:42 [INFO]   Training abgeschlossen in 15.28s (Backend: cuml)\n",
      "02:15:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:15:49 [INFO]   Training abgeschlossen in 15.60s (Backend: cuml)\n",
      "02:16:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:16:55 [INFO]   Training abgeschlossen in 15.93s (Backend: cuml)\n",
      "02:17:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:18:01 [INFO]   Training abgeschlossen in 16.12s (Backend: cuml)\n",
      "02:18:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:19:06 [INFO]   Training abgeschlossen in 16.06s (Backend: cuml)\n",
      "02:19:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:20:11 [INFO]   Training abgeschlossen in 16.26s (Backend: cuml)\n",
      "02:20:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:21:16 [INFO]   Training abgeschlossen in 16.56s (Backend: cuml)\n",
      "02:22:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:22:20 [INFO]   Training abgeschlossen in 16.74s (Backend: cuml)\n",
      "02:23:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:23:24 [INFO]   Training abgeschlossen in 17.10s (Backend: cuml)\n",
      "02:24:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:24:28 [INFO]   Training abgeschlossen in 17.32s (Backend: cuml)\n",
      "02:25:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:25:32 [INFO]   Training abgeschlossen in 17.42s (Backend: cuml)\n",
      "02:26:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:26:36 [INFO]   Training abgeschlossen in 17.69s (Backend: cuml)\n",
      "02:27:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:27:39 [INFO]   Training abgeschlossen in 17.89s (Backend: cuml)\n",
      "02:28:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:28:42 [INFO]   Training abgeschlossen in 18.09s (Backend: cuml)\n",
      "02:29:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:29:44 [INFO]   Training abgeschlossen in 18.30s (Backend: cuml)\n",
      "02:30:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:30:46 [INFO]   Training abgeschlossen in 18.49s (Backend: cuml)\n",
      "02:31:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:31:48 [INFO]   Training abgeschlossen in 18.65s (Backend: cuml)\n",
      "02:32:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:32:50 [INFO]   Training abgeschlossen in 18.86s (Backend: cuml)\n",
      "02:33:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:33:51 [INFO]   Training abgeschlossen in 19.15s (Backend: cuml)\n",
      "02:34:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:34:52 [INFO]   Training abgeschlossen in 19.51s (Backend: cuml)\n",
      "02:35:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:35:53 [INFO]   Training abgeschlossen in 19.82s (Backend: cuml)\n",
      "02:36:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:36:53 [INFO]   Training abgeschlossen in 19.94s (Backend: cuml)\n",
      "02:37:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:37:53 [INFO]   Training abgeschlossen in 20.08s (Backend: cuml)\n",
      "02:38:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:38:53 [INFO]   Training abgeschlossen in 20.26s (Backend: cuml)\n",
      "02:39:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:39:52 [INFO]   Training abgeschlossen in 20.39s (Backend: cuml)\n",
      "02:40:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:40:51 [INFO]   Training abgeschlossen in 20.64s (Backend: cuml)\n",
      "02:41:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:41:50 [INFO]   Training abgeschlossen in 20.84s (Backend: cuml)\n",
      "02:42:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:42:49 [INFO]   Training abgeschlossen in 21.11s (Backend: cuml)\n",
      "02:43:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:43:47 [INFO]   Training abgeschlossen in 21.36s (Backend: cuml)\n",
      "02:44:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:44:45 [INFO]   Training abgeschlossen in 21.55s (Backend: cuml)\n",
      "02:45:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:45:43 [INFO]   Training abgeschlossen in 21.79s (Backend: cuml)\n",
      "02:46:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:46:40 [INFO]   Training abgeschlossen in 21.88s (Backend: cuml)\n",
      "02:47:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:47:37 [INFO]   Training abgeschlossen in 22.09s (Backend: cuml)\n",
      "02:48:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:48:33 [INFO]   Training abgeschlossen in 22.37s (Backend: cuml)\n",
      "02:49:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:49:30 [INFO]   Training abgeschlossen in 22.53s (Backend: cuml)\n",
      "02:50:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:50:26 [INFO]   Training abgeschlossen in 22.74s (Backend: cuml)\n",
      "02:50:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:51:21 [INFO]   Training abgeschlossen in 22.95s (Backend: cuml)\n",
      "02:51:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:52:17 [INFO]   Training abgeschlossen in 23.25s (Backend: cuml)\n",
      "02:52:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:53:12 [INFO]   Training abgeschlossen in 23.35s (Backend: cuml)\n",
      "02:53:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:54:06 [INFO]   Training abgeschlossen in 23.61s (Backend: cuml)\n",
      "02:54:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:55:01 [INFO]   Training abgeschlossen in 23.79s (Backend: cuml)\n",
      "02:55:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:55:55 [INFO]   Training abgeschlossen in 24.11s (Backend: cuml)\n",
      "02:56:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:56:48 [INFO]   Training abgeschlossen in 24.22s (Backend: cuml)\n",
      "02:57:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:57:42 [INFO]   Training abgeschlossen in 24.60s (Backend: cuml)\n",
      "02:58:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:58:35 [INFO]   Training abgeschlossen in 24.75s (Backend: cuml)\n",
      "02:59:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:59:27 [INFO]   Training abgeschlossen in 24.99s (Backend: cuml)\n",
      "02:59:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:00:20 [INFO]   Training abgeschlossen in 25.00s (Backend: cuml)\n",
      "03:00:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:01:12 [INFO]   Training abgeschlossen in 25.37s (Backend: cuml)\n",
      "03:01:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:02:03 [INFO]   Training abgeschlossen in 25.36s (Backend: cuml)\n",
      "03:02:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:02:54 [INFO]   Training abgeschlossen in 25.57s (Backend: cuml)\n",
      "03:03:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:03:45 [INFO]   Training abgeschlossen in 25.75s (Backend: cuml)\n",
      "03:04:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:04:35 [INFO]   Training abgeschlossen in 26.13s (Backend: cuml)\n",
      "03:04:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:05:39 [INFO]   Training abgeschlossen in 39.95s (Backend: cuml)\n",
      "03:06:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:06:40 [INFO]   Training abgeschlossen in 37.99s (Backend: cuml)\n",
      "03:07:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:07:41 [INFO]   Training abgeschlossen in 38.24s (Backend: cuml)\n",
      "03:08:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:08:43 [INFO]   Training abgeschlossen in 39.50s (Backend: cuml)\n",
      "03:09:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:09:44 [INFO]   Training abgeschlossen in 40.09s (Backend: cuml)\n",
      "03:10:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:10:45 [INFO]   Training abgeschlossen in 40.09s (Backend: cuml)\n",
      "03:11:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:11:45 [INFO]   Training abgeschlossen in 39.83s (Backend: cuml)\n",
      "03:12:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:12:47 [INFO]   Training abgeschlossen in 42.12s (Backend: cuml)\n",
      "03:13:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:13:50 [INFO]   Training abgeschlossen in 43.39s (Backend: cuml)\n",
      "03:14:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:14:51 [INFO]   Training abgeschlossen in 42.29s (Backend: cuml)\n",
      "03:15:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:15:50 [INFO]   Training abgeschlossen in 40.97s (Backend: cuml)\n",
      "03:16:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:16:52 [INFO]   Training abgeschlossen in 44.32s (Backend: cuml)\n",
      "03:17:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:17:50 [INFO]   Training abgeschlossen in 40.71s (Backend: cuml)\n",
      "03:18:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:18:49 [INFO]   Training abgeschlossen in 42.41s (Backend: cuml)\n",
      "03:19:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:19:48 [INFO]   Training abgeschlossen in 42.91s (Backend: cuml)\n",
      "03:20:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:20:46 [INFO]   Training abgeschlossen in 42.55s (Backend: cuml)\n",
      "03:21:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:21:43 [INFO]   Training abgeschlossen in 42.13s (Backend: cuml)\n",
      "03:21:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:22:40 [INFO]   Training abgeschlossen in 43.24s (Backend: cuml)\n",
      "03:22:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:23:39 [INFO]   Training abgeschlossen in 45.62s (Backend: cuml)\n",
      "03:23:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:24:36 [INFO]   Training abgeschlossen in 43.80s (Backend: cuml)\n",
      "03:24:49 [INFO]     60,000 labeled → Accuracy: 0.9666 (Train: 43.8s, Query: 0.74s) | GPU: 2.8/8.0 GB\n",
      "03:24:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:25:33 [INFO]   Training abgeschlossen in 43.25s (Backend: cuml)\n",
      "03:25:44 [INFO]     Final: 60,000 labeled → Accuracy: 0.9665, F1: 0.9662\n",
      "03:25:44 [INFO]   Run 3/5\n",
      "03:25:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:25:49 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "03:26:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:27:01 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "03:28:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:28:13 [INFO]   Training abgeschlossen in 5.05s (Backend: cuml)\n",
      "03:29:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:29:25 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "03:30:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:30:37 [INFO]   Training abgeschlossen in 5.51s (Backend: cuml)\n",
      "03:31:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:31:50 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "03:32:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:33:03 [INFO]   Training abgeschlossen in 5.91s (Backend: cuml)\n",
      "03:34:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:34:16 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "03:35:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:35:30 [INFO]   Training abgeschlossen in 7.06s (Backend: cuml)\n",
      "03:36:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:36:44 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "03:37:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:37:58 [INFO]   Training abgeschlossen in 7.80s (Backend: cuml)\n",
      "03:39:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:39:13 [INFO]   Training abgeschlossen in 7.95s (Backend: cuml)\n",
      "03:40:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:40:27 [INFO]   Training abgeschlossen in 8.07s (Backend: cuml)\n",
      "03:41:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:41:41 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "03:42:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:42:55 [INFO]   Training abgeschlossen in 8.55s (Backend: cuml)\n",
      "03:44:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:44:09 [INFO]   Training abgeschlossen in 8.74s (Backend: cuml)\n",
      "03:45:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:45:22 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "03:46:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:46:36 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "03:47:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:47:50 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "03:48:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:49:03 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "03:50:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:50:16 [INFO]   Training abgeschlossen in 9.89s (Backend: cuml)\n",
      "03:51:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:51:29 [INFO]   Training abgeschlossen in 10.18s (Backend: cuml)\n",
      "03:52:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:52:43 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "03:53:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:53:56 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "03:54:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:55:08 [INFO]   Training abgeschlossen in 10.72s (Backend: cuml)\n",
      "03:56:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:56:21 [INFO]   Training abgeschlossen in 11.12s (Backend: cuml)\n",
      "03:57:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:57:33 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "03:58:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:58:44 [INFO]   Training abgeschlossen in 11.34s (Backend: cuml)\n",
      "03:59:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:59:56 [INFO]   Training abgeschlossen in 11.55s (Backend: cuml)\n",
      "04:00:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:01:07 [INFO]   Training abgeschlossen in 11.86s (Backend: cuml)\n",
      "04:02:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:02:19 [INFO]   Training abgeschlossen in 11.97s (Backend: cuml)\n",
      "04:03:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:03:29 [INFO]   Training abgeschlossen in 12.13s (Backend: cuml)\n",
      "04:04:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:04:41 [INFO]   Training abgeschlossen in 12.38s (Backend: cuml)\n",
      "04:05:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:05:51 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "04:06:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:07:01 [INFO]   Training abgeschlossen in 12.88s (Backend: cuml)\n",
      "04:07:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:08:11 [INFO]   Training abgeschlossen in 13.09s (Backend: cuml)\n",
      "04:09:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:09:22 [INFO]   Training abgeschlossen in 13.26s (Backend: cuml)\n",
      "04:10:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:10:32 [INFO]   Training abgeschlossen in 13.47s (Backend: cuml)\n",
      "04:11:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:11:42 [INFO]   Training abgeschlossen in 13.68s (Backend: cuml)\n",
      "04:12:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:12:52 [INFO]   Training abgeschlossen in 13.80s (Backend: cuml)\n",
      "04:13:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:14:02 [INFO]   Training abgeschlossen in 14.09s (Backend: cuml)\n",
      "04:14:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:15:11 [INFO]   Training abgeschlossen in 14.30s (Backend: cuml)\n",
      "04:16:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:16:20 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "04:17:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:17:27 [INFO]   Training abgeschlossen in 14.44s (Backend: cuml)\n",
      "04:18:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:18:34 [INFO]   Training abgeschlossen in 14.71s (Backend: cuml)\n",
      "04:19:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:19:41 [INFO]   Training abgeschlossen in 14.86s (Backend: cuml)\n",
      "04:20:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:20:48 [INFO]   Training abgeschlossen in 15.01s (Backend: cuml)\n",
      "04:21:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:21:55 [INFO]   Training abgeschlossen in 15.37s (Backend: cuml)\n",
      "04:22:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:23:01 [INFO]   Training abgeschlossen in 15.49s (Backend: cuml)\n",
      "04:23:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:24:07 [INFO]   Training abgeschlossen in 15.74s (Backend: cuml)\n",
      "04:24:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:25:12 [INFO]   Training abgeschlossen in 16.12s (Backend: cuml)\n",
      "04:26:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:26:18 [INFO]   Training abgeschlossen in 16.10s (Backend: cuml)\n",
      "04:27:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:27:23 [INFO]   Training abgeschlossen in 16.30s (Backend: cuml)\n",
      "04:28:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:28:27 [INFO]   Training abgeschlossen in 16.62s (Backend: cuml)\n",
      "04:29:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:29:33 [INFO]   Training abgeschlossen in 16.90s (Backend: cuml)\n",
      "04:30:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:30:37 [INFO]   Training abgeschlossen in 16.96s (Backend: cuml)\n",
      "04:31:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:31:42 [INFO]   Training abgeschlossen in 17.15s (Backend: cuml)\n",
      "04:32:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:32:46 [INFO]   Training abgeschlossen in 17.58s (Backend: cuml)\n",
      "04:33:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:33:50 [INFO]   Training abgeschlossen in 17.71s (Backend: cuml)\n",
      "04:34:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:34:54 [INFO]   Training abgeschlossen in 17.94s (Backend: cuml)\n",
      "04:35:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:35:57 [INFO]   Training abgeschlossen in 18.18s (Backend: cuml)\n",
      "04:36:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:36:59 [INFO]   Training abgeschlossen in 18.38s (Backend: cuml)\n",
      "04:37:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:38:02 [INFO]   Training abgeschlossen in 18.71s (Backend: cuml)\n",
      "04:38:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:39:04 [INFO]   Training abgeschlossen in 18.89s (Backend: cuml)\n",
      "04:39:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:40:05 [INFO]   Training abgeschlossen in 19.01s (Backend: cuml)\n",
      "04:40:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:41:07 [INFO]   Training abgeschlossen in 19.28s (Backend: cuml)\n",
      "04:41:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:42:08 [INFO]   Training abgeschlossen in 19.45s (Backend: cuml)\n",
      "04:42:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:43:09 [INFO]   Training abgeschlossen in 19.69s (Backend: cuml)\n",
      "04:43:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:44:09 [INFO]   Training abgeschlossen in 19.89s (Backend: cuml)\n",
      "04:44:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:45:09 [INFO]   Training abgeschlossen in 20.18s (Backend: cuml)\n",
      "04:45:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:46:09 [INFO]   Training abgeschlossen in 20.31s (Backend: cuml)\n",
      "04:46:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:47:09 [INFO]   Training abgeschlossen in 20.54s (Backend: cuml)\n",
      "04:47:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:48:08 [INFO]   Training abgeschlossen in 20.95s (Backend: cuml)\n",
      "04:48:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:49:08 [INFO]   Training abgeschlossen in 21.14s (Backend: cuml)\n",
      "04:49:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:50:06 [INFO]   Training abgeschlossen in 21.27s (Backend: cuml)\n",
      "04:50:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:51:05 [INFO]   Training abgeschlossen in 21.38s (Backend: cuml)\n",
      "04:51:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:52:03 [INFO]   Training abgeschlossen in 21.70s (Backend: cuml)\n",
      "04:52:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:53:01 [INFO]   Training abgeschlossen in 21.86s (Backend: cuml)\n",
      "04:53:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:53:58 [INFO]   Training abgeschlossen in 21.99s (Backend: cuml)\n",
      "04:54:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:54:55 [INFO]   Training abgeschlossen in 22.17s (Backend: cuml)\n",
      "04:55:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:55:52 [INFO]   Training abgeschlossen in 22.37s (Backend: cuml)\n",
      "04:56:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:56:48 [INFO]   Training abgeschlossen in 22.51s (Backend: cuml)\n",
      "04:57:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:57:44 [INFO]   Training abgeschlossen in 22.80s (Backend: cuml)\n",
      "04:58:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:58:40 [INFO]   Training abgeschlossen in 23.10s (Backend: cuml)\n",
      "04:59:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:59:35 [INFO]   Training abgeschlossen in 23.19s (Backend: cuml)\n",
      "05:00:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:00:30 [INFO]   Training abgeschlossen in 23.45s (Backend: cuml)\n",
      "05:01:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:01:25 [INFO]   Training abgeschlossen in 23.54s (Backend: cuml)\n",
      "05:01:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:02:19 [INFO]   Training abgeschlossen in 23.74s (Backend: cuml)\n",
      "05:02:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:03:13 [INFO]   Training abgeschlossen in 24.12s (Backend: cuml)\n",
      "05:03:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:04:07 [INFO]   Training abgeschlossen in 24.27s (Backend: cuml)\n",
      "05:04:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:05:00 [INFO]   Training abgeschlossen in 24.45s (Backend: cuml)\n",
      "05:05:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:05:53 [INFO]   Training abgeschlossen in 24.55s (Backend: cuml)\n",
      "05:06:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:06:45 [INFO]   Training abgeschlossen in 24.79s (Backend: cuml)\n",
      "05:07:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:07:38 [INFO]   Training abgeschlossen in 25.12s (Backend: cuml)\n",
      "05:08:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:08:29 [INFO]   Training abgeschlossen in 25.18s (Backend: cuml)\n",
      "05:08:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:09:21 [INFO]   Training abgeschlossen in 25.35s (Backend: cuml)\n",
      "05:09:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:10:12 [INFO]   Training abgeschlossen in 25.60s (Backend: cuml)\n",
      "05:10:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:11:02 [INFO]   Training abgeschlossen in 25.85s (Backend: cuml)\n",
      "05:11:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:11:53 [INFO]   Training abgeschlossen in 26.43s (Backend: cuml)\n",
      "05:12:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:12:55 [INFO]   Training abgeschlossen in 38.34s (Backend: cuml)\n",
      "05:13:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:13:59 [INFO]   Training abgeschlossen in 40.06s (Backend: cuml)\n",
      "05:14:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:15:01 [INFO]   Training abgeschlossen in 39.59s (Backend: cuml)\n",
      "05:15:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:16:03 [INFO]   Training abgeschlossen in 40.05s (Backend: cuml)\n",
      "05:16:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:17:05 [INFO]   Training abgeschlossen in 41.01s (Backend: cuml)\n",
      "05:17:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:18:06 [INFO]   Training abgeschlossen in 40.04s (Backend: cuml)\n",
      "05:18:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:19:08 [INFO]   Training abgeschlossen in 40.96s (Backend: cuml)\n",
      "05:19:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:20:07 [INFO]   Training abgeschlossen in 39.35s (Backend: cuml)\n",
      "05:20:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:21:07 [INFO]   Training abgeschlossen in 40.65s (Backend: cuml)\n",
      "05:21:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:22:08 [INFO]   Training abgeschlossen in 42.54s (Backend: cuml)\n",
      "05:22:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:23:06 [INFO]   Training abgeschlossen in 40.17s (Backend: cuml)\n",
      "05:23:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:24:06 [INFO]   Training abgeschlossen in 41.96s (Backend: cuml)\n",
      "05:24:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:25:06 [INFO]   Training abgeschlossen in 43.20s (Backend: cuml)\n",
      "05:25:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:26:05 [INFO]   Training abgeschlossen in 42.73s (Backend: cuml)\n",
      "05:26:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:27:05 [INFO]   Training abgeschlossen in 43.81s (Backend: cuml)\n",
      "05:27:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:28:05 [INFO]   Training abgeschlossen in 44.66s (Backend: cuml)\n",
      "05:28:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:29:05 [INFO]   Training abgeschlossen in 44.98s (Backend: cuml)\n",
      "05:29:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:30:03 [INFO]   Training abgeschlossen in 43.48s (Backend: cuml)\n",
      "05:30:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:31:00 [INFO]   Training abgeschlossen in 42.79s (Backend: cuml)\n",
      "05:31:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:31:56 [INFO]   Training abgeschlossen in 43.25s (Backend: cuml)\n",
      "05:32:09 [INFO]     60,000 labeled → Accuracy: 0.9659 (Train: 43.3s, Query: 0.67s) | GPU: 2.8/8.0 GB\n",
      "05:32:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:32:52 [INFO]   Training abgeschlossen in 42.97s (Backend: cuml)\n",
      "05:33:03 [INFO]     Final: 60,000 labeled → Accuracy: 0.9660, F1: 0.9657\n",
      "05:33:04 [INFO]   Run 4/5\n",
      "05:33:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:33:09 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "05:34:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "05:34:20 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "05:35:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "05:35:32 [INFO]   Training abgeschlossen in 5.01s (Backend: cuml)\n",
      "05:36:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "05:36:44 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "05:37:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:37:56 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "05:39:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:39:09 [INFO]   Training abgeschlossen in 5.78s (Backend: cuml)\n",
      "05:40:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:40:22 [INFO]   Training abgeschlossen in 5.97s (Backend: cuml)\n",
      "05:41:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:41:35 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "05:42:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:42:49 [INFO]   Training abgeschlossen in 6.76s (Backend: cuml)\n",
      "05:43:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:44:03 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "05:45:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:45:18 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "05:46:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:46:32 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "05:47:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:47:46 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "05:48:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:49:00 [INFO]   Training abgeschlossen in 8.31s (Backend: cuml)\n",
      "05:50:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:50:15 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "05:51:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:51:28 [INFO]   Training abgeschlossen in 8.85s (Backend: cuml)\n",
      "05:52:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:52:42 [INFO]   Training abgeschlossen in 8.91s (Backend: cuml)\n",
      "05:53:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:53:56 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "05:54:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:55:09 [INFO]   Training abgeschlossen in 9.37s (Backend: cuml)\n",
      "05:56:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:56:22 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "05:57:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:57:35 [INFO]   Training abgeschlossen in 9.84s (Backend: cuml)\n",
      "05:58:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:58:48 [INFO]   Training abgeschlossen in 10.06s (Backend: cuml)\n",
      "05:59:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:00:02 [INFO]   Training abgeschlossen in 10.34s (Backend: cuml)\n",
      "06:01:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:01:14 [INFO]   Training abgeschlossen in 10.60s (Backend: cuml)\n",
      "06:02:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:02:27 [INFO]   Training abgeschlossen in 10.72s (Backend: cuml)\n",
      "06:03:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:03:39 [INFO]   Training abgeschlossen in 10.90s (Backend: cuml)\n",
      "06:04:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:04:51 [INFO]   Training abgeschlossen in 11.29s (Backend: cuml)\n",
      "06:05:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:06:03 [INFO]   Training abgeschlossen in 11.30s (Backend: cuml)\n",
      "06:07:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:07:15 [INFO]   Training abgeschlossen in 11.52s (Backend: cuml)\n",
      "06:08:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:08:26 [INFO]   Training abgeschlossen in 11.73s (Backend: cuml)\n",
      "06:09:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:09:39 [INFO]   Training abgeschlossen in 12.19s (Backend: cuml)\n",
      "06:10:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:10:51 [INFO]   Training abgeschlossen in 12.13s (Backend: cuml)\n",
      "06:11:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:12:02 [INFO]   Training abgeschlossen in 12.35s (Backend: cuml)\n",
      "06:13:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:13:14 [INFO]   Training abgeschlossen in 12.64s (Backend: cuml)\n",
      "06:14:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:14:25 [INFO]   Training abgeschlossen in 12.92s (Backend: cuml)\n",
      "06:15:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:15:36 [INFO]   Training abgeschlossen in 12.99s (Backend: cuml)\n",
      "06:16:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:16:47 [INFO]   Training abgeschlossen in 13.22s (Backend: cuml)\n",
      "06:17:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:17:57 [INFO]   Training abgeschlossen in 13.43s (Backend: cuml)\n",
      "06:18:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:19:07 [INFO]   Training abgeschlossen in 13.78s (Backend: cuml)\n",
      "06:20:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:20:17 [INFO]   Training abgeschlossen in 13.92s (Backend: cuml)\n",
      "06:21:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:21:27 [INFO]   Training abgeschlossen in 14.08s (Backend: cuml)\n",
      "06:22:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:22:36 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "06:23:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:23:46 [INFO]   Training abgeschlossen in 14.73s (Backend: cuml)\n",
      "06:24:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:24:53 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "06:25:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:26:01 [INFO]   Training abgeschlossen in 14.64s (Backend: cuml)\n",
      "06:26:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:27:07 [INFO]   Training abgeschlossen in 14.78s (Backend: cuml)\n",
      "06:27:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:28:14 [INFO]   Training abgeschlossen in 15.04s (Backend: cuml)\n",
      "06:29:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:29:22 [INFO]   Training abgeschlossen in 15.25s (Backend: cuml)\n",
      "06:30:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:30:28 [INFO]   Training abgeschlossen in 15.61s (Backend: cuml)\n",
      "06:31:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:31:34 [INFO]   Training abgeschlossen in 15.73s (Backend: cuml)\n",
      "06:32:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:32:40 [INFO]   Training abgeschlossen in 16.11s (Backend: cuml)\n",
      "06:33:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:33:46 [INFO]   Training abgeschlossen in 16.04s (Backend: cuml)\n",
      "06:34:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:34:51 [INFO]   Training abgeschlossen in 16.32s (Backend: cuml)\n",
      "06:35:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:35:56 [INFO]   Training abgeschlossen in 16.47s (Backend: cuml)\n",
      "06:36:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:37:00 [INFO]   Training abgeschlossen in 16.94s (Backend: cuml)\n",
      "06:37:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:38:05 [INFO]   Training abgeschlossen in 17.19s (Backend: cuml)\n",
      "06:38:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:39:09 [INFO]   Training abgeschlossen in 17.32s (Backend: cuml)\n",
      "06:39:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:40:13 [INFO]   Training abgeschlossen in 17.55s (Backend: cuml)\n",
      "06:40:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:41:16 [INFO]   Training abgeschlossen in 17.61s (Backend: cuml)\n",
      "06:42:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:42:19 [INFO]   Training abgeschlossen in 17.87s (Backend: cuml)\n",
      "06:43:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:43:22 [INFO]   Training abgeschlossen in 18.06s (Backend: cuml)\n",
      "06:44:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:44:24 [INFO]   Training abgeschlossen in 18.35s (Backend: cuml)\n",
      "06:45:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:45:26 [INFO]   Training abgeschlossen in 18.41s (Backend: cuml)\n",
      "06:46:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:46:28 [INFO]   Training abgeschlossen in 18.76s (Backend: cuml)\n",
      "06:47:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:47:30 [INFO]   Training abgeschlossen in 18.89s (Backend: cuml)\n",
      "06:48:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:48:31 [INFO]   Training abgeschlossen in 19.09s (Backend: cuml)\n",
      "06:49:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:49:32 [INFO]   Training abgeschlossen in 19.46s (Backend: cuml)\n",
      "06:50:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:50:33 [INFO]   Training abgeschlossen in 19.68s (Backend: cuml)\n",
      "06:51:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:51:33 [INFO]   Training abgeschlossen in 19.76s (Backend: cuml)\n",
      "06:52:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:52:33 [INFO]   Training abgeschlossen in 20.05s (Backend: cuml)\n",
      "06:53:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:53:32 [INFO]   Training abgeschlossen in 20.22s (Backend: cuml)\n",
      "06:54:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:54:32 [INFO]   Training abgeschlossen in 20.40s (Backend: cuml)\n",
      "06:55:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:55:31 [INFO]   Training abgeschlossen in 20.60s (Backend: cuml)\n",
      "06:56:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:56:30 [INFO]   Training abgeschlossen in 20.85s (Backend: cuml)\n",
      "06:57:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:57:28 [INFO]   Training abgeschlossen in 21.10s (Backend: cuml)\n",
      "06:58:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:58:26 [INFO]   Training abgeschlossen in 21.34s (Backend: cuml)\n",
      "06:59:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:59:24 [INFO]   Training abgeschlossen in 21.53s (Backend: cuml)\n",
      "07:00:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:00:22 [INFO]   Training abgeschlossen in 21.68s (Backend: cuml)\n",
      "07:00:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:01:19 [INFO]   Training abgeschlossen in 21.91s (Backend: cuml)\n",
      "07:01:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:02:16 [INFO]   Training abgeschlossen in 22.05s (Backend: cuml)\n",
      "07:02:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:03:12 [INFO]   Training abgeschlossen in 22.26s (Backend: cuml)\n",
      "07:03:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:04:09 [INFO]   Training abgeschlossen in 22.47s (Backend: cuml)\n",
      "07:04:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:05:05 [INFO]   Training abgeschlossen in 22.83s (Backend: cuml)\n",
      "07:05:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:06:01 [INFO]   Training abgeschlossen in 22.96s (Backend: cuml)\n",
      "07:06:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:06:56 [INFO]   Training abgeschlossen in 23.05s (Backend: cuml)\n",
      "07:07:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:07:51 [INFO]   Training abgeschlossen in 23.33s (Backend: cuml)\n",
      "07:08:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:08:45 [INFO]   Training abgeschlossen in 23.61s (Backend: cuml)\n",
      "07:09:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:09:40 [INFO]   Training abgeschlossen in 23.88s (Backend: cuml)\n",
      "07:10:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:10:34 [INFO]   Training abgeschlossen in 24.01s (Backend: cuml)\n",
      "07:11:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:11:27 [INFO]   Training abgeschlossen in 24.21s (Backend: cuml)\n",
      "07:11:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:12:21 [INFO]   Training abgeschlossen in 24.48s (Backend: cuml)\n",
      "07:12:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:13:14 [INFO]   Training abgeschlossen in 24.64s (Backend: cuml)\n",
      "07:13:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:14:06 [INFO]   Training abgeschlossen in 24.79s (Backend: cuml)\n",
      "07:14:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:14:58 [INFO]   Training abgeschlossen in 25.04s (Backend: cuml)\n",
      "07:15:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:15:50 [INFO]   Training abgeschlossen in 25.27s (Backend: cuml)\n",
      "07:16:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:16:41 [INFO]   Training abgeschlossen in 25.43s (Backend: cuml)\n",
      "07:17:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:17:32 [INFO]   Training abgeschlossen in 25.57s (Backend: cuml)\n",
      "07:17:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:18:23 [INFO]   Training abgeschlossen in 25.83s (Backend: cuml)\n",
      "07:18:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:19:14 [INFO]   Training abgeschlossen in 26.17s (Backend: cuml)\n",
      "07:19:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:20:16 [INFO]   Training abgeschlossen in 38.18s (Backend: cuml)\n",
      "07:20:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:21:19 [INFO]   Training abgeschlossen in 39.65s (Backend: cuml)\n",
      "07:21:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:22:21 [INFO]   Training abgeschlossen in 40.27s (Backend: cuml)\n",
      "07:22:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:23:23 [INFO]   Training abgeschlossen in 39.93s (Backend: cuml)\n",
      "07:23:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:24:26 [INFO]   Training abgeschlossen in 41.13s (Backend: cuml)\n",
      "07:24:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:25:28 [INFO]   Training abgeschlossen in 41.53s (Backend: cuml)\n",
      "07:25:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:26:28 [INFO]   Training abgeschlossen in 39.23s (Backend: cuml)\n",
      "07:26:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:27:29 [INFO]   Training abgeschlossen in 41.41s (Backend: cuml)\n",
      "07:27:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:28:29 [INFO]   Training abgeschlossen in 40.96s (Backend: cuml)\n",
      "07:28:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:29:30 [INFO]   Training abgeschlossen in 41.69s (Backend: cuml)\n",
      "07:29:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:30:30 [INFO]   Training abgeschlossen in 42.38s (Backend: cuml)\n",
      "07:30:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:31:30 [INFO]   Training abgeschlossen in 42.50s (Backend: cuml)\n",
      "07:31:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:32:29 [INFO]   Training abgeschlossen in 41.51s (Backend: cuml)\n",
      "07:32:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:33:29 [INFO]   Training abgeschlossen in 43.67s (Backend: cuml)\n",
      "07:33:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:34:27 [INFO]   Training abgeschlossen in 41.50s (Backend: cuml)\n",
      "07:34:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:35:25 [INFO]   Training abgeschlossen in 42.45s (Backend: cuml)\n",
      "07:35:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:36:22 [INFO]   Training abgeschlossen in 42.55s (Backend: cuml)\n",
      "07:36:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:37:19 [INFO]   Training abgeschlossen in 42.96s (Backend: cuml)\n",
      "07:37:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:38:16 [INFO]   Training abgeschlossen in 42.82s (Backend: cuml)\n",
      "07:38:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:39:11 [INFO]   Training abgeschlossen in 42.41s (Backend: cuml)\n",
      "07:39:24 [INFO]     60,000 labeled → Accuracy: 0.9662 (Train: 42.4s, Query: 0.67s) | GPU: 2.8/8.0 GB\n",
      "07:39:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:40:09 [INFO]   Training abgeschlossen in 45.30s (Backend: cuml)\n",
      "07:40:21 [INFO]     Final: 60,000 labeled → Accuracy: 0.9663, F1: 0.9660\n",
      "07:40:21 [INFO]   Run 5/5\n",
      "07:40:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:40:26 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "07:41:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "07:41:37 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "07:42:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "07:42:49 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "07:43:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "07:44:01 [INFO]   Training abgeschlossen in 5.17s (Backend: cuml)\n",
      "07:45:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:45:14 [INFO]   Training abgeschlossen in 5.52s (Backend: cuml)\n",
      "07:46:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:46:27 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "07:47:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:47:40 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "07:48:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:48:54 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "07:50:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:50:07 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "07:51:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:51:21 [INFO]   Training abgeschlossen in 7.11s (Backend: cuml)\n",
      "07:52:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:52:36 [INFO]   Training abgeschlossen in 7.72s (Backend: cuml)\n",
      "07:53:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:53:50 [INFO]   Training abgeschlossen in 7.92s (Backend: cuml)\n",
      "07:54:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:55:05 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "07:56:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:56:19 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "07:57:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:57:33 [INFO]   Training abgeschlossen in 8.75s (Backend: cuml)\n",
      "07:58:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:58:47 [INFO]   Training abgeschlossen in 8.69s (Backend: cuml)\n",
      "07:59:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:00:01 [INFO]   Training abgeschlossen in 8.94s (Backend: cuml)\n",
      "08:01:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:01:15 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "08:02:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:02:28 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "08:03:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:03:41 [INFO]   Training abgeschlossen in 9.62s (Backend: cuml)\n",
      "08:04:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:04:54 [INFO]   Training abgeschlossen in 9.85s (Backend: cuml)\n",
      "08:05:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:06:08 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "08:07:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:07:21 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "08:08:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:08:33 [INFO]   Training abgeschlossen in 10.51s (Backend: cuml)\n",
      "08:09:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:09:46 [INFO]   Training abgeschlossen in 10.76s (Backend: cuml)\n",
      "08:10:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:10:58 [INFO]   Training abgeschlossen in 11.04s (Backend: cuml)\n",
      "08:11:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:12:10 [INFO]   Training abgeschlossen in 11.24s (Backend: cuml)\n",
      "08:13:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:13:22 [INFO]   Training abgeschlossen in 11.43s (Backend: cuml)\n",
      "08:14:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:14:34 [INFO]   Training abgeschlossen in 11.71s (Backend: cuml)\n",
      "08:15:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:15:45 [INFO]   Training abgeschlossen in 11.96s (Backend: cuml)\n",
      "08:16:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:16:56 [INFO]   Training abgeschlossen in 11.97s (Backend: cuml)\n",
      "08:17:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:18:07 [INFO]   Training abgeschlossen in 12.17s (Backend: cuml)\n",
      "08:19:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:19:18 [INFO]   Training abgeschlossen in 12.41s (Backend: cuml)\n",
      "08:20:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:20:29 [INFO]   Training abgeschlossen in 12.84s (Backend: cuml)\n",
      "08:21:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:21:39 [INFO]   Training abgeschlossen in 12.83s (Backend: cuml)\n",
      "08:22:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:22:49 [INFO]   Training abgeschlossen in 13.10s (Backend: cuml)\n",
      "08:23:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:23:59 [INFO]   Training abgeschlossen in 13.23s (Backend: cuml)\n",
      "08:24:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:25:08 [INFO]   Training abgeschlossen in 13.57s (Backend: cuml)\n",
      "08:26:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:26:18 [INFO]   Training abgeschlossen in 13.67s (Backend: cuml)\n",
      "08:27:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:27:27 [INFO]   Training abgeschlossen in 13.85s (Backend: cuml)\n",
      "08:28:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:28:35 [INFO]   Training abgeschlossen in 14.08s (Backend: cuml)\n",
      "08:29:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:29:44 [INFO]   Training abgeschlossen in 14.36s (Backend: cuml)\n",
      "08:30:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:30:53 [INFO]   Training abgeschlossen in 14.70s (Backend: cuml)\n",
      "08:31:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:32:00 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "08:32:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:33:08 [INFO]   Training abgeschlossen in 14.65s (Backend: cuml)\n",
      "08:34:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:34:15 [INFO]   Training abgeschlossen in 14.97s (Backend: cuml)\n",
      "08:35:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:35:22 [INFO]   Training abgeschlossen in 15.27s (Backend: cuml)\n",
      "08:36:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:36:28 [INFO]   Training abgeschlossen in 15.42s (Backend: cuml)\n",
      "08:37:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:37:34 [INFO]   Training abgeschlossen in 15.47s (Backend: cuml)\n",
      "08:38:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:38:40 [INFO]   Training abgeschlossen in 15.72s (Backend: cuml)\n",
      "08:39:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:39:46 [INFO]   Training abgeschlossen in 16.12s (Backend: cuml)\n",
      "08:40:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:40:51 [INFO]   Training abgeschlossen in 16.10s (Backend: cuml)\n",
      "08:41:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:41:56 [INFO]   Training abgeschlossen in 16.44s (Backend: cuml)\n",
      "08:42:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:43:01 [INFO]   Training abgeschlossen in 16.56s (Backend: cuml)\n",
      "08:43:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:44:05 [INFO]   Training abgeschlossen in 16.78s (Backend: cuml)\n",
      "08:44:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:45:10 [INFO]   Training abgeschlossen in 17.11s (Backend: cuml)\n",
      "08:45:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:46:13 [INFO]   Training abgeschlossen in 17.21s (Backend: cuml)\n",
      "08:46:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:47:17 [INFO]   Training abgeschlossen in 17.39s (Backend: cuml)\n",
      "08:48:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:48:20 [INFO]   Training abgeschlossen in 17.72s (Backend: cuml)\n",
      "08:49:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:49:23 [INFO]   Training abgeschlossen in 17.98s (Backend: cuml)\n",
      "08:50:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:50:26 [INFO]   Training abgeschlossen in 18.20s (Backend: cuml)\n",
      "08:51:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:51:29 [INFO]   Training abgeschlossen in 18.34s (Backend: cuml)\n",
      "08:52:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:52:31 [INFO]   Training abgeschlossen in 18.52s (Backend: cuml)\n",
      "08:53:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:53:33 [INFO]   Training abgeschlossen in 18.78s (Backend: cuml)\n",
      "08:54:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:54:34 [INFO]   Training abgeschlossen in 18.94s (Backend: cuml)\n",
      "08:55:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:55:36 [INFO]   Training abgeschlossen in 19.24s (Backend: cuml)\n",
      "08:56:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:56:37 [INFO]   Training abgeschlossen in 19.48s (Backend: cuml)\n",
      "08:57:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:57:38 [INFO]   Training abgeschlossen in 19.75s (Backend: cuml)\n",
      "08:58:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:58:38 [INFO]   Training abgeschlossen in 19.91s (Backend: cuml)\n",
      "08:59:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:59:38 [INFO]   Training abgeschlossen in 20.16s (Backend: cuml)\n",
      "09:00:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:00:38 [INFO]   Training abgeschlossen in 20.46s (Backend: cuml)\n",
      "09:01:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:01:38 [INFO]   Training abgeschlossen in 20.69s (Backend: cuml)\n",
      "09:02:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:02:37 [INFO]   Training abgeschlossen in 20.76s (Backend: cuml)\n",
      "09:03:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:03:36 [INFO]   Training abgeschlossen in 21.14s (Backend: cuml)\n",
      "09:04:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:04:35 [INFO]   Training abgeschlossen in 21.40s (Backend: cuml)\n",
      "09:05:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:05:34 [INFO]   Training abgeschlossen in 21.48s (Backend: cuml)\n",
      "09:06:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:06:32 [INFO]   Training abgeschlossen in 21.58s (Backend: cuml)\n",
      "09:07:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:07:29 [INFO]   Training abgeschlossen in 21.87s (Backend: cuml)\n",
      "09:08:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:08:27 [INFO]   Training abgeschlossen in 21.95s (Backend: cuml)\n",
      "09:09:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:09:24 [INFO]   Training abgeschlossen in 22.21s (Backend: cuml)\n",
      "09:09:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:10:21 [INFO]   Training abgeschlossen in 22.45s (Backend: cuml)\n",
      "09:10:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:11:18 [INFO]   Training abgeschlossen in 22.72s (Backend: cuml)\n",
      "09:11:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:12:14 [INFO]   Training abgeschlossen in 22.93s (Backend: cuml)\n",
      "09:12:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:13:09 [INFO]   Training abgeschlossen in 23.00s (Backend: cuml)\n",
      "09:13:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:14:05 [INFO]   Training abgeschlossen in 23.26s (Backend: cuml)\n",
      "09:14:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:15:00 [INFO]   Training abgeschlossen in 23.49s (Backend: cuml)\n",
      "09:15:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:15:55 [INFO]   Training abgeschlossen in 23.81s (Backend: cuml)\n",
      "09:16:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:16:49 [INFO]   Training abgeschlossen in 23.83s (Backend: cuml)\n",
      "09:17:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:17:43 [INFO]   Training abgeschlossen in 24.19s (Backend: cuml)\n",
      "09:18:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:18:37 [INFO]   Training abgeschlossen in 24.49s (Backend: cuml)\n",
      "09:19:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:19:31 [INFO]   Training abgeschlossen in 24.52s (Backend: cuml)\n",
      "09:19:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:20:24 [INFO]   Training abgeschlossen in 24.82s (Backend: cuml)\n",
      "09:20:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:21:16 [INFO]   Training abgeschlossen in 24.95s (Backend: cuml)\n",
      "09:21:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:22:09 [INFO]   Training abgeschlossen in 25.19s (Backend: cuml)\n",
      "09:22:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:23:01 [INFO]   Training abgeschlossen in 25.36s (Backend: cuml)\n",
      "09:23:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:23:52 [INFO]   Training abgeschlossen in 25.61s (Backend: cuml)\n",
      "09:24:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:24:43 [INFO]   Training abgeschlossen in 25.73s (Backend: cuml)\n",
      "09:25:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:25:34 [INFO]   Training abgeschlossen in 26.02s (Backend: cuml)\n",
      "09:25:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:26:25 [INFO]   Training abgeschlossen in 26.25s (Backend: cuml)\n",
      "09:26:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:27:28 [INFO]   Training abgeschlossen in 39.65s (Backend: cuml)\n",
      "09:27:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:28:31 [INFO]   Training abgeschlossen in 39.94s (Backend: cuml)\n",
      "09:28:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:29:34 [INFO]   Training abgeschlossen in 39.95s (Backend: cuml)\n",
      "09:29:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:30:37 [INFO]   Training abgeschlossen in 40.71s (Backend: cuml)\n",
      "09:30:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:31:39 [INFO]   Training abgeschlossen in 40.29s (Backend: cuml)\n",
      "09:31:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:32:40 [INFO]   Training abgeschlossen in 40.49s (Backend: cuml)\n",
      "09:33:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:33:43 [INFO]   Training abgeschlossen in 42.22s (Backend: cuml)\n",
      "09:34:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:34:44 [INFO]   Training abgeschlossen in 41.44s (Backend: cuml)\n",
      "09:35:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:35:46 [INFO]   Training abgeschlossen in 43.13s (Backend: cuml)\n",
      "09:36:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:36:48 [INFO]   Training abgeschlossen in 42.81s (Backend: cuml)\n",
      "09:37:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:37:50 [INFO]   Training abgeschlossen in 44.09s (Backend: cuml)\n",
      "09:38:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:38:51 [INFO]   Training abgeschlossen in 43.00s (Backend: cuml)\n",
      "09:39:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:39:50 [INFO]   Training abgeschlossen in 42.07s (Backend: cuml)\n",
      "09:40:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:40:48 [INFO]   Training abgeschlossen in 41.91s (Backend: cuml)\n",
      "09:41:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:41:47 [INFO]   Training abgeschlossen in 43.16s (Backend: cuml)\n",
      "09:42:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:42:45 [INFO]   Training abgeschlossen in 42.64s (Backend: cuml)\n",
      "09:43:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:43:43 [INFO]   Training abgeschlossen in 42.75s (Backend: cuml)\n",
      "09:43:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:44:41 [INFO]   Training abgeschlossen in 43.80s (Backend: cuml)\n",
      "09:44:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:45:41 [INFO]   Training abgeschlossen in 46.24s (Backend: cuml)\n",
      "09:45:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:46:36 [INFO]   Training abgeschlossen in 42.08s (Backend: cuml)\n",
      "09:46:49 [INFO]     60,000 labeled → Accuracy: 0.9666 (Train: 42.1s, Query: 0.67s) | GPU: 2.8/8.0 GB\n",
      "09:46:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:47:35 [INFO]   Training abgeschlossen in 46.32s (Backend: cuml)\n",
      "09:47:47 [INFO]     Final: 60,000 labeled → Accuracy: 0.9664, F1: 0.9662\n",
      "\n",
      "============================================================\n",
      "Strategie: Margin Sampling\n",
      "============================================================\n",
      "09:47:47 [INFO] \n",
      "GPU-SVM + Margin Sampling - Budget: 20% (12,000 Samples)\n",
      "09:47:47 [INFO]   Run 1/5\n",
      "09:47:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 0.1/8.0 GB)\n",
      "09:47:52 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "09:48:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "09:49:03 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "09:50:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "09:50:15 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "09:51:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "09:51:27 [INFO]   Training abgeschlossen in 5.28s (Backend: cuml)\n",
      "09:52:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:52:39 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "09:53:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:53:52 [INFO]   Training abgeschlossen in 5.56s (Backend: cuml)\n",
      "09:54:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:55:05 [INFO]   Training abgeschlossen in 6.04s (Backend: cuml)\n",
      "09:56:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:56:19 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "09:57:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:57:32 [INFO]   Training abgeschlossen in 6.99s (Backend: cuml)\n",
      "09:58:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:58:46 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "09:59:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:00:01 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "10:01:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:01:16 [INFO]   Training abgeschlossen in 7.95s (Backend: cuml)\n",
      "10:02:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:02:30 [INFO]   Training abgeschlossen in 8.22s (Backend: cuml)\n",
      "10:03:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:03:44 [INFO]   Training abgeschlossen in 8.48s (Backend: cuml)\n",
      "10:04:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:04:58 [INFO]   Training abgeschlossen in 8.62s (Backend: cuml)\n",
      "10:06:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:06:13 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "10:07:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:07:27 [INFO]   Training abgeschlossen in 9.01s (Backend: cuml)\n",
      "10:08:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:08:41 [INFO]   Training abgeschlossen in 9.16s (Backend: cuml)\n",
      "10:09:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:09:54 [INFO]   Training abgeschlossen in 9.39s (Backend: cuml)\n",
      "10:10:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:11:08 [INFO]   Training abgeschlossen in 9.62s (Backend: cuml)\n",
      "10:12:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:12:21 [INFO]   Training abgeschlossen in 9.90s (Backend: cuml)\n",
      "10:13:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:13:35 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "10:14:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:14:48 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "10:15:51 [INFO]     12,000 labeled → Accuracy: 0.9674 (Train: 10.3s, Query: 52.12s) | GPU: 2.6/8.0 GB\n",
      "10:15:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:16:01 [INFO]   Training abgeschlossen in 10.46s (Backend: cuml)\n",
      "10:16:12 [INFO]     Final: 12,000 labeled → Accuracy: 0.9671, F1: 0.9668\n",
      "10:16:12 [INFO]   Run 2/5\n",
      "10:16:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:16:17 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "10:17:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:17:29 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "10:18:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:18:40 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "10:19:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:19:53 [INFO]   Training abgeschlossen in 5.24s (Backend: cuml)\n",
      "10:20:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:21:05 [INFO]   Training abgeschlossen in 5.28s (Backend: cuml)\n",
      "10:22:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:22:18 [INFO]   Training abgeschlossen in 5.77s (Backend: cuml)\n",
      "10:23:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:23:31 [INFO]   Training abgeschlossen in 5.91s (Backend: cuml)\n",
      "10:24:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:24:44 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "10:25:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:25:58 [INFO]   Training abgeschlossen in 7.16s (Backend: cuml)\n",
      "10:27:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:27:12 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "10:28:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:28:27 [INFO]   Training abgeschlossen in 7.77s (Backend: cuml)\n",
      "10:29:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:29:42 [INFO]   Training abgeschlossen in 8.05s (Backend: cuml)\n",
      "10:30:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:30:56 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "10:32:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:32:10 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "10:33:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:33:24 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "10:34:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:34:39 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "10:35:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:35:53 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "10:36:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:37:07 [INFO]   Training abgeschlossen in 9.16s (Backend: cuml)\n",
      "10:38:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:38:20 [INFO]   Training abgeschlossen in 9.39s (Backend: cuml)\n",
      "10:39:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:39:34 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "10:40:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:40:47 [INFO]   Training abgeschlossen in 9.87s (Backend: cuml)\n",
      "10:41:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:42:02 [INFO]   Training abgeschlossen in 10.07s (Backend: cuml)\n",
      "10:43:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:43:15 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "10:44:17 [INFO]     12,000 labeled → Accuracy: 0.9685 (Train: 10.3s, Query: 51.14s) | GPU: 2.6/8.0 GB\n",
      "10:44:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:44:27 [INFO]   Training abgeschlossen in 10.48s (Backend: cuml)\n",
      "10:44:38 [INFO]     Final: 12,000 labeled → Accuracy: 0.9682, F1: 0.9679\n",
      "10:44:38 [INFO]   Run 3/5\n",
      "10:44:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:44:43 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "10:45:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:45:55 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "10:47:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:47:06 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "10:48:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:48:18 [INFO]   Training abgeschlossen in 5.20s (Backend: cuml)\n",
      "10:49:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:49:30 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "10:50:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:50:43 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "10:51:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:51:56 [INFO]   Training abgeschlossen in 5.98s (Backend: cuml)\n",
      "10:53:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:53:09 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "10:54:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:54:22 [INFO]   Training abgeschlossen in 6.72s (Backend: cuml)\n",
      "10:55:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:55:36 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "10:56:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:56:50 [INFO]   Training abgeschlossen in 7.69s (Backend: cuml)\n",
      "10:57:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:58:05 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "10:59:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:59:19 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "11:00:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:00:33 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "11:01:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:01:47 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "11:02:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:03:02 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "11:04:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:04:16 [INFO]   Training abgeschlossen in 8.94s (Backend: cuml)\n",
      "11:05:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:05:30 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "11:06:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:06:43 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "11:07:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:07:57 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "11:09:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:09:10 [INFO]   Training abgeschlossen in 9.85s (Backend: cuml)\n",
      "11:10:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:10:24 [INFO]   Training abgeschlossen in 10.22s (Backend: cuml)\n",
      "11:11:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:11:37 [INFO]   Training abgeschlossen in 10.34s (Backend: cuml)\n",
      "11:12:39 [INFO]     12,000 labeled → Accuracy: 0.9665 (Train: 10.3s, Query: 51.08s) | GPU: 2.6/8.0 GB\n",
      "11:12:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:12:50 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "11:13:01 [INFO]     Final: 12,000 labeled → Accuracy: 0.9668, F1: 0.9665\n",
      "11:13:01 [INFO]   Run 4/5\n",
      "11:13:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:13:06 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "11:14:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "11:14:17 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "11:15:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "11:15:29 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "11:16:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "11:16:41 [INFO]   Training abgeschlossen in 5.21s (Backend: cuml)\n",
      "11:17:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:17:53 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "11:19:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:19:06 [INFO]   Training abgeschlossen in 5.74s (Backend: cuml)\n",
      "11:20:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:20:20 [INFO]   Training abgeschlossen in 6.13s (Backend: cuml)\n",
      "11:21:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:21:33 [INFO]   Training abgeschlossen in 6.40s (Backend: cuml)\n",
      "11:22:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:22:46 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "11:23:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:24:00 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "11:25:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:25:15 [INFO]   Training abgeschlossen in 7.70s (Backend: cuml)\n",
      "11:26:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:26:29 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "11:27:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:27:44 [INFO]   Training abgeschlossen in 8.10s (Backend: cuml)\n",
      "11:28:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:28:58 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "11:30:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:30:12 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "11:31:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:31:27 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "11:32:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:32:41 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "11:33:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:33:55 [INFO]   Training abgeschlossen in 9.36s (Backend: cuml)\n",
      "11:34:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:35:08 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "11:36:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:36:22 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "11:37:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:37:35 [INFO]   Training abgeschlossen in 9.93s (Backend: cuml)\n",
      "11:38:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:38:49 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "11:39:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:40:02 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "11:41:04 [INFO]     12,000 labeled → Accuracy: 0.9679 (Train: 10.3s, Query: 51.10s) | GPU: 2.6/8.0 GB\n",
      "11:41:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:41:15 [INFO]   Training abgeschlossen in 10.54s (Backend: cuml)\n",
      "11:41:26 [INFO]     Final: 12,000 labeled → Accuracy: 0.9684, F1: 0.9681\n",
      "11:41:26 [INFO]   Run 5/5\n",
      "11:41:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:41:31 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "11:42:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "11:42:43 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "11:43:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "11:43:55 [INFO]   Training abgeschlossen in 5.03s (Backend: cuml)\n",
      "11:45:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "11:45:06 [INFO]   Training abgeschlossen in 5.18s (Backend: cuml)\n",
      "11:46:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "11:46:19 [INFO]   Training abgeschlossen in 5.57s (Backend: cuml)\n",
      "11:47:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:47:32 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "11:48:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:48:45 [INFO]   Training abgeschlossen in 6.05s (Backend: cuml)\n",
      "11:49:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:49:58 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "11:51:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:51:12 [INFO]   Training abgeschlossen in 6.77s (Backend: cuml)\n",
      "11:52:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:52:25 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "11:53:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:53:40 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "11:54:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:54:54 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "11:56:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:56:09 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "11:57:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:57:23 [INFO]   Training abgeschlossen in 8.40s (Backend: cuml)\n",
      "11:58:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:58:37 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "11:59:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:59:51 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "12:00:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:01:06 [INFO]   Training abgeschlossen in 9.12s (Backend: cuml)\n",
      "12:02:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:02:20 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "12:03:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:03:33 [INFO]   Training abgeschlossen in 9.51s (Backend: cuml)\n",
      "12:04:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:04:47 [INFO]   Training abgeschlossen in 9.85s (Backend: cuml)\n",
      "12:05:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:06:00 [INFO]   Training abgeschlossen in 9.90s (Backend: cuml)\n",
      "12:07:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:07:14 [INFO]   Training abgeschlossen in 10.06s (Backend: cuml)\n",
      "12:08:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:08:27 [INFO]   Training abgeschlossen in 10.39s (Backend: cuml)\n",
      "12:09:29 [INFO]     12,000 labeled → Accuracy: 0.9684 (Train: 10.4s, Query: 51.04s) | GPU: 2.6/8.0 GB\n",
      "12:09:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:09:40 [INFO]   Training abgeschlossen in 10.56s (Backend: cuml)\n",
      "12:09:51 [INFO]     Final: 12,000 labeled → Accuracy: 0.9684, F1: 0.9681\n",
      "12:09:51 [INFO] \n",
      "GPU-SVM + Margin Sampling - Budget: 40% (24,000 Samples)\n",
      "12:09:51 [INFO]   Run 1/5\n",
      "12:09:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:09:56 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "12:11:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "12:11:07 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "12:12:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "12:12:18 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "12:13:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "12:13:30 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "12:14:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "12:14:43 [INFO]   Training abgeschlossen in 5.52s (Backend: cuml)\n",
      "12:15:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:15:55 [INFO]   Training abgeschlossen in 5.57s (Backend: cuml)\n",
      "12:17:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:17:09 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "12:18:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:18:22 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "12:19:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:19:35 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "12:20:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:20:49 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "12:21:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:22:03 [INFO]   Training abgeschlossen in 7.70s (Backend: cuml)\n",
      "12:23:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:23:18 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "12:24:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:24:32 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "12:25:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:25:46 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "12:26:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:27:01 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "12:28:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:28:15 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "12:29:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:29:30 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "12:30:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:30:44 [INFO]   Training abgeschlossen in 9.16s (Backend: cuml)\n",
      "12:31:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:31:57 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "12:33:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:33:11 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "12:34:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:34:24 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "12:35:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:35:37 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "12:36:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:36:52 [INFO]   Training abgeschlossen in 10.45s (Backend: cuml)\n",
      "12:37:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:38:05 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "12:39:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:39:19 [INFO]   Training abgeschlossen in 10.72s (Backend: cuml)\n",
      "12:40:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:40:33 [INFO]   Training abgeschlossen in 11.13s (Backend: cuml)\n",
      "12:41:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:41:46 [INFO]   Training abgeschlossen in 11.21s (Backend: cuml)\n",
      "12:42:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:42:59 [INFO]   Training abgeschlossen in 11.41s (Backend: cuml)\n",
      "12:44:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:44:12 [INFO]   Training abgeschlossen in 11.62s (Backend: cuml)\n",
      "12:45:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:45:24 [INFO]   Training abgeschlossen in 11.91s (Backend: cuml)\n",
      "12:46:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:46:36 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "12:47:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:47:49 [INFO]   Training abgeschlossen in 12.22s (Backend: cuml)\n",
      "12:48:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:49:00 [INFO]   Training abgeschlossen in 12.59s (Backend: cuml)\n",
      "12:49:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:50:11 [INFO]   Training abgeschlossen in 12.64s (Backend: cuml)\n",
      "12:51:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:51:22 [INFO]   Training abgeschlossen in 12.85s (Backend: cuml)\n",
      "12:52:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:52:32 [INFO]   Training abgeschlossen in 13.03s (Backend: cuml)\n",
      "12:53:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:53:43 [INFO]   Training abgeschlossen in 13.41s (Backend: cuml)\n",
      "12:54:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:54:54 [INFO]   Training abgeschlossen in 13.45s (Backend: cuml)\n",
      "12:55:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:56:04 [INFO]   Training abgeschlossen in 13.61s (Backend: cuml)\n",
      "12:57:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:57:14 [INFO]   Training abgeschlossen in 13.85s (Backend: cuml)\n",
      "12:58:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:58:23 [INFO]   Training abgeschlossen in 14.09s (Backend: cuml)\n",
      "12:59:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:59:32 [INFO]   Training abgeschlossen in 14.24s (Backend: cuml)\n",
      "13:00:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:00:40 [INFO]   Training abgeschlossen in 14.45s (Backend: cuml)\n",
      "13:01:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:01:47 [INFO]   Training abgeschlossen in 14.36s (Backend: cuml)\n",
      "13:02:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:02:55 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "13:03:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:04:02 [INFO]   Training abgeschlossen in 14.87s (Backend: cuml)\n",
      "13:04:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:05:08 [INFO]   Training abgeschlossen in 15.00s (Backend: cuml)\n",
      "13:06:00 [INFO]     24,000 labeled → Accuracy: 0.9666 (Train: 15.0s, Query: 39.90s) | GPU: 2.7/8.0 GB\n",
      "13:06:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:06:15 [INFO]   Training abgeschlossen in 15.21s (Backend: cuml)\n",
      "13:06:26 [INFO]     Final: 24,000 labeled → Accuracy: 0.9665, F1: 0.9662\n",
      "13:06:26 [INFO]   Run 2/5\n",
      "13:06:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:06:31 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "13:07:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:07:43 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "13:08:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:08:54 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "13:10:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:10:06 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "13:11:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "13:11:18 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "13:12:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:12:31 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "13:13:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:13:44 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "13:14:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:14:57 [INFO]   Training abgeschlossen in 6.33s (Backend: cuml)\n",
      "13:16:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:16:11 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "13:17:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:17:25 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "13:18:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:18:39 [INFO]   Training abgeschlossen in 7.80s (Backend: cuml)\n",
      "13:19:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:19:54 [INFO]   Training abgeschlossen in 8.15s (Backend: cuml)\n",
      "13:21:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:21:08 [INFO]   Training abgeschlossen in 8.11s (Backend: cuml)\n",
      "13:22:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:22:22 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "13:23:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:23:37 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "13:24:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:24:53 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "13:25:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:26:08 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "13:27:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:27:23 [INFO]   Training abgeschlossen in 9.31s (Backend: cuml)\n",
      "13:28:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:28:37 [INFO]   Training abgeschlossen in 9.49s (Backend: cuml)\n",
      "13:29:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:29:51 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "13:30:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:31:05 [INFO]   Training abgeschlossen in 10.02s (Backend: cuml)\n",
      "13:32:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:32:19 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "13:33:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:33:33 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "13:34:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:34:47 [INFO]   Training abgeschlossen in 10.61s (Backend: cuml)\n",
      "13:35:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:36:01 [INFO]   Training abgeschlossen in 10.73s (Backend: cuml)\n",
      "13:37:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:37:15 [INFO]   Training abgeschlossen in 11.02s (Backend: cuml)\n",
      "13:38:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:38:27 [INFO]   Training abgeschlossen in 11.23s (Backend: cuml)\n",
      "13:39:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:39:39 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "13:40:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:40:52 [INFO]   Training abgeschlossen in 11.63s (Backend: cuml)\n",
      "13:41:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:42:05 [INFO]   Training abgeschlossen in 11.79s (Backend: cuml)\n",
      "13:43:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:43:17 [INFO]   Training abgeschlossen in 12.25s (Backend: cuml)\n",
      "13:44:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:44:28 [INFO]   Training abgeschlossen in 12.24s (Backend: cuml)\n",
      "13:45:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:45:39 [INFO]   Training abgeschlossen in 12.49s (Backend: cuml)\n",
      "13:46:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:46:50 [INFO]   Training abgeschlossen in 12.77s (Backend: cuml)\n",
      "13:47:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:48:00 [INFO]   Training abgeschlossen in 13.12s (Backend: cuml)\n",
      "13:48:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:49:10 [INFO]   Training abgeschlossen in 13.05s (Backend: cuml)\n",
      "13:50:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:50:20 [INFO]   Training abgeschlossen in 13.32s (Backend: cuml)\n",
      "13:51:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:51:30 [INFO]   Training abgeschlossen in 13.46s (Backend: cuml)\n",
      "13:52:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:52:40 [INFO]   Training abgeschlossen in 13.84s (Backend: cuml)\n",
      "13:53:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:53:49 [INFO]   Training abgeschlossen in 13.97s (Backend: cuml)\n",
      "13:54:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:54:57 [INFO]   Training abgeschlossen in 14.07s (Backend: cuml)\n",
      "13:55:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:56:06 [INFO]   Training abgeschlossen in 14.35s (Backend: cuml)\n",
      "13:57:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:57:14 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "13:58:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:58:22 [INFO]   Training abgeschlossen in 14.57s (Backend: cuml)\n",
      "13:59:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:59:29 [INFO]   Training abgeschlossen in 14.59s (Backend: cuml)\n",
      "14:00:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:00:36 [INFO]   Training abgeschlossen in 14.86s (Backend: cuml)\n",
      "14:01:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:01:44 [INFO]   Training abgeschlossen in 15.15s (Backend: cuml)\n",
      "14:02:35 [INFO]     24,000 labeled → Accuracy: 0.9679 (Train: 15.2s, Query: 39.93s) | GPU: 2.7/8.0 GB\n",
      "14:02:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:02:51 [INFO]   Training abgeschlossen in 15.36s (Backend: cuml)\n",
      "14:03:02 [INFO]     Final: 24,000 labeled → Accuracy: 0.9681, F1: 0.9679\n",
      "14:03:02 [INFO]   Run 3/5\n",
      "14:03:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:03:07 [INFO]   Training abgeschlossen in 4.67s (Backend: cuml)\n",
      "14:04:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:04:18 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "14:05:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:05:30 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "14:06:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:06:42 [INFO]   Training abgeschlossen in 5.21s (Backend: cuml)\n",
      "14:07:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:07:54 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "14:09:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:09:06 [INFO]   Training abgeschlossen in 5.65s (Backend: cuml)\n",
      "14:10:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:10:19 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "14:11:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:11:33 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "14:12:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:12:46 [INFO]   Training abgeschlossen in 6.74s (Backend: cuml)\n",
      "14:13:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:14:00 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "14:15:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:15:14 [INFO]   Training abgeschlossen in 7.84s (Backend: cuml)\n",
      "14:16:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:16:29 [INFO]   Training abgeschlossen in 7.92s (Backend: cuml)\n",
      "14:17:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:17:43 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "14:18:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:18:58 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "14:20:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:20:12 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "14:21:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:21:26 [INFO]   Training abgeschlossen in 8.74s (Backend: cuml)\n",
      "14:22:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:22:40 [INFO]   Training abgeschlossen in 9.08s (Backend: cuml)\n",
      "14:23:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:23:54 [INFO]   Training abgeschlossen in 9.18s (Backend: cuml)\n",
      "14:24:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:25:08 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "14:26:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:26:21 [INFO]   Training abgeschlossen in 9.76s (Backend: cuml)\n",
      "14:27:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:27:35 [INFO]   Training abgeschlossen in 9.84s (Backend: cuml)\n",
      "14:28:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:28:48 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "14:29:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:30:02 [INFO]   Training abgeschlossen in 10.39s (Backend: cuml)\n",
      "14:31:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:31:14 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "14:32:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:32:27 [INFO]   Training abgeschlossen in 10.78s (Backend: cuml)\n",
      "14:33:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:33:39 [INFO]   Training abgeschlossen in 10.93s (Backend: cuml)\n",
      "14:34:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:34:52 [INFO]   Training abgeschlossen in 11.29s (Backend: cuml)\n",
      "14:35:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:36:03 [INFO]   Training abgeschlossen in 11.46s (Backend: cuml)\n",
      "14:37:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:37:15 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "14:38:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:38:27 [INFO]   Training abgeschlossen in 11.92s (Backend: cuml)\n",
      "14:39:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:39:38 [INFO]   Training abgeschlossen in 12.10s (Backend: cuml)\n",
      "14:40:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:40:49 [INFO]   Training abgeschlossen in 12.26s (Backend: cuml)\n",
      "14:41:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:42:00 [INFO]   Training abgeschlossen in 12.51s (Backend: cuml)\n",
      "14:42:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:43:10 [INFO]   Training abgeschlossen in 12.66s (Backend: cuml)\n",
      "14:44:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:44:21 [INFO]   Training abgeschlossen in 12.87s (Backend: cuml)\n",
      "14:45:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:45:31 [INFO]   Training abgeschlossen in 13.08s (Backend: cuml)\n",
      "14:46:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:46:41 [INFO]   Training abgeschlossen in 13.25s (Backend: cuml)\n",
      "14:47:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:47:50 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "14:48:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:49:00 [INFO]   Training abgeschlossen in 13.65s (Backend: cuml)\n",
      "14:49:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:50:08 [INFO]   Training abgeschlossen in 13.87s (Backend: cuml)\n",
      "14:51:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:51:17 [INFO]   Training abgeschlossen in 14.07s (Backend: cuml)\n",
      "14:52:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:52:26 [INFO]   Training abgeschlossen in 14.32s (Backend: cuml)\n",
      "14:53:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:53:34 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "14:54:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:54:42 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "14:55:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:55:49 [INFO]   Training abgeschlossen in 14.72s (Backend: cuml)\n",
      "14:56:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:56:56 [INFO]   Training abgeschlossen in 14.81s (Backend: cuml)\n",
      "14:57:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:58:03 [INFO]   Training abgeschlossen in 15.07s (Backend: cuml)\n",
      "14:58:54 [INFO]     24,000 labeled → Accuracy: 0.9682 (Train: 15.1s, Query: 39.62s) | GPU: 2.7/8.0 GB\n",
      "14:58:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:59:09 [INFO]   Training abgeschlossen in 15.26s (Backend: cuml)\n",
      "14:59:21 [INFO]     Final: 24,000 labeled → Accuracy: 0.9683, F1: 0.9680\n",
      "14:59:21 [INFO]   Run 4/5\n",
      "14:59:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:59:26 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "15:00:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:00:38 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "15:01:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:01:49 [INFO]   Training abgeschlossen in 5.03s (Backend: cuml)\n",
      "15:02:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:03:01 [INFO]   Training abgeschlossen in 5.25s (Backend: cuml)\n",
      "15:04:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:04:14 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "15:05:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:05:26 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "15:06:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:06:40 [INFO]   Training abgeschlossen in 6.11s (Backend: cuml)\n",
      "15:07:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:07:53 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "15:09:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:09:07 [INFO]   Training abgeschlossen in 6.80s (Backend: cuml)\n",
      "15:10:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:10:21 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "15:11:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:11:35 [INFO]   Training abgeschlossen in 7.72s (Backend: cuml)\n",
      "15:12:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:12:50 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "15:13:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:14:04 [INFO]   Training abgeschlossen in 8.20s (Backend: cuml)\n",
      "15:15:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:15:18 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "15:16:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:16:32 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "15:17:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:17:47 [INFO]   Training abgeschlossen in 8.84s (Backend: cuml)\n",
      "15:18:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:19:01 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "15:20:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:20:15 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "15:21:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:21:28 [INFO]   Training abgeschlossen in 9.50s (Backend: cuml)\n",
      "15:22:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:22:42 [INFO]   Training abgeschlossen in 9.83s (Backend: cuml)\n",
      "15:23:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:23:55 [INFO]   Training abgeschlossen in 9.98s (Backend: cuml)\n",
      "15:24:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:25:09 [INFO]   Training abgeschlossen in 10.17s (Backend: cuml)\n",
      "15:26:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:26:22 [INFO]   Training abgeschlossen in 10.43s (Backend: cuml)\n",
      "15:27:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:27:35 [INFO]   Training abgeschlossen in 10.56s (Backend: cuml)\n",
      "15:28:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:28:47 [INFO]   Training abgeschlossen in 10.78s (Backend: cuml)\n",
      "15:29:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:30:00 [INFO]   Training abgeschlossen in 11.03s (Backend: cuml)\n",
      "15:31:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:31:12 [INFO]   Training abgeschlossen in 11.22s (Backend: cuml)\n",
      "15:32:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:32:24 [INFO]   Training abgeschlossen in 11.42s (Backend: cuml)\n",
      "15:33:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:33:37 [INFO]   Training abgeschlossen in 11.65s (Backend: cuml)\n",
      "15:34:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:34:49 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "15:35:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:36:00 [INFO]   Training abgeschlossen in 12.03s (Backend: cuml)\n",
      "15:36:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:37:11 [INFO]   Training abgeschlossen in 12.25s (Backend: cuml)\n",
      "15:38:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:38:22 [INFO]   Training abgeschlossen in 12.44s (Backend: cuml)\n",
      "15:39:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:39:32 [INFO]   Training abgeschlossen in 12.63s (Backend: cuml)\n",
      "15:40:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:40:42 [INFO]   Training abgeschlossen in 12.91s (Backend: cuml)\n",
      "15:41:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:41:52 [INFO]   Training abgeschlossen in 13.10s (Backend: cuml)\n",
      "15:42:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:43:02 [INFO]   Training abgeschlossen in 13.23s (Backend: cuml)\n",
      "15:43:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:44:12 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "15:45:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:45:21 [INFO]   Training abgeschlossen in 13.63s (Backend: cuml)\n",
      "15:46:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:46:29 [INFO]   Training abgeschlossen in 13.89s (Backend: cuml)\n",
      "15:47:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:47:38 [INFO]   Training abgeschlossen in 14.06s (Backend: cuml)\n",
      "15:48:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:48:47 [INFO]   Training abgeschlossen in 14.33s (Backend: cuml)\n",
      "15:49:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:49:55 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "15:50:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:51:03 [INFO]   Training abgeschlossen in 14.43s (Backend: cuml)\n",
      "15:51:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:52:10 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "15:53:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:53:17 [INFO]   Training abgeschlossen in 14.82s (Backend: cuml)\n",
      "15:54:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:54:24 [INFO]   Training abgeschlossen in 15.15s (Backend: cuml)\n",
      "15:55:16 [INFO]     24,000 labeled → Accuracy: 0.9683 (Train: 15.2s, Query: 40.31s) | GPU: 2.7/8.0 GB\n",
      "15:55:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:55:31 [INFO]   Training abgeschlossen in 15.31s (Backend: cuml)\n",
      "15:55:42 [INFO]     Final: 24,000 labeled → Accuracy: 0.9679, F1: 0.9676\n",
      "15:55:43 [INFO]   Run 5/5\n",
      "15:55:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:55:47 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "15:56:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:56:59 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "15:58:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:58:11 [INFO]   Training abgeschlossen in 5.04s (Backend: cuml)\n",
      "15:59:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:59:23 [INFO]   Training abgeschlossen in 5.16s (Backend: cuml)\n",
      "16:00:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:00:35 [INFO]   Training abgeschlossen in 5.52s (Backend: cuml)\n",
      "16:01:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:01:48 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "16:02:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:03:01 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "16:04:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:04:14 [INFO]   Training abgeschlossen in 6.33s (Backend: cuml)\n",
      "16:05:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:05:28 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "16:06:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:06:41 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "16:07:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:07:56 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "16:09:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:09:11 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "16:10:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:10:25 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "16:11:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:11:39 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "16:12:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:12:53 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "16:13:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:14:08 [INFO]   Training abgeschlossen in 8.85s (Backend: cuml)\n",
      "16:15:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:15:22 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "16:16:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:16:36 [INFO]   Training abgeschlossen in 9.22s (Backend: cuml)\n",
      "16:17:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:17:50 [INFO]   Training abgeschlossen in 9.52s (Backend: cuml)\n",
      "16:18:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:19:04 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "16:20:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:20:17 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "16:21:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:21:31 [INFO]   Training abgeschlossen in 10.19s (Backend: cuml)\n",
      "16:22:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:22:44 [INFO]   Training abgeschlossen in 10.32s (Backend: cuml)\n",
      "16:23:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:23:57 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "16:25:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:25:11 [INFO]   Training abgeschlossen in 10.90s (Backend: cuml)\n",
      "16:26:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:26:24 [INFO]   Training abgeschlossen in 10.89s (Backend: cuml)\n",
      "16:27:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:27:38 [INFO]   Training abgeschlossen in 11.15s (Backend: cuml)\n",
      "16:28:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:28:50 [INFO]   Training abgeschlossen in 11.41s (Backend: cuml)\n",
      "16:29:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:30:01 [INFO]   Training abgeschlossen in 11.71s (Backend: cuml)\n",
      "16:31:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:31:13 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "16:32:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:32:24 [INFO]   Training abgeschlossen in 11.98s (Backend: cuml)\n",
      "16:33:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:33:35 [INFO]   Training abgeschlossen in 12.31s (Backend: cuml)\n",
      "16:34:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:34:46 [INFO]   Training abgeschlossen in 12.46s (Backend: cuml)\n",
      "16:35:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:35:56 [INFO]   Training abgeschlossen in 12.61s (Backend: cuml)\n",
      "16:36:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:37:07 [INFO]   Training abgeschlossen in 12.85s (Backend: cuml)\n",
      "16:38:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:38:17 [INFO]   Training abgeschlossen in 13.04s (Backend: cuml)\n",
      "16:39:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:39:27 [INFO]   Training abgeschlossen in 13.29s (Backend: cuml)\n",
      "16:40:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:40:36 [INFO]   Training abgeschlossen in 13.45s (Backend: cuml)\n",
      "16:41:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:41:46 [INFO]   Training abgeschlossen in 13.72s (Backend: cuml)\n",
      "16:42:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:42:55 [INFO]   Training abgeschlossen in 13.97s (Backend: cuml)\n",
      "16:43:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:44:04 [INFO]   Training abgeschlossen in 14.28s (Backend: cuml)\n",
      "16:44:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:45:12 [INFO]   Training abgeschlossen in 14.35s (Backend: cuml)\n",
      "16:46:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:46:20 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "16:47:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:47:28 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "16:48:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:48:35 [INFO]   Training abgeschlossen in 14.64s (Backend: cuml)\n",
      "16:49:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:49:43 [INFO]   Training abgeschlossen in 15.12s (Backend: cuml)\n",
      "16:50:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:50:50 [INFO]   Training abgeschlossen in 15.22s (Backend: cuml)\n",
      "16:51:40 [INFO]     24,000 labeled → Accuracy: 0.9676 (Train: 15.2s, Query: 39.61s) | GPU: 2.7/8.0 GB\n",
      "16:51:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:51:56 [INFO]   Training abgeschlossen in 15.43s (Backend: cuml)\n",
      "16:52:07 [INFO]     Final: 24,000 labeled → Accuracy: 0.9675, F1: 0.9673\n",
      "16:52:07 [INFO] \n",
      "GPU-SVM + Margin Sampling - Budget: 60% (36,000 Samples)\n",
      "16:52:07 [INFO]   Run 1/5\n",
      "16:52:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:52:12 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "16:53:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:53:23 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "16:54:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:54:35 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "16:55:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:55:47 [INFO]   Training abgeschlossen in 5.21s (Backend: cuml)\n",
      "16:56:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:56:59 [INFO]   Training abgeschlossen in 5.43s (Backend: cuml)\n",
      "16:58:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:58:12 [INFO]   Training abgeschlossen in 5.53s (Backend: cuml)\n",
      "16:59:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:59:25 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "17:00:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:00:38 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "17:01:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:01:51 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "17:02:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:03:05 [INFO]   Training abgeschlossen in 7.14s (Backend: cuml)\n",
      "17:04:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:04:20 [INFO]   Training abgeschlossen in 7.82s (Backend: cuml)\n",
      "17:05:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:05:34 [INFO]   Training abgeschlossen in 7.90s (Backend: cuml)\n",
      "17:06:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:06:48 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "17:07:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:08:02 [INFO]   Training abgeschlossen in 8.36s (Backend: cuml)\n",
      "17:09:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:09:17 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "17:10:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:10:31 [INFO]   Training abgeschlossen in 8.87s (Backend: cuml)\n",
      "17:11:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:11:45 [INFO]   Training abgeschlossen in 9.03s (Backend: cuml)\n",
      "17:12:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:12:59 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "17:14:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:14:13 [INFO]   Training abgeschlossen in 9.56s (Backend: cuml)\n",
      "17:15:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:15:26 [INFO]   Training abgeschlossen in 9.63s (Backend: cuml)\n",
      "17:16:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:16:40 [INFO]   Training abgeschlossen in 9.81s (Backend: cuml)\n",
      "17:17:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:17:53 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "17:18:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:19:06 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "17:20:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:20:19 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "17:21:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:21:31 [INFO]   Training abgeschlossen in 10.72s (Backend: cuml)\n",
      "17:22:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:22:44 [INFO]   Training abgeschlossen in 11.09s (Backend: cuml)\n",
      "17:23:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:23:56 [INFO]   Training abgeschlossen in 11.22s (Backend: cuml)\n",
      "17:24:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:25:08 [INFO]   Training abgeschlossen in 11.41s (Backend: cuml)\n",
      "17:26:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:26:20 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "17:27:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:27:31 [INFO]   Training abgeschlossen in 11.88s (Backend: cuml)\n",
      "17:28:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:28:42 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "17:29:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:29:54 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "17:30:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:31:04 [INFO]   Training abgeschlossen in 12.51s (Backend: cuml)\n",
      "17:32:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:32:15 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "17:33:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:33:24 [INFO]   Training abgeschlossen in 12.87s (Backend: cuml)\n",
      "17:34:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:34:34 [INFO]   Training abgeschlossen in 13.08s (Backend: cuml)\n",
      "17:35:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:35:44 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "17:36:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:36:54 [INFO]   Training abgeschlossen in 13.54s (Backend: cuml)\n",
      "17:37:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:38:03 [INFO]   Training abgeschlossen in 13.63s (Backend: cuml)\n",
      "17:38:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:39:12 [INFO]   Training abgeschlossen in 13.83s (Backend: cuml)\n",
      "17:40:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:40:21 [INFO]   Training abgeschlossen in 14.04s (Backend: cuml)\n",
      "17:41:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:41:29 [INFO]   Training abgeschlossen in 14.36s (Backend: cuml)\n",
      "17:42:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:42:38 [INFO]   Training abgeschlossen in 14.51s (Backend: cuml)\n",
      "17:43:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:43:46 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "17:44:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:44:53 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "17:45:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:46:00 [INFO]   Training abgeschlossen in 14.94s (Backend: cuml)\n",
      "17:46:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:47:07 [INFO]   Training abgeschlossen in 15.22s (Backend: cuml)\n",
      "17:47:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:48:14 [INFO]   Training abgeschlossen in 15.25s (Backend: cuml)\n",
      "17:49:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:49:20 [INFO]   Training abgeschlossen in 15.51s (Backend: cuml)\n",
      "17:50:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:50:26 [INFO]   Training abgeschlossen in 15.73s (Backend: cuml)\n",
      "17:51:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:51:32 [INFO]   Training abgeschlossen in 16.10s (Backend: cuml)\n",
      "17:52:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:52:37 [INFO]   Training abgeschlossen in 16.22s (Backend: cuml)\n",
      "17:53:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:53:42 [INFO]   Training abgeschlossen in 16.45s (Backend: cuml)\n",
      "17:54:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:54:47 [INFO]   Training abgeschlossen in 16.57s (Backend: cuml)\n",
      "17:55:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:55:51 [INFO]   Training abgeschlossen in 16.68s (Backend: cuml)\n",
      "17:56:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:56:55 [INFO]   Training abgeschlossen in 16.87s (Backend: cuml)\n",
      "17:57:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:57:59 [INFO]   Training abgeschlossen in 17.13s (Backend: cuml)\n",
      "17:58:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:59:02 [INFO]   Training abgeschlossen in 17.33s (Backend: cuml)\n",
      "17:59:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:00:06 [INFO]   Training abgeschlossen in 17.75s (Backend: cuml)\n",
      "18:00:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:01:09 [INFO]   Training abgeschlossen in 17.91s (Backend: cuml)\n",
      "18:01:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:02:12 [INFO]   Training abgeschlossen in 18.17s (Backend: cuml)\n",
      "18:02:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:03:14 [INFO]   Training abgeschlossen in 18.31s (Backend: cuml)\n",
      "18:03:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:04:16 [INFO]   Training abgeschlossen in 18.41s (Backend: cuml)\n",
      "18:04:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:05:18 [INFO]   Training abgeschlossen in 18.59s (Backend: cuml)\n",
      "18:06:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:06:19 [INFO]   Training abgeschlossen in 18.96s (Backend: cuml)\n",
      "18:07:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:07:20 [INFO]   Training abgeschlossen in 19.12s (Backend: cuml)\n",
      "18:08:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:08:21 [INFO]   Training abgeschlossen in 19.41s (Backend: cuml)\n",
      "18:09:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:09:22 [INFO]   Training abgeschlossen in 19.45s (Backend: cuml)\n",
      "18:10:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:10:22 [INFO]   Training abgeschlossen in 19.71s (Backend: cuml)\n",
      "18:11:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:11:22 [INFO]   Training abgeschlossen in 19.86s (Backend: cuml)\n",
      "18:12:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:12:21 [INFO]   Training abgeschlossen in 20.09s (Backend: cuml)\n",
      "18:13:00 [INFO]     36,000 labeled → Accuracy: 0.9674 (Train: 20.1s, Query: 27.34s) | GPU: 2.8/8.0 GB\n",
      "18:13:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:13:21 [INFO]   Training abgeschlossen in 20.42s (Backend: cuml)\n",
      "18:13:32 [INFO]     Final: 36,000 labeled → Accuracy: 0.9676, F1: 0.9674\n",
      "18:13:32 [INFO]   Run 2/5\n",
      "18:13:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:13:37 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "18:14:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:14:48 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "18:15:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:16:00 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "18:17:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:17:11 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "18:18:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:18:24 [INFO]   Training abgeschlossen in 5.36s (Backend: cuml)\n",
      "18:19:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:19:36 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "18:20:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:20:50 [INFO]   Training abgeschlossen in 6.09s (Backend: cuml)\n",
      "18:21:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:22:03 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "18:23:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:23:17 [INFO]   Training abgeschlossen in 6.90s (Backend: cuml)\n",
      "18:24:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:24:31 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "18:25:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:25:45 [INFO]   Training abgeschlossen in 7.77s (Backend: cuml)\n",
      "18:26:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:27:00 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "18:28:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:28:14 [INFO]   Training abgeschlossen in 8.11s (Backend: cuml)\n",
      "18:29:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:29:28 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "18:30:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:30:43 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "18:31:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:31:57 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "18:33:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:33:12 [INFO]   Training abgeschlossen in 9.06s (Backend: cuml)\n",
      "18:34:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:34:26 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "18:35:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:35:39 [INFO]   Training abgeschlossen in 9.47s (Backend: cuml)\n",
      "18:36:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:36:53 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "18:37:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:38:06 [INFO]   Training abgeschlossen in 9.89s (Backend: cuml)\n",
      "18:39:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:39:21 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "18:40:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:40:35 [INFO]   Training abgeschlossen in 10.38s (Backend: cuml)\n",
      "18:41:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:41:49 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "18:42:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:43:03 [INFO]   Training abgeschlossen in 10.81s (Backend: cuml)\n",
      "18:44:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:44:15 [INFO]   Training abgeschlossen in 11.09s (Backend: cuml)\n",
      "18:45:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:45:29 [INFO]   Training abgeschlossen in 11.25s (Backend: cuml)\n",
      "18:46:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:46:41 [INFO]   Training abgeschlossen in 11.47s (Backend: cuml)\n",
      "18:47:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:47:54 [INFO]   Training abgeschlossen in 11.62s (Backend: cuml)\n",
      "18:48:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:49:07 [INFO]   Training abgeschlossen in 12.02s (Backend: cuml)\n",
      "18:50:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:50:19 [INFO]   Training abgeschlossen in 12.01s (Backend: cuml)\n",
      "18:51:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:51:30 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "18:52:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:52:41 [INFO]   Training abgeschlossen in 12.50s (Backend: cuml)\n",
      "18:53:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:53:53 [INFO]   Training abgeschlossen in 12.75s (Backend: cuml)\n",
      "18:54:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:55:03 [INFO]   Training abgeschlossen in 12.90s (Backend: cuml)\n",
      "18:56:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:56:14 [INFO]   Training abgeschlossen in 13.10s (Backend: cuml)\n",
      "18:57:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:57:25 [INFO]   Training abgeschlossen in 13.42s (Backend: cuml)\n",
      "18:58:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:58:35 [INFO]   Training abgeschlossen in 13.58s (Backend: cuml)\n",
      "18:59:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:59:45 [INFO]   Training abgeschlossen in 13.75s (Backend: cuml)\n",
      "19:00:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:00:54 [INFO]   Training abgeschlossen in 13.95s (Backend: cuml)\n",
      "19:01:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:02:03 [INFO]   Training abgeschlossen in 14.24s (Backend: cuml)\n",
      "19:02:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:03:12 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "19:04:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:04:20 [INFO]   Training abgeschlossen in 14.61s (Backend: cuml)\n",
      "19:05:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:05:28 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "19:06:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:06:35 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "19:07:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:07:43 [INFO]   Training abgeschlossen in 15.16s (Backend: cuml)\n",
      "19:08:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:08:49 [INFO]   Training abgeschlossen in 15.16s (Backend: cuml)\n",
      "19:09:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:09:56 [INFO]   Training abgeschlossen in 15.29s (Backend: cuml)\n",
      "19:10:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:11:02 [INFO]   Training abgeschlossen in 15.43s (Backend: cuml)\n",
      "19:11:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:12:08 [INFO]   Training abgeschlossen in 15.72s (Backend: cuml)\n",
      "19:12:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:13:14 [INFO]   Training abgeschlossen in 16.21s (Backend: cuml)\n",
      "19:14:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:14:19 [INFO]   Training abgeschlossen in 16.25s (Backend: cuml)\n",
      "19:15:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:15:24 [INFO]   Training abgeschlossen in 16.36s (Backend: cuml)\n",
      "19:16:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:16:29 [INFO]   Training abgeschlossen in 16.58s (Backend: cuml)\n",
      "19:17:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:17:33 [INFO]   Training abgeschlossen in 16.71s (Backend: cuml)\n",
      "19:18:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:18:38 [INFO]   Training abgeschlossen in 16.96s (Backend: cuml)\n",
      "19:19:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:19:42 [INFO]   Training abgeschlossen in 17.11s (Backend: cuml)\n",
      "19:20:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:20:45 [INFO]   Training abgeschlossen in 17.50s (Backend: cuml)\n",
      "19:21:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:21:49 [INFO]   Training abgeschlossen in 17.71s (Backend: cuml)\n",
      "19:22:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:22:52 [INFO]   Training abgeschlossen in 17.96s (Backend: cuml)\n",
      "19:23:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:23:55 [INFO]   Training abgeschlossen in 18.00s (Backend: cuml)\n",
      "19:24:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:24:57 [INFO]   Training abgeschlossen in 18.22s (Backend: cuml)\n",
      "19:25:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:25:59 [INFO]   Training abgeschlossen in 18.53s (Backend: cuml)\n",
      "19:26:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:27:01 [INFO]   Training abgeschlossen in 18.71s (Backend: cuml)\n",
      "19:27:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:28:02 [INFO]   Training abgeschlossen in 18.81s (Backend: cuml)\n",
      "19:28:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:29:04 [INFO]   Training abgeschlossen in 19.10s (Backend: cuml)\n",
      "19:29:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:30:04 [INFO]   Training abgeschlossen in 19.37s (Backend: cuml)\n",
      "19:30:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:31:05 [INFO]   Training abgeschlossen in 19.53s (Backend: cuml)\n",
      "19:31:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:32:05 [INFO]   Training abgeschlossen in 19.83s (Backend: cuml)\n",
      "19:32:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:33:05 [INFO]   Training abgeschlossen in 20.12s (Backend: cuml)\n",
      "19:33:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:34:05 [INFO]   Training abgeschlossen in 20.29s (Backend: cuml)\n",
      "19:34:44 [INFO]     36,000 labeled → Accuracy: 0.9672 (Train: 20.3s, Query: 27.44s) | GPU: 2.8/8.0 GB\n",
      "19:34:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:35:05 [INFO]   Training abgeschlossen in 20.50s (Backend: cuml)\n",
      "19:35:16 [INFO]     Final: 36,000 labeled → Accuracy: 0.9675, F1: 0.9673\n",
      "19:35:16 [INFO]   Run 3/5\n",
      "19:35:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:35:21 [INFO]   Training abgeschlossen in 4.65s (Backend: cuml)\n",
      "19:36:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:36:32 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "19:37:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:37:44 [INFO]   Training abgeschlossen in 5.03s (Backend: cuml)\n",
      "19:38:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:38:56 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "19:40:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:40:08 [INFO]   Training abgeschlossen in 5.24s (Backend: cuml)\n",
      "19:41:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:41:20 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "19:42:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:42:32 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "19:43:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:43:45 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "19:44:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:44:59 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "19:46:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:46:13 [INFO]   Training abgeschlossen in 7.21s (Backend: cuml)\n",
      "19:47:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:47:27 [INFO]   Training abgeschlossen in 7.59s (Backend: cuml)\n",
      "19:48:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:48:42 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "19:49:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:49:56 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "19:51:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:51:10 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "19:52:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:52:25 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "19:53:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:53:39 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "19:54:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:54:53 [INFO]   Training abgeschlossen in 9.08s (Backend: cuml)\n",
      "19:55:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:56:07 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "19:57:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:57:21 [INFO]   Training abgeschlossen in 9.36s (Backend: cuml)\n",
      "19:58:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:58:34 [INFO]   Training abgeschlossen in 9.61s (Backend: cuml)\n",
      "19:59:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:59:48 [INFO]   Training abgeschlossen in 9.85s (Backend: cuml)\n",
      "20:00:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:01:01 [INFO]   Training abgeschlossen in 10.42s (Backend: cuml)\n",
      "20:02:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:02:15 [INFO]   Training abgeschlossen in 10.32s (Backend: cuml)\n",
      "20:03:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:03:27 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "20:04:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:04:40 [INFO]   Training abgeschlossen in 10.70s (Backend: cuml)\n",
      "20:05:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:05:52 [INFO]   Training abgeschlossen in 10.91s (Backend: cuml)\n",
      "20:06:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:07:04 [INFO]   Training abgeschlossen in 11.10s (Backend: cuml)\n",
      "20:08:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:08:17 [INFO]   Training abgeschlossen in 11.31s (Backend: cuml)\n",
      "20:09:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:09:29 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "20:10:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:10:40 [INFO]   Training abgeschlossen in 11.72s (Backend: cuml)\n",
      "20:11:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:11:51 [INFO]   Training abgeschlossen in 12.02s (Backend: cuml)\n",
      "20:12:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:13:02 [INFO]   Training abgeschlossen in 12.26s (Backend: cuml)\n",
      "20:14:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:14:12 [INFO]   Training abgeschlossen in 12.46s (Backend: cuml)\n",
      "20:15:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:15:23 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "20:16:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:16:33 [INFO]   Training abgeschlossen in 12.84s (Backend: cuml)\n",
      "20:17:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:17:43 [INFO]   Training abgeschlossen in 13.12s (Backend: cuml)\n",
      "20:18:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:18:53 [INFO]   Training abgeschlossen in 13.18s (Backend: cuml)\n",
      "20:19:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:20:02 [INFO]   Training abgeschlossen in 13.36s (Backend: cuml)\n",
      "20:20:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:21:12 [INFO]   Training abgeschlossen in 13.70s (Backend: cuml)\n",
      "20:22:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:22:21 [INFO]   Training abgeschlossen in 13.98s (Backend: cuml)\n",
      "20:23:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:23:29 [INFO]   Training abgeschlossen in 14.13s (Backend: cuml)\n",
      "20:24:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:24:38 [INFO]   Training abgeschlossen in 14.23s (Backend: cuml)\n",
      "20:25:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:25:46 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "20:26:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:26:54 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "20:27:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:28:01 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "20:28:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:29:08 [INFO]   Training abgeschlossen in 14.84s (Backend: cuml)\n",
      "20:29:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:30:15 [INFO]   Training abgeschlossen in 15.07s (Backend: cuml)\n",
      "20:31:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:31:21 [INFO]   Training abgeschlossen in 15.22s (Backend: cuml)\n",
      "20:32:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:32:27 [INFO]   Training abgeschlossen in 15.49s (Backend: cuml)\n",
      "20:33:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:33:33 [INFO]   Training abgeschlossen in 15.58s (Backend: cuml)\n",
      "20:34:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:34:38 [INFO]   Training abgeschlossen in 16.05s (Backend: cuml)\n",
      "20:35:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:35:43 [INFO]   Training abgeschlossen in 15.99s (Backend: cuml)\n",
      "20:36:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:36:48 [INFO]   Training abgeschlossen in 16.28s (Backend: cuml)\n",
      "20:37:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:37:53 [INFO]   Training abgeschlossen in 16.56s (Backend: cuml)\n",
      "20:38:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:38:57 [INFO]   Training abgeschlossen in 16.63s (Backend: cuml)\n",
      "20:39:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:40:01 [INFO]   Training abgeschlossen in 16.89s (Backend: cuml)\n",
      "20:40:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:41:04 [INFO]   Training abgeschlossen in 17.08s (Backend: cuml)\n",
      "20:41:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:42:08 [INFO]   Training abgeschlossen in 17.42s (Backend: cuml)\n",
      "20:42:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:43:11 [INFO]   Training abgeschlossen in 17.63s (Backend: cuml)\n",
      "20:43:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:44:14 [INFO]   Training abgeschlossen in 17.87s (Backend: cuml)\n",
      "20:44:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:45:17 [INFO]   Training abgeschlossen in 17.97s (Backend: cuml)\n",
      "20:46:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:46:19 [INFO]   Training abgeschlossen in 18.24s (Backend: cuml)\n",
      "20:47:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:47:21 [INFO]   Training abgeschlossen in 18.43s (Backend: cuml)\n",
      "20:48:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:48:23 [INFO]   Training abgeschlossen in 18.65s (Backend: cuml)\n",
      "20:49:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:49:24 [INFO]   Training abgeschlossen in 18.91s (Backend: cuml)\n",
      "20:50:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:50:25 [INFO]   Training abgeschlossen in 19.22s (Backend: cuml)\n",
      "20:51:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:51:26 [INFO]   Training abgeschlossen in 19.52s (Backend: cuml)\n",
      "20:52:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:52:27 [INFO]   Training abgeschlossen in 19.71s (Backend: cuml)\n",
      "20:53:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:53:27 [INFO]   Training abgeschlossen in 19.78s (Backend: cuml)\n",
      "20:54:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:54:27 [INFO]   Training abgeschlossen in 19.88s (Backend: cuml)\n",
      "20:55:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:55:26 [INFO]   Training abgeschlossen in 20.13s (Backend: cuml)\n",
      "20:56:05 [INFO]     36,000 labeled → Accuracy: 0.9679 (Train: 20.1s, Query: 27.24s) | GPU: 2.8/8.0 GB\n",
      "20:56:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:56:26 [INFO]   Training abgeschlossen in 20.33s (Backend: cuml)\n",
      "20:56:37 [INFO]     Final: 36,000 labeled → Accuracy: 0.9677, F1: 0.9675\n",
      "20:56:37 [INFO]   Run 4/5\n",
      "20:56:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:56:42 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "20:57:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:57:53 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "20:59:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:59:05 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "21:00:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:00:17 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "21:01:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:01:29 [INFO]   Training abgeschlossen in 5.39s (Backend: cuml)\n",
      "21:02:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:02:42 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "21:03:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:03:56 [INFO]   Training abgeschlossen in 6.02s (Backend: cuml)\n",
      "21:05:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:05:09 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "21:06:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:06:22 [INFO]   Training abgeschlossen in 6.78s (Backend: cuml)\n",
      "21:07:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:07:36 [INFO]   Training abgeschlossen in 7.12s (Backend: cuml)\n",
      "21:08:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:08:51 [INFO]   Training abgeschlossen in 7.80s (Backend: cuml)\n",
      "21:09:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:10:06 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "21:11:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:11:20 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "21:12:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:12:35 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "21:13:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:13:49 [INFO]   Training abgeschlossen in 8.57s (Backend: cuml)\n",
      "21:14:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:15:04 [INFO]   Training abgeschlossen in 8.73s (Backend: cuml)\n",
      "21:16:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:16:18 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "21:17:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:17:32 [INFO]   Training abgeschlossen in 9.19s (Backend: cuml)\n",
      "21:18:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:18:46 [INFO]   Training abgeschlossen in 9.52s (Backend: cuml)\n",
      "21:19:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:19:59 [INFO]   Training abgeschlossen in 9.62s (Backend: cuml)\n",
      "21:21:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:21:12 [INFO]   Training abgeschlossen in 9.85s (Backend: cuml)\n",
      "21:22:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:22:26 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "21:23:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:23:40 [INFO]   Training abgeschlossen in 10.61s (Backend: cuml)\n",
      "21:24:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:24:53 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "21:25:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:26:06 [INFO]   Training abgeschlossen in 10.89s (Backend: cuml)\n",
      "21:27:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:27:19 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "21:28:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:28:31 [INFO]   Training abgeschlossen in 11.10s (Backend: cuml)\n",
      "21:29:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:29:43 [INFO]   Training abgeschlossen in 11.53s (Backend: cuml)\n",
      "21:30:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:30:56 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "21:31:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:32:07 [INFO]   Training abgeschlossen in 11.71s (Backend: cuml)\n",
      "21:33:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:33:18 [INFO]   Training abgeschlossen in 12.00s (Backend: cuml)\n",
      "21:34:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:34:30 [INFO]   Training abgeschlossen in 12.24s (Backend: cuml)\n",
      "21:35:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:35:40 [INFO]   Training abgeschlossen in 12.41s (Backend: cuml)\n",
      "21:36:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:36:51 [INFO]   Training abgeschlossen in 12.55s (Backend: cuml)\n",
      "21:37:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:38:00 [INFO]   Training abgeschlossen in 12.84s (Backend: cuml)\n",
      "21:38:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:39:12 [INFO]   Training abgeschlossen in 13.14s (Backend: cuml)\n",
      "21:40:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:40:21 [INFO]   Training abgeschlossen in 13.18s (Backend: cuml)\n",
      "21:41:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:41:31 [INFO]   Training abgeschlossen in 13.43s (Backend: cuml)\n",
      "21:42:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:42:40 [INFO]   Training abgeschlossen in 13.62s (Backend: cuml)\n",
      "21:43:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:43:49 [INFO]   Training abgeschlossen in 13.88s (Backend: cuml)\n",
      "21:44:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:44:58 [INFO]   Training abgeschlossen in 14.22s (Backend: cuml)\n",
      "21:45:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:46:06 [INFO]   Training abgeschlossen in 14.24s (Backend: cuml)\n",
      "21:46:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:47:14 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "21:48:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:48:21 [INFO]   Training abgeschlossen in 14.39s (Backend: cuml)\n",
      "21:49:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:49:29 [INFO]   Training abgeschlossen in 14.56s (Backend: cuml)\n",
      "21:50:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:50:36 [INFO]   Training abgeschlossen in 14.86s (Backend: cuml)\n",
      "21:51:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:51:42 [INFO]   Training abgeschlossen in 15.01s (Backend: cuml)\n",
      "21:52:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:52:49 [INFO]   Training abgeschlossen in 15.24s (Backend: cuml)\n",
      "21:53:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:53:55 [INFO]   Training abgeschlossen in 15.45s (Backend: cuml)\n",
      "21:54:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:55:01 [INFO]   Training abgeschlossen in 15.72s (Backend: cuml)\n",
      "21:55:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:56:07 [INFO]   Training abgeschlossen in 16.28s (Backend: cuml)\n",
      "21:56:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:57:13 [INFO]   Training abgeschlossen in 16.34s (Backend: cuml)\n",
      "21:58:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:58:18 [INFO]   Training abgeschlossen in 16.36s (Backend: cuml)\n",
      "21:59:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:59:23 [INFO]   Training abgeschlossen in 16.62s (Backend: cuml)\n",
      "22:00:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:00:27 [INFO]   Training abgeschlossen in 16.77s (Backend: cuml)\n",
      "22:01:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:01:31 [INFO]   Training abgeschlossen in 16.98s (Backend: cuml)\n",
      "22:02:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:02:35 [INFO]   Training abgeschlossen in 17.24s (Backend: cuml)\n",
      "22:03:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:03:39 [INFO]   Training abgeschlossen in 17.46s (Backend: cuml)\n",
      "22:04:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:04:42 [INFO]   Training abgeschlossen in 17.82s (Backend: cuml)\n",
      "22:05:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:05:45 [INFO]   Training abgeschlossen in 17.88s (Backend: cuml)\n",
      "22:06:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:06:48 [INFO]   Training abgeschlossen in 17.99s (Backend: cuml)\n",
      "22:07:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:07:50 [INFO]   Training abgeschlossen in 18.25s (Backend: cuml)\n",
      "22:08:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:08:52 [INFO]   Training abgeschlossen in 18.51s (Backend: cuml)\n",
      "22:09:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:09:54 [INFO]   Training abgeschlossen in 18.66s (Backend: cuml)\n",
      "22:10:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:10:56 [INFO]   Training abgeschlossen in 18.87s (Backend: cuml)\n",
      "22:11:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:11:57 [INFO]   Training abgeschlossen in 19.16s (Backend: cuml)\n",
      "22:12:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:12:58 [INFO]   Training abgeschlossen in 19.43s (Backend: cuml)\n",
      "22:13:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:13:58 [INFO]   Training abgeschlossen in 19.56s (Backend: cuml)\n",
      "22:14:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:14:59 [INFO]   Training abgeschlossen in 19.88s (Backend: cuml)\n",
      "22:15:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:15:59 [INFO]   Training abgeschlossen in 20.12s (Backend: cuml)\n",
      "22:16:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:16:58 [INFO]   Training abgeschlossen in 20.26s (Backend: cuml)\n",
      "22:17:37 [INFO]     36,000 labeled → Accuracy: 0.9668 (Train: 20.3s, Query: 27.25s) | GPU: 2.8/8.0 GB\n",
      "22:17:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:17:58 [INFO]   Training abgeschlossen in 20.43s (Backend: cuml)\n",
      "22:18:09 [INFO]     Final: 36,000 labeled → Accuracy: 0.9668, F1: 0.9666\n",
      "22:18:09 [INFO]   Run 5/5\n",
      "22:18:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:18:14 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "22:19:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:19:26 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "22:20:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:20:37 [INFO]   Training abgeschlossen in 5.07s (Backend: cuml)\n",
      "22:21:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:21:49 [INFO]   Training abgeschlossen in 5.16s (Backend: cuml)\n",
      "22:22:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:23:01 [INFO]   Training abgeschlossen in 5.57s (Backend: cuml)\n",
      "22:24:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:24:14 [INFO]   Training abgeschlossen in 5.59s (Backend: cuml)\n",
      "22:25:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:25:27 [INFO]   Training abgeschlossen in 6.07s (Backend: cuml)\n",
      "22:26:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:26:40 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "22:27:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:27:54 [INFO]   Training abgeschlossen in 6.86s (Backend: cuml)\n",
      "22:29:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:29:08 [INFO]   Training abgeschlossen in 7.29s (Backend: cuml)\n",
      "22:30:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:30:22 [INFO]   Training abgeschlossen in 7.82s (Backend: cuml)\n",
      "22:31:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:31:37 [INFO]   Training abgeschlossen in 7.94s (Backend: cuml)\n",
      "22:32:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:32:51 [INFO]   Training abgeschlossen in 8.31s (Backend: cuml)\n",
      "22:33:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:34:06 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "22:35:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:35:20 [INFO]   Training abgeschlossen in 8.62s (Backend: cuml)\n",
      "22:36:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:36:35 [INFO]   Training abgeschlossen in 9.05s (Backend: cuml)\n",
      "22:37:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:37:49 [INFO]   Training abgeschlossen in 9.05s (Backend: cuml)\n",
      "22:38:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:39:03 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "22:40:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:40:16 [INFO]   Training abgeschlossen in 9.48s (Backend: cuml)\n",
      "22:41:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:41:30 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "22:42:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:42:43 [INFO]   Training abgeschlossen in 9.85s (Backend: cuml)\n",
      "22:43:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:43:56 [INFO]   Training abgeschlossen in 10.16s (Backend: cuml)\n",
      "22:44:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:45:10 [INFO]   Training abgeschlossen in 10.41s (Backend: cuml)\n",
      "22:46:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:46:22 [INFO]   Training abgeschlossen in 10.51s (Backend: cuml)\n",
      "22:47:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:47:35 [INFO]   Training abgeschlossen in 10.70s (Backend: cuml)\n",
      "22:48:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:48:47 [INFO]   Training abgeschlossen in 11.04s (Backend: cuml)\n",
      "22:49:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:50:00 [INFO]   Training abgeschlossen in 11.18s (Backend: cuml)\n",
      "22:51:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:51:12 [INFO]   Training abgeschlossen in 11.42s (Backend: cuml)\n",
      "22:52:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:52:23 [INFO]   Training abgeschlossen in 11.63s (Backend: cuml)\n",
      "22:53:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:53:35 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "22:54:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:54:46 [INFO]   Training abgeschlossen in 12.01s (Backend: cuml)\n",
      "22:55:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:55:57 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "22:56:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:57:08 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "22:58:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:58:18 [INFO]   Training abgeschlossen in 12.74s (Backend: cuml)\n",
      "22:59:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:59:29 [INFO]   Training abgeschlossen in 12.88s (Backend: cuml)\n",
      "23:00:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:00:38 [INFO]   Training abgeschlossen in 13.05s (Backend: cuml)\n",
      "23:01:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:01:48 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "23:02:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:02:58 [INFO]   Training abgeschlossen in 13.68s (Backend: cuml)\n",
      "23:03:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:04:07 [INFO]   Training abgeschlossen in 13.70s (Backend: cuml)\n",
      "23:05:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:05:17 [INFO]   Training abgeschlossen in 13.95s (Backend: cuml)\n",
      "23:06:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:06:25 [INFO]   Training abgeschlossen in 14.17s (Backend: cuml)\n",
      "23:07:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:07:34 [INFO]   Training abgeschlossen in 14.51s (Backend: cuml)\n",
      "23:08:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:08:42 [INFO]   Training abgeschlossen in 14.53s (Backend: cuml)\n",
      "23:09:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:09:50 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "23:10:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:10:58 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "23:11:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:12:05 [INFO]   Training abgeschlossen in 14.80s (Backend: cuml)\n",
      "23:12:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:13:12 [INFO]   Training abgeschlossen in 15.19s (Backend: cuml)\n",
      "23:14:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:14:19 [INFO]   Training abgeschlossen in 15.36s (Backend: cuml)\n",
      "23:15:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:15:25 [INFO]   Training abgeschlossen in 15.49s (Backend: cuml)\n",
      "23:16:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:16:31 [INFO]   Training abgeschlossen in 15.66s (Backend: cuml)\n",
      "23:17:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:17:37 [INFO]   Training abgeschlossen in 16.14s (Backend: cuml)\n",
      "23:18:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:18:43 [INFO]   Training abgeschlossen in 16.06s (Backend: cuml)\n",
      "23:19:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:19:49 [INFO]   Training abgeschlossen in 16.32s (Backend: cuml)\n",
      "23:20:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:20:54 [INFO]   Training abgeschlossen in 16.61s (Backend: cuml)\n",
      "23:21:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:22:00 [INFO]   Training abgeschlossen in 16.73s (Backend: cuml)\n",
      "23:22:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:23:05 [INFO]   Training abgeschlossen in 16.93s (Backend: cuml)\n",
      "23:23:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:24:09 [INFO]   Training abgeschlossen in 17.13s (Backend: cuml)\n",
      "23:24:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:25:14 [INFO]   Training abgeschlossen in 17.33s (Backend: cuml)\n",
      "23:25:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:26:17 [INFO]   Training abgeschlossen in 17.67s (Backend: cuml)\n",
      "23:27:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:27:20 [INFO]   Training abgeschlossen in 17.89s (Backend: cuml)\n",
      "23:28:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:28:23 [INFO]   Training abgeschlossen in 18.09s (Backend: cuml)\n",
      "23:29:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:29:25 [INFO]   Training abgeschlossen in 18.33s (Backend: cuml)\n",
      "23:30:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:30:27 [INFO]   Training abgeschlossen in 18.52s (Backend: cuml)\n",
      "23:31:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:31:29 [INFO]   Training abgeschlossen in 18.76s (Backend: cuml)\n",
      "23:32:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:32:31 [INFO]   Training abgeschlossen in 18.89s (Backend: cuml)\n",
      "23:33:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:33:32 [INFO]   Training abgeschlossen in 19.11s (Backend: cuml)\n",
      "23:34:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:34:33 [INFO]   Training abgeschlossen in 19.34s (Backend: cuml)\n",
      "23:35:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:35:33 [INFO]   Training abgeschlossen in 19.66s (Backend: cuml)\n",
      "23:36:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:36:34 [INFO]   Training abgeschlossen in 19.79s (Backend: cuml)\n",
      "23:37:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:37:34 [INFO]   Training abgeschlossen in 19.92s (Backend: cuml)\n",
      "23:38:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:38:33 [INFO]   Training abgeschlossen in 20.19s (Backend: cuml)\n",
      "23:39:12 [INFO]     36,000 labeled → Accuracy: 0.9670 (Train: 20.2s, Query: 27.30s) | GPU: 2.8/8.0 GB\n",
      "23:39:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:39:33 [INFO]   Training abgeschlossen in 20.48s (Backend: cuml)\n",
      "23:39:44 [INFO]     Final: 36,000 labeled → Accuracy: 0.9668, F1: 0.9666\n",
      "23:39:44 [INFO] \n",
      "GPU-SVM + Margin Sampling - Budget: 80% (48,000 Samples)\n",
      "23:39:44 [INFO]   Run 1/5\n",
      "23:39:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:39:49 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "23:40:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:41:01 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "23:42:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:42:12 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "23:43:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:43:24 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "23:44:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:44:37 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "23:45:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:45:49 [INFO]   Training abgeschlossen in 5.56s (Backend: cuml)\n",
      "23:46:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:47:02 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "23:48:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:48:16 [INFO]   Training abgeschlossen in 6.40s (Backend: cuml)\n",
      "23:49:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:49:29 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "23:50:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:50:43 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "23:51:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:51:57 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "23:53:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:53:12 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "23:54:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:54:26 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "23:55:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:55:40 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "23:56:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:56:55 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "23:58:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:58:09 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "23:59:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:59:23 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "00:00:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:00:38 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "00:01:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:01:51 [INFO]   Training abgeschlossen in 9.52s (Backend: cuml)\n",
      "00:02:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:03:04 [INFO]   Training abgeschlossen in 9.66s (Backend: cuml)\n",
      "00:04:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:04:18 [INFO]   Training abgeschlossen in 9.97s (Backend: cuml)\n",
      "00:05:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:05:31 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "00:06:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:06:45 [INFO]   Training abgeschlossen in 10.38s (Backend: cuml)\n",
      "00:07:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:07:57 [INFO]   Training abgeschlossen in 10.67s (Backend: cuml)\n",
      "00:08:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:09:10 [INFO]   Training abgeschlossen in 10.79s (Backend: cuml)\n",
      "00:10:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:10:22 [INFO]   Training abgeschlossen in 11.01s (Backend: cuml)\n",
      "00:11:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:11:35 [INFO]   Training abgeschlossen in 11.22s (Backend: cuml)\n",
      "00:12:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:12:47 [INFO]   Training abgeschlossen in 11.56s (Backend: cuml)\n",
      "00:13:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:13:58 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "00:14:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:15:10 [INFO]   Training abgeschlossen in 11.84s (Backend: cuml)\n",
      "00:16:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:16:21 [INFO]   Training abgeschlossen in 12.19s (Backend: cuml)\n",
      "00:17:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:17:32 [INFO]   Training abgeschlossen in 12.41s (Backend: cuml)\n",
      "00:18:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:18:43 [INFO]   Training abgeschlossen in 12.48s (Backend: cuml)\n",
      "00:19:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:19:53 [INFO]   Training abgeschlossen in 12.67s (Backend: cuml)\n",
      "00:20:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:21:03 [INFO]   Training abgeschlossen in 13.03s (Backend: cuml)\n",
      "00:22:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:22:14 [INFO]   Training abgeschlossen in 13.20s (Backend: cuml)\n",
      "00:23:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:23:23 [INFO]   Training abgeschlossen in 13.28s (Backend: cuml)\n",
      "00:24:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:24:33 [INFO]   Training abgeschlossen in 13.47s (Backend: cuml)\n",
      "00:25:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:25:42 [INFO]   Training abgeschlossen in 13.67s (Backend: cuml)\n",
      "00:26:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:26:52 [INFO]   Training abgeschlossen in 14.00s (Backend: cuml)\n",
      "00:27:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:28:01 [INFO]   Training abgeschlossen in 14.12s (Backend: cuml)\n",
      "00:28:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:29:09 [INFO]   Training abgeschlossen in 14.30s (Backend: cuml)\n",
      "00:30:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:30:17 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "00:31:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:31:25 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "00:32:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:32:33 [INFO]   Training abgeschlossen in 14.87s (Backend: cuml)\n",
      "00:33:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:33:40 [INFO]   Training abgeschlossen in 15.09s (Backend: cuml)\n",
      "00:34:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:34:47 [INFO]   Training abgeschlossen in 15.16s (Backend: cuml)\n",
      "00:35:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:35:53 [INFO]   Training abgeschlossen in 15.39s (Backend: cuml)\n",
      "00:36:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:37:00 [INFO]   Training abgeschlossen in 15.48s (Backend: cuml)\n",
      "00:37:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:38:05 [INFO]   Training abgeschlossen in 15.71s (Backend: cuml)\n",
      "00:38:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:39:11 [INFO]   Training abgeschlossen in 16.27s (Backend: cuml)\n",
      "00:40:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:40:17 [INFO]   Training abgeschlossen in 16.24s (Backend: cuml)\n",
      "00:41:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:41:22 [INFO]   Training abgeschlossen in 16.38s (Backend: cuml)\n",
      "00:42:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:42:27 [INFO]   Training abgeschlossen in 16.54s (Backend: cuml)\n",
      "00:43:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:43:33 [INFO]   Training abgeschlossen in 16.76s (Backend: cuml)\n",
      "00:44:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:44:38 [INFO]   Training abgeschlossen in 16.96s (Backend: cuml)\n",
      "00:45:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:45:42 [INFO]   Training abgeschlossen in 17.28s (Backend: cuml)\n",
      "00:46:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:46:46 [INFO]   Training abgeschlossen in 17.46s (Backend: cuml)\n",
      "00:47:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:47:50 [INFO]   Training abgeschlossen in 17.71s (Backend: cuml)\n",
      "00:48:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:48:54 [INFO]   Training abgeschlossen in 17.81s (Backend: cuml)\n",
      "00:49:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:49:57 [INFO]   Training abgeschlossen in 17.97s (Backend: cuml)\n",
      "00:50:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:50:59 [INFO]   Training abgeschlossen in 18.34s (Backend: cuml)\n",
      "00:51:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:52:01 [INFO]   Training abgeschlossen in 18.47s (Backend: cuml)\n",
      "00:52:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:53:03 [INFO]   Training abgeschlossen in 18.64s (Backend: cuml)\n",
      "00:53:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:54:04 [INFO]   Training abgeschlossen in 18.89s (Backend: cuml)\n",
      "00:54:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:55:06 [INFO]   Training abgeschlossen in 19.22s (Backend: cuml)\n",
      "00:55:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:56:07 [INFO]   Training abgeschlossen in 19.56s (Backend: cuml)\n",
      "00:56:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:57:08 [INFO]   Training abgeschlossen in 19.63s (Backend: cuml)\n",
      "00:57:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:58:08 [INFO]   Training abgeschlossen in 19.82s (Backend: cuml)\n",
      "00:58:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:59:08 [INFO]   Training abgeschlossen in 20.09s (Backend: cuml)\n",
      "00:59:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:00:08 [INFO]   Training abgeschlossen in 20.29s (Backend: cuml)\n",
      "01:00:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:01:07 [INFO]   Training abgeschlossen in 20.50s (Backend: cuml)\n",
      "01:01:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:02:07 [INFO]   Training abgeschlossen in 20.76s (Backend: cuml)\n",
      "01:02:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:03:06 [INFO]   Training abgeschlossen in 20.94s (Backend: cuml)\n",
      "01:03:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:04:04 [INFO]   Training abgeschlossen in 21.12s (Backend: cuml)\n",
      "01:04:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:05:02 [INFO]   Training abgeschlossen in 21.22s (Backend: cuml)\n",
      "01:05:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:06:00 [INFO]   Training abgeschlossen in 21.44s (Backend: cuml)\n",
      "01:06:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:06:57 [INFO]   Training abgeschlossen in 21.66s (Backend: cuml)\n",
      "01:07:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:07:55 [INFO]   Training abgeschlossen in 21.81s (Backend: cuml)\n",
      "01:08:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:08:51 [INFO]   Training abgeschlossen in 22.03s (Backend: cuml)\n",
      "01:09:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:09:48 [INFO]   Training abgeschlossen in 22.25s (Backend: cuml)\n",
      "01:10:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:10:44 [INFO]   Training abgeschlossen in 22.52s (Backend: cuml)\n",
      "01:11:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:11:40 [INFO]   Training abgeschlossen in 22.80s (Backend: cuml)\n",
      "01:12:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:12:36 [INFO]   Training abgeschlossen in 22.95s (Backend: cuml)\n",
      "01:13:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:13:31 [INFO]   Training abgeschlossen in 23.23s (Backend: cuml)\n",
      "01:14:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:14:26 [INFO]   Training abgeschlossen in 23.41s (Backend: cuml)\n",
      "01:14:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:15:20 [INFO]   Training abgeschlossen in 23.54s (Backend: cuml)\n",
      "01:15:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:16:15 [INFO]   Training abgeschlossen in 23.76s (Backend: cuml)\n",
      "01:16:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:17:09 [INFO]   Training abgeschlossen in 24.20s (Backend: cuml)\n",
      "01:17:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:18:02 [INFO]   Training abgeschlossen in 24.19s (Backend: cuml)\n",
      "01:18:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:18:56 [INFO]   Training abgeschlossen in 24.47s (Backend: cuml)\n",
      "01:19:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:19:49 [INFO]   Training abgeschlossen in 24.75s (Backend: cuml)\n",
      "01:20:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:20:41 [INFO]   Training abgeschlossen in 24.84s (Backend: cuml)\n",
      "01:21:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:21:33 [INFO]   Training abgeschlossen in 24.92s (Backend: cuml)\n",
      "01:21:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:22:25 [INFO]   Training abgeschlossen in 25.19s (Backend: cuml)\n",
      "01:22:51 [INFO]     48,000 labeled → Accuracy: 0.9672 (Train: 25.2s, Query: 14.26s) | GPU: 2.8/8.0 GB\n",
      "01:22:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:23:16 [INFO]   Training abgeschlossen in 25.40s (Backend: cuml)\n",
      "01:23:28 [INFO]     Final: 48,000 labeled → Accuracy: 0.9672, F1: 0.9670\n",
      "01:23:28 [INFO]   Run 2/5\n",
      "01:23:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:23:33 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "01:24:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:24:44 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "01:25:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:25:56 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "01:27:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:27:07 [INFO]   Training abgeschlossen in 5.25s (Backend: cuml)\n",
      "01:28:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:28:20 [INFO]   Training abgeschlossen in 5.38s (Backend: cuml)\n",
      "01:29:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:29:33 [INFO]   Training abgeschlossen in 5.70s (Backend: cuml)\n",
      "01:30:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:30:46 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "01:31:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:31:59 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "01:33:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:33:13 [INFO]   Training abgeschlossen in 6.90s (Backend: cuml)\n",
      "01:34:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:34:27 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "01:35:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:35:42 [INFO]   Training abgeschlossen in 7.72s (Backend: cuml)\n",
      "01:36:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:36:57 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "01:38:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:38:11 [INFO]   Training abgeschlossen in 8.11s (Backend: cuml)\n",
      "01:39:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:39:25 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "01:40:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:40:40 [INFO]   Training abgeschlossen in 8.68s (Backend: cuml)\n",
      "01:41:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:41:54 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "01:42:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:43:08 [INFO]   Training abgeschlossen in 9.06s (Backend: cuml)\n",
      "01:44:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:44:23 [INFO]   Training abgeschlossen in 9.57s (Backend: cuml)\n",
      "01:45:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:45:36 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "01:46:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:46:50 [INFO]   Training abgeschlossen in 9.72s (Backend: cuml)\n",
      "01:47:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:48:03 [INFO]   Training abgeschlossen in 9.98s (Backend: cuml)\n",
      "01:49:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:49:17 [INFO]   Training abgeschlossen in 10.24s (Backend: cuml)\n",
      "01:50:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:50:31 [INFO]   Training abgeschlossen in 10.47s (Backend: cuml)\n",
      "01:51:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:51:45 [INFO]   Training abgeschlossen in 10.59s (Backend: cuml)\n",
      "01:52:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:52:59 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "01:54:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:54:13 [INFO]   Training abgeschlossen in 10.98s (Backend: cuml)\n",
      "01:55:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:55:26 [INFO]   Training abgeschlossen in 11.26s (Backend: cuml)\n",
      "01:56:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:56:39 [INFO]   Training abgeschlossen in 11.65s (Backend: cuml)\n",
      "01:57:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:57:51 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "01:58:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:59:02 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "02:00:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:00:13 [INFO]   Training abgeschlossen in 12.05s (Backend: cuml)\n",
      "02:01:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:01:25 [INFO]   Training abgeschlossen in 12.37s (Backend: cuml)\n",
      "02:02:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:02:35 [INFO]   Training abgeschlossen in 12.47s (Backend: cuml)\n",
      "02:03:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:03:46 [INFO]   Training abgeschlossen in 12.73s (Backend: cuml)\n",
      "02:04:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:04:56 [INFO]   Training abgeschlossen in 12.92s (Backend: cuml)\n",
      "02:05:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:06:08 [INFO]   Training abgeschlossen in 13.25s (Backend: cuml)\n",
      "02:07:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:07:18 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "02:08:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:08:27 [INFO]   Training abgeschlossen in 13.53s (Backend: cuml)\n",
      "02:09:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:09:37 [INFO]   Training abgeschlossen in 13.74s (Backend: cuml)\n",
      "02:10:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:10:46 [INFO]   Training abgeschlossen in 14.08s (Backend: cuml)\n",
      "02:11:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:11:55 [INFO]   Training abgeschlossen in 14.25s (Backend: cuml)\n",
      "02:12:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:13:04 [INFO]   Training abgeschlossen in 14.33s (Backend: cuml)\n",
      "02:13:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:14:12 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "02:15:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:15:20 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "02:16:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:16:27 [INFO]   Training abgeschlossen in 14.77s (Backend: cuml)\n",
      "02:17:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:17:35 [INFO]   Training abgeschlossen in 14.98s (Backend: cuml)\n",
      "02:18:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:18:41 [INFO]   Training abgeschlossen in 15.06s (Backend: cuml)\n",
      "02:19:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:19:48 [INFO]   Training abgeschlossen in 15.29s (Backend: cuml)\n",
      "02:20:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:20:54 [INFO]   Training abgeschlossen in 15.47s (Backend: cuml)\n",
      "02:21:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:22:00 [INFO]   Training abgeschlossen in 15.71s (Backend: cuml)\n",
      "02:22:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:23:06 [INFO]   Training abgeschlossen in 16.24s (Backend: cuml)\n",
      "02:23:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:24:12 [INFO]   Training abgeschlossen in 16.26s (Backend: cuml)\n",
      "02:25:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:25:17 [INFO]   Training abgeschlossen in 16.37s (Backend: cuml)\n",
      "02:26:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:26:22 [INFO]   Training abgeschlossen in 16.55s (Backend: cuml)\n",
      "02:27:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:27:27 [INFO]   Training abgeschlossen in 16.76s (Backend: cuml)\n",
      "02:28:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:28:31 [INFO]   Training abgeschlossen in 16.95s (Backend: cuml)\n",
      "02:29:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:29:36 [INFO]   Training abgeschlossen in 17.20s (Backend: cuml)\n",
      "02:30:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:30:40 [INFO]   Training abgeschlossen in 17.55s (Backend: cuml)\n",
      "02:31:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:31:45 [INFO]   Training abgeschlossen in 17.80s (Backend: cuml)\n",
      "02:32:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:32:48 [INFO]   Training abgeschlossen in 17.92s (Backend: cuml)\n",
      "02:33:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:33:51 [INFO]   Training abgeschlossen in 18.11s (Backend: cuml)\n",
      "02:34:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:34:54 [INFO]   Training abgeschlossen in 18.32s (Backend: cuml)\n",
      "02:35:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:35:56 [INFO]   Training abgeschlossen in 18.47s (Backend: cuml)\n",
      "02:36:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:36:58 [INFO]   Training abgeschlossen in 18.68s (Backend: cuml)\n",
      "02:37:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:37:59 [INFO]   Training abgeschlossen in 18.89s (Backend: cuml)\n",
      "02:38:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:39:00 [INFO]   Training abgeschlossen in 19.09s (Backend: cuml)\n",
      "02:39:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:40:01 [INFO]   Training abgeschlossen in 19.38s (Backend: cuml)\n",
      "02:40:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:41:02 [INFO]   Training abgeschlossen in 19.75s (Backend: cuml)\n",
      "02:41:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:42:02 [INFO]   Training abgeschlossen in 19.76s (Backend: cuml)\n",
      "02:42:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:43:03 [INFO]   Training abgeschlossen in 20.02s (Backend: cuml)\n",
      "02:43:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:44:02 [INFO]   Training abgeschlossen in 20.20s (Backend: cuml)\n",
      "02:44:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:45:02 [INFO]   Training abgeschlossen in 20.63s (Backend: cuml)\n",
      "02:45:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:46:01 [INFO]   Training abgeschlossen in 20.71s (Backend: cuml)\n",
      "02:46:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:47:00 [INFO]   Training abgeschlossen in 20.88s (Backend: cuml)\n",
      "02:47:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:47:58 [INFO]   Training abgeschlossen in 21.17s (Backend: cuml)\n",
      "02:48:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:48:56 [INFO]   Training abgeschlossen in 21.29s (Backend: cuml)\n",
      "02:49:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:49:54 [INFO]   Training abgeschlossen in 21.46s (Backend: cuml)\n",
      "02:50:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:50:52 [INFO]   Training abgeschlossen in 21.75s (Backend: cuml)\n",
      "02:51:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:51:49 [INFO]   Training abgeschlossen in 21.87s (Backend: cuml)\n",
      "02:52:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:52:46 [INFO]   Training abgeschlossen in 22.08s (Backend: cuml)\n",
      "02:53:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:53:42 [INFO]   Training abgeschlossen in 22.38s (Backend: cuml)\n",
      "02:54:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:54:39 [INFO]   Training abgeschlossen in 22.52s (Backend: cuml)\n",
      "02:55:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:55:35 [INFO]   Training abgeschlossen in 22.75s (Backend: cuml)\n",
      "02:56:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:56:30 [INFO]   Training abgeschlossen in 23.00s (Backend: cuml)\n",
      "02:57:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:57:25 [INFO]   Training abgeschlossen in 23.10s (Backend: cuml)\n",
      "02:57:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:58:20 [INFO]   Training abgeschlossen in 23.37s (Backend: cuml)\n",
      "02:58:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:59:15 [INFO]   Training abgeschlossen in 23.60s (Backend: cuml)\n",
      "02:59:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:00:09 [INFO]   Training abgeschlossen in 23.79s (Backend: cuml)\n",
      "03:00:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:01:03 [INFO]   Training abgeschlossen in 24.01s (Backend: cuml)\n",
      "03:01:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:01:57 [INFO]   Training abgeschlossen in 24.19s (Backend: cuml)\n",
      "03:02:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:02:50 [INFO]   Training abgeschlossen in 24.39s (Backend: cuml)\n",
      "03:03:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:03:43 [INFO]   Training abgeschlossen in 24.47s (Backend: cuml)\n",
      "03:04:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:04:36 [INFO]   Training abgeschlossen in 24.84s (Backend: cuml)\n",
      "03:05:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:05:28 [INFO]   Training abgeschlossen in 24.95s (Backend: cuml)\n",
      "03:05:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:06:19 [INFO]   Training abgeschlossen in 25.12s (Backend: cuml)\n",
      "03:06:45 [INFO]     48,000 labeled → Accuracy: 0.9667 (Train: 25.1s, Query: 14.24s) | GPU: 2.8/8.0 GB\n",
      "03:06:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:07:11 [INFO]   Training abgeschlossen in 25.35s (Backend: cuml)\n",
      "03:07:22 [INFO]     Final: 48,000 labeled → Accuracy: 0.9664, F1: 0.9662\n",
      "03:07:22 [INFO]   Run 3/5\n",
      "03:07:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:07:27 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "03:08:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:08:39 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "03:09:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:09:50 [INFO]   Training abgeschlossen in 5.02s (Backend: cuml)\n",
      "03:10:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:11:02 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "03:12:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:12:14 [INFO]   Training abgeschlossen in 5.37s (Backend: cuml)\n",
      "03:13:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:13:27 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "03:14:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:14:40 [INFO]   Training abgeschlossen in 5.96s (Backend: cuml)\n",
      "03:15:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:15:53 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "03:17:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:17:07 [INFO]   Training abgeschlossen in 6.85s (Backend: cuml)\n",
      "03:18:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:18:20 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "03:19:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:19:35 [INFO]   Training abgeschlossen in 7.65s (Backend: cuml)\n",
      "03:20:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:20:49 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "03:21:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:22:04 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "03:23:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:23:18 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "03:24:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:24:33 [INFO]   Training abgeschlossen in 8.57s (Backend: cuml)\n",
      "03:25:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:25:48 [INFO]   Training abgeschlossen in 8.88s (Backend: cuml)\n",
      "03:26:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:27:04 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "03:28:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:28:19 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "03:29:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:29:33 [INFO]   Training abgeschlossen in 9.58s (Backend: cuml)\n",
      "03:30:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:30:47 [INFO]   Training abgeschlossen in 9.73s (Backend: cuml)\n",
      "03:31:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:32:00 [INFO]   Training abgeschlossen in 9.95s (Backend: cuml)\n",
      "03:33:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:33:14 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "03:34:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:34:27 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "03:35:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:35:40 [INFO]   Training abgeschlossen in 10.57s (Backend: cuml)\n",
      "03:36:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:36:53 [INFO]   Training abgeschlossen in 10.81s (Backend: cuml)\n",
      "03:37:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:38:05 [INFO]   Training abgeschlossen in 10.98s (Backend: cuml)\n",
      "03:39:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:39:18 [INFO]   Training abgeschlossen in 11.26s (Backend: cuml)\n",
      "03:40:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:40:30 [INFO]   Training abgeschlossen in 11.43s (Backend: cuml)\n",
      "03:41:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:41:42 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "03:42:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:42:53 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "03:43:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:44:05 [INFO]   Training abgeschlossen in 12.02s (Backend: cuml)\n",
      "03:45:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:45:17 [INFO]   Training abgeschlossen in 12.33s (Backend: cuml)\n",
      "03:46:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:46:29 [INFO]   Training abgeschlossen in 12.60s (Backend: cuml)\n",
      "03:47:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:47:40 [INFO]   Training abgeschlossen in 12.75s (Backend: cuml)\n",
      "03:48:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:48:50 [INFO]   Training abgeschlossen in 12.88s (Backend: cuml)\n",
      "03:49:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:50:01 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "03:50:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:51:12 [INFO]   Training abgeschlossen in 13.40s (Backend: cuml)\n",
      "03:52:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:52:23 [INFO]   Training abgeschlossen in 13.45s (Backend: cuml)\n",
      "03:53:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:53:33 [INFO]   Training abgeschlossen in 13.67s (Backend: cuml)\n",
      "03:54:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:54:43 [INFO]   Training abgeschlossen in 13.87s (Backend: cuml)\n",
      "03:55:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:55:53 [INFO]   Training abgeschlossen in 14.17s (Backend: cuml)\n",
      "03:56:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:57:03 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "03:57:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:58:12 [INFO]   Training abgeschlossen in 14.57s (Backend: cuml)\n",
      "03:59:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:59:21 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "04:00:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:00:28 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "04:01:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:01:35 [INFO]   Training abgeschlossen in 14.93s (Backend: cuml)\n",
      "04:02:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:02:43 [INFO]   Training abgeschlossen in 15.19s (Backend: cuml)\n",
      "04:03:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:03:51 [INFO]   Training abgeschlossen in 15.24s (Backend: cuml)\n",
      "04:04:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:04:58 [INFO]   Training abgeschlossen in 15.44s (Backend: cuml)\n",
      "04:05:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:06:04 [INFO]   Training abgeschlossen in 15.68s (Backend: cuml)\n",
      "04:06:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:07:10 [INFO]   Training abgeschlossen in 16.18s (Backend: cuml)\n",
      "04:07:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:08:15 [INFO]   Training abgeschlossen in 16.22s (Backend: cuml)\n",
      "04:09:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:09:21 [INFO]   Training abgeschlossen in 16.26s (Backend: cuml)\n",
      "04:10:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:10:26 [INFO]   Training abgeschlossen in 16.52s (Backend: cuml)\n",
      "04:11:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:11:32 [INFO]   Training abgeschlossen in 16.70s (Backend: cuml)\n",
      "04:12:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:12:37 [INFO]   Training abgeschlossen in 16.93s (Backend: cuml)\n",
      "04:13:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:13:40 [INFO]   Training abgeschlossen in 17.10s (Backend: cuml)\n",
      "04:14:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:14:44 [INFO]   Training abgeschlossen in 17.39s (Backend: cuml)\n",
      "04:15:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:15:49 [INFO]   Training abgeschlossen in 17.72s (Backend: cuml)\n",
      "04:16:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:16:53 [INFO]   Training abgeschlossen in 17.95s (Backend: cuml)\n",
      "04:17:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:17:55 [INFO]   Training abgeschlossen in 18.13s (Backend: cuml)\n",
      "04:18:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:18:58 [INFO]   Training abgeschlossen in 18.36s (Backend: cuml)\n",
      "04:19:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:20:00 [INFO]   Training abgeschlossen in 18.49s (Backend: cuml)\n",
      "04:20:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:21:02 [INFO]   Training abgeschlossen in 18.70s (Backend: cuml)\n",
      "04:21:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:22:04 [INFO]   Training abgeschlossen in 18.87s (Backend: cuml)\n",
      "04:22:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:23:05 [INFO]   Training abgeschlossen in 19.04s (Backend: cuml)\n",
      "04:23:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:24:06 [INFO]   Training abgeschlossen in 19.46s (Backend: cuml)\n",
      "04:24:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:25:07 [INFO]   Training abgeschlossen in 19.56s (Backend: cuml)\n",
      "04:25:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:26:07 [INFO]   Training abgeschlossen in 19.73s (Backend: cuml)\n",
      "04:26:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:27:07 [INFO]   Training abgeschlossen in 20.07s (Backend: cuml)\n",
      "04:27:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:28:07 [INFO]   Training abgeschlossen in 20.32s (Backend: cuml)\n",
      "04:28:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:29:06 [INFO]   Training abgeschlossen in 20.50s (Backend: cuml)\n",
      "04:29:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:30:05 [INFO]   Training abgeschlossen in 20.73s (Backend: cuml)\n",
      "04:30:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:31:04 [INFO]   Training abgeschlossen in 20.93s (Backend: cuml)\n",
      "04:31:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:32:03 [INFO]   Training abgeschlossen in 21.17s (Backend: cuml)\n",
      "04:32:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:33:01 [INFO]   Training abgeschlossen in 21.37s (Backend: cuml)\n",
      "04:33:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:33:59 [INFO]   Training abgeschlossen in 21.47s (Backend: cuml)\n",
      "04:34:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:34:56 [INFO]   Training abgeschlossen in 21.67s (Backend: cuml)\n",
      "04:35:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:35:53 [INFO]   Training abgeschlossen in 21.79s (Backend: cuml)\n",
      "04:36:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:36:50 [INFO]   Training abgeschlossen in 22.03s (Backend: cuml)\n",
      "04:37:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:37:46 [INFO]   Training abgeschlossen in 22.19s (Backend: cuml)\n",
      "04:38:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:38:42 [INFO]   Training abgeschlossen in 22.51s (Backend: cuml)\n",
      "04:39:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:39:38 [INFO]   Training abgeschlossen in 22.65s (Backend: cuml)\n",
      "04:40:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:40:33 [INFO]   Training abgeschlossen in 22.91s (Backend: cuml)\n",
      "04:41:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:41:29 [INFO]   Training abgeschlossen in 23.16s (Backend: cuml)\n",
      "04:42:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:42:24 [INFO]   Training abgeschlossen in 23.41s (Backend: cuml)\n",
      "04:42:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:43:18 [INFO]   Training abgeschlossen in 23.57s (Backend: cuml)\n",
      "04:43:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:44:12 [INFO]   Training abgeschlossen in 23.75s (Backend: cuml)\n",
      "04:44:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:45:06 [INFO]   Training abgeschlossen in 23.89s (Backend: cuml)\n",
      "04:45:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:46:00 [INFO]   Training abgeschlossen in 24.13s (Backend: cuml)\n",
      "04:46:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:46:53 [INFO]   Training abgeschlossen in 24.39s (Backend: cuml)\n",
      "04:47:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:47:46 [INFO]   Training abgeschlossen in 24.65s (Backend: cuml)\n",
      "04:48:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:48:38 [INFO]   Training abgeschlossen in 24.79s (Backend: cuml)\n",
      "04:49:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:49:31 [INFO]   Training abgeschlossen in 25.09s (Backend: cuml)\n",
      "04:49:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:50:23 [INFO]   Training abgeschlossen in 25.33s (Backend: cuml)\n",
      "04:50:48 [INFO]     48,000 labeled → Accuracy: 0.9673 (Train: 25.4s, Query: 14.27s) | GPU: 2.8/8.0 GB\n",
      "04:50:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:51:14 [INFO]   Training abgeschlossen in 25.36s (Backend: cuml)\n",
      "04:51:25 [INFO]     Final: 48,000 labeled → Accuracy: 0.9672, F1: 0.9670\n",
      "04:51:26 [INFO]   Run 4/5\n",
      "04:51:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:51:31 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "04:52:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "04:52:42 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "04:53:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "04:53:54 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "04:55:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "04:55:06 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "04:56:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:56:18 [INFO]   Training abgeschlossen in 5.41s (Backend: cuml)\n",
      "04:57:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:57:31 [INFO]   Training abgeschlossen in 5.76s (Backend: cuml)\n",
      "04:58:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:58:44 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "04:59:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:59:58 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "05:01:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:01:11 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "05:02:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:02:25 [INFO]   Training abgeschlossen in 7.11s (Backend: cuml)\n",
      "05:03:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:03:40 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "05:04:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:04:54 [INFO]   Training abgeschlossen in 7.96s (Backend: cuml)\n",
      "05:06:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:06:09 [INFO]   Training abgeschlossen in 8.20s (Backend: cuml)\n",
      "05:07:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:07:23 [INFO]   Training abgeschlossen in 8.43s (Backend: cuml)\n",
      "05:08:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:08:37 [INFO]   Training abgeschlossen in 8.65s (Backend: cuml)\n",
      "05:09:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:09:52 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "05:10:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:11:06 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "05:12:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:12:20 [INFO]   Training abgeschlossen in 9.22s (Backend: cuml)\n",
      "05:13:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:13:34 [INFO]   Training abgeschlossen in 9.53s (Backend: cuml)\n",
      "05:14:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:14:47 [INFO]   Training abgeschlossen in 9.70s (Backend: cuml)\n",
      "05:15:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:16:01 [INFO]   Training abgeschlossen in 9.93s (Backend: cuml)\n",
      "05:17:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:17:15 [INFO]   Training abgeschlossen in 10.21s (Backend: cuml)\n",
      "05:18:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:18:28 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "05:19:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:19:41 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "05:20:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:20:54 [INFO]   Training abgeschlossen in 10.79s (Backend: cuml)\n",
      "05:21:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:22:06 [INFO]   Training abgeschlossen in 11.04s (Backend: cuml)\n",
      "05:23:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:23:19 [INFO]   Training abgeschlossen in 11.21s (Backend: cuml)\n",
      "05:24:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:24:31 [INFO]   Training abgeschlossen in 11.39s (Backend: cuml)\n",
      "05:25:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:25:42 [INFO]   Training abgeschlossen in 11.73s (Backend: cuml)\n",
      "05:26:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:26:53 [INFO]   Training abgeschlossen in 11.83s (Backend: cuml)\n",
      "05:27:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:28:05 [INFO]   Training abgeschlossen in 12.01s (Backend: cuml)\n",
      "05:29:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:29:16 [INFO]   Training abgeschlossen in 12.25s (Backend: cuml)\n",
      "05:30:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:30:26 [INFO]   Training abgeschlossen in 12.63s (Backend: cuml)\n",
      "05:31:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:31:37 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "05:32:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:32:47 [INFO]   Training abgeschlossen in 12.88s (Backend: cuml)\n",
      "05:33:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:33:57 [INFO]   Training abgeschlossen in 13.18s (Backend: cuml)\n",
      "05:34:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:35:07 [INFO]   Training abgeschlossen in 13.37s (Backend: cuml)\n",
      "05:36:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:36:17 [INFO]   Training abgeschlossen in 13.56s (Backend: cuml)\n",
      "05:37:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:37:26 [INFO]   Training abgeschlossen in 13.66s (Backend: cuml)\n",
      "05:38:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:38:35 [INFO]   Training abgeschlossen in 13.90s (Backend: cuml)\n",
      "05:39:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:39:44 [INFO]   Training abgeschlossen in 14.10s (Backend: cuml)\n",
      "05:40:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:40:52 [INFO]   Training abgeschlossen in 14.45s (Backend: cuml)\n",
      "05:41:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:42:01 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "05:42:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:43:08 [INFO]   Training abgeschlossen in 14.40s (Backend: cuml)\n",
      "05:44:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:44:16 [INFO]   Training abgeschlossen in 14.56s (Backend: cuml)\n",
      "05:45:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:45:23 [INFO]   Training abgeschlossen in 14.85s (Backend: cuml)\n",
      "05:46:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:46:29 [INFO]   Training abgeschlossen in 15.21s (Backend: cuml)\n",
      "05:47:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:47:36 [INFO]   Training abgeschlossen in 15.38s (Backend: cuml)\n",
      "05:48:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:48:42 [INFO]   Training abgeschlossen in 15.50s (Backend: cuml)\n",
      "05:49:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:49:48 [INFO]   Training abgeschlossen in 15.73s (Backend: cuml)\n",
      "05:50:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:50:54 [INFO]   Training abgeschlossen in 16.14s (Backend: cuml)\n",
      "05:51:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:51:58 [INFO]   Training abgeschlossen in 16.11s (Backend: cuml)\n",
      "05:52:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:53:04 [INFO]   Training abgeschlossen in 16.35s (Backend: cuml)\n",
      "05:53:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:54:10 [INFO]   Training abgeschlossen in 16.65s (Backend: cuml)\n",
      "05:54:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:55:15 [INFO]   Training abgeschlossen in 16.73s (Backend: cuml)\n",
      "05:56:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:56:20 [INFO]   Training abgeschlossen in 17.00s (Backend: cuml)\n",
      "05:57:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:57:24 [INFO]   Training abgeschlossen in 17.08s (Backend: cuml)\n",
      "05:58:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:58:28 [INFO]   Training abgeschlossen in 17.34s (Backend: cuml)\n",
      "05:59:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:59:32 [INFO]   Training abgeschlossen in 17.78s (Backend: cuml)\n",
      "06:00:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:00:35 [INFO]   Training abgeschlossen in 17.94s (Backend: cuml)\n",
      "06:01:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:01:38 [INFO]   Training abgeschlossen in 18.13s (Backend: cuml)\n",
      "06:02:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:02:40 [INFO]   Training abgeschlossen in 18.41s (Backend: cuml)\n",
      "06:03:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:03:43 [INFO]   Training abgeschlossen in 18.55s (Backend: cuml)\n",
      "06:04:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:04:45 [INFO]   Training abgeschlossen in 18.67s (Backend: cuml)\n",
      "06:05:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:05:46 [INFO]   Training abgeschlossen in 18.92s (Backend: cuml)\n",
      "06:06:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:06:47 [INFO]   Training abgeschlossen in 19.14s (Backend: cuml)\n",
      "06:07:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:07:48 [INFO]   Training abgeschlossen in 19.37s (Backend: cuml)\n",
      "06:08:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:08:49 [INFO]   Training abgeschlossen in 19.56s (Backend: cuml)\n",
      "06:09:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:09:49 [INFO]   Training abgeschlossen in 19.77s (Backend: cuml)\n",
      "06:10:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:10:49 [INFO]   Training abgeschlossen in 20.06s (Backend: cuml)\n",
      "06:11:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:11:49 [INFO]   Training abgeschlossen in 20.31s (Backend: cuml)\n",
      "06:12:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:12:48 [INFO]   Training abgeschlossen in 20.50s (Backend: cuml)\n",
      "06:13:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:13:47 [INFO]   Training abgeschlossen in 20.70s (Backend: cuml)\n",
      "06:14:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:14:46 [INFO]   Training abgeschlossen in 21.16s (Backend: cuml)\n",
      "06:15:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:15:45 [INFO]   Training abgeschlossen in 21.28s (Backend: cuml)\n",
      "06:16:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:16:44 [INFO]   Training abgeschlossen in 21.52s (Backend: cuml)\n",
      "06:17:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:17:42 [INFO]   Training abgeschlossen in 21.68s (Backend: cuml)\n",
      "06:18:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:18:39 [INFO]   Training abgeschlossen in 21.83s (Backend: cuml)\n",
      "06:19:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:19:37 [INFO]   Training abgeschlossen in 22.06s (Backend: cuml)\n",
      "06:20:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:20:34 [INFO]   Training abgeschlossen in 22.25s (Backend: cuml)\n",
      "06:21:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:21:31 [INFO]   Training abgeschlossen in 22.43s (Backend: cuml)\n",
      "06:22:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:22:27 [INFO]   Training abgeschlossen in 22.64s (Backend: cuml)\n",
      "06:23:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:23:23 [INFO]   Training abgeschlossen in 22.81s (Backend: cuml)\n",
      "06:23:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:24:19 [INFO]   Training abgeschlossen in 23.07s (Backend: cuml)\n",
      "06:24:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:25:14 [INFO]   Training abgeschlossen in 23.26s (Backend: cuml)\n",
      "06:25:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:26:09 [INFO]   Training abgeschlossen in 23.43s (Backend: cuml)\n",
      "06:26:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:27:04 [INFO]   Training abgeschlossen in 23.85s (Backend: cuml)\n",
      "06:27:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:27:58 [INFO]   Training abgeschlossen in 23.83s (Backend: cuml)\n",
      "06:28:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:28:52 [INFO]   Training abgeschlossen in 24.21s (Backend: cuml)\n",
      "06:29:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:29:46 [INFO]   Training abgeschlossen in 24.32s (Backend: cuml)\n",
      "06:30:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:30:39 [INFO]   Training abgeschlossen in 24.53s (Backend: cuml)\n",
      "06:31:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:31:32 [INFO]   Training abgeschlossen in 24.56s (Backend: cuml)\n",
      "06:32:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:32:25 [INFO]   Training abgeschlossen in 24.83s (Backend: cuml)\n",
      "06:32:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:33:17 [INFO]   Training abgeschlossen in 24.97s (Backend: cuml)\n",
      "06:33:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:34:08 [INFO]   Training abgeschlossen in 25.17s (Backend: cuml)\n",
      "06:34:34 [INFO]     48,000 labeled → Accuracy: 0.9664 (Train: 25.2s, Query: 14.22s) | GPU: 2.8/8.0 GB\n",
      "06:34:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:35:00 [INFO]   Training abgeschlossen in 25.36s (Backend: cuml)\n",
      "06:35:11 [INFO]     Final: 48,000 labeled → Accuracy: 0.9664, F1: 0.9662\n",
      "06:35:11 [INFO]   Run 5/5\n",
      "06:35:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:35:16 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "06:36:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "06:36:28 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "06:37:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "06:37:40 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "06:38:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "06:38:51 [INFO]   Training abgeschlossen in 5.18s (Backend: cuml)\n",
      "06:39:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:40:04 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "06:41:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:41:17 [INFO]   Training abgeschlossen in 5.61s (Backend: cuml)\n",
      "06:42:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:42:30 [INFO]   Training abgeschlossen in 6.09s (Backend: cuml)\n",
      "06:43:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:43:43 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "06:44:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:44:57 [INFO]   Training abgeschlossen in 6.98s (Backend: cuml)\n",
      "06:46:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:46:11 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "06:47:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:47:25 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "06:48:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:48:40 [INFO]   Training abgeschlossen in 7.99s (Backend: cuml)\n",
      "06:49:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:49:54 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "06:51:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:51:08 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "06:52:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:52:23 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "06:53:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:53:37 [INFO]   Training abgeschlossen in 9.05s (Backend: cuml)\n",
      "06:54:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:54:51 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "06:55:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:56:05 [INFO]   Training abgeschlossen in 9.18s (Backend: cuml)\n",
      "06:57:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:57:18 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "06:58:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:58:32 [INFO]   Training abgeschlossen in 9.72s (Backend: cuml)\n",
      "06:59:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:59:46 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "07:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:00:59 [INFO]   Training abgeschlossen in 10.17s (Backend: cuml)\n",
      "07:02:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:02:13 [INFO]   Training abgeschlossen in 10.42s (Backend: cuml)\n",
      "07:03:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:03:26 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "07:04:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:04:40 [INFO]   Training abgeschlossen in 10.74s (Backend: cuml)\n",
      "07:05:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:05:53 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "07:06:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:07:06 [INFO]   Training abgeschlossen in 11.20s (Backend: cuml)\n",
      "07:08:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:08:20 [INFO]   Training abgeschlossen in 11.41s (Backend: cuml)\n",
      "07:09:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:09:32 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "07:10:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:10:44 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "07:11:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:11:56 [INFO]   Training abgeschlossen in 11.99s (Backend: cuml)\n",
      "07:12:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:13:07 [INFO]   Training abgeschlossen in 12.18s (Backend: cuml)\n",
      "07:14:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:14:19 [INFO]   Training abgeschlossen in 12.48s (Backend: cuml)\n",
      "07:15:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:15:30 [INFO]   Training abgeschlossen in 12.69s (Backend: cuml)\n",
      "07:16:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:16:40 [INFO]   Training abgeschlossen in 12.85s (Backend: cuml)\n",
      "07:17:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:17:51 [INFO]   Training abgeschlossen in 13.06s (Backend: cuml)\n",
      "07:18:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:19:01 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "07:19:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:20:12 [INFO]   Training abgeschlossen in 13.57s (Backend: cuml)\n",
      "07:21:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:21:22 [INFO]   Training abgeschlossen in 13.73s (Backend: cuml)\n",
      "07:22:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:22:32 [INFO]   Training abgeschlossen in 13.88s (Backend: cuml)\n",
      "07:23:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:23:42 [INFO]   Training abgeschlossen in 14.08s (Backend: cuml)\n",
      "07:24:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:24:51 [INFO]   Training abgeschlossen in 14.39s (Backend: cuml)\n",
      "07:25:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:26:00 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "07:26:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:27:09 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "07:28:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:28:16 [INFO]   Training abgeschlossen in 14.56s (Backend: cuml)\n",
      "07:29:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:29:24 [INFO]   Training abgeschlossen in 14.93s (Backend: cuml)\n",
      "07:30:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:30:31 [INFO]   Training abgeschlossen in 15.17s (Backend: cuml)\n",
      "07:31:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:31:37 [INFO]   Training abgeschlossen in 15.28s (Backend: cuml)\n",
      "07:32:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:32:43 [INFO]   Training abgeschlossen in 15.42s (Backend: cuml)\n",
      "07:33:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:33:49 [INFO]   Training abgeschlossen in 15.58s (Backend: cuml)\n",
      "07:34:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:34:55 [INFO]   Training abgeschlossen in 16.09s (Backend: cuml)\n",
      "07:35:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:36:00 [INFO]   Training abgeschlossen in 16.19s (Backend: cuml)\n",
      "07:36:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:37:05 [INFO]   Training abgeschlossen in 16.47s (Backend: cuml)\n",
      "07:37:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:38:10 [INFO]   Training abgeschlossen in 16.59s (Backend: cuml)\n",
      "07:38:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:39:15 [INFO]   Training abgeschlossen in 16.76s (Backend: cuml)\n",
      "07:40:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:40:18 [INFO]   Training abgeschlossen in 16.86s (Backend: cuml)\n",
      "07:41:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:41:22 [INFO]   Training abgeschlossen in 17.17s (Backend: cuml)\n",
      "07:42:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:42:26 [INFO]   Training abgeschlossen in 17.41s (Backend: cuml)\n",
      "07:43:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:43:29 [INFO]   Training abgeschlossen in 17.71s (Backend: cuml)\n",
      "07:44:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:44:32 [INFO]   Training abgeschlossen in 17.96s (Backend: cuml)\n",
      "07:45:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:45:35 [INFO]   Training abgeschlossen in 18.13s (Backend: cuml)\n",
      "07:46:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:46:37 [INFO]   Training abgeschlossen in 18.50s (Backend: cuml)\n",
      "07:47:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:47:40 [INFO]   Training abgeschlossen in 18.46s (Backend: cuml)\n",
      "07:48:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:48:41 [INFO]   Training abgeschlossen in 18.61s (Backend: cuml)\n",
      "07:49:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:49:43 [INFO]   Training abgeschlossen in 18.85s (Backend: cuml)\n",
      "07:50:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:50:44 [INFO]   Training abgeschlossen in 19.01s (Backend: cuml)\n",
      "07:51:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:51:45 [INFO]   Training abgeschlossen in 19.29s (Backend: cuml)\n",
      "07:52:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:52:45 [INFO]   Training abgeschlossen in 19.47s (Backend: cuml)\n",
      "07:53:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:53:46 [INFO]   Training abgeschlossen in 19.64s (Backend: cuml)\n",
      "07:54:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:54:46 [INFO]   Training abgeschlossen in 19.90s (Backend: cuml)\n",
      "07:55:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:55:45 [INFO]   Training abgeschlossen in 20.12s (Backend: cuml)\n",
      "07:56:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:56:44 [INFO]   Training abgeschlossen in 20.36s (Backend: cuml)\n",
      "07:57:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:57:43 [INFO]   Training abgeschlossen in 20.57s (Backend: cuml)\n",
      "07:58:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:58:42 [INFO]   Training abgeschlossen in 20.78s (Backend: cuml)\n",
      "07:59:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:59:40 [INFO]   Training abgeschlossen in 21.13s (Backend: cuml)\n",
      "08:00:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:00:38 [INFO]   Training abgeschlossen in 21.29s (Backend: cuml)\n",
      "08:01:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:01:36 [INFO]   Training abgeschlossen in 21.46s (Backend: cuml)\n",
      "08:02:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:02:33 [INFO]   Training abgeschlossen in 21.65s (Backend: cuml)\n",
      "08:03:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:03:30 [INFO]   Training abgeschlossen in 21.78s (Backend: cuml)\n",
      "08:04:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:04:27 [INFO]   Training abgeschlossen in 21.97s (Backend: cuml)\n",
      "08:05:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:05:23 [INFO]   Training abgeschlossen in 22.20s (Backend: cuml)\n",
      "08:05:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:06:19 [INFO]   Training abgeschlossen in 22.47s (Backend: cuml)\n",
      "08:06:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:07:15 [INFO]   Training abgeschlossen in 22.82s (Backend: cuml)\n",
      "08:07:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:08:11 [INFO]   Training abgeschlossen in 23.02s (Backend: cuml)\n",
      "08:08:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:09:06 [INFO]   Training abgeschlossen in 23.15s (Backend: cuml)\n",
      "08:09:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:10:01 [INFO]   Training abgeschlossen in 23.45s (Backend: cuml)\n",
      "08:10:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:10:56 [INFO]   Training abgeschlossen in 23.57s (Backend: cuml)\n",
      "08:11:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:11:50 [INFO]   Training abgeschlossen in 23.92s (Backend: cuml)\n",
      "08:12:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:12:44 [INFO]   Training abgeschlossen in 24.18s (Backend: cuml)\n",
      "08:13:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:13:38 [INFO]   Training abgeschlossen in 24.35s (Backend: cuml)\n",
      "08:14:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:14:31 [INFO]   Training abgeschlossen in 24.50s (Backend: cuml)\n",
      "08:14:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:15:24 [INFO]   Training abgeschlossen in 24.61s (Backend: cuml)\n",
      "08:15:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:16:17 [INFO]   Training abgeschlossen in 24.85s (Backend: cuml)\n",
      "08:16:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:17:09 [INFO]   Training abgeschlossen in 25.12s (Backend: cuml)\n",
      "08:17:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:18:01 [INFO]   Training abgeschlossen in 25.24s (Backend: cuml)\n",
      "08:18:26 [INFO]     48,000 labeled → Accuracy: 0.9669 (Train: 25.3s, Query: 14.26s) | GPU: 2.8/8.0 GB\n",
      "08:18:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:18:52 [INFO]   Training abgeschlossen in 25.32s (Backend: cuml)\n",
      "08:19:04 [INFO]     Final: 48,000 labeled → Accuracy: 0.9666, F1: 0.9664\n",
      "08:19:04 [INFO] \n",
      "GPU-SVM + Margin Sampling - Budget: 100% (60,000 Samples)\n",
      "08:19:04 [INFO]   Run 1/5\n",
      "08:19:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:19:09 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "08:20:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "08:20:20 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "08:21:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "08:21:32 [INFO]   Training abgeschlossen in 5.06s (Backend: cuml)\n",
      "08:22:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "08:22:44 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "08:23:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "08:23:57 [INFO]   Training abgeschlossen in 5.46s (Backend: cuml)\n",
      "08:25:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:25:09 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "08:26:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:26:22 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "08:27:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:27:36 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "08:28:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:28:49 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "08:29:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:30:03 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "08:31:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:31:17 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "08:32:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:32:32 [INFO]   Training abgeschlossen in 7.84s (Backend: cuml)\n",
      "08:33:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:33:46 [INFO]   Training abgeschlossen in 8.11s (Backend: cuml)\n",
      "08:34:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:35:00 [INFO]   Training abgeschlossen in 8.44s (Backend: cuml)\n",
      "08:36:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:36:14 [INFO]   Training abgeschlossen in 8.58s (Backend: cuml)\n",
      "08:37:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:37:28 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "08:38:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:38:43 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "08:39:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:39:57 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "08:41:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:41:10 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "08:42:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:42:23 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "08:43:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:43:37 [INFO]   Training abgeschlossen in 10.10s (Backend: cuml)\n",
      "08:44:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:44:51 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "08:45:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:46:04 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "08:47:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:47:16 [INFO]   Training abgeschlossen in 10.59s (Backend: cuml)\n",
      "08:48:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:48:29 [INFO]   Training abgeschlossen in 10.80s (Backend: cuml)\n",
      "08:49:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:49:42 [INFO]   Training abgeschlossen in 10.94s (Backend: cuml)\n",
      "08:50:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:50:54 [INFO]   Training abgeschlossen in 11.20s (Backend: cuml)\n",
      "08:51:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:52:06 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "08:53:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:53:18 [INFO]   Training abgeschlossen in 11.64s (Backend: cuml)\n",
      "08:54:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:54:29 [INFO]   Training abgeschlossen in 11.76s (Backend: cuml)\n",
      "08:55:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:55:40 [INFO]   Training abgeschlossen in 12.01s (Backend: cuml)\n",
      "08:56:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:56:51 [INFO]   Training abgeschlossen in 12.24s (Backend: cuml)\n",
      "08:57:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:58:02 [INFO]   Training abgeschlossen in 12.46s (Backend: cuml)\n",
      "08:59:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:59:12 [INFO]   Training abgeschlossen in 12.60s (Backend: cuml)\n",
      "09:00:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:00:23 [INFO]   Training abgeschlossen in 12.81s (Backend: cuml)\n",
      "09:01:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:01:33 [INFO]   Training abgeschlossen in 13.19s (Backend: cuml)\n",
      "09:02:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:02:43 [INFO]   Training abgeschlossen in 13.30s (Backend: cuml)\n",
      "09:03:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:03:53 [INFO]   Training abgeschlossen in 13.45s (Backend: cuml)\n",
      "09:04:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:05:03 [INFO]   Training abgeschlossen in 13.69s (Backend: cuml)\n",
      "09:05:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:06:13 [INFO]   Training abgeschlossen in 14.03s (Backend: cuml)\n",
      "09:07:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:07:23 [INFO]   Training abgeschlossen in 14.05s (Backend: cuml)\n",
      "09:08:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:08:32 [INFO]   Training abgeschlossen in 14.27s (Backend: cuml)\n",
      "09:09:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:09:40 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "09:10:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:10:48 [INFO]   Training abgeschlossen in 14.64s (Backend: cuml)\n",
      "09:11:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:11:56 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "09:12:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:13:03 [INFO]   Training abgeschlossen in 14.88s (Backend: cuml)\n",
      "09:13:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:14:09 [INFO]   Training abgeschlossen in 15.03s (Backend: cuml)\n",
      "09:15:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:15:16 [INFO]   Training abgeschlossen in 15.20s (Backend: cuml)\n",
      "09:16:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:16:22 [INFO]   Training abgeschlossen in 15.68s (Backend: cuml)\n",
      "09:17:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:17:28 [INFO]   Training abgeschlossen in 15.79s (Backend: cuml)\n",
      "09:18:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:18:34 [INFO]   Training abgeschlossen in 16.10s (Backend: cuml)\n",
      "09:19:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:19:39 [INFO]   Training abgeschlossen in 16.15s (Backend: cuml)\n",
      "09:20:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:20:44 [INFO]   Training abgeschlossen in 16.37s (Backend: cuml)\n",
      "09:21:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:21:48 [INFO]   Training abgeschlossen in 16.56s (Backend: cuml)\n",
      "09:22:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:22:54 [INFO]   Training abgeschlossen in 16.84s (Backend: cuml)\n",
      "09:23:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:23:59 [INFO]   Training abgeschlossen in 16.98s (Backend: cuml)\n",
      "09:24:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:25:02 [INFO]   Training abgeschlossen in 17.06s (Backend: cuml)\n",
      "09:25:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:26:06 [INFO]   Training abgeschlossen in 17.36s (Backend: cuml)\n",
      "09:26:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:27:11 [INFO]   Training abgeschlossen in 17.60s (Backend: cuml)\n",
      "09:27:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:28:14 [INFO]   Training abgeschlossen in 17.76s (Backend: cuml)\n",
      "09:28:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:29:17 [INFO]   Training abgeschlossen in 18.05s (Backend: cuml)\n",
      "09:30:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:30:19 [INFO]   Training abgeschlossen in 18.31s (Backend: cuml)\n",
      "09:31:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:31:21 [INFO]   Training abgeschlossen in 18.57s (Backend: cuml)\n",
      "09:32:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:32:23 [INFO]   Training abgeschlossen in 18.92s (Backend: cuml)\n",
      "09:33:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:33:24 [INFO]   Training abgeschlossen in 18.79s (Backend: cuml)\n",
      "09:34:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:34:25 [INFO]   Training abgeschlossen in 18.95s (Backend: cuml)\n",
      "09:35:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:35:26 [INFO]   Training abgeschlossen in 19.41s (Backend: cuml)\n",
      "09:36:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:36:27 [INFO]   Training abgeschlossen in 19.64s (Backend: cuml)\n",
      "09:37:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:37:27 [INFO]   Training abgeschlossen in 19.73s (Backend: cuml)\n",
      "09:38:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:38:27 [INFO]   Training abgeschlossen in 20.02s (Backend: cuml)\n",
      "09:39:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:39:27 [INFO]   Training abgeschlossen in 20.21s (Backend: cuml)\n",
      "09:40:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:40:26 [INFO]   Training abgeschlossen in 20.36s (Backend: cuml)\n",
      "09:41:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:41:25 [INFO]   Training abgeschlossen in 20.62s (Backend: cuml)\n",
      "09:42:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:42:24 [INFO]   Training abgeschlossen in 20.91s (Backend: cuml)\n",
      "09:43:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:43:22 [INFO]   Training abgeschlossen in 21.16s (Backend: cuml)\n",
      "09:43:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:44:20 [INFO]   Training abgeschlossen in 21.25s (Backend: cuml)\n",
      "09:44:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:45:18 [INFO]   Training abgeschlossen in 21.52s (Backend: cuml)\n",
      "09:45:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:46:16 [INFO]   Training abgeschlossen in 21.79s (Backend: cuml)\n",
      "09:46:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:47:13 [INFO]   Training abgeschlossen in 21.85s (Backend: cuml)\n",
      "09:47:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:48:09 [INFO]   Training abgeschlossen in 22.04s (Backend: cuml)\n",
      "09:48:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:49:06 [INFO]   Training abgeschlossen in 22.45s (Backend: cuml)\n",
      "09:49:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:50:02 [INFO]   Training abgeschlossen in 22.62s (Backend: cuml)\n",
      "09:50:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:50:58 [INFO]   Training abgeschlossen in 22.81s (Backend: cuml)\n",
      "09:51:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:51:54 [INFO]   Training abgeschlossen in 23.06s (Backend: cuml)\n",
      "09:52:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:52:49 [INFO]   Training abgeschlossen in 23.22s (Backend: cuml)\n",
      "09:53:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:53:44 [INFO]   Training abgeschlossen in 23.34s (Backend: cuml)\n",
      "09:54:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:54:38 [INFO]   Training abgeschlossen in 23.56s (Backend: cuml)\n",
      "09:55:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:55:33 [INFO]   Training abgeschlossen in 23.83s (Backend: cuml)\n",
      "09:56:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:56:27 [INFO]   Training abgeschlossen in 23.98s (Backend: cuml)\n",
      "09:56:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:57:20 [INFO]   Training abgeschlossen in 24.12s (Backend: cuml)\n",
      "09:57:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:58:13 [INFO]   Training abgeschlossen in 24.40s (Backend: cuml)\n",
      "09:58:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:59:06 [INFO]   Training abgeschlossen in 24.51s (Backend: cuml)\n",
      "09:59:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:59:58 [INFO]   Training abgeschlossen in 24.63s (Backend: cuml)\n",
      "10:00:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:00:50 [INFO]   Training abgeschlossen in 24.99s (Backend: cuml)\n",
      "10:01:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:01:42 [INFO]   Training abgeschlossen in 25.12s (Backend: cuml)\n",
      "10:02:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:02:34 [INFO]   Training abgeschlossen in 25.31s (Backend: cuml)\n",
      "10:02:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:03:24 [INFO]   Training abgeschlossen in 25.46s (Backend: cuml)\n",
      "10:03:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:04:15 [INFO]   Training abgeschlossen in 25.72s (Backend: cuml)\n",
      "10:04:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:05:05 [INFO]   Training abgeschlossen in 26.08s (Backend: cuml)\n",
      "10:05:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:06:09 [INFO]   Training abgeschlossen in 39.64s (Backend: cuml)\n",
      "10:06:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:07:13 [INFO]   Training abgeschlossen in 40.71s (Backend: cuml)\n",
      "10:07:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:08:17 [INFO]   Training abgeschlossen in 41.57s (Backend: cuml)\n",
      "10:08:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:09:18 [INFO]   Training abgeschlossen in 39.51s (Backend: cuml)\n",
      "10:09:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:10:21 [INFO]   Training abgeschlossen in 41.26s (Backend: cuml)\n",
      "10:10:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:11:21 [INFO]   Training abgeschlossen in 38.98s (Backend: cuml)\n",
      "10:11:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:12:24 [INFO]   Training abgeschlossen in 43.00s (Backend: cuml)\n",
      "10:12:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:13:25 [INFO]   Training abgeschlossen in 41.17s (Backend: cuml)\n",
      "10:13:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:14:26 [INFO]   Training abgeschlossen in 41.05s (Backend: cuml)\n",
      "10:14:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:15:25 [INFO]   Training abgeschlossen in 40.83s (Backend: cuml)\n",
      "10:15:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:16:24 [INFO]   Training abgeschlossen in 40.77s (Backend: cuml)\n",
      "10:16:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:17:24 [INFO]   Training abgeschlossen in 42.39s (Backend: cuml)\n",
      "10:17:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:18:24 [INFO]   Training abgeschlossen in 42.81s (Backend: cuml)\n",
      "10:18:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:19:25 [INFO]   Training abgeschlossen in 44.56s (Backend: cuml)\n",
      "10:19:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:20:26 [INFO]   Training abgeschlossen in 45.41s (Backend: cuml)\n",
      "10:20:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:21:25 [INFO]   Training abgeschlossen in 43.49s (Backend: cuml)\n",
      "10:21:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:22:23 [INFO]   Training abgeschlossen in 43.28s (Backend: cuml)\n",
      "10:22:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:23:19 [INFO]   Training abgeschlossen in 41.17s (Backend: cuml)\n",
      "10:23:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:24:16 [INFO]   Training abgeschlossen in 43.50s (Backend: cuml)\n",
      "10:24:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:25:14 [INFO]   Training abgeschlossen in 44.75s (Backend: cuml)\n",
      "10:25:26 [INFO]     60,000 labeled → Accuracy: 0.9674 (Train: 44.8s, Query: 0.67s) | GPU: 2.8/8.0 GB\n",
      "10:25:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:26:09 [INFO]   Training abgeschlossen in 42.78s (Backend: cuml)\n",
      "10:26:21 [INFO]     Final: 60,000 labeled → Accuracy: 0.9671, F1: 0.9668\n",
      "10:26:21 [INFO]   Run 2/5\n",
      "10:26:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:26:26 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "10:27:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:27:38 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "10:28:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:28:49 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "10:29:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:30:01 [INFO]   Training abgeschlossen in 5.20s (Backend: cuml)\n",
      "10:31:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:31:13 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "10:32:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:32:26 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "10:33:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:33:39 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "10:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:34:52 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "10:35:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:36:06 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "10:37:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:37:20 [INFO]   Training abgeschlossen in 7.13s (Backend: cuml)\n",
      "10:38:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:38:34 [INFO]   Training abgeschlossen in 7.74s (Backend: cuml)\n",
      "10:39:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:39:49 [INFO]   Training abgeschlossen in 8.02s (Backend: cuml)\n",
      "10:40:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:41:03 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "10:42:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:42:17 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "10:43:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:43:31 [INFO]   Training abgeschlossen in 8.62s (Backend: cuml)\n",
      "10:44:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:44:45 [INFO]   Training abgeschlossen in 8.75s (Backend: cuml)\n",
      "10:45:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:46:00 [INFO]   Training abgeschlossen in 9.03s (Backend: cuml)\n",
      "10:47:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:47:14 [INFO]   Training abgeschlossen in 9.30s (Backend: cuml)\n",
      "10:48:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:48:27 [INFO]   Training abgeschlossen in 9.38s (Backend: cuml)\n",
      "10:49:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:49:41 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "10:50:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:50:54 [INFO]   Training abgeschlossen in 9.98s (Backend: cuml)\n",
      "10:51:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:52:07 [INFO]   Training abgeschlossen in 10.16s (Backend: cuml)\n",
      "10:53:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:53:22 [INFO]   Training abgeschlossen in 10.37s (Backend: cuml)\n",
      "10:54:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:54:36 [INFO]   Training abgeschlossen in 10.58s (Backend: cuml)\n",
      "10:55:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:55:49 [INFO]   Training abgeschlossen in 10.81s (Backend: cuml)\n",
      "10:56:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:57:02 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "10:58:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:58:14 [INFO]   Training abgeschlossen in 11.22s (Backend: cuml)\n",
      "10:59:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:59:26 [INFO]   Training abgeschlossen in 11.36s (Backend: cuml)\n",
      "11:00:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:00:39 [INFO]   Training abgeschlossen in 11.56s (Backend: cuml)\n",
      "11:01:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:01:51 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "11:02:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:03:03 [INFO]   Training abgeschlossen in 11.94s (Backend: cuml)\n",
      "11:04:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:04:14 [INFO]   Training abgeschlossen in 12.21s (Backend: cuml)\n",
      "11:05:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:05:25 [INFO]   Training abgeschlossen in 12.49s (Backend: cuml)\n",
      "11:06:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:06:36 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "11:07:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:07:47 [INFO]   Training abgeschlossen in 13.08s (Backend: cuml)\n",
      "11:08:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:08:57 [INFO]   Training abgeschlossen in 13.01s (Backend: cuml)\n",
      "11:09:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:10:07 [INFO]   Training abgeschlossen in 13.29s (Backend: cuml)\n",
      "11:11:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:11:17 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "11:12:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:12:26 [INFO]   Training abgeschlossen in 13.66s (Backend: cuml)\n",
      "11:13:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:13:35 [INFO]   Training abgeschlossen in 13.90s (Backend: cuml)\n",
      "11:14:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:14:44 [INFO]   Training abgeschlossen in 14.12s (Backend: cuml)\n",
      "11:15:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:15:53 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "11:16:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:17:01 [INFO]   Training abgeschlossen in 14.51s (Backend: cuml)\n",
      "11:17:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:18:08 [INFO]   Training abgeschlossen in 14.38s (Backend: cuml)\n",
      "11:19:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:19:16 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "11:20:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:20:23 [INFO]   Training abgeschlossen in 14.88s (Backend: cuml)\n",
      "11:21:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:21:29 [INFO]   Training abgeschlossen in 15.19s (Backend: cuml)\n",
      "11:22:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:22:36 [INFO]   Training abgeschlossen in 15.38s (Backend: cuml)\n",
      "11:23:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:23:42 [INFO]   Training abgeschlossen in 15.47s (Backend: cuml)\n",
      "11:24:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:24:48 [INFO]   Training abgeschlossen in 15.85s (Backend: cuml)\n",
      "11:25:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:25:54 [INFO]   Training abgeschlossen in 16.16s (Backend: cuml)\n",
      "11:26:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:27:00 [INFO]   Training abgeschlossen in 16.12s (Backend: cuml)\n",
      "11:27:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:28:05 [INFO]   Training abgeschlossen in 16.34s (Backend: cuml)\n",
      "11:28:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:29:09 [INFO]   Training abgeschlossen in 16.67s (Backend: cuml)\n",
      "11:29:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:30:14 [INFO]   Training abgeschlossen in 16.73s (Backend: cuml)\n",
      "11:31:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:31:18 [INFO]   Training abgeschlossen in 16.92s (Backend: cuml)\n",
      "11:32:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:32:21 [INFO]   Training abgeschlossen in 17.14s (Backend: cuml)\n",
      "11:33:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:33:25 [INFO]   Training abgeschlossen in 17.34s (Backend: cuml)\n",
      "11:34:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:34:28 [INFO]   Training abgeschlossen in 17.66s (Backend: cuml)\n",
      "11:35:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:35:32 [INFO]   Training abgeschlossen in 18.09s (Backend: cuml)\n",
      "11:36:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:36:35 [INFO]   Training abgeschlossen in 18.16s (Backend: cuml)\n",
      "11:37:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:37:37 [INFO]   Training abgeschlossen in 18.37s (Backend: cuml)\n",
      "11:38:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:38:39 [INFO]   Training abgeschlossen in 18.40s (Backend: cuml)\n",
      "11:39:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:39:41 [INFO]   Training abgeschlossen in 18.65s (Backend: cuml)\n",
      "11:40:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:40:42 [INFO]   Training abgeschlossen in 18.89s (Backend: cuml)\n",
      "11:41:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:41:44 [INFO]   Training abgeschlossen in 19.20s (Backend: cuml)\n",
      "11:42:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:42:45 [INFO]   Training abgeschlossen in 19.44s (Backend: cuml)\n",
      "11:43:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:43:46 [INFO]   Training abgeschlossen in 19.53s (Backend: cuml)\n",
      "11:44:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:44:46 [INFO]   Training abgeschlossen in 19.83s (Backend: cuml)\n",
      "11:45:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:45:46 [INFO]   Training abgeschlossen in 20.13s (Backend: cuml)\n",
      "11:46:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:46:46 [INFO]   Training abgeschlossen in 20.20s (Backend: cuml)\n",
      "11:47:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:47:45 [INFO]   Training abgeschlossen in 20.49s (Backend: cuml)\n",
      "11:48:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:48:44 [INFO]   Training abgeschlossen in 20.65s (Backend: cuml)\n",
      "11:49:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:49:43 [INFO]   Training abgeschlossen in 21.04s (Backend: cuml)\n",
      "11:50:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:50:41 [INFO]   Training abgeschlossen in 21.26s (Backend: cuml)\n",
      "11:51:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:51:40 [INFO]   Training abgeschlossen in 21.45s (Backend: cuml)\n",
      "11:52:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:52:37 [INFO]   Training abgeschlossen in 21.52s (Backend: cuml)\n",
      "11:53:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:53:35 [INFO]   Training abgeschlossen in 21.79s (Backend: cuml)\n",
      "11:54:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:54:32 [INFO]   Training abgeschlossen in 21.86s (Backend: cuml)\n",
      "11:55:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:55:29 [INFO]   Training abgeschlossen in 22.13s (Backend: cuml)\n",
      "11:56:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:56:25 [INFO]   Training abgeschlossen in 22.23s (Backend: cuml)\n",
      "11:56:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:57:22 [INFO]   Training abgeschlossen in 22.45s (Backend: cuml)\n",
      "11:57:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:58:18 [INFO]   Training abgeschlossen in 22.70s (Backend: cuml)\n",
      "11:58:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:59:13 [INFO]   Training abgeschlossen in 22.83s (Backend: cuml)\n",
      "11:59:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:00:08 [INFO]   Training abgeschlossen in 23.07s (Backend: cuml)\n",
      "12:00:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:01:03 [INFO]   Training abgeschlossen in 23.28s (Backend: cuml)\n",
      "12:01:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:01:57 [INFO]   Training abgeschlossen in 23.51s (Backend: cuml)\n",
      "12:02:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:02:52 [INFO]   Training abgeschlossen in 23.81s (Backend: cuml)\n",
      "12:03:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:03:46 [INFO]   Training abgeschlossen in 23.93s (Backend: cuml)\n",
      "12:04:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:04:39 [INFO]   Training abgeschlossen in 24.15s (Backend: cuml)\n",
      "12:05:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:05:32 [INFO]   Training abgeschlossen in 24.38s (Backend: cuml)\n",
      "12:06:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:06:25 [INFO]   Training abgeschlossen in 24.62s (Backend: cuml)\n",
      "12:06:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:07:18 [INFO]   Training abgeschlossen in 24.69s (Backend: cuml)\n",
      "12:07:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:08:10 [INFO]   Training abgeschlossen in 24.90s (Backend: cuml)\n",
      "12:08:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:09:02 [INFO]   Training abgeschlossen in 25.27s (Backend: cuml)\n",
      "12:09:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:09:53 [INFO]   Training abgeschlossen in 25.37s (Backend: cuml)\n",
      "12:10:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:10:44 [INFO]   Training abgeschlossen in 25.71s (Backend: cuml)\n",
      "12:11:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:11:35 [INFO]   Training abgeschlossen in 25.94s (Backend: cuml)\n",
      "12:11:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:12:25 [INFO]   Training abgeschlossen in 26.20s (Backend: cuml)\n",
      "12:12:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:13:27 [INFO]   Training abgeschlossen in 37.45s (Backend: cuml)\n",
      "12:13:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:14:30 [INFO]   Training abgeschlossen in 40.30s (Backend: cuml)\n",
      "12:14:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:15:34 [INFO]   Training abgeschlossen in 41.18s (Backend: cuml)\n",
      "12:15:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:16:38 [INFO]   Training abgeschlossen in 41.37s (Backend: cuml)\n",
      "12:16:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:17:39 [INFO]   Training abgeschlossen in 40.09s (Backend: cuml)\n",
      "12:18:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:18:42 [INFO]   Training abgeschlossen in 42.20s (Backend: cuml)\n",
      "12:19:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:19:44 [INFO]   Training abgeschlossen in 41.84s (Backend: cuml)\n",
      "12:20:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:20:45 [INFO]   Training abgeschlossen in 40.82s (Backend: cuml)\n",
      "12:21:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:21:44 [INFO]   Training abgeschlossen in 39.72s (Backend: cuml)\n",
      "12:22:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:22:45 [INFO]   Training abgeschlossen in 42.54s (Backend: cuml)\n",
      "12:23:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:23:45 [INFO]   Training abgeschlossen in 41.35s (Backend: cuml)\n",
      "12:24:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:24:46 [INFO]   Training abgeschlossen in 43.93s (Backend: cuml)\n",
      "12:25:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:25:44 [INFO]   Training abgeschlossen in 41.07s (Backend: cuml)\n",
      "12:26:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:26:44 [INFO]   Training abgeschlossen in 42.95s (Backend: cuml)\n",
      "12:27:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:27:41 [INFO]   Training abgeschlossen in 40.91s (Backend: cuml)\n",
      "12:27:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:28:38 [INFO]   Training abgeschlossen in 41.80s (Backend: cuml)\n",
      "12:28:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:29:37 [INFO]   Training abgeschlossen in 43.73s (Backend: cuml)\n",
      "12:29:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:30:34 [INFO]   Training abgeschlossen in 42.90s (Backend: cuml)\n",
      "12:30:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:31:30 [INFO]   Training abgeschlossen in 42.91s (Backend: cuml)\n",
      "12:31:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:32:28 [INFO]   Training abgeschlossen in 44.73s (Backend: cuml)\n",
      "12:32:40 [INFO]     60,000 labeled → Accuracy: 0.9672 (Train: 44.8s, Query: 0.68s) | GPU: 2.8/8.0 GB\n",
      "12:32:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:33:24 [INFO]   Training abgeschlossen in 43.10s (Backend: cuml)\n",
      "12:33:35 [INFO]     Final: 60,000 labeled → Accuracy: 0.9671, F1: 0.9668\n",
      "12:33:36 [INFO]   Run 3/5\n",
      "12:33:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:33:41 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "12:34:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "12:34:52 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "12:35:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "12:36:04 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "12:37:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "12:37:15 [INFO]   Training abgeschlossen in 5.08s (Backend: cuml)\n",
      "12:38:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "12:38:27 [INFO]   Training abgeschlossen in 5.24s (Backend: cuml)\n",
      "12:39:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:39:40 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "12:40:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:40:53 [INFO]   Training abgeschlossen in 5.88s (Backend: cuml)\n",
      "12:41:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:42:06 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "12:43:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:43:19 [INFO]   Training abgeschlossen in 6.78s (Backend: cuml)\n",
      "12:44:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:44:33 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "12:45:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:45:47 [INFO]   Training abgeschlossen in 7.78s (Backend: cuml)\n",
      "12:46:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:47:02 [INFO]   Training abgeschlossen in 7.91s (Backend: cuml)\n",
      "12:48:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:48:16 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "12:49:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:49:31 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "12:50:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:50:46 [INFO]   Training abgeschlossen in 8.66s (Backend: cuml)\n",
      "12:51:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:52:00 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "12:53:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:53:14 [INFO]   Training abgeschlossen in 8.92s (Backend: cuml)\n",
      "12:54:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:54:28 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "12:55:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:55:41 [INFO]   Training abgeschlossen in 9.42s (Backend: cuml)\n",
      "12:56:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:56:55 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "12:57:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:58:08 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "12:59:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:59:22 [INFO]   Training abgeschlossen in 10.04s (Backend: cuml)\n",
      "13:00:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:00:36 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "13:01:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:01:50 [INFO]   Training abgeschlossen in 10.60s (Backend: cuml)\n",
      "13:02:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:03:02 [INFO]   Training abgeschlossen in 10.75s (Backend: cuml)\n",
      "13:04:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:04:15 [INFO]   Training abgeschlossen in 10.95s (Backend: cuml)\n",
      "13:05:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:05:27 [INFO]   Training abgeschlossen in 11.25s (Backend: cuml)\n",
      "13:06:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:06:39 [INFO]   Training abgeschlossen in 11.35s (Backend: cuml)\n",
      "13:07:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:07:51 [INFO]   Training abgeschlossen in 11.57s (Backend: cuml)\n",
      "13:08:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:09:02 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "13:10:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:10:13 [INFO]   Training abgeschlossen in 12.00s (Backend: cuml)\n",
      "13:11:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:11:24 [INFO]   Training abgeschlossen in 12.30s (Backend: cuml)\n",
      "13:12:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:12:35 [INFO]   Training abgeschlossen in 12.39s (Backend: cuml)\n",
      "13:13:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:13:46 [INFO]   Training abgeschlossen in 12.74s (Backend: cuml)\n",
      "13:14:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:14:56 [INFO]   Training abgeschlossen in 12.87s (Backend: cuml)\n",
      "13:15:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:16:06 [INFO]   Training abgeschlossen in 13.03s (Backend: cuml)\n",
      "13:17:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:17:16 [INFO]   Training abgeschlossen in 13.25s (Backend: cuml)\n",
      "13:18:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:18:26 [INFO]   Training abgeschlossen in 13.43s (Backend: cuml)\n",
      "13:19:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:19:35 [INFO]   Training abgeschlossen in 13.72s (Backend: cuml)\n",
      "13:20:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:20:44 [INFO]   Training abgeschlossen in 13.85s (Backend: cuml)\n",
      "13:21:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:21:53 [INFO]   Training abgeschlossen in 14.23s (Backend: cuml)\n",
      "13:22:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:23:02 [INFO]   Training abgeschlossen in 14.22s (Backend: cuml)\n",
      "13:23:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:24:11 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "13:25:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:25:20 [INFO]   Training abgeschlossen in 14.37s (Backend: cuml)\n",
      "13:26:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:26:27 [INFO]   Training abgeschlossen in 14.64s (Backend: cuml)\n",
      "13:27:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:27:34 [INFO]   Training abgeschlossen in 14.78s (Backend: cuml)\n",
      "13:28:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:28:41 [INFO]   Training abgeschlossen in 14.99s (Backend: cuml)\n",
      "13:29:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:29:47 [INFO]   Training abgeschlossen in 15.23s (Backend: cuml)\n",
      "13:30:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:30:53 [INFO]   Training abgeschlossen in 15.50s (Backend: cuml)\n",
      "13:31:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:31:59 [INFO]   Training abgeschlossen in 15.62s (Backend: cuml)\n",
      "13:32:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:33:05 [INFO]   Training abgeschlossen in 16.08s (Backend: cuml)\n",
      "13:33:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:34:11 [INFO]   Training abgeschlossen in 15.99s (Backend: cuml)\n",
      "13:35:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:35:17 [INFO]   Training abgeschlossen in 16.20s (Backend: cuml)\n",
      "13:36:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:36:22 [INFO]   Training abgeschlossen in 16.44s (Backend: cuml)\n",
      "13:37:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:37:27 [INFO]   Training abgeschlossen in 16.73s (Backend: cuml)\n",
      "13:38:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:38:32 [INFO]   Training abgeschlossen in 16.89s (Backend: cuml)\n",
      "13:39:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:39:37 [INFO]   Training abgeschlossen in 17.13s (Backend: cuml)\n",
      "13:40:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:40:41 [INFO]   Training abgeschlossen in 17.34s (Backend: cuml)\n",
      "13:41:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:41:45 [INFO]   Training abgeschlossen in 17.56s (Backend: cuml)\n",
      "13:42:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:42:48 [INFO]   Training abgeschlossen in 17.86s (Backend: cuml)\n",
      "13:43:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:43:51 [INFO]   Training abgeschlossen in 17.96s (Backend: cuml)\n",
      "13:44:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:44:53 [INFO]   Training abgeschlossen in 18.23s (Backend: cuml)\n",
      "13:45:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:45:55 [INFO]   Training abgeschlossen in 18.38s (Backend: cuml)\n",
      "13:46:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:46:57 [INFO]   Training abgeschlossen in 18.70s (Backend: cuml)\n",
      "13:47:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:47:58 [INFO]   Training abgeschlossen in 18.92s (Backend: cuml)\n",
      "13:48:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:48:59 [INFO]   Training abgeschlossen in 19.01s (Backend: cuml)\n",
      "13:49:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:50:00 [INFO]   Training abgeschlossen in 19.28s (Backend: cuml)\n",
      "13:50:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:51:00 [INFO]   Training abgeschlossen in 19.60s (Backend: cuml)\n",
      "13:51:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:52:01 [INFO]   Training abgeschlossen in 19.87s (Backend: cuml)\n",
      "13:52:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:53:01 [INFO]   Training abgeschlossen in 19.99s (Backend: cuml)\n",
      "13:53:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:54:00 [INFO]   Training abgeschlossen in 20.15s (Backend: cuml)\n",
      "13:54:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:54:59 [INFO]   Training abgeschlossen in 20.30s (Backend: cuml)\n",
      "13:55:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:55:58 [INFO]   Training abgeschlossen in 20.43s (Backend: cuml)\n",
      "13:56:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:56:57 [INFO]   Training abgeschlossen in 20.73s (Backend: cuml)\n",
      "13:57:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:57:55 [INFO]   Training abgeschlossen in 21.08s (Backend: cuml)\n",
      "13:58:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:58:53 [INFO]   Training abgeschlossen in 21.35s (Backend: cuml)\n",
      "13:59:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:59:51 [INFO]   Training abgeschlossen in 21.38s (Backend: cuml)\n",
      "14:00:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:00:48 [INFO]   Training abgeschlossen in 21.59s (Backend: cuml)\n",
      "14:01:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:01:45 [INFO]   Training abgeschlossen in 21.70s (Backend: cuml)\n",
      "14:02:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:02:42 [INFO]   Training abgeschlossen in 21.88s (Backend: cuml)\n",
      "14:03:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:03:38 [INFO]   Training abgeschlossen in 22.12s (Backend: cuml)\n",
      "14:04:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:04:34 [INFO]   Training abgeschlossen in 22.32s (Backend: cuml)\n",
      "14:05:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:05:30 [INFO]   Training abgeschlossen in 22.57s (Backend: cuml)\n",
      "14:06:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:06:25 [INFO]   Training abgeschlossen in 22.75s (Backend: cuml)\n",
      "14:06:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:07:20 [INFO]   Training abgeschlossen in 22.94s (Backend: cuml)\n",
      "14:07:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:08:14 [INFO]   Training abgeschlossen in 23.28s (Backend: cuml)\n",
      "14:08:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:09:09 [INFO]   Training abgeschlossen in 23.45s (Backend: cuml)\n",
      "14:09:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:10:03 [INFO]   Training abgeschlossen in 23.88s (Backend: cuml)\n",
      "14:10:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:10:57 [INFO]   Training abgeschlossen in 23.96s (Backend: cuml)\n",
      "14:11:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:11:51 [INFO]   Training abgeschlossen in 24.26s (Backend: cuml)\n",
      "14:12:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:12:44 [INFO]   Training abgeschlossen in 24.46s (Backend: cuml)\n",
      "14:13:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:13:37 [INFO]   Training abgeschlossen in 24.82s (Backend: cuml)\n",
      "14:14:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:14:30 [INFO]   Training abgeschlossen in 25.18s (Backend: cuml)\n",
      "14:14:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:15:23 [INFO]   Training abgeschlossen in 25.19s (Backend: cuml)\n",
      "14:15:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:16:15 [INFO]   Training abgeschlossen in 25.55s (Backend: cuml)\n",
      "14:16:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:17:06 [INFO]   Training abgeschlossen in 25.70s (Backend: cuml)\n",
      "14:17:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:17:58 [INFO]   Training abgeschlossen in 25.96s (Backend: cuml)\n",
      "14:18:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:18:49 [INFO]   Training abgeschlossen in 26.07s (Backend: cuml)\n",
      "14:19:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:19:39 [INFO]   Training abgeschlossen in 26.29s (Backend: cuml)\n",
      "14:20:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:20:43 [INFO]   Training abgeschlossen in 39.32s (Backend: cuml)\n",
      "14:21:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:21:46 [INFO]   Training abgeschlossen in 40.59s (Backend: cuml)\n",
      "14:22:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:22:51 [INFO]   Training abgeschlossen in 41.61s (Backend: cuml)\n",
      "14:23:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:23:54 [INFO]   Training abgeschlossen in 41.44s (Backend: cuml)\n",
      "14:24:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:24:55 [INFO]   Training abgeschlossen in 39.79s (Backend: cuml)\n",
      "14:25:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:25:58 [INFO]   Training abgeschlossen in 41.42s (Backend: cuml)\n",
      "14:26:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:26:59 [INFO]   Training abgeschlossen in 41.10s (Backend: cuml)\n",
      "14:27:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:27:59 [INFO]   Training abgeschlossen in 40.05s (Backend: cuml)\n",
      "14:28:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:29:00 [INFO]   Training abgeschlossen in 41.84s (Backend: cuml)\n",
      "14:29:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:30:00 [INFO]   Training abgeschlossen in 41.22s (Backend: cuml)\n",
      "14:30:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:30:59 [INFO]   Training abgeschlossen in 41.19s (Backend: cuml)\n",
      "14:31:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:31:59 [INFO]   Training abgeschlossen in 42.05s (Backend: cuml)\n",
      "14:32:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:32:57 [INFO]   Training abgeschlossen in 41.16s (Backend: cuml)\n",
      "14:33:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:33:55 [INFO]   Training abgeschlossen in 41.61s (Backend: cuml)\n",
      "14:34:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:34:54 [INFO]   Training abgeschlossen in 42.35s (Backend: cuml)\n",
      "14:35:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:35:51 [INFO]   Training abgeschlossen in 42.22s (Backend: cuml)\n",
      "14:36:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:36:50 [INFO]   Training abgeschlossen in 43.73s (Backend: cuml)\n",
      "14:37:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:37:48 [INFO]   Training abgeschlossen in 43.70s (Backend: cuml)\n",
      "14:38:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:38:48 [INFO]   Training abgeschlossen in 46.16s (Backend: cuml)\n",
      "14:39:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:39:45 [INFO]   Training abgeschlossen in 44.13s (Backend: cuml)\n",
      "14:39:57 [INFO]     60,000 labeled → Accuracy: 0.9672 (Train: 44.2s, Query: 0.67s) | GPU: 2.8/8.0 GB\n",
      "14:39:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:40:42 [INFO]   Training abgeschlossen in 44.63s (Backend: cuml)\n",
      "14:40:54 [INFO]     Final: 60,000 labeled → Accuracy: 0.9673, F1: 0.9671\n",
      "14:40:54 [INFO]   Run 4/5\n",
      "14:40:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:40:59 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "14:42:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:42:10 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "14:43:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:43:22 [INFO]   Training abgeschlossen in 4.94s (Backend: cuml)\n",
      "14:44:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:44:34 [INFO]   Training abgeschlossen in 5.23s (Backend: cuml)\n",
      "14:45:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:45:47 [INFO]   Training abgeschlossen in 5.37s (Backend: cuml)\n",
      "14:46:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:47:00 [INFO]   Training abgeschlossen in 5.74s (Backend: cuml)\n",
      "14:48:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:48:13 [INFO]   Training abgeschlossen in 6.08s (Backend: cuml)\n",
      "14:49:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:49:27 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "14:50:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:50:40 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "14:51:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:51:54 [INFO]   Training abgeschlossen in 7.26s (Backend: cuml)\n",
      "14:53:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:53:09 [INFO]   Training abgeschlossen in 7.83s (Backend: cuml)\n",
      "14:54:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:54:24 [INFO]   Training abgeschlossen in 7.94s (Backend: cuml)\n",
      "14:55:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:55:38 [INFO]   Training abgeschlossen in 8.15s (Backend: cuml)\n",
      "14:56:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:56:52 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "14:57:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:58:07 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "14:59:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:59:21 [INFO]   Training abgeschlossen in 8.81s (Backend: cuml)\n",
      "15:00:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:00:35 [INFO]   Training abgeschlossen in 9.19s (Backend: cuml)\n",
      "15:01:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:01:49 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "15:02:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:03:03 [INFO]   Training abgeschlossen in 9.53s (Backend: cuml)\n",
      "15:04:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:04:16 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "15:05:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:05:30 [INFO]   Training abgeschlossen in 10.00s (Backend: cuml)\n",
      "15:06:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:06:44 [INFO]   Training abgeschlossen in 10.23s (Backend: cuml)\n",
      "15:07:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:07:57 [INFO]   Training abgeschlossen in 10.37s (Backend: cuml)\n",
      "15:08:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:09:10 [INFO]   Training abgeschlossen in 10.58s (Backend: cuml)\n",
      "15:10:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:10:23 [INFO]   Training abgeschlossen in 10.81s (Backend: cuml)\n",
      "15:11:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:11:37 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "15:12:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:12:50 [INFO]   Training abgeschlossen in 11.12s (Backend: cuml)\n",
      "15:13:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:14:03 [INFO]   Training abgeschlossen in 11.37s (Backend: cuml)\n",
      "15:15:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:15:15 [INFO]   Training abgeschlossen in 11.72s (Backend: cuml)\n",
      "15:16:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:16:28 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "15:17:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:17:40 [INFO]   Training abgeschlossen in 11.96s (Backend: cuml)\n",
      "15:18:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:18:51 [INFO]   Training abgeschlossen in 12.20s (Backend: cuml)\n",
      "15:19:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:20:02 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "15:21:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:21:13 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "15:22:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:22:23 [INFO]   Training abgeschlossen in 12.95s (Backend: cuml)\n",
      "15:23:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:23:33 [INFO]   Training abgeschlossen in 13.06s (Backend: cuml)\n",
      "15:24:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:24:43 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "15:25:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:25:53 [INFO]   Training abgeschlossen in 13.40s (Backend: cuml)\n",
      "15:26:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:27:02 [INFO]   Training abgeschlossen in 13.62s (Backend: cuml)\n",
      "15:27:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:28:11 [INFO]   Training abgeschlossen in 13.95s (Backend: cuml)\n",
      "15:29:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:29:20 [INFO]   Training abgeschlossen in 14.25s (Backend: cuml)\n",
      "15:30:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:30:28 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "15:31:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:31:36 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "15:32:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:32:44 [INFO]   Training abgeschlossen in 14.39s (Backend: cuml)\n",
      "15:33:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:33:51 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "15:34:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:34:57 [INFO]   Training abgeschlossen in 14.87s (Backend: cuml)\n",
      "15:35:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:36:05 [INFO]   Training abgeschlossen in 15.22s (Backend: cuml)\n",
      "15:36:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:37:11 [INFO]   Training abgeschlossen in 15.33s (Backend: cuml)\n",
      "15:38:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:38:17 [INFO]   Training abgeschlossen in 15.44s (Backend: cuml)\n",
      "15:39:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:39:23 [INFO]   Training abgeschlossen in 15.63s (Backend: cuml)\n",
      "15:40:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:40:29 [INFO]   Training abgeschlossen in 16.09s (Backend: cuml)\n",
      "15:41:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:41:34 [INFO]   Training abgeschlossen in 16.08s (Backend: cuml)\n",
      "15:42:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:42:40 [INFO]   Training abgeschlossen in 16.49s (Backend: cuml)\n",
      "15:43:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:43:44 [INFO]   Training abgeschlossen in 16.62s (Backend: cuml)\n",
      "15:44:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:44:49 [INFO]   Training abgeschlossen in 16.82s (Backend: cuml)\n",
      "15:45:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:45:54 [INFO]   Training abgeschlossen in 17.04s (Backend: cuml)\n",
      "15:46:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:46:57 [INFO]   Training abgeschlossen in 17.10s (Backend: cuml)\n",
      "15:47:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:48:01 [INFO]   Training abgeschlossen in 17.37s (Backend: cuml)\n",
      "15:48:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:49:05 [INFO]   Training abgeschlossen in 17.63s (Backend: cuml)\n",
      "15:49:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:50:09 [INFO]   Training abgeschlossen in 18.04s (Backend: cuml)\n",
      "15:50:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:51:12 [INFO]   Training abgeschlossen in 18.17s (Backend: cuml)\n",
      "15:51:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:52:14 [INFO]   Training abgeschlossen in 18.40s (Backend: cuml)\n",
      "15:52:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:53:16 [INFO]   Training abgeschlossen in 18.56s (Backend: cuml)\n",
      "15:53:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:54:18 [INFO]   Training abgeschlossen in 18.83s (Backend: cuml)\n",
      "15:55:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:55:20 [INFO]   Training abgeschlossen in 18.89s (Backend: cuml)\n",
      "15:56:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:56:21 [INFO]   Training abgeschlossen in 19.03s (Backend: cuml)\n",
      "15:57:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:57:22 [INFO]   Training abgeschlossen in 19.39s (Backend: cuml)\n",
      "15:58:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:58:23 [INFO]   Training abgeschlossen in 19.58s (Backend: cuml)\n",
      "15:59:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:59:23 [INFO]   Training abgeschlossen in 19.84s (Backend: cuml)\n",
      "16:00:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:00:23 [INFO]   Training abgeschlossen in 20.08s (Backend: cuml)\n",
      "16:01:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:01:23 [INFO]   Training abgeschlossen in 20.25s (Backend: cuml)\n",
      "16:02:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:02:22 [INFO]   Training abgeschlossen in 20.46s (Backend: cuml)\n",
      "16:03:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:03:21 [INFO]   Training abgeschlossen in 20.62s (Backend: cuml)\n",
      "16:03:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:04:20 [INFO]   Training abgeschlossen in 20.89s (Backend: cuml)\n",
      "16:04:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:05:19 [INFO]   Training abgeschlossen in 21.24s (Backend: cuml)\n",
      "16:05:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:06:17 [INFO]   Training abgeschlossen in 21.43s (Backend: cuml)\n",
      "16:06:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:07:14 [INFO]   Training abgeschlossen in 21.41s (Backend: cuml)\n",
      "16:07:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:08:12 [INFO]   Training abgeschlossen in 21.77s (Backend: cuml)\n",
      "16:08:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:09:09 [INFO]   Training abgeschlossen in 21.85s (Backend: cuml)\n",
      "16:09:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:10:06 [INFO]   Training abgeschlossen in 22.12s (Backend: cuml)\n",
      "16:10:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:11:02 [INFO]   Training abgeschlossen in 22.37s (Backend: cuml)\n",
      "16:11:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:11:59 [INFO]   Training abgeschlossen in 22.50s (Backend: cuml)\n",
      "16:12:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:12:55 [INFO]   Training abgeschlossen in 22.73s (Backend: cuml)\n",
      "16:13:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:13:50 [INFO]   Training abgeschlossen in 22.94s (Backend: cuml)\n",
      "16:14:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:14:45 [INFO]   Training abgeschlossen in 23.12s (Backend: cuml)\n",
      "16:15:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:15:40 [INFO]   Training abgeschlossen in 23.36s (Backend: cuml)\n",
      "16:16:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:16:35 [INFO]   Training abgeschlossen in 23.66s (Backend: cuml)\n",
      "16:17:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:17:29 [INFO]   Training abgeschlossen in 23.79s (Backend: cuml)\n",
      "16:17:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:18:23 [INFO]   Training abgeschlossen in 23.84s (Backend: cuml)\n",
      "16:18:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:19:16 [INFO]   Training abgeschlossen in 24.23s (Backend: cuml)\n",
      "16:19:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:20:09 [INFO]   Training abgeschlossen in 24.36s (Backend: cuml)\n",
      "16:20:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:21:02 [INFO]   Training abgeschlossen in 24.55s (Backend: cuml)\n",
      "16:21:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:21:55 [INFO]   Training abgeschlossen in 24.78s (Backend: cuml)\n",
      "16:22:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:22:47 [INFO]   Training abgeschlossen in 25.06s (Backend: cuml)\n",
      "16:23:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:23:39 [INFO]   Training abgeschlossen in 25.15s (Backend: cuml)\n",
      "16:24:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:24:30 [INFO]   Training abgeschlossen in 25.33s (Backend: cuml)\n",
      "16:24:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:25:21 [INFO]   Training abgeschlossen in 25.75s (Backend: cuml)\n",
      "16:25:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:26:12 [INFO]   Training abgeschlossen in 25.92s (Backend: cuml)\n",
      "16:26:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:27:03 [INFO]   Training abgeschlossen in 26.20s (Backend: cuml)\n",
      "16:27:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:28:07 [INFO]   Training abgeschlossen in 40.92s (Backend: cuml)\n",
      "16:28:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:29:10 [INFO]   Training abgeschlossen in 40.00s (Backend: cuml)\n",
      "16:29:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:30:12 [INFO]   Training abgeschlossen in 38.89s (Backend: cuml)\n",
      "16:30:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:31:13 [INFO]   Training abgeschlossen in 39.18s (Backend: cuml)\n",
      "16:31:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:32:14 [INFO]   Training abgeschlossen in 39.62s (Backend: cuml)\n",
      "16:32:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:33:15 [INFO]   Training abgeschlossen in 40.18s (Backend: cuml)\n",
      "16:33:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:34:16 [INFO]   Training abgeschlossen in 40.49s (Backend: cuml)\n",
      "16:34:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:35:18 [INFO]   Training abgeschlossen in 42.01s (Backend: cuml)\n",
      "16:35:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:36:18 [INFO]   Training abgeschlossen in 41.34s (Backend: cuml)\n",
      "16:36:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:37:21 [INFO]   Training abgeschlossen in 43.96s (Backend: cuml)\n",
      "16:37:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:38:21 [INFO]   Training abgeschlossen in 41.35s (Backend: cuml)\n",
      "16:38:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:39:20 [INFO]   Training abgeschlossen in 41.88s (Backend: cuml)\n",
      "16:39:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:40:18 [INFO]   Training abgeschlossen in 41.07s (Backend: cuml)\n",
      "16:40:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:41:15 [INFO]   Training abgeschlossen in 40.28s (Backend: cuml)\n",
      "16:41:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:42:13 [INFO]   Training abgeschlossen in 41.47s (Backend: cuml)\n",
      "16:42:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:43:13 [INFO]   Training abgeschlossen in 44.34s (Backend: cuml)\n",
      "16:43:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:44:13 [INFO]   Training abgeschlossen in 45.94s (Backend: cuml)\n",
      "16:44:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:45:10 [INFO]   Training abgeschlossen in 41.73s (Backend: cuml)\n",
      "16:45:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:46:07 [INFO]   Training abgeschlossen in 43.73s (Backend: cuml)\n",
      "16:46:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:47:03 [INFO]   Training abgeschlossen in 43.37s (Backend: cuml)\n",
      "16:47:16 [INFO]     60,000 labeled → Accuracy: 0.9673 (Train: 43.4s, Query: 0.68s) | GPU: 2.8/8.0 GB\n",
      "16:47:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:48:00 [INFO]   Training abgeschlossen in 44.20s (Backend: cuml)\n",
      "16:48:12 [INFO]     Final: 60,000 labeled → Accuracy: 0.9673, F1: 0.9670\n",
      "16:48:12 [INFO]   Run 5/5\n",
      "16:48:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:48:17 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "16:49:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:49:29 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "16:50:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:50:41 [INFO]   Training abgeschlossen in 5.02s (Backend: cuml)\n",
      "16:51:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "16:51:52 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "16:52:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:53:05 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "16:54:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:54:18 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "16:55:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:55:31 [INFO]   Training abgeschlossen in 6.05s (Backend: cuml)\n",
      "16:56:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:56:44 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "16:57:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:57:58 [INFO]   Training abgeschlossen in 6.82s (Backend: cuml)\n",
      "16:59:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:59:12 [INFO]   Training abgeschlossen in 7.28s (Backend: cuml)\n",
      "17:00:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:00:26 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "17:01:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:01:41 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "17:02:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:02:55 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "17:04:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:04:09 [INFO]   Training abgeschlossen in 8.36s (Backend: cuml)\n",
      "17:05:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:05:23 [INFO]   Training abgeschlossen in 8.55s (Backend: cuml)\n",
      "17:06:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:06:37 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "17:07:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:07:52 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "17:08:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:09:06 [INFO]   Training abgeschlossen in 9.18s (Backend: cuml)\n",
      "17:10:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:10:19 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "17:11:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:11:33 [INFO]   Training abgeschlossen in 9.78s (Backend: cuml)\n",
      "17:12:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:12:46 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "17:13:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:13:59 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "17:15:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:15:14 [INFO]   Training abgeschlossen in 10.34s (Backend: cuml)\n",
      "17:16:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:16:27 [INFO]   Training abgeschlossen in 10.61s (Backend: cuml)\n",
      "17:17:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:17:40 [INFO]   Training abgeschlossen in 10.73s (Backend: cuml)\n",
      "17:18:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:18:52 [INFO]   Training abgeschlossen in 10.92s (Backend: cuml)\n",
      "17:19:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:20:05 [INFO]   Training abgeschlossen in 11.24s (Backend: cuml)\n",
      "17:21:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:21:19 [INFO]   Training abgeschlossen in 11.37s (Backend: cuml)\n",
      "17:22:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:22:31 [INFO]   Training abgeschlossen in 11.54s (Backend: cuml)\n",
      "17:23:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:23:44 [INFO]   Training abgeschlossen in 11.79s (Backend: cuml)\n",
      "17:24:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:24:56 [INFO]   Training abgeschlossen in 12.07s (Backend: cuml)\n",
      "17:25:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:26:08 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "17:27:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:27:20 [INFO]   Training abgeschlossen in 12.41s (Backend: cuml)\n",
      "17:28:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:28:30 [INFO]   Training abgeschlossen in 12.77s (Backend: cuml)\n",
      "17:29:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:29:41 [INFO]   Training abgeschlossen in 12.94s (Backend: cuml)\n",
      "17:30:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:30:52 [INFO]   Training abgeschlossen in 13.06s (Backend: cuml)\n",
      "17:31:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:32:03 [INFO]   Training abgeschlossen in 13.20s (Backend: cuml)\n",
      "17:33:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:33:13 [INFO]   Training abgeschlossen in 13.54s (Backend: cuml)\n",
      "17:34:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:34:24 [INFO]   Training abgeschlossen in 13.77s (Backend: cuml)\n",
      "17:35:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:35:34 [INFO]   Training abgeschlossen in 13.89s (Backend: cuml)\n",
      "17:36:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:36:43 [INFO]   Training abgeschlossen in 14.17s (Backend: cuml)\n",
      "17:37:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:37:53 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "17:38:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:39:02 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "17:39:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:40:11 [INFO]   Training abgeschlossen in 14.36s (Backend: cuml)\n",
      "17:41:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:41:18 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "17:42:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:42:25 [INFO]   Training abgeschlossen in 14.88s (Backend: cuml)\n",
      "17:43:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:43:31 [INFO]   Training abgeschlossen in 15.19s (Backend: cuml)\n",
      "17:44:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:44:38 [INFO]   Training abgeschlossen in 15.39s (Backend: cuml)\n",
      "17:45:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:45:44 [INFO]   Training abgeschlossen in 15.50s (Backend: cuml)\n",
      "17:46:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:46:50 [INFO]   Training abgeschlossen in 15.63s (Backend: cuml)\n",
      "17:47:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:47:56 [INFO]   Training abgeschlossen in 16.14s (Backend: cuml)\n",
      "17:48:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:49:02 [INFO]   Training abgeschlossen in 16.00s (Backend: cuml)\n",
      "17:49:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:50:08 [INFO]   Training abgeschlossen in 16.34s (Backend: cuml)\n",
      "17:50:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:51:14 [INFO]   Training abgeschlossen in 16.60s (Backend: cuml)\n",
      "17:52:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:52:19 [INFO]   Training abgeschlossen in 16.75s (Backend: cuml)\n",
      "17:53:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:53:24 [INFO]   Training abgeschlossen in 16.87s (Backend: cuml)\n",
      "17:54:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:54:29 [INFO]   Training abgeschlossen in 17.13s (Backend: cuml)\n",
      "17:55:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:55:33 [INFO]   Training abgeschlossen in 17.31s (Backend: cuml)\n",
      "17:56:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:56:37 [INFO]   Training abgeschlossen in 17.60s (Backend: cuml)\n",
      "17:57:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:57:41 [INFO]   Training abgeschlossen in 18.08s (Backend: cuml)\n",
      "17:58:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:58:44 [INFO]   Training abgeschlossen in 18.30s (Backend: cuml)\n",
      "17:59:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:59:46 [INFO]   Training abgeschlossen in 18.48s (Backend: cuml)\n",
      "18:00:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:00:49 [INFO]   Training abgeschlossen in 18.61s (Backend: cuml)\n",
      "18:01:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:01:51 [INFO]   Training abgeschlossen in 18.81s (Backend: cuml)\n",
      "18:02:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:02:52 [INFO]   Training abgeschlossen in 18.86s (Backend: cuml)\n",
      "18:03:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:03:53 [INFO]   Training abgeschlossen in 19.07s (Backend: cuml)\n",
      "18:04:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:04:54 [INFO]   Training abgeschlossen in 19.34s (Backend: cuml)\n",
      "18:05:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:05:55 [INFO]   Training abgeschlossen in 19.54s (Backend: cuml)\n",
      "18:06:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:06:55 [INFO]   Training abgeschlossen in 19.83s (Backend: cuml)\n",
      "18:07:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:07:56 [INFO]   Training abgeschlossen in 20.06s (Backend: cuml)\n",
      "18:08:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:08:55 [INFO]   Training abgeschlossen in 20.21s (Backend: cuml)\n",
      "18:09:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:09:55 [INFO]   Training abgeschlossen in 20.55s (Backend: cuml)\n",
      "18:10:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:10:54 [INFO]   Training abgeschlossen in 20.62s (Backend: cuml)\n",
      "18:11:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:11:53 [INFO]   Training abgeschlossen in 21.10s (Backend: cuml)\n",
      "18:12:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:12:51 [INFO]   Training abgeschlossen in 21.22s (Backend: cuml)\n",
      "18:13:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:13:50 [INFO]   Training abgeschlossen in 21.23s (Backend: cuml)\n",
      "18:14:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:14:47 [INFO]   Training abgeschlossen in 21.54s (Backend: cuml)\n",
      "18:15:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:15:45 [INFO]   Training abgeschlossen in 21.69s (Backend: cuml)\n",
      "18:16:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:16:42 [INFO]   Training abgeschlossen in 21.98s (Backend: cuml)\n",
      "18:17:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:17:40 [INFO]   Training abgeschlossen in 22.10s (Backend: cuml)\n",
      "18:18:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:18:36 [INFO]   Training abgeschlossen in 22.21s (Backend: cuml)\n",
      "18:19:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:19:33 [INFO]   Training abgeschlossen in 22.63s (Backend: cuml)\n",
      "18:20:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:20:29 [INFO]   Training abgeschlossen in 22.83s (Backend: cuml)\n",
      "18:21:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:21:24 [INFO]   Training abgeschlossen in 22.95s (Backend: cuml)\n",
      "18:21:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:22:19 [INFO]   Training abgeschlossen in 23.13s (Backend: cuml)\n",
      "18:22:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:23:14 [INFO]   Training abgeschlossen in 23.42s (Backend: cuml)\n",
      "18:23:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:24:09 [INFO]   Training abgeschlossen in 23.75s (Backend: cuml)\n",
      "18:24:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:25:04 [INFO]   Training abgeschlossen in 23.99s (Backend: cuml)\n",
      "18:25:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:25:58 [INFO]   Training abgeschlossen in 24.05s (Backend: cuml)\n",
      "18:26:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:26:52 [INFO]   Training abgeschlossen in 24.36s (Backend: cuml)\n",
      "18:27:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:27:45 [INFO]   Training abgeschlossen in 24.60s (Backend: cuml)\n",
      "18:28:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:28:38 [INFO]   Training abgeschlossen in 24.66s (Backend: cuml)\n",
      "18:29:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:29:30 [INFO]   Training abgeschlossen in 24.89s (Backend: cuml)\n",
      "18:29:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:30:22 [INFO]   Training abgeschlossen in 24.92s (Backend: cuml)\n",
      "18:30:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:31:14 [INFO]   Training abgeschlossen in 25.29s (Backend: cuml)\n",
      "18:31:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:32:06 [INFO]   Training abgeschlossen in 25.43s (Backend: cuml)\n",
      "18:32:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:32:57 [INFO]   Training abgeschlossen in 25.60s (Backend: cuml)\n",
      "18:33:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:33:47 [INFO]   Training abgeschlossen in 25.95s (Backend: cuml)\n",
      "18:34:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:34:38 [INFO]   Training abgeschlossen in 26.13s (Backend: cuml)\n",
      "18:35:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:35:43 [INFO]   Training abgeschlossen in 41.43s (Backend: cuml)\n",
      "18:36:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:36:46 [INFO]   Training abgeschlossen in 39.70s (Backend: cuml)\n",
      "18:37:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:37:48 [INFO]   Training abgeschlossen in 39.07s (Backend: cuml)\n",
      "18:38:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:38:50 [INFO]   Training abgeschlossen in 39.95s (Backend: cuml)\n",
      "18:39:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:39:50 [INFO]   Training abgeschlossen in 39.20s (Backend: cuml)\n",
      "18:40:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:40:52 [INFO]   Training abgeschlossen in 41.06s (Backend: cuml)\n",
      "18:41:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:41:55 [INFO]   Training abgeschlossen in 42.80s (Backend: cuml)\n",
      "18:42:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:42:56 [INFO]   Training abgeschlossen in 41.18s (Backend: cuml)\n",
      "18:43:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:43:57 [INFO]   Training abgeschlossen in 41.36s (Backend: cuml)\n",
      "18:44:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:44:58 [INFO]   Training abgeschlossen in 42.09s (Backend: cuml)\n",
      "18:45:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:45:59 [INFO]   Training abgeschlossen in 42.85s (Backend: cuml)\n",
      "18:46:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:47:00 [INFO]   Training abgeschlossen in 43.52s (Backend: cuml)\n",
      "18:47:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:47:59 [INFO]   Training abgeschlossen in 42.81s (Backend: cuml)\n",
      "18:48:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:48:58 [INFO]   Training abgeschlossen in 42.03s (Backend: cuml)\n",
      "18:49:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:49:57 [INFO]   Training abgeschlossen in 42.82s (Backend: cuml)\n",
      "18:50:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:50:55 [INFO]   Training abgeschlossen in 42.96s (Backend: cuml)\n",
      "18:51:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:51:54 [INFO]   Training abgeschlossen in 43.60s (Backend: cuml)\n",
      "18:52:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:52:51 [INFO]   Training abgeschlossen in 42.96s (Backend: cuml)\n",
      "18:53:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:53:49 [INFO]   Training abgeschlossen in 44.22s (Backend: cuml)\n",
      "18:54:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:54:46 [INFO]   Training abgeschlossen in 44.09s (Backend: cuml)\n",
      "18:54:58 [INFO]     60,000 labeled → Accuracy: 0.9671 (Train: 44.1s, Query: 0.68s) | GPU: 2.8/8.0 GB\n",
      "18:54:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:55:43 [INFO]   Training abgeschlossen in 44.36s (Backend: cuml)\n",
      "18:55:55 [INFO]     Final: 60,000 labeled → Accuracy: 0.9672, F1: 0.9670\n",
      "\n",
      "============================================================\n",
      "Strategie: Least Confidence\n",
      "============================================================\n",
      "18:55:55 [INFO] \n",
      "GPU-SVM + Least Confidence - Budget: 20% (12,000 Samples)\n",
      "18:55:55 [INFO]   Run 1/5\n",
      "18:55:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 0.1/8.0 GB)\n",
      "18:56:00 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "18:57:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:57:11 [INFO]   Training abgeschlossen in 5.01s (Backend: cuml)\n",
      "18:58:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:58:23 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "18:59:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "18:59:35 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "19:00:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:00:48 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "19:01:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:02:01 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "19:03:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:03:14 [INFO]   Training abgeschlossen in 5.81s (Backend: cuml)\n",
      "19:04:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:04:27 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "19:05:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:05:41 [INFO]   Training abgeschlossen in 6.90s (Backend: cuml)\n",
      "19:06:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:06:55 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "19:08:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:08:09 [INFO]   Training abgeschlossen in 7.58s (Backend: cuml)\n",
      "19:09:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:09:24 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "19:10:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:10:39 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "19:11:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:11:53 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "19:12:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:13:07 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "19:14:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:14:22 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "19:15:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:15:36 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "19:16:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:16:50 [INFO]   Training abgeschlossen in 9.16s (Backend: cuml)\n",
      "19:17:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:18:03 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "19:19:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:19:17 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "19:20:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:20:31 [INFO]   Training abgeschlossen in 9.89s (Backend: cuml)\n",
      "19:21:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:21:44 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "19:22:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:22:58 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "19:24:00 [INFO]     12,000 labeled → Accuracy: 0.9673 (Train: 10.3s, Query: 51.19s) | GPU: 2.6/8.0 GB\n",
      "19:24:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:24:10 [INFO]   Training abgeschlossen in 10.44s (Backend: cuml)\n",
      "19:24:21 [INFO]     Final: 12,000 labeled → Accuracy: 0.9675, F1: 0.9672\n",
      "19:24:21 [INFO]   Run 2/5\n",
      "19:24:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:24:26 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "19:25:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:25:38 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "19:26:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:26:49 [INFO]   Training abgeschlossen in 5.04s (Backend: cuml)\n",
      "19:27:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:28:01 [INFO]   Training abgeschlossen in 5.24s (Backend: cuml)\n",
      "19:29:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:29:14 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "19:30:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:30:27 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "19:31:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:31:40 [INFO]   Training abgeschlossen in 6.05s (Backend: cuml)\n",
      "19:32:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:32:54 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "19:34:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:34:07 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "19:35:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:35:22 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "19:36:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:36:36 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "19:37:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:37:51 [INFO]   Training abgeschlossen in 7.91s (Backend: cuml)\n",
      "19:38:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:39:06 [INFO]   Training abgeschlossen in 8.19s (Backend: cuml)\n",
      "19:40:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:40:20 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "19:41:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:41:34 [INFO]   Training abgeschlossen in 8.55s (Backend: cuml)\n",
      "19:42:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:42:49 [INFO]   Training abgeschlossen in 8.75s (Backend: cuml)\n",
      "19:43:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:44:03 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "19:45:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:45:17 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "19:46:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:46:31 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "19:47:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:47:44 [INFO]   Training abgeschlossen in 9.62s (Backend: cuml)\n",
      "19:48:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:48:58 [INFO]   Training abgeschlossen in 9.84s (Backend: cuml)\n",
      "19:50:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:50:11 [INFO]   Training abgeschlossen in 10.06s (Backend: cuml)\n",
      "19:51:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:51:25 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "19:52:27 [INFO]     12,000 labeled → Accuracy: 0.9672 (Train: 10.3s, Query: 51.20s) | GPU: 2.6/8.0 GB\n",
      "19:52:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:52:38 [INFO]   Training abgeschlossen in 10.56s (Backend: cuml)\n",
      "19:52:49 [INFO]     Final: 12,000 labeled → Accuracy: 0.9674, F1: 0.9671\n",
      "19:52:49 [INFO]   Run 3/5\n",
      "19:52:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:52:54 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "19:54:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:54:05 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "19:55:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:55:17 [INFO]   Training abgeschlossen in 5.02s (Backend: cuml)\n",
      "19:56:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:56:29 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "19:57:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:57:41 [INFO]   Training abgeschlossen in 5.37s (Backend: cuml)\n",
      "19:58:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:58:54 [INFO]   Training abgeschlossen in 5.75s (Backend: cuml)\n",
      "20:00:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:00:07 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "20:01:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:01:20 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "20:02:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:02:34 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "20:03:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:03:48 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "20:04:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:05:02 [INFO]   Training abgeschlossen in 7.58s (Backend: cuml)\n",
      "20:06:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:06:17 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "20:07:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:07:31 [INFO]   Training abgeschlossen in 8.13s (Backend: cuml)\n",
      "20:08:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:08:45 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "20:09:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:09:59 [INFO]   Training abgeschlossen in 8.67s (Backend: cuml)\n",
      "20:11:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:11:14 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "20:12:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:12:28 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "20:13:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:13:42 [INFO]   Training abgeschlossen in 9.26s (Backend: cuml)\n",
      "20:14:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:14:56 [INFO]   Training abgeschlossen in 9.42s (Backend: cuml)\n",
      "20:15:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:16:09 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "20:17:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:17:22 [INFO]   Training abgeschlossen in 9.90s (Backend: cuml)\n",
      "20:18:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:18:36 [INFO]   Training abgeschlossen in 10.12s (Backend: cuml)\n",
      "20:19:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:19:50 [INFO]   Training abgeschlossen in 10.58s (Backend: cuml)\n",
      "20:20:53 [INFO]     12,000 labeled → Accuracy: 0.9666 (Train: 10.6s, Query: 52.14s) | GPU: 2.6/8.0 GB\n",
      "20:20:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:21:03 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "20:21:14 [INFO]     Final: 12,000 labeled → Accuracy: 0.9665, F1: 0.9662\n",
      "20:21:14 [INFO]   Run 4/5\n",
      "20:21:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:21:19 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "20:22:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:22:31 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "20:23:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:23:42 [INFO]   Training abgeschlossen in 5.06s (Backend: cuml)\n",
      "20:24:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:24:54 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "20:26:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:26:07 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "20:27:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:27:20 [INFO]   Training abgeschlossen in 5.61s (Backend: cuml)\n",
      "20:28:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:28:34 [INFO]   Training abgeschlossen in 5.97s (Backend: cuml)\n",
      "20:29:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:29:47 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "20:30:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:31:00 [INFO]   Training abgeschlossen in 6.77s (Backend: cuml)\n",
      "20:32:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:32:14 [INFO]   Training abgeschlossen in 7.32s (Backend: cuml)\n",
      "20:33:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:33:29 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "20:34:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:34:44 [INFO]   Training abgeschlossen in 7.92s (Backend: cuml)\n",
      "20:35:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:35:58 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "20:37:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:37:12 [INFO]   Training abgeschlossen in 8.37s (Backend: cuml)\n",
      "20:38:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:38:27 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "20:39:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:39:41 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "20:40:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:40:55 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "20:42:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:42:09 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "20:43:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:43:23 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "20:44:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:44:36 [INFO]   Training abgeschlossen in 9.60s (Backend: cuml)\n",
      "20:45:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:45:50 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "20:46:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:47:03 [INFO]   Training abgeschlossen in 10.23s (Backend: cuml)\n",
      "20:48:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:48:18 [INFO]   Training abgeschlossen in 10.30s (Backend: cuml)\n",
      "20:49:21 [INFO]     12,000 labeled → Accuracy: 0.9685 (Train: 10.3s, Query: 52.15s) | GPU: 2.6/8.0 GB\n",
      "20:49:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:49:31 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "20:49:42 [INFO]     Final: 12,000 labeled → Accuracy: 0.9683, F1: 0.9679\n",
      "20:49:42 [INFO]   Run 5/5\n",
      "20:49:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:49:47 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "20:50:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:50:59 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "20:52:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:52:10 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "20:53:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "20:53:22 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "20:54:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:54:35 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "20:55:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:55:48 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "20:56:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:57:01 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "20:58:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:58:14 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "20:59:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:59:28 [INFO]   Training abgeschlossen in 6.92s (Backend: cuml)\n",
      "21:00:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:00:41 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "21:01:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:01:56 [INFO]   Training abgeschlossen in 7.69s (Backend: cuml)\n",
      "21:03:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:03:11 [INFO]   Training abgeschlossen in 7.91s (Backend: cuml)\n",
      "21:04:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:04:25 [INFO]   Training abgeschlossen in 8.19s (Backend: cuml)\n",
      "21:05:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:05:39 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "21:06:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:06:53 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "21:07:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:08:08 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "21:09:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:09:22 [INFO]   Training abgeschlossen in 9.04s (Backend: cuml)\n",
      "21:10:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:10:36 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "21:11:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:11:50 [INFO]   Training abgeschlossen in 9.50s (Backend: cuml)\n",
      "21:12:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:13:03 [INFO]   Training abgeschlossen in 9.60s (Backend: cuml)\n",
      "21:14:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:14:16 [INFO]   Training abgeschlossen in 9.83s (Backend: cuml)\n",
      "21:15:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:15:30 [INFO]   Training abgeschlossen in 10.20s (Backend: cuml)\n",
      "21:16:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:16:43 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "21:17:45 [INFO]     12,000 labeled → Accuracy: 0.9689 (Train: 10.3s, Query: 51.16s) | GPU: 2.6/8.0 GB\n",
      "21:17:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:17:56 [INFO]   Training abgeschlossen in 10.51s (Backend: cuml)\n",
      "21:18:07 [INFO]     Final: 12,000 labeled → Accuracy: 0.9688, F1: 0.9685\n",
      "21:18:07 [INFO] \n",
      "GPU-SVM + Least Confidence - Budget: 40% (24,000 Samples)\n",
      "21:18:07 [INFO]   Run 1/5\n",
      "21:18:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:18:12 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "21:19:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:19:23 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "21:20:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:20:35 [INFO]   Training abgeschlossen in 5.05s (Backend: cuml)\n",
      "21:21:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:21:47 [INFO]   Training abgeschlossen in 5.34s (Backend: cuml)\n",
      "21:22:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:23:00 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "21:24:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:24:13 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "21:25:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:25:26 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "21:26:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:26:39 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "21:27:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:27:53 [INFO]   Training abgeschlossen in 6.80s (Backend: cuml)\n",
      "21:28:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:29:06 [INFO]   Training abgeschlossen in 7.11s (Backend: cuml)\n",
      "21:30:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:30:21 [INFO]   Training abgeschlossen in 7.66s (Backend: cuml)\n",
      "21:31:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:31:35 [INFO]   Training abgeschlossen in 7.86s (Backend: cuml)\n",
      "21:32:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:32:50 [INFO]   Training abgeschlossen in 8.11s (Backend: cuml)\n",
      "21:33:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:34:04 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "21:35:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:35:18 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "21:36:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:36:33 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "21:37:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:37:47 [INFO]   Training abgeschlossen in 8.94s (Backend: cuml)\n",
      "21:38:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:39:01 [INFO]   Training abgeschlossen in 9.22s (Backend: cuml)\n",
      "21:40:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:40:14 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "21:41:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:41:28 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "21:42:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:42:42 [INFO]   Training abgeschlossen in 10.10s (Backend: cuml)\n",
      "21:43:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:43:56 [INFO]   Training abgeschlossen in 10.24s (Backend: cuml)\n",
      "21:44:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:45:09 [INFO]   Training abgeschlossen in 10.40s (Backend: cuml)\n",
      "21:46:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:46:22 [INFO]   Training abgeschlossen in 10.60s (Backend: cuml)\n",
      "21:47:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:47:35 [INFO]   Training abgeschlossen in 10.79s (Backend: cuml)\n",
      "21:48:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:48:47 [INFO]   Training abgeschlossen in 11.06s (Backend: cuml)\n",
      "21:49:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:50:00 [INFO]   Training abgeschlossen in 11.50s (Backend: cuml)\n",
      "21:51:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:51:12 [INFO]   Training abgeschlossen in 11.36s (Backend: cuml)\n",
      "21:52:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:52:24 [INFO]   Training abgeschlossen in 11.54s (Backend: cuml)\n",
      "21:53:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:53:36 [INFO]   Training abgeschlossen in 12.13s (Backend: cuml)\n",
      "21:54:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:54:47 [INFO]   Training abgeschlossen in 12.16s (Backend: cuml)\n",
      "21:55:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:55:58 [INFO]   Training abgeschlossen in 12.22s (Backend: cuml)\n",
      "21:56:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:57:09 [INFO]   Training abgeschlossen in 12.47s (Backend: cuml)\n",
      "21:58:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:58:19 [INFO]   Training abgeschlossen in 12.78s (Backend: cuml)\n",
      "21:59:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:59:29 [INFO]   Training abgeschlossen in 12.88s (Backend: cuml)\n",
      "22:00:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:00:39 [INFO]   Training abgeschlossen in 13.07s (Backend: cuml)\n",
      "22:01:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:01:49 [INFO]   Training abgeschlossen in 13.32s (Backend: cuml)\n",
      "22:02:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:02:59 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "22:03:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:04:09 [INFO]   Training abgeschlossen in 13.74s (Backend: cuml)\n",
      "22:05:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:05:19 [INFO]   Training abgeschlossen in 13.94s (Backend: cuml)\n",
      "22:06:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:06:29 [INFO]   Training abgeschlossen in 14.15s (Backend: cuml)\n",
      "22:07:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:07:38 [INFO]   Training abgeschlossen in 14.43s (Backend: cuml)\n",
      "22:08:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:08:48 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "22:09:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:09:55 [INFO]   Training abgeschlossen in 14.51s (Backend: cuml)\n",
      "22:10:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:11:03 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "22:11:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:12:10 [INFO]   Training abgeschlossen in 14.86s (Backend: cuml)\n",
      "22:13:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:13:17 [INFO]   Training abgeschlossen in 15.23s (Backend: cuml)\n",
      "22:14:08 [INFO]     24,000 labeled → Accuracy: 0.9679 (Train: 15.2s, Query: 39.87s) | GPU: 2.7/8.0 GB\n",
      "22:14:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:14:24 [INFO]   Training abgeschlossen in 15.40s (Backend: cuml)\n",
      "22:14:35 [INFO]     Final: 24,000 labeled → Accuracy: 0.9676, F1: 0.9673\n",
      "22:14:35 [INFO]   Run 2/5\n",
      "22:14:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:14:40 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "22:15:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:15:52 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "22:16:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:17:03 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "22:18:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "22:18:15 [INFO]   Training abgeschlossen in 5.28s (Backend: cuml)\n",
      "22:19:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:19:28 [INFO]   Training abgeschlossen in 5.54s (Backend: cuml)\n",
      "22:20:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:20:41 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "22:21:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:21:54 [INFO]   Training abgeschlossen in 6.05s (Backend: cuml)\n",
      "22:23:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:23:08 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "22:24:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:24:21 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "22:25:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:25:36 [INFO]   Training abgeschlossen in 7.31s (Backend: cuml)\n",
      "22:26:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:26:50 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "22:27:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:28:05 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "22:29:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:29:19 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "22:30:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:30:34 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "22:31:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:31:48 [INFO]   Training abgeschlossen in 8.55s (Backend: cuml)\n",
      "22:32:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:33:03 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "22:34:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:34:17 [INFO]   Training abgeschlossen in 9.08s (Backend: cuml)\n",
      "22:35:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:35:31 [INFO]   Training abgeschlossen in 9.18s (Backend: cuml)\n",
      "22:36:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:36:45 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "22:37:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:37:58 [INFO]   Training abgeschlossen in 9.88s (Backend: cuml)\n",
      "22:39:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:39:12 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "22:40:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:40:25 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "22:41:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:41:40 [INFO]   Training abgeschlossen in 10.39s (Backend: cuml)\n",
      "22:42:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:42:54 [INFO]   Training abgeschlossen in 10.59s (Backend: cuml)\n",
      "22:43:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:44:06 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "22:45:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:45:20 [INFO]   Training abgeschlossen in 11.01s (Backend: cuml)\n",
      "22:46:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:46:34 [INFO]   Training abgeschlossen in 11.47s (Backend: cuml)\n",
      "22:47:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:47:47 [INFO]   Training abgeschlossen in 11.43s (Backend: cuml)\n",
      "22:48:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:48:58 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "22:49:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:50:10 [INFO]   Training abgeschlossen in 11.81s (Backend: cuml)\n",
      "22:51:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:51:21 [INFO]   Training abgeschlossen in 12.08s (Backend: cuml)\n",
      "22:52:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:52:32 [INFO]   Training abgeschlossen in 12.21s (Backend: cuml)\n",
      "22:53:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:53:43 [INFO]   Training abgeschlossen in 12.45s (Backend: cuml)\n",
      "22:54:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:54:54 [INFO]   Training abgeschlossen in 12.68s (Backend: cuml)\n",
      "22:55:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:56:04 [INFO]   Training abgeschlossen in 12.95s (Backend: cuml)\n",
      "22:57:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:57:14 [INFO]   Training abgeschlossen in 13.06s (Backend: cuml)\n",
      "22:58:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:58:23 [INFO]   Training abgeschlossen in 13.24s (Backend: cuml)\n",
      "22:59:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:59:33 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "23:00:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:00:42 [INFO]   Training abgeschlossen in 13.79s (Backend: cuml)\n",
      "23:01:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:01:52 [INFO]   Training abgeschlossen in 13.96s (Backend: cuml)\n",
      "23:02:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:03:01 [INFO]   Training abgeschlossen in 14.19s (Backend: cuml)\n",
      "23:03:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:04:11 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "23:05:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:05:20 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "23:06:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:06:28 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "23:07:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:07:35 [INFO]   Training abgeschlossen in 14.70s (Backend: cuml)\n",
      "23:08:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:08:42 [INFO]   Training abgeschlossen in 14.96s (Backend: cuml)\n",
      "23:09:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:09:49 [INFO]   Training abgeschlossen in 15.11s (Backend: cuml)\n",
      "23:10:40 [INFO]     24,000 labeled → Accuracy: 0.9682 (Train: 15.1s, Query: 39.72s) | GPU: 2.7/8.0 GB\n",
      "23:10:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:10:56 [INFO]   Training abgeschlossen in 15.27s (Backend: cuml)\n",
      "23:11:07 [INFO]     Final: 24,000 labeled → Accuracy: 0.9680, F1: 0.9678\n",
      "23:11:07 [INFO]   Run 3/5\n",
      "23:11:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:11:12 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "23:12:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:12:23 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "23:13:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:13:35 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "23:14:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:14:47 [INFO]   Training abgeschlossen in 5.24s (Backend: cuml)\n",
      "23:15:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:16:00 [INFO]   Training abgeschlossen in 5.42s (Backend: cuml)\n",
      "23:17:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:17:13 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "23:18:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:18:26 [INFO]   Training abgeschlossen in 5.91s (Backend: cuml)\n",
      "23:19:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:19:39 [INFO]   Training abgeschlossen in 6.58s (Backend: cuml)\n",
      "23:20:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:20:53 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "23:22:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:22:07 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "23:23:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:23:21 [INFO]   Training abgeschlossen in 7.59s (Backend: cuml)\n",
      "23:24:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:24:36 [INFO]   Training abgeschlossen in 7.97s (Backend: cuml)\n",
      "23:25:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:25:50 [INFO]   Training abgeschlossen in 8.20s (Backend: cuml)\n",
      "23:26:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:27:04 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "23:28:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:28:19 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "23:29:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:29:34 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "23:30:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:30:48 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "23:31:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:32:03 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "23:33:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:33:17 [INFO]   Training abgeschlossen in 9.50s (Backend: cuml)\n",
      "23:34:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:34:31 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "23:35:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:35:44 [INFO]   Training abgeschlossen in 9.84s (Backend: cuml)\n",
      "23:36:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:36:57 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "23:38:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:38:10 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "23:39:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:39:23 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "23:40:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:40:36 [INFO]   Training abgeschlossen in 10.76s (Backend: cuml)\n",
      "23:41:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:41:48 [INFO]   Training abgeschlossen in 10.98s (Backend: cuml)\n",
      "23:42:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:43:01 [INFO]   Training abgeschlossen in 11.27s (Backend: cuml)\n",
      "23:44:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:44:14 [INFO]   Training abgeschlossen in 11.42s (Backend: cuml)\n",
      "23:45:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:45:26 [INFO]   Training abgeschlossen in 11.75s (Backend: cuml)\n",
      "23:46:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:46:37 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "23:47:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:47:49 [INFO]   Training abgeschlossen in 11.96s (Backend: cuml)\n",
      "23:48:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:49:00 [INFO]   Training abgeschlossen in 12.22s (Backend: cuml)\n",
      "23:49:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:50:11 [INFO]   Training abgeschlossen in 12.54s (Backend: cuml)\n",
      "23:51:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:51:21 [INFO]   Training abgeschlossen in 12.60s (Backend: cuml)\n",
      "23:52:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:52:32 [INFO]   Training abgeschlossen in 12.88s (Backend: cuml)\n",
      "23:53:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:53:42 [INFO]   Training abgeschlossen in 13.09s (Backend: cuml)\n",
      "23:54:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:54:52 [INFO]   Training abgeschlossen in 13.56s (Backend: cuml)\n",
      "23:55:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:56:02 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "23:56:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:57:11 [INFO]   Training abgeschlossen in 13.65s (Backend: cuml)\n",
      "23:58:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:58:21 [INFO]   Training abgeschlossen in 13.88s (Backend: cuml)\n",
      "23:59:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:59:30 [INFO]   Training abgeschlossen in 14.17s (Backend: cuml)\n",
      "00:00:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:00:38 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "00:01:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:01:47 [INFO]   Training abgeschlossen in 14.68s (Backend: cuml)\n",
      "00:02:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:02:55 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "00:03:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:04:02 [INFO]   Training abgeschlossen in 14.74s (Backend: cuml)\n",
      "00:04:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:05:09 [INFO]   Training abgeschlossen in 15.04s (Backend: cuml)\n",
      "00:06:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:06:16 [INFO]   Training abgeschlossen in 15.13s (Backend: cuml)\n",
      "00:07:09 [INFO]     24,000 labeled → Accuracy: 0.9681 (Train: 15.1s, Query: 40.85s) | GPU: 2.8/8.0 GB\n",
      "00:07:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:07:24 [INFO]   Training abgeschlossen in 15.28s (Backend: cuml)\n",
      "00:07:35 [INFO]     Final: 24,000 labeled → Accuracy: 0.9675, F1: 0.9673\n",
      "00:07:35 [INFO]   Run 4/5\n",
      "00:07:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:07:40 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "00:08:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "00:08:52 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "00:09:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "00:10:04 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "00:11:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "00:11:16 [INFO]   Training abgeschlossen in 5.16s (Backend: cuml)\n",
      "00:12:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:12:29 [INFO]   Training abgeschlossen in 5.53s (Backend: cuml)\n",
      "00:13:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:13:42 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "00:14:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:14:55 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "00:16:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:16:09 [INFO]   Training abgeschlossen in 6.33s (Backend: cuml)\n",
      "00:17:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:17:22 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "00:18:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:18:37 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "00:19:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:19:51 [INFO]   Training abgeschlossen in 7.57s (Backend: cuml)\n",
      "00:20:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:21:06 [INFO]   Training abgeschlossen in 7.91s (Backend: cuml)\n",
      "00:22:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:22:20 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "00:23:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:23:34 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "00:24:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:24:48 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "00:25:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:26:03 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "00:27:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:27:17 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "00:28:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:28:31 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "00:29:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:29:45 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "00:30:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:30:58 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "00:32:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:32:12 [INFO]   Training abgeschlossen in 9.87s (Backend: cuml)\n",
      "00:33:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:33:25 [INFO]   Training abgeschlossen in 10.19s (Backend: cuml)\n",
      "00:34:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:34:39 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "00:35:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:35:53 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "00:36:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:37:07 [INFO]   Training abgeschlossen in 10.81s (Backend: cuml)\n",
      "00:38:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:38:21 [INFO]   Training abgeschlossen in 11.02s (Backend: cuml)\n",
      "00:39:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:39:34 [INFO]   Training abgeschlossen in 11.20s (Backend: cuml)\n",
      "00:40:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:40:47 [INFO]   Training abgeschlossen in 11.38s (Backend: cuml)\n",
      "00:41:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:42:00 [INFO]   Training abgeschlossen in 11.72s (Backend: cuml)\n",
      "00:43:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:43:13 [INFO]   Training abgeschlossen in 11.87s (Backend: cuml)\n",
      "00:44:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:44:24 [INFO]   Training abgeschlossen in 12.00s (Backend: cuml)\n",
      "00:45:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:45:35 [INFO]   Training abgeschlossen in 12.43s (Backend: cuml)\n",
      "00:46:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:46:46 [INFO]   Training abgeschlossen in 12.60s (Backend: cuml)\n",
      "00:47:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:47:57 [INFO]   Training abgeschlossen in 12.64s (Backend: cuml)\n",
      "00:48:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:49:07 [INFO]   Training abgeschlossen in 12.89s (Backend: cuml)\n",
      "00:50:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:50:17 [INFO]   Training abgeschlossen in 13.14s (Backend: cuml)\n",
      "00:51:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:51:28 [INFO]   Training abgeschlossen in 13.54s (Backend: cuml)\n",
      "00:52:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:52:37 [INFO]   Training abgeschlossen in 13.48s (Backend: cuml)\n",
      "00:53:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:53:47 [INFO]   Training abgeschlossen in 13.66s (Backend: cuml)\n",
      "00:54:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:54:56 [INFO]   Training abgeschlossen in 13.95s (Backend: cuml)\n",
      "00:55:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:56:04 [INFO]   Training abgeschlossen in 14.18s (Backend: cuml)\n",
      "00:56:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:57:13 [INFO]   Training abgeschlossen in 14.39s (Backend: cuml)\n",
      "00:58:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:58:21 [INFO]   Training abgeschlossen in 14.61s (Backend: cuml)\n",
      "00:59:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:59:29 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "01:00:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:00:37 [INFO]   Training abgeschlossen in 14.74s (Backend: cuml)\n",
      "01:01:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:01:44 [INFO]   Training abgeschlossen in 14.99s (Backend: cuml)\n",
      "01:02:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:02:51 [INFO]   Training abgeschlossen in 15.08s (Backend: cuml)\n",
      "01:03:42 [INFO]     24,000 labeled → Accuracy: 0.9693 (Train: 15.1s, Query: 39.81s) | GPU: 2.7/8.0 GB\n",
      "01:03:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:03:58 [INFO]   Training abgeschlossen in 15.28s (Backend: cuml)\n",
      "01:04:09 [INFO]     Final: 24,000 labeled → Accuracy: 0.9693, F1: 0.9691\n",
      "01:04:09 [INFO]   Run 5/5\n",
      "01:04:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:04:14 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "01:05:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:05:26 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "01:06:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:06:37 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "01:07:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "01:07:49 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "01:08:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:09:02 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "01:10:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:10:15 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "01:11:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:11:28 [INFO]   Training abgeschlossen in 5.90s (Backend: cuml)\n",
      "01:12:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:12:41 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "01:13:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:13:55 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "01:15:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:15:09 [INFO]   Training abgeschlossen in 7.14s (Backend: cuml)\n",
      "01:16:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:16:24 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "01:17:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:17:38 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "01:18:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:18:52 [INFO]   Training abgeschlossen in 8.10s (Backend: cuml)\n",
      "01:19:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:20:07 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "01:21:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:21:21 [INFO]   Training abgeschlossen in 8.63s (Backend: cuml)\n",
      "01:22:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:22:36 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "01:23:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:23:50 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "01:24:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:25:04 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "01:26:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:26:18 [INFO]   Training abgeschlossen in 9.53s (Backend: cuml)\n",
      "01:27:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:27:31 [INFO]   Training abgeschlossen in 9.66s (Backend: cuml)\n",
      "01:28:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:28:45 [INFO]   Training abgeschlossen in 9.88s (Backend: cuml)\n",
      "01:29:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:29:58 [INFO]   Training abgeschlossen in 10.17s (Backend: cuml)\n",
      "01:31:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:31:12 [INFO]   Training abgeschlossen in 10.32s (Backend: cuml)\n",
      "01:32:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:32:24 [INFO]   Training abgeschlossen in 10.56s (Backend: cuml)\n",
      "01:33:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:33:37 [INFO]   Training abgeschlossen in 10.78s (Backend: cuml)\n",
      "01:34:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:34:50 [INFO]   Training abgeschlossen in 11.06s (Backend: cuml)\n",
      "01:35:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:36:02 [INFO]   Training abgeschlossen in 11.23s (Backend: cuml)\n",
      "01:37:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:37:14 [INFO]   Training abgeschlossen in 11.36s (Backend: cuml)\n",
      "01:38:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:38:26 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "01:39:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:39:37 [INFO]   Training abgeschlossen in 12.02s (Backend: cuml)\n",
      "01:40:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:40:49 [INFO]   Training abgeschlossen in 12.04s (Backend: cuml)\n",
      "01:41:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:42:00 [INFO]   Training abgeschlossen in 12.19s (Backend: cuml)\n",
      "01:42:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:43:11 [INFO]   Training abgeschlossen in 12.38s (Backend: cuml)\n",
      "01:44:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:44:22 [INFO]   Training abgeschlossen in 12.84s (Backend: cuml)\n",
      "01:45:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:45:32 [INFO]   Training abgeschlossen in 12.85s (Backend: cuml)\n",
      "01:46:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:46:41 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "01:47:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:47:51 [INFO]   Training abgeschlossen in 13.25s (Backend: cuml)\n",
      "01:48:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:49:01 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "01:49:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:50:10 [INFO]   Training abgeschlossen in 13.77s (Backend: cuml)\n",
      "01:51:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:51:19 [INFO]   Training abgeschlossen in 13.90s (Backend: cuml)\n",
      "01:52:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:52:28 [INFO]   Training abgeschlossen in 14.19s (Backend: cuml)\n",
      "01:53:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:53:37 [INFO]   Training abgeschlossen in 14.40s (Backend: cuml)\n",
      "01:54:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:54:45 [INFO]   Training abgeschlossen in 14.70s (Backend: cuml)\n",
      "01:55:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:55:53 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "01:56:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:57:00 [INFO]   Training abgeschlossen in 14.72s (Backend: cuml)\n",
      "01:57:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:58:08 [INFO]   Training abgeschlossen in 14.94s (Backend: cuml)\n",
      "01:58:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:59:14 [INFO]   Training abgeschlossen in 15.09s (Backend: cuml)\n",
      "02:00:05 [INFO]     24,000 labeled → Accuracy: 0.9672 (Train: 15.1s, Query: 39.76s) | GPU: 2.7/8.0 GB\n",
      "02:00:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:00:21 [INFO]   Training abgeschlossen in 15.32s (Backend: cuml)\n",
      "02:00:32 [INFO]     Final: 24,000 labeled → Accuracy: 0.9675, F1: 0.9672\n",
      "02:00:32 [INFO] \n",
      "GPU-SVM + Least Confidence - Budget: 60% (36,000 Samples)\n",
      "02:00:32 [INFO]   Run 1/5\n",
      "02:00:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:00:37 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "02:01:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:01:49 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "02:02:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:03:00 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "02:04:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:04:13 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "02:05:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:05:25 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "02:06:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:06:38 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "02:07:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:07:51 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "02:08:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:09:04 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "02:10:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:10:18 [INFO]   Training abgeschlossen in 6.92s (Backend: cuml)\n",
      "02:11:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:11:32 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "02:12:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:12:47 [INFO]   Training abgeschlossen in 7.67s (Backend: cuml)\n",
      "02:13:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:14:01 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "02:15:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:15:16 [INFO]   Training abgeschlossen in 8.13s (Backend: cuml)\n",
      "02:16:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:16:30 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "02:17:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:17:45 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "02:18:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:18:59 [INFO]   Training abgeschlossen in 8.75s (Backend: cuml)\n",
      "02:20:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:20:14 [INFO]   Training abgeschlossen in 9.16s (Backend: cuml)\n",
      "02:21:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:21:28 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "02:22:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:22:41 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "02:23:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:23:55 [INFO]   Training abgeschlossen in 9.75s (Backend: cuml)\n",
      "02:24:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:25:08 [INFO]   Training abgeschlossen in 9.94s (Backend: cuml)\n",
      "02:26:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:26:22 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "02:27:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:27:35 [INFO]   Training abgeschlossen in 10.37s (Backend: cuml)\n",
      "02:28:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:28:48 [INFO]   Training abgeschlossen in 10.66s (Backend: cuml)\n",
      "02:29:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:30:01 [INFO]   Training abgeschlossen in 10.72s (Backend: cuml)\n",
      "02:31:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:31:14 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "02:32:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:32:28 [INFO]   Training abgeschlossen in 11.32s (Backend: cuml)\n",
      "02:33:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:33:41 [INFO]   Training abgeschlossen in 11.47s (Backend: cuml)\n",
      "02:34:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:34:54 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "02:35:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:36:06 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "02:37:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:37:18 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "02:38:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:38:29 [INFO]   Training abgeschlossen in 12.25s (Backend: cuml)\n",
      "02:39:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:39:40 [INFO]   Training abgeschlossen in 12.44s (Backend: cuml)\n",
      "02:40:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:40:50 [INFO]   Training abgeschlossen in 12.69s (Backend: cuml)\n",
      "02:41:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:42:00 [INFO]   Training abgeschlossen in 12.95s (Backend: cuml)\n",
      "02:42:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:43:10 [INFO]   Training abgeschlossen in 13.14s (Backend: cuml)\n",
      "02:44:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:44:20 [INFO]   Training abgeschlossen in 13.26s (Backend: cuml)\n",
      "02:45:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:45:30 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "02:46:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:46:39 [INFO]   Training abgeschlossen in 13.70s (Backend: cuml)\n",
      "02:47:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:47:49 [INFO]   Training abgeschlossen in 14.13s (Backend: cuml)\n",
      "02:48:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:48:57 [INFO]   Training abgeschlossen in 14.12s (Backend: cuml)\n",
      "02:49:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:50:06 [INFO]   Training abgeschlossen in 14.30s (Backend: cuml)\n",
      "02:51:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:51:14 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "02:52:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:52:22 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "02:53:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:53:30 [INFO]   Training abgeschlossen in 14.82s (Backend: cuml)\n",
      "02:54:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:54:37 [INFO]   Training abgeschlossen in 14.97s (Backend: cuml)\n",
      "02:55:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:55:44 [INFO]   Training abgeschlossen in 15.13s (Backend: cuml)\n",
      "02:56:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:56:50 [INFO]   Training abgeschlossen in 15.34s (Backend: cuml)\n",
      "02:57:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:57:57 [INFO]   Training abgeschlossen in 15.50s (Backend: cuml)\n",
      "02:58:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:59:03 [INFO]   Training abgeschlossen in 15.80s (Backend: cuml)\n",
      "02:59:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:00:09 [INFO]   Training abgeschlossen in 16.32s (Backend: cuml)\n",
      "03:00:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:01:15 [INFO]   Training abgeschlossen in 16.14s (Backend: cuml)\n",
      "03:02:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:02:20 [INFO]   Training abgeschlossen in 16.33s (Backend: cuml)\n",
      "03:03:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:03:25 [INFO]   Training abgeschlossen in 16.61s (Backend: cuml)\n",
      "03:04:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:04:31 [INFO]   Training abgeschlossen in 16.92s (Backend: cuml)\n",
      "03:05:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:05:36 [INFO]   Training abgeschlossen in 17.09s (Backend: cuml)\n",
      "03:06:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:06:41 [INFO]   Training abgeschlossen in 17.17s (Backend: cuml)\n",
      "03:07:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:07:45 [INFO]   Training abgeschlossen in 17.34s (Backend: cuml)\n",
      "03:08:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:08:49 [INFO]   Training abgeschlossen in 17.75s (Backend: cuml)\n",
      "03:09:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:09:53 [INFO]   Training abgeschlossen in 17.97s (Backend: cuml)\n",
      "03:10:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:10:56 [INFO]   Training abgeschlossen in 18.11s (Backend: cuml)\n",
      "03:11:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:11:58 [INFO]   Training abgeschlossen in 18.22s (Backend: cuml)\n",
      "03:12:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:13:00 [INFO]   Training abgeschlossen in 18.44s (Backend: cuml)\n",
      "03:13:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:14:02 [INFO]   Training abgeschlossen in 18.70s (Backend: cuml)\n",
      "03:14:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:15:04 [INFO]   Training abgeschlossen in 19.01s (Backend: cuml)\n",
      "03:15:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:16:05 [INFO]   Training abgeschlossen in 19.15s (Backend: cuml)\n",
      "03:16:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:17:06 [INFO]   Training abgeschlossen in 19.48s (Backend: cuml)\n",
      "03:17:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:18:07 [INFO]   Training abgeschlossen in 19.69s (Backend: cuml)\n",
      "03:18:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:19:08 [INFO]   Training abgeschlossen in 19.86s (Backend: cuml)\n",
      "03:19:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:20:08 [INFO]   Training abgeschlossen in 20.24s (Backend: cuml)\n",
      "03:20:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:21:08 [INFO]   Training abgeschlossen in 20.52s (Backend: cuml)\n",
      "03:21:47 [INFO]     36,000 labeled → Accuracy: 0.9669 (Train: 20.5s, Query: 27.36s) | GPU: 2.8/8.0 GB\n",
      "03:21:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:22:08 [INFO]   Training abgeschlossen in 20.64s (Backend: cuml)\n",
      "03:22:19 [INFO]     Final: 36,000 labeled → Accuracy: 0.9668, F1: 0.9666\n",
      "03:22:19 [INFO]   Run 2/5\n",
      "03:22:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:22:24 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "03:23:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:23:36 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "03:24:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:24:47 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "03:25:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "03:26:00 [INFO]   Training abgeschlossen in 5.35s (Backend: cuml)\n",
      "03:27:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:27:12 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "03:28:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:28:25 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "03:29:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:29:39 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "03:30:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:30:52 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "03:31:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:32:05 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "03:33:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:33:20 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "03:34:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:34:34 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "03:35:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:35:49 [INFO]   Training abgeschlossen in 7.89s (Backend: cuml)\n",
      "03:36:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:37:03 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "03:38:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:38:18 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "03:39:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:39:33 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "03:40:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:40:48 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "03:41:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:42:03 [INFO]   Training abgeschlossen in 9.08s (Backend: cuml)\n",
      "03:43:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:43:18 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "03:44:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:44:32 [INFO]   Training abgeschlossen in 9.39s (Backend: cuml)\n",
      "03:45:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:45:45 [INFO]   Training abgeschlossen in 9.74s (Backend: cuml)\n",
      "03:46:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:46:59 [INFO]   Training abgeschlossen in 9.93s (Backend: cuml)\n",
      "03:48:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:48:13 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "03:49:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:49:26 [INFO]   Training abgeschlossen in 10.34s (Backend: cuml)\n",
      "03:50:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:50:39 [INFO]   Training abgeschlossen in 10.67s (Backend: cuml)\n",
      "03:51:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:51:52 [INFO]   Training abgeschlossen in 10.83s (Backend: cuml)\n",
      "03:52:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:53:04 [INFO]   Training abgeschlossen in 11.01s (Backend: cuml)\n",
      "03:54:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:54:17 [INFO]   Training abgeschlossen in 11.27s (Backend: cuml)\n",
      "03:55:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:55:29 [INFO]   Training abgeschlossen in 11.43s (Backend: cuml)\n",
      "03:56:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:56:41 [INFO]   Training abgeschlossen in 11.56s (Backend: cuml)\n",
      "03:57:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:57:52 [INFO]   Training abgeschlossen in 11.81s (Backend: cuml)\n",
      "03:58:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:59:03 [INFO]   Training abgeschlossen in 12.13s (Backend: cuml)\n",
      "04:00:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:00:14 [INFO]   Training abgeschlossen in 12.27s (Backend: cuml)\n",
      "04:01:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:01:25 [INFO]   Training abgeschlossen in 12.43s (Backend: cuml)\n",
      "04:02:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:02:35 [INFO]   Training abgeschlossen in 12.66s (Backend: cuml)\n",
      "04:03:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:03:46 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "04:04:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:04:56 [INFO]   Training abgeschlossen in 13.21s (Backend: cuml)\n",
      "04:05:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:06:06 [INFO]   Training abgeschlossen in 13.34s (Backend: cuml)\n",
      "04:07:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:07:17 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "04:08:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:08:27 [INFO]   Training abgeschlossen in 13.72s (Backend: cuml)\n",
      "04:09:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:09:37 [INFO]   Training abgeschlossen in 14.07s (Backend: cuml)\n",
      "04:10:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:10:47 [INFO]   Training abgeschlossen in 14.15s (Backend: cuml)\n",
      "04:11:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:11:57 [INFO]   Training abgeschlossen in 14.30s (Backend: cuml)\n",
      "04:12:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:13:06 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "04:13:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:14:13 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "04:15:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:15:21 [INFO]   Training abgeschlossen in 14.88s (Backend: cuml)\n",
      "04:16:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:16:28 [INFO]   Training abgeschlossen in 14.88s (Backend: cuml)\n",
      "04:17:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:17:35 [INFO]   Training abgeschlossen in 15.10s (Backend: cuml)\n",
      "04:18:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:18:41 [INFO]   Training abgeschlossen in 15.30s (Backend: cuml)\n",
      "04:19:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:19:48 [INFO]   Training abgeschlossen in 15.54s (Backend: cuml)\n",
      "04:20:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:20:54 [INFO]   Training abgeschlossen in 15.77s (Backend: cuml)\n",
      "04:21:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:22:00 [INFO]   Training abgeschlossen in 16.28s (Backend: cuml)\n",
      "04:22:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:23:05 [INFO]   Training abgeschlossen in 16.14s (Backend: cuml)\n",
      "04:23:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:24:11 [INFO]   Training abgeschlossen in 16.38s (Backend: cuml)\n",
      "04:24:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:25:15 [INFO]   Training abgeschlossen in 16.68s (Backend: cuml)\n",
      "04:26:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:26:20 [INFO]   Training abgeschlossen in 16.77s (Backend: cuml)\n",
      "04:27:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:27:24 [INFO]   Training abgeschlossen in 17.03s (Backend: cuml)\n",
      "04:28:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:28:28 [INFO]   Training abgeschlossen in 17.42s (Backend: cuml)\n",
      "04:29:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:29:32 [INFO]   Training abgeschlossen in 17.56s (Backend: cuml)\n",
      "04:30:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:30:35 [INFO]   Training abgeschlossen in 17.61s (Backend: cuml)\n",
      "04:31:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:31:38 [INFO]   Training abgeschlossen in 17.95s (Backend: cuml)\n",
      "04:32:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:32:40 [INFO]   Training abgeschlossen in 18.01s (Backend: cuml)\n",
      "04:33:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:33:43 [INFO]   Training abgeschlossen in 18.36s (Backend: cuml)\n",
      "04:34:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:34:45 [INFO]   Training abgeschlossen in 18.48s (Backend: cuml)\n",
      "04:35:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:35:47 [INFO]   Training abgeschlossen in 18.70s (Backend: cuml)\n",
      "04:36:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:36:49 [INFO]   Training abgeschlossen in 18.98s (Backend: cuml)\n",
      "04:37:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:37:50 [INFO]   Training abgeschlossen in 19.23s (Backend: cuml)\n",
      "04:38:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:38:51 [INFO]   Training abgeschlossen in 19.63s (Backend: cuml)\n",
      "04:39:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:39:52 [INFO]   Training abgeschlossen in 19.66s (Backend: cuml)\n",
      "04:40:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:40:52 [INFO]   Training abgeschlossen in 19.80s (Backend: cuml)\n",
      "04:41:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:41:53 [INFO]   Training abgeschlossen in 19.99s (Backend: cuml)\n",
      "04:42:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:42:52 [INFO]   Training abgeschlossen in 20.32s (Backend: cuml)\n",
      "04:43:31 [INFO]     36,000 labeled → Accuracy: 0.9665 (Train: 20.3s, Query: 27.36s) | GPU: 2.8/8.0 GB\n",
      "04:43:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:43:52 [INFO]   Training abgeschlossen in 20.47s (Backend: cuml)\n",
      "04:44:03 [INFO]     Final: 36,000 labeled → Accuracy: 0.9670, F1: 0.9667\n",
      "04:44:03 [INFO]   Run 3/5\n",
      "04:44:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:44:08 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "04:45:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "04:45:20 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "04:46:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "04:46:32 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "04:47:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "04:47:44 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "04:48:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:48:56 [INFO]   Training abgeschlossen in 5.38s (Backend: cuml)\n",
      "04:50:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:50:09 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "04:51:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:51:22 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "04:52:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:52:35 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "04:53:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:53:48 [INFO]   Training abgeschlossen in 6.76s (Backend: cuml)\n",
      "04:54:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:55:02 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "04:56:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:56:16 [INFO]   Training abgeschlossen in 7.64s (Backend: cuml)\n",
      "04:57:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:57:30 [INFO]   Training abgeschlossen in 7.90s (Backend: cuml)\n",
      "04:58:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:58:45 [INFO]   Training abgeschlossen in 8.22s (Backend: cuml)\n",
      "04:59:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:00:00 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "05:01:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:01:14 [INFO]   Training abgeschlossen in 8.58s (Backend: cuml)\n",
      "05:02:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:02:28 [INFO]   Training abgeschlossen in 8.88s (Backend: cuml)\n",
      "05:03:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:03:42 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "05:04:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:04:56 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "05:06:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:06:11 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "05:07:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:07:25 [INFO]   Training abgeschlossen in 9.74s (Backend: cuml)\n",
      "05:08:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:08:38 [INFO]   Training abgeschlossen in 9.94s (Backend: cuml)\n",
      "05:09:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:09:51 [INFO]   Training abgeschlossen in 10.12s (Backend: cuml)\n",
      "05:10:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:11:04 [INFO]   Training abgeschlossen in 10.36s (Backend: cuml)\n",
      "05:12:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:12:17 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "05:13:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:13:30 [INFO]   Training abgeschlossen in 10.76s (Backend: cuml)\n",
      "05:14:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:14:43 [INFO]   Training abgeschlossen in 11.08s (Backend: cuml)\n",
      "05:15:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:15:55 [INFO]   Training abgeschlossen in 11.24s (Backend: cuml)\n",
      "05:16:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:17:08 [INFO]   Training abgeschlossen in 11.40s (Backend: cuml)\n",
      "05:18:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:18:20 [INFO]   Training abgeschlossen in 11.62s (Backend: cuml)\n",
      "05:19:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:19:33 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "05:20:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:20:45 [INFO]   Training abgeschlossen in 12.01s (Backend: cuml)\n",
      "05:21:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:21:57 [INFO]   Training abgeschlossen in 12.18s (Backend: cuml)\n",
      "05:22:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:23:09 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "05:24:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:24:19 [INFO]   Training abgeschlossen in 12.67s (Backend: cuml)\n",
      "05:25:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:25:29 [INFO]   Training abgeschlossen in 12.83s (Backend: cuml)\n",
      "05:26:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:26:40 [INFO]   Training abgeschlossen in 13.15s (Backend: cuml)\n",
      "05:27:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:27:51 [INFO]   Training abgeschlossen in 13.40s (Backend: cuml)\n",
      "05:28:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:29:02 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "05:29:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:30:12 [INFO]   Training abgeschlossen in 13.75s (Backend: cuml)\n",
      "05:31:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:31:22 [INFO]   Training abgeschlossen in 13.89s (Backend: cuml)\n",
      "05:32:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:32:31 [INFO]   Training abgeschlossen in 14.20s (Backend: cuml)\n",
      "05:33:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:33:41 [INFO]   Training abgeschlossen in 14.36s (Backend: cuml)\n",
      "05:34:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:34:50 [INFO]   Training abgeschlossen in 14.56s (Backend: cuml)\n",
      "05:35:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:35:58 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "05:36:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:37:04 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "05:37:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:38:12 [INFO]   Training abgeschlossen in 14.95s (Backend: cuml)\n",
      "05:39:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:39:18 [INFO]   Training abgeschlossen in 15.28s (Backend: cuml)\n",
      "05:40:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:40:25 [INFO]   Training abgeschlossen in 15.31s (Backend: cuml)\n",
      "05:41:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:41:31 [INFO]   Training abgeschlossen in 15.56s (Backend: cuml)\n",
      "05:42:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:42:37 [INFO]   Training abgeschlossen in 15.80s (Backend: cuml)\n",
      "05:43:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:43:43 [INFO]   Training abgeschlossen in 16.14s (Backend: cuml)\n",
      "05:44:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:44:48 [INFO]   Training abgeschlossen in 16.27s (Backend: cuml)\n",
      "05:45:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:45:54 [INFO]   Training abgeschlossen in 16.49s (Backend: cuml)\n",
      "05:46:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:46:59 [INFO]   Training abgeschlossen in 16.75s (Backend: cuml)\n",
      "05:47:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:48:03 [INFO]   Training abgeschlossen in 16.81s (Backend: cuml)\n",
      "05:48:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:49:08 [INFO]   Training abgeschlossen in 17.03s (Backend: cuml)\n",
      "05:49:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:50:12 [INFO]   Training abgeschlossen in 17.23s (Backend: cuml)\n",
      "05:50:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:51:16 [INFO]   Training abgeschlossen in 17.50s (Backend: cuml)\n",
      "05:52:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:52:20 [INFO]   Training abgeschlossen in 17.62s (Backend: cuml)\n",
      "05:53:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:53:24 [INFO]   Training abgeschlossen in 17.98s (Backend: cuml)\n",
      "05:54:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:54:27 [INFO]   Training abgeschlossen in 18.19s (Backend: cuml)\n",
      "05:55:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:55:29 [INFO]   Training abgeschlossen in 18.26s (Backend: cuml)\n",
      "05:56:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:56:31 [INFO]   Training abgeschlossen in 18.48s (Backend: cuml)\n",
      "05:57:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:57:33 [INFO]   Training abgeschlossen in 18.66s (Backend: cuml)\n",
      "05:58:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:58:34 [INFO]   Training abgeschlossen in 18.87s (Backend: cuml)\n",
      "05:59:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:59:36 [INFO]   Training abgeschlossen in 19.12s (Backend: cuml)\n",
      "06:00:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:00:37 [INFO]   Training abgeschlossen in 19.37s (Backend: cuml)\n",
      "06:01:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:01:37 [INFO]   Training abgeschlossen in 19.51s (Backend: cuml)\n",
      "06:02:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:02:37 [INFO]   Training abgeschlossen in 19.69s (Backend: cuml)\n",
      "06:03:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:03:37 [INFO]   Training abgeschlossen in 19.91s (Backend: cuml)\n",
      "06:04:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:04:37 [INFO]   Training abgeschlossen in 20.26s (Backend: cuml)\n",
      "06:05:16 [INFO]     36,000 labeled → Accuracy: 0.9670 (Train: 20.3s, Query: 27.33s) | GPU: 2.8/8.0 GB\n",
      "06:05:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:05:36 [INFO]   Training abgeschlossen in 20.42s (Backend: cuml)\n",
      "06:05:48 [INFO]     Final: 36,000 labeled → Accuracy: 0.9670, F1: 0.9668\n",
      "06:05:48 [INFO]   Run 4/5\n",
      "06:05:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:05:53 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "06:06:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "06:07:04 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "06:08:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "06:08:16 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "06:09:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "06:09:28 [INFO]   Training abgeschlossen in 5.20s (Backend: cuml)\n",
      "06:10:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:10:41 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "06:11:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:11:53 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "06:13:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:13:07 [INFO]   Training abgeschlossen in 6.15s (Backend: cuml)\n",
      "06:14:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:14:20 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "06:15:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:15:33 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "06:16:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:16:47 [INFO]   Training abgeschlossen in 7.28s (Backend: cuml)\n",
      "06:17:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:18:01 [INFO]   Training abgeschlossen in 7.67s (Backend: cuml)\n",
      "06:19:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:19:16 [INFO]   Training abgeschlossen in 7.89s (Backend: cuml)\n",
      "06:20:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:20:30 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "06:21:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:21:45 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "06:22:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:22:59 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "06:24:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:24:13 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "06:25:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:25:27 [INFO]   Training abgeschlossen in 9.15s (Backend: cuml)\n",
      "06:26:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:26:41 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "06:27:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:27:55 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "06:29:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:29:09 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "06:30:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:30:23 [INFO]   Training abgeschlossen in 10.12s (Backend: cuml)\n",
      "06:31:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:31:36 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "06:32:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:32:49 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "06:33:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:34:02 [INFO]   Training abgeschlossen in 10.61s (Backend: cuml)\n",
      "06:35:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:35:15 [INFO]   Training abgeschlossen in 10.80s (Backend: cuml)\n",
      "06:36:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:36:27 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "06:37:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:37:40 [INFO]   Training abgeschlossen in 11.20s (Backend: cuml)\n",
      "06:38:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:38:52 [INFO]   Training abgeschlossen in 11.54s (Backend: cuml)\n",
      "06:39:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:40:03 [INFO]   Training abgeschlossen in 11.58s (Backend: cuml)\n",
      "06:41:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:41:15 [INFO]   Training abgeschlossen in 11.84s (Backend: cuml)\n",
      "06:42:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:42:26 [INFO]   Training abgeschlossen in 12.08s (Backend: cuml)\n",
      "06:43:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:43:38 [INFO]   Training abgeschlossen in 12.36s (Backend: cuml)\n",
      "06:44:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:44:48 [INFO]   Training abgeschlossen in 12.43s (Backend: cuml)\n",
      "06:45:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:45:59 [INFO]   Training abgeschlossen in 12.65s (Backend: cuml)\n",
      "06:46:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:47:09 [INFO]   Training abgeschlossen in 12.91s (Backend: cuml)\n",
      "06:48:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:48:20 [INFO]   Training abgeschlossen in 13.38s (Backend: cuml)\n",
      "06:49:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:49:30 [INFO]   Training abgeschlossen in 13.35s (Backend: cuml)\n",
      "06:50:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:50:41 [INFO]   Training abgeschlossen in 13.48s (Backend: cuml)\n",
      "06:51:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:51:51 [INFO]   Training abgeschlossen in 13.69s (Backend: cuml)\n",
      "06:52:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:53:01 [INFO]   Training abgeschlossen in 14.00s (Backend: cuml)\n",
      "06:53:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:54:11 [INFO]   Training abgeschlossen in 14.15s (Backend: cuml)\n",
      "06:55:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:55:20 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "06:56:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:56:29 [INFO]   Training abgeschlossen in 14.53s (Backend: cuml)\n",
      "06:57:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:57:38 [INFO]   Training abgeschlossen in 14.56s (Backend: cuml)\n",
      "06:58:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:58:45 [INFO]   Training abgeschlossen in 14.64s (Backend: cuml)\n",
      "06:59:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:59:52 [INFO]   Training abgeschlossen in 14.89s (Backend: cuml)\n",
      "07:00:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:00:59 [INFO]   Training abgeschlossen in 15.02s (Backend: cuml)\n",
      "07:01:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:02:06 [INFO]   Training abgeschlossen in 15.22s (Backend: cuml)\n",
      "07:02:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:03:12 [INFO]   Training abgeschlossen in 15.47s (Backend: cuml)\n",
      "07:04:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:04:18 [INFO]   Training abgeschlossen in 15.69s (Backend: cuml)\n",
      "07:05:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:05:24 [INFO]   Training abgeschlossen in 16.23s (Backend: cuml)\n",
      "07:06:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:06:29 [INFO]   Training abgeschlossen in 16.02s (Backend: cuml)\n",
      "07:07:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:07:35 [INFO]   Training abgeschlossen in 16.24s (Backend: cuml)\n",
      "07:08:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:08:41 [INFO]   Training abgeschlossen in 16.52s (Backend: cuml)\n",
      "07:09:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:09:46 [INFO]   Training abgeschlossen in 16.88s (Backend: cuml)\n",
      "07:10:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:10:51 [INFO]   Training abgeschlossen in 17.08s (Backend: cuml)\n",
      "07:11:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:11:56 [INFO]   Training abgeschlossen in 17.20s (Backend: cuml)\n",
      "07:12:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:13:00 [INFO]   Training abgeschlossen in 17.54s (Backend: cuml)\n",
      "07:13:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:14:04 [INFO]   Training abgeschlossen in 17.62s (Backend: cuml)\n",
      "07:14:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:15:08 [INFO]   Training abgeschlossen in 17.85s (Backend: cuml)\n",
      "07:15:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:16:11 [INFO]   Training abgeschlossen in 18.07s (Backend: cuml)\n",
      "07:16:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:17:13 [INFO]   Training abgeschlossen in 18.33s (Backend: cuml)\n",
      "07:17:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:18:16 [INFO]   Training abgeschlossen in 18.65s (Backend: cuml)\n",
      "07:18:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:19:18 [INFO]   Training abgeschlossen in 18.88s (Backend: cuml)\n",
      "07:20:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:20:20 [INFO]   Training abgeschlossen in 19.11s (Backend: cuml)\n",
      "07:21:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:21:21 [INFO]   Training abgeschlossen in 19.25s (Backend: cuml)\n",
      "07:22:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:22:22 [INFO]   Training abgeschlossen in 19.47s (Backend: cuml)\n",
      "07:23:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:23:22 [INFO]   Training abgeschlossen in 19.72s (Backend: cuml)\n",
      "07:24:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:24:23 [INFO]   Training abgeschlossen in 19.85s (Backend: cuml)\n",
      "07:25:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:25:23 [INFO]   Training abgeschlossen in 20.05s (Backend: cuml)\n",
      "07:26:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:26:23 [INFO]   Training abgeschlossen in 20.26s (Backend: cuml)\n",
      "07:27:02 [INFO]     36,000 labeled → Accuracy: 0.9674 (Train: 20.3s, Query: 27.43s) | GPU: 2.8/8.0 GB\n",
      "07:27:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:27:22 [INFO]   Training abgeschlossen in 20.44s (Backend: cuml)\n",
      "07:27:34 [INFO]     Final: 36,000 labeled → Accuracy: 0.9672, F1: 0.9669\n",
      "07:27:34 [INFO]   Run 5/5\n",
      "07:27:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:27:39 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "07:28:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "07:28:50 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "07:29:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "07:30:02 [INFO]   Training abgeschlossen in 5.01s (Backend: cuml)\n",
      "07:31:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "07:31:15 [INFO]   Training abgeschlossen in 5.20s (Backend: cuml)\n",
      "07:32:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:32:27 [INFO]   Training abgeschlossen in 5.56s (Backend: cuml)\n",
      "07:33:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:33:40 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "07:34:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:34:53 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "07:35:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:36:06 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "07:37:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:37:19 [INFO]   Training abgeschlossen in 6.87s (Backend: cuml)\n",
      "07:38:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:38:33 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "07:39:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:39:47 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "07:40:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:41:02 [INFO]   Training abgeschlossen in 8.13s (Backend: cuml)\n",
      "07:42:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:42:16 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "07:43:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:43:31 [INFO]   Training abgeschlossen in 8.37s (Backend: cuml)\n",
      "07:44:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:44:45 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "07:45:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:46:00 [INFO]   Training abgeschlossen in 8.81s (Backend: cuml)\n",
      "07:47:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:47:13 [INFO]   Training abgeschlossen in 9.01s (Backend: cuml)\n",
      "07:48:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:48:28 [INFO]   Training abgeschlossen in 9.33s (Backend: cuml)\n",
      "07:49:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:49:42 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "07:50:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:50:55 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "07:51:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:52:09 [INFO]   Training abgeschlossen in 9.89s (Backend: cuml)\n",
      "07:53:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:53:22 [INFO]   Training abgeschlossen in 10.18s (Backend: cuml)\n",
      "07:54:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:54:35 [INFO]   Training abgeschlossen in 10.32s (Backend: cuml)\n",
      "07:55:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:55:49 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "07:56:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:57:03 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "07:58:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:58:17 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "07:59:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:59:30 [INFO]   Training abgeschlossen in 11.23s (Backend: cuml)\n",
      "08:00:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:00:43 [INFO]   Training abgeschlossen in 11.49s (Backend: cuml)\n",
      "08:01:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:01:56 [INFO]   Training abgeschlossen in 11.67s (Backend: cuml)\n",
      "08:02:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:03:09 [INFO]   Training abgeschlossen in 11.86s (Backend: cuml)\n",
      "08:04:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:04:21 [INFO]   Training abgeschlossen in 12.02s (Backend: cuml)\n",
      "08:05:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:05:34 [INFO]   Training abgeschlossen in 12.39s (Backend: cuml)\n",
      "08:06:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:06:44 [INFO]   Training abgeschlossen in 12.49s (Backend: cuml)\n",
      "08:07:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:07:55 [INFO]   Training abgeschlossen in 12.68s (Backend: cuml)\n",
      "08:08:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:09:05 [INFO]   Training abgeschlossen in 12.95s (Backend: cuml)\n",
      "08:10:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:10:16 [INFO]   Training abgeschlossen in 13.12s (Backend: cuml)\n",
      "08:11:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:11:27 [INFO]   Training abgeschlossen in 13.39s (Backend: cuml)\n",
      "08:12:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:12:37 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "08:13:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:13:47 [INFO]   Training abgeschlossen in 13.75s (Backend: cuml)\n",
      "08:14:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:14:57 [INFO]   Training abgeschlossen in 13.99s (Backend: cuml)\n",
      "08:15:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:16:07 [INFO]   Training abgeschlossen in 14.29s (Backend: cuml)\n",
      "08:17:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:17:17 [INFO]   Training abgeschlossen in 14.40s (Backend: cuml)\n",
      "08:18:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:18:26 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "08:19:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:19:33 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "08:20:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:20:41 [INFO]   Training abgeschlossen in 14.86s (Backend: cuml)\n",
      "08:21:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:21:48 [INFO]   Training abgeschlossen in 14.99s (Backend: cuml)\n",
      "08:22:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:22:54 [INFO]   Training abgeschlossen in 15.03s (Backend: cuml)\n",
      "08:23:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:24:01 [INFO]   Training abgeschlossen in 15.25s (Backend: cuml)\n",
      "08:24:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:25:07 [INFO]   Training abgeschlossen in 15.48s (Backend: cuml)\n",
      "08:25:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:26:13 [INFO]   Training abgeschlossen in 15.68s (Backend: cuml)\n",
      "08:27:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:27:19 [INFO]   Training abgeschlossen in 16.35s (Backend: cuml)\n",
      "08:28:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:28:25 [INFO]   Training abgeschlossen in 16.31s (Backend: cuml)\n",
      "08:29:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:29:30 [INFO]   Training abgeschlossen in 16.31s (Backend: cuml)\n",
      "08:30:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:30:35 [INFO]   Training abgeschlossen in 16.67s (Backend: cuml)\n",
      "08:31:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:31:39 [INFO]   Training abgeschlossen in 16.84s (Backend: cuml)\n",
      "08:32:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:32:44 [INFO]   Training abgeschlossen in 17.13s (Backend: cuml)\n",
      "08:33:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:33:48 [INFO]   Training abgeschlossen in 17.22s (Backend: cuml)\n",
      "08:34:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:34:52 [INFO]   Training abgeschlossen in 17.55s (Backend: cuml)\n",
      "08:35:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:35:55 [INFO]   Training abgeschlossen in 17.79s (Backend: cuml)\n",
      "08:36:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:36:58 [INFO]   Training abgeschlossen in 17.87s (Backend: cuml)\n",
      "08:37:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:38:01 [INFO]   Training abgeschlossen in 18.13s (Backend: cuml)\n",
      "08:38:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:39:04 [INFO]   Training abgeschlossen in 18.44s (Backend: cuml)\n",
      "08:39:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:40:05 [INFO]   Training abgeschlossen in 18.49s (Backend: cuml)\n",
      "08:40:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:41:07 [INFO]   Training abgeschlossen in 18.81s (Backend: cuml)\n",
      "08:41:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:42:09 [INFO]   Training abgeschlossen in 18.92s (Backend: cuml)\n",
      "08:42:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:43:10 [INFO]   Training abgeschlossen in 19.11s (Backend: cuml)\n",
      "08:43:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:44:11 [INFO]   Training abgeschlossen in 19.38s (Backend: cuml)\n",
      "08:44:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:45:12 [INFO]   Training abgeschlossen in 19.68s (Backend: cuml)\n",
      "08:45:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:46:13 [INFO]   Training abgeschlossen in 19.95s (Backend: cuml)\n",
      "08:46:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:47:13 [INFO]   Training abgeschlossen in 20.20s (Backend: cuml)\n",
      "08:47:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:48:13 [INFO]   Training abgeschlossen in 20.49s (Backend: cuml)\n",
      "08:48:52 [INFO]     36,000 labeled → Accuracy: 0.9663 (Train: 20.5s, Query: 27.31s) | GPU: 2.8/8.0 GB\n",
      "08:48:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:49:13 [INFO]   Training abgeschlossen in 20.72s (Backend: cuml)\n",
      "08:49:24 [INFO]     Final: 36,000 labeled → Accuracy: 0.9659, F1: 0.9656\n",
      "08:49:24 [INFO] \n",
      "GPU-SVM + Least Confidence - Budget: 80% (48,000 Samples)\n",
      "08:49:24 [INFO]   Run 1/5\n",
      "08:49:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:49:29 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "08:50:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "08:50:41 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "08:51:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "08:51:53 [INFO]   Training abgeschlossen in 5.07s (Backend: cuml)\n",
      "08:52:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "08:53:05 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "08:54:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:54:18 [INFO]   Training abgeschlossen in 5.59s (Backend: cuml)\n",
      "08:55:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:55:31 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "08:56:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:56:44 [INFO]   Training abgeschlossen in 5.82s (Backend: cuml)\n",
      "08:57:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:57:57 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "08:59:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:59:11 [INFO]   Training abgeschlossen in 6.80s (Backend: cuml)\n",
      "09:00:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:00:24 [INFO]   Training abgeschlossen in 7.12s (Backend: cuml)\n",
      "09:01:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:01:39 [INFO]   Training abgeschlossen in 7.69s (Backend: cuml)\n",
      "09:02:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:02:53 [INFO]   Training abgeschlossen in 7.92s (Backend: cuml)\n",
      "09:04:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:04:08 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "09:05:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:05:22 [INFO]   Training abgeschlossen in 8.36s (Backend: cuml)\n",
      "09:06:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:06:36 [INFO]   Training abgeschlossen in 8.64s (Backend: cuml)\n",
      "09:07:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:07:51 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "09:08:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:09:05 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "09:10:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:10:19 [INFO]   Training abgeschlossen in 9.32s (Backend: cuml)\n",
      "09:11:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:11:33 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "09:12:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:12:46 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "09:13:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:14:00 [INFO]   Training abgeschlossen in 9.85s (Backend: cuml)\n",
      "09:15:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:15:14 [INFO]   Training abgeschlossen in 10.22s (Backend: cuml)\n",
      "09:16:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:16:27 [INFO]   Training abgeschlossen in 10.30s (Backend: cuml)\n",
      "09:17:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:17:40 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "09:18:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:18:54 [INFO]   Training abgeschlossen in 10.84s (Backend: cuml)\n",
      "09:19:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:20:08 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "09:21:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:21:21 [INFO]   Training abgeschlossen in 11.26s (Backend: cuml)\n",
      "09:22:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:22:35 [INFO]   Training abgeschlossen in 11.65s (Backend: cuml)\n",
      "09:23:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:23:47 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "09:24:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:25:00 [INFO]   Training abgeschlossen in 11.76s (Backend: cuml)\n",
      "09:26:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:26:12 [INFO]   Training abgeschlossen in 12.09s (Backend: cuml)\n",
      "09:27:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:27:23 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "09:28:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:28:34 [INFO]   Training abgeschlossen in 12.44s (Backend: cuml)\n",
      "09:29:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:29:46 [INFO]   Training abgeschlossen in 12.73s (Backend: cuml)\n",
      "09:30:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:30:56 [INFO]   Training abgeschlossen in 12.96s (Backend: cuml)\n",
      "09:31:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:32:07 [INFO]   Training abgeschlossen in 13.14s (Backend: cuml)\n",
      "09:33:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:33:18 [INFO]   Training abgeschlossen in 13.25s (Backend: cuml)\n",
      "09:34:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:34:28 [INFO]   Training abgeschlossen in 13.44s (Backend: cuml)\n",
      "09:35:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:35:38 [INFO]   Training abgeschlossen in 13.71s (Backend: cuml)\n",
      "09:36:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:36:47 [INFO]   Training abgeschlossen in 14.14s (Backend: cuml)\n",
      "09:37:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:37:56 [INFO]   Training abgeschlossen in 14.07s (Backend: cuml)\n",
      "09:38:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:39:04 [INFO]   Training abgeschlossen in 14.40s (Backend: cuml)\n",
      "09:39:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:40:12 [INFO]   Training abgeschlossen in 14.59s (Backend: cuml)\n",
      "09:41:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:41:20 [INFO]   Training abgeschlossen in 14.68s (Backend: cuml)\n",
      "09:42:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:42:28 [INFO]   Training abgeschlossen in 14.73s (Backend: cuml)\n",
      "09:43:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:43:35 [INFO]   Training abgeschlossen in 14.86s (Backend: cuml)\n",
      "09:44:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:44:42 [INFO]   Training abgeschlossen in 15.06s (Backend: cuml)\n",
      "09:45:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:45:49 [INFO]   Training abgeschlossen in 15.26s (Backend: cuml)\n",
      "09:46:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:46:55 [INFO]   Training abgeschlossen in 15.53s (Backend: cuml)\n",
      "09:47:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:48:01 [INFO]   Training abgeschlossen in 15.86s (Backend: cuml)\n",
      "09:48:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:49:08 [INFO]   Training abgeschlossen in 16.24s (Backend: cuml)\n",
      "09:49:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:50:13 [INFO]   Training abgeschlossen in 16.18s (Backend: cuml)\n",
      "09:51:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:51:18 [INFO]   Training abgeschlossen in 16.33s (Backend: cuml)\n",
      "09:52:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:52:23 [INFO]   Training abgeschlossen in 16.60s (Backend: cuml)\n",
      "09:53:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:53:27 [INFO]   Training abgeschlossen in 16.79s (Backend: cuml)\n",
      "09:54:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:54:32 [INFO]   Training abgeschlossen in 17.13s (Backend: cuml)\n",
      "09:55:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:55:36 [INFO]   Training abgeschlossen in 17.24s (Backend: cuml)\n",
      "09:56:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:56:40 [INFO]   Training abgeschlossen in 17.56s (Backend: cuml)\n",
      "09:57:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:57:43 [INFO]   Training abgeschlossen in 17.63s (Backend: cuml)\n",
      "09:58:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:58:46 [INFO]   Training abgeschlossen in 17.88s (Backend: cuml)\n",
      "09:59:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:59:49 [INFO]   Training abgeschlossen in 18.03s (Backend: cuml)\n",
      "10:00:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:00:51 [INFO]   Training abgeschlossen in 18.21s (Backend: cuml)\n",
      "10:01:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:01:54 [INFO]   Training abgeschlossen in 18.51s (Backend: cuml)\n",
      "10:02:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:02:55 [INFO]   Training abgeschlossen in 18.74s (Backend: cuml)\n",
      "10:03:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:03:57 [INFO]   Training abgeschlossen in 18.95s (Backend: cuml)\n",
      "10:04:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:04:58 [INFO]   Training abgeschlossen in 19.24s (Backend: cuml)\n",
      "10:05:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:06:00 [INFO]   Training abgeschlossen in 19.48s (Backend: cuml)\n",
      "10:06:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:07:00 [INFO]   Training abgeschlossen in 19.65s (Backend: cuml)\n",
      "10:07:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:08:01 [INFO]   Training abgeschlossen in 19.79s (Backend: cuml)\n",
      "10:08:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:09:01 [INFO]   Training abgeschlossen in 19.96s (Backend: cuml)\n",
      "10:09:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:10:00 [INFO]   Training abgeschlossen in 20.17s (Backend: cuml)\n",
      "10:10:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:11:00 [INFO]   Training abgeschlossen in 20.35s (Backend: cuml)\n",
      "10:11:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:11:59 [INFO]   Training abgeschlossen in 20.57s (Backend: cuml)\n",
      "10:12:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:12:58 [INFO]   Training abgeschlossen in 20.83s (Backend: cuml)\n",
      "10:13:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:13:56 [INFO]   Training abgeschlossen in 21.08s (Backend: cuml)\n",
      "10:14:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:14:54 [INFO]   Training abgeschlossen in 21.25s (Backend: cuml)\n",
      "10:15:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:15:52 [INFO]   Training abgeschlossen in 21.41s (Backend: cuml)\n",
      "10:16:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:16:49 [INFO]   Training abgeschlossen in 21.61s (Backend: cuml)\n",
      "10:17:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:17:46 [INFO]   Training abgeschlossen in 21.88s (Backend: cuml)\n",
      "10:18:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:18:43 [INFO]   Training abgeschlossen in 22.07s (Backend: cuml)\n",
      "10:19:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:19:40 [INFO]   Training abgeschlossen in 22.22s (Backend: cuml)\n",
      "10:20:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:20:36 [INFO]   Training abgeschlossen in 22.48s (Backend: cuml)\n",
      "10:21:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:21:31 [INFO]   Training abgeschlossen in 22.73s (Backend: cuml)\n",
      "10:22:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:22:27 [INFO]   Training abgeschlossen in 22.90s (Backend: cuml)\n",
      "10:22:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:23:22 [INFO]   Training abgeschlossen in 23.11s (Backend: cuml)\n",
      "10:23:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:24:17 [INFO]   Training abgeschlossen in 23.31s (Backend: cuml)\n",
      "10:24:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:25:12 [INFO]   Training abgeschlossen in 23.58s (Backend: cuml)\n",
      "10:25:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:26:06 [INFO]   Training abgeschlossen in 23.81s (Backend: cuml)\n",
      "10:26:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:27:00 [INFO]   Training abgeschlossen in 23.94s (Backend: cuml)\n",
      "10:27:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:27:54 [INFO]   Training abgeschlossen in 24.23s (Backend: cuml)\n",
      "10:28:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:28:47 [INFO]   Training abgeschlossen in 24.58s (Backend: cuml)\n",
      "10:29:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:29:40 [INFO]   Training abgeschlossen in 24.78s (Backend: cuml)\n",
      "10:30:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:30:33 [INFO]   Training abgeschlossen in 24.98s (Backend: cuml)\n",
      "10:31:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:31:25 [INFO]   Training abgeschlossen in 25.03s (Backend: cuml)\n",
      "10:31:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:32:17 [INFO]   Training abgeschlossen in 25.43s (Backend: cuml)\n",
      "10:32:43 [INFO]     48,000 labeled → Accuracy: 0.9667 (Train: 25.4s, Query: 14.26s) | GPU: 2.8/8.0 GB\n",
      "10:32:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:33:09 [INFO]   Training abgeschlossen in 25.57s (Backend: cuml)\n",
      "10:33:20 [INFO]     Final: 48,000 labeled → Accuracy: 0.9664, F1: 0.9662\n",
      "10:33:21 [INFO]   Run 2/5\n",
      "10:33:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:33:25 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "10:34:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:34:37 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "10:35:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:35:48 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "10:36:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "10:37:01 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "10:38:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:38:13 [INFO]   Training abgeschlossen in 5.36s (Backend: cuml)\n",
      "10:39:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:39:26 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "10:40:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:40:40 [INFO]   Training abgeschlossen in 6.02s (Backend: cuml)\n",
      "10:41:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:41:53 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "10:43:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:43:07 [INFO]   Training abgeschlossen in 6.71s (Backend: cuml)\n",
      "10:44:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:44:21 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "10:45:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:45:35 [INFO]   Training abgeschlossen in 7.73s (Backend: cuml)\n",
      "10:46:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:46:50 [INFO]   Training abgeschlossen in 7.92s (Backend: cuml)\n",
      "10:47:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:48:04 [INFO]   Training abgeschlossen in 8.11s (Backend: cuml)\n",
      "10:49:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:49:19 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "10:50:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:50:33 [INFO]   Training abgeschlossen in 8.57s (Backend: cuml)\n",
      "10:51:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:51:48 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "10:52:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:53:02 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "10:54:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:54:16 [INFO]   Training abgeschlossen in 9.36s (Backend: cuml)\n",
      "10:55:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:55:30 [INFO]   Training abgeschlossen in 9.48s (Backend: cuml)\n",
      "10:56:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:56:43 [INFO]   Training abgeschlossen in 9.66s (Backend: cuml)\n",
      "10:57:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:57:57 [INFO]   Training abgeschlossen in 10.07s (Backend: cuml)\n",
      "10:59:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:59:11 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "11:00:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:00:24 [INFO]   Training abgeschlossen in 10.36s (Backend: cuml)\n",
      "11:01:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:01:38 [INFO]   Training abgeschlossen in 10.60s (Backend: cuml)\n",
      "11:02:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:02:51 [INFO]   Training abgeschlossen in 10.86s (Backend: cuml)\n",
      "11:03:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:04:03 [INFO]   Training abgeschlossen in 11.02s (Backend: cuml)\n",
      "11:05:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:05:16 [INFO]   Training abgeschlossen in 11.27s (Backend: cuml)\n",
      "11:06:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:06:28 [INFO]   Training abgeschlossen in 11.46s (Backend: cuml)\n",
      "11:07:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:07:40 [INFO]   Training abgeschlossen in 11.66s (Backend: cuml)\n",
      "11:08:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:08:51 [INFO]   Training abgeschlossen in 11.86s (Backend: cuml)\n",
      "11:09:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:10:03 [INFO]   Training abgeschlossen in 11.99s (Backend: cuml)\n",
      "11:11:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:11:14 [INFO]   Training abgeschlossen in 12.39s (Backend: cuml)\n",
      "11:12:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:12:25 [INFO]   Training abgeschlossen in 12.51s (Backend: cuml)\n",
      "11:13:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:13:35 [INFO]   Training abgeschlossen in 12.68s (Backend: cuml)\n",
      "11:14:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:14:46 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "11:15:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:15:56 [INFO]   Training abgeschlossen in 13.15s (Backend: cuml)\n",
      "11:16:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:17:06 [INFO]   Training abgeschlossen in 13.42s (Backend: cuml)\n",
      "11:18:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:18:15 [INFO]   Training abgeschlossen in 13.48s (Backend: cuml)\n",
      "11:19:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:19:25 [INFO]   Training abgeschlossen in 13.70s (Backend: cuml)\n",
      "11:20:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:20:34 [INFO]   Training abgeschlossen in 13.91s (Backend: cuml)\n",
      "11:21:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:21:43 [INFO]   Training abgeschlossen in 14.19s (Backend: cuml)\n",
      "11:22:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:22:52 [INFO]   Training abgeschlossen in 14.38s (Backend: cuml)\n",
      "11:23:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:24:00 [INFO]   Training abgeschlossen in 14.58s (Backend: cuml)\n",
      "11:24:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:25:08 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "11:26:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:26:15 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "11:27:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:27:22 [INFO]   Training abgeschlossen in 15.05s (Backend: cuml)\n",
      "11:28:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:28:29 [INFO]   Training abgeschlossen in 15.09s (Backend: cuml)\n",
      "11:29:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:29:36 [INFO]   Training abgeschlossen in 15.24s (Backend: cuml)\n",
      "11:30:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:30:42 [INFO]   Training abgeschlossen in 15.43s (Backend: cuml)\n",
      "11:31:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:31:48 [INFO]   Training abgeschlossen in 15.66s (Backend: cuml)\n",
      "11:32:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:32:54 [INFO]   Training abgeschlossen in 16.16s (Backend: cuml)\n",
      "11:33:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:33:59 [INFO]   Training abgeschlossen in 16.18s (Backend: cuml)\n",
      "11:34:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:35:05 [INFO]   Training abgeschlossen in 16.51s (Backend: cuml)\n",
      "11:35:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:36:09 [INFO]   Training abgeschlossen in 16.57s (Backend: cuml)\n",
      "11:36:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:37:14 [INFO]   Training abgeschlossen in 16.75s (Backend: cuml)\n",
      "11:38:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:38:18 [INFO]   Training abgeschlossen in 16.94s (Backend: cuml)\n",
      "11:39:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:39:22 [INFO]   Training abgeschlossen in 17.19s (Backend: cuml)\n",
      "11:40:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:40:25 [INFO]   Training abgeschlossen in 17.45s (Backend: cuml)\n",
      "11:41:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:41:30 [INFO]   Training abgeschlossen in 17.85s (Backend: cuml)\n",
      "11:42:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:42:34 [INFO]   Training abgeschlossen in 18.03s (Backend: cuml)\n",
      "11:43:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:43:36 [INFO]   Training abgeschlossen in 18.07s (Backend: cuml)\n",
      "11:44:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:44:39 [INFO]   Training abgeschlossen in 18.36s (Backend: cuml)\n",
      "11:45:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:45:41 [INFO]   Training abgeschlossen in 18.49s (Backend: cuml)\n",
      "11:46:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:46:43 [INFO]   Training abgeschlossen in 18.82s (Backend: cuml)\n",
      "11:47:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:47:44 [INFO]   Training abgeschlossen in 18.90s (Backend: cuml)\n",
      "11:48:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:48:46 [INFO]   Training abgeschlossen in 19.18s (Backend: cuml)\n",
      "11:49:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:49:47 [INFO]   Training abgeschlossen in 19.35s (Backend: cuml)\n",
      "11:50:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:50:47 [INFO]   Training abgeschlossen in 19.56s (Backend: cuml)\n",
      "11:51:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:51:48 [INFO]   Training abgeschlossen in 19.80s (Backend: cuml)\n",
      "11:52:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:52:48 [INFO]   Training abgeschlossen in 20.13s (Backend: cuml)\n",
      "11:53:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:53:48 [INFO]   Training abgeschlossen in 20.32s (Backend: cuml)\n",
      "11:54:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:54:47 [INFO]   Training abgeschlossen in 20.47s (Backend: cuml)\n",
      "11:55:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:55:46 [INFO]   Training abgeschlossen in 20.69s (Backend: cuml)\n",
      "11:56:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:56:45 [INFO]   Training abgeschlossen in 21.01s (Backend: cuml)\n",
      "11:57:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:57:43 [INFO]   Training abgeschlossen in 21.08s (Backend: cuml)\n",
      "11:58:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:58:42 [INFO]   Training abgeschlossen in 21.23s (Backend: cuml)\n",
      "11:59:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:59:40 [INFO]   Training abgeschlossen in 21.50s (Backend: cuml)\n",
      "12:00:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:00:37 [INFO]   Training abgeschlossen in 21.80s (Backend: cuml)\n",
      "12:01:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:01:34 [INFO]   Training abgeschlossen in 21.82s (Backend: cuml)\n",
      "12:02:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:02:31 [INFO]   Training abgeschlossen in 22.13s (Backend: cuml)\n",
      "12:03:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:03:28 [INFO]   Training abgeschlossen in 22.33s (Backend: cuml)\n",
      "12:04:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:04:24 [INFO]   Training abgeschlossen in 22.57s (Backend: cuml)\n",
      "12:04:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:05:21 [INFO]   Training abgeschlossen in 22.84s (Backend: cuml)\n",
      "12:05:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:06:16 [INFO]   Training abgeschlossen in 23.08s (Backend: cuml)\n",
      "12:06:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:07:11 [INFO]   Training abgeschlossen in 23.08s (Backend: cuml)\n",
      "12:07:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:08:06 [INFO]   Training abgeschlossen in 23.37s (Backend: cuml)\n",
      "12:08:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:09:01 [INFO]   Training abgeschlossen in 23.61s (Backend: cuml)\n",
      "12:09:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:09:56 [INFO]   Training abgeschlossen in 23.74s (Backend: cuml)\n",
      "12:10:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:10:50 [INFO]   Training abgeschlossen in 24.01s (Backend: cuml)\n",
      "12:11:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:11:43 [INFO]   Training abgeschlossen in 24.27s (Backend: cuml)\n",
      "12:12:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:12:37 [INFO]   Training abgeschlossen in 24.50s (Backend: cuml)\n",
      "12:13:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:13:29 [INFO]   Training abgeschlossen in 24.60s (Backend: cuml)\n",
      "12:13:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:14:22 [INFO]   Training abgeschlossen in 24.85s (Backend: cuml)\n",
      "12:14:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:15:14 [INFO]   Training abgeschlossen in 25.15s (Backend: cuml)\n",
      "12:15:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:16:06 [INFO]   Training abgeschlossen in 25.53s (Backend: cuml)\n",
      "12:16:32 [INFO]     48,000 labeled → Accuracy: 0.9655 (Train: 25.5s, Query: 14.24s) | GPU: 2.8/8.0 GB\n",
      "12:16:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:16:57 [INFO]   Training abgeschlossen in 25.49s (Backend: cuml)\n",
      "12:17:09 [INFO]     Final: 48,000 labeled → Accuracy: 0.9654, F1: 0.9652\n",
      "12:17:09 [INFO]   Run 3/5\n",
      "12:17:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:17:14 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "12:18:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "12:18:25 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "12:19:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "12:19:37 [INFO]   Training abgeschlossen in 5.05s (Backend: cuml)\n",
      "12:20:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "12:20:49 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "12:21:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:22:02 [INFO]   Training abgeschlossen in 5.44s (Backend: cuml)\n",
      "12:23:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:23:15 [INFO]   Training abgeschlossen in 5.65s (Backend: cuml)\n",
      "12:24:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:24:28 [INFO]   Training abgeschlossen in 6.06s (Backend: cuml)\n",
      "12:25:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:25:41 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "12:26:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:26:55 [INFO]   Training abgeschlossen in 6.63s (Backend: cuml)\n",
      "12:28:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:28:09 [INFO]   Training abgeschlossen in 7.31s (Backend: cuml)\n",
      "12:29:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:29:23 [INFO]   Training abgeschlossen in 7.66s (Backend: cuml)\n",
      "12:30:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:30:38 [INFO]   Training abgeschlossen in 7.90s (Backend: cuml)\n",
      "12:31:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:31:52 [INFO]   Training abgeschlossen in 8.13s (Backend: cuml)\n",
      "12:32:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:33:07 [INFO]   Training abgeschlossen in 8.53s (Backend: cuml)\n",
      "12:34:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:34:21 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "12:35:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:35:35 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "12:36:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:36:51 [INFO]   Training abgeschlossen in 9.15s (Backend: cuml)\n",
      "12:37:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:38:05 [INFO]   Training abgeschlossen in 9.19s (Backend: cuml)\n",
      "12:39:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:39:18 [INFO]   Training abgeschlossen in 9.39s (Backend: cuml)\n",
      "12:40:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:40:32 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "12:41:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:41:45 [INFO]   Training abgeschlossen in 9.87s (Backend: cuml)\n",
      "12:42:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:42:59 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "12:44:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:44:12 [INFO]   Training abgeschlossen in 10.36s (Backend: cuml)\n",
      "12:45:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:45:25 [INFO]   Training abgeschlossen in 10.67s (Backend: cuml)\n",
      "12:46:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:46:37 [INFO]   Training abgeschlossen in 10.74s (Backend: cuml)\n",
      "12:47:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:47:50 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "12:48:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:49:02 [INFO]   Training abgeschlossen in 11.26s (Backend: cuml)\n",
      "12:50:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:50:14 [INFO]   Training abgeschlossen in 11.43s (Backend: cuml)\n",
      "12:51:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:51:26 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "12:52:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:52:38 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "12:53:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:53:49 [INFO]   Training abgeschlossen in 12.04s (Backend: cuml)\n",
      "12:54:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:55:00 [INFO]   Training abgeschlossen in 12.30s (Backend: cuml)\n",
      "12:55:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:56:11 [INFO]   Training abgeschlossen in 12.46s (Backend: cuml)\n",
      "12:57:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:57:22 [INFO]   Training abgeschlossen in 12.69s (Backend: cuml)\n",
      "12:58:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:58:32 [INFO]   Training abgeschlossen in 13.03s (Backend: cuml)\n",
      "12:59:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:59:42 [INFO]   Training abgeschlossen in 13.13s (Backend: cuml)\n",
      "13:00:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:00:52 [INFO]   Training abgeschlossen in 13.24s (Backend: cuml)\n",
      "13:01:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:02:01 [INFO]   Training abgeschlossen in 13.50s (Backend: cuml)\n",
      "13:02:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:03:11 [INFO]   Training abgeschlossen in 13.94s (Backend: cuml)\n",
      "13:04:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:04:20 [INFO]   Training abgeschlossen in 14.08s (Backend: cuml)\n",
      "13:05:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:05:29 [INFO]   Training abgeschlossen in 14.10s (Backend: cuml)\n",
      "13:06:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:06:37 [INFO]   Training abgeschlossen in 14.35s (Backend: cuml)\n",
      "13:07:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:07:45 [INFO]   Training abgeschlossen in 14.58s (Backend: cuml)\n",
      "13:08:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:08:53 [INFO]   Training abgeschlossen in 14.74s (Backend: cuml)\n",
      "13:09:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:10:01 [INFO]   Training abgeschlossen in 14.71s (Backend: cuml)\n",
      "13:10:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:11:08 [INFO]   Training abgeschlossen in 14.94s (Backend: cuml)\n",
      "13:11:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:12:14 [INFO]   Training abgeschlossen in 15.09s (Backend: cuml)\n",
      "13:13:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:13:21 [INFO]   Training abgeschlossen in 15.24s (Backend: cuml)\n",
      "13:14:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:14:28 [INFO]   Training abgeschlossen in 15.51s (Backend: cuml)\n",
      "13:15:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:15:34 [INFO]   Training abgeschlossen in 15.85s (Backend: cuml)\n",
      "13:16:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:16:40 [INFO]   Training abgeschlossen in 16.20s (Backend: cuml)\n",
      "13:17:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:17:45 [INFO]   Training abgeschlossen in 16.08s (Backend: cuml)\n",
      "13:18:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:18:50 [INFO]   Training abgeschlossen in 16.28s (Backend: cuml)\n",
      "13:19:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:19:54 [INFO]   Training abgeschlossen in 16.53s (Backend: cuml)\n",
      "13:20:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:20:59 [INFO]   Training abgeschlossen in 16.78s (Backend: cuml)\n",
      "13:21:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:22:03 [INFO]   Training abgeschlossen in 17.07s (Backend: cuml)\n",
      "13:22:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:23:07 [INFO]   Training abgeschlossen in 17.39s (Backend: cuml)\n",
      "13:23:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:24:11 [INFO]   Training abgeschlossen in 17.61s (Backend: cuml)\n",
      "13:24:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:25:14 [INFO]   Training abgeschlossen in 17.62s (Backend: cuml)\n",
      "13:25:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:26:17 [INFO]   Training abgeschlossen in 17.83s (Backend: cuml)\n",
      "13:27:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:27:20 [INFO]   Training abgeschlossen in 18.01s (Backend: cuml)\n",
      "13:28:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:28:22 [INFO]   Training abgeschlossen in 18.24s (Backend: cuml)\n",
      "13:29:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:29:24 [INFO]   Training abgeschlossen in 18.47s (Backend: cuml)\n",
      "13:30:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:30:26 [INFO]   Training abgeschlossen in 18.72s (Backend: cuml)\n",
      "13:31:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:31:28 [INFO]   Training abgeschlossen in 18.93s (Backend: cuml)\n",
      "13:32:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:32:29 [INFO]   Training abgeschlossen in 19.17s (Backend: cuml)\n",
      "13:33:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:33:30 [INFO]   Training abgeschlossen in 19.49s (Backend: cuml)\n",
      "13:34:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:34:31 [INFO]   Training abgeschlossen in 19.60s (Backend: cuml)\n",
      "13:35:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:35:31 [INFO]   Training abgeschlossen in 19.71s (Backend: cuml)\n",
      "13:36:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:36:31 [INFO]   Training abgeschlossen in 19.91s (Backend: cuml)\n",
      "13:37:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:37:30 [INFO]   Training abgeschlossen in 20.15s (Backend: cuml)\n",
      "13:38:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:38:30 [INFO]   Training abgeschlossen in 20.44s (Backend: cuml)\n",
      "13:39:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:39:29 [INFO]   Training abgeschlossen in 20.50s (Backend: cuml)\n",
      "13:40:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:40:27 [INFO]   Training abgeschlossen in 20.77s (Backend: cuml)\n",
      "13:41:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:41:26 [INFO]   Training abgeschlossen in 21.00s (Backend: cuml)\n",
      "13:42:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:42:24 [INFO]   Training abgeschlossen in 21.19s (Backend: cuml)\n",
      "13:43:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:43:22 [INFO]   Training abgeschlossen in 21.39s (Backend: cuml)\n",
      "13:43:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:44:19 [INFO]   Training abgeschlossen in 21.57s (Backend: cuml)\n",
      "13:44:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:45:16 [INFO]   Training abgeschlossen in 21.77s (Backend: cuml)\n",
      "13:45:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:46:13 [INFO]   Training abgeschlossen in 22.00s (Backend: cuml)\n",
      "13:46:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:47:10 [INFO]   Training abgeschlossen in 22.23s (Backend: cuml)\n",
      "13:47:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:48:06 [INFO]   Training abgeschlossen in 22.51s (Backend: cuml)\n",
      "13:48:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:49:02 [INFO]   Training abgeschlossen in 22.77s (Backend: cuml)\n",
      "13:49:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:49:58 [INFO]   Training abgeschlossen in 22.90s (Backend: cuml)\n",
      "13:50:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:50:53 [INFO]   Training abgeschlossen in 23.27s (Backend: cuml)\n",
      "13:51:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:51:49 [INFO]   Training abgeschlossen in 23.49s (Backend: cuml)\n",
      "13:52:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:52:43 [INFO]   Training abgeschlossen in 23.58s (Backend: cuml)\n",
      "13:53:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:53:38 [INFO]   Training abgeschlossen in 23.74s (Backend: cuml)\n",
      "13:54:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:54:31 [INFO]   Training abgeschlossen in 23.91s (Backend: cuml)\n",
      "13:55:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:55:25 [INFO]   Training abgeschlossen in 24.14s (Backend: cuml)\n",
      "13:55:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:56:18 [INFO]   Training abgeschlossen in 24.49s (Backend: cuml)\n",
      "13:56:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:57:11 [INFO]   Training abgeschlossen in 24.60s (Backend: cuml)\n",
      "13:57:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:58:03 [INFO]   Training abgeschlossen in 24.73s (Backend: cuml)\n",
      "13:58:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:58:55 [INFO]   Training abgeschlossen in 24.95s (Backend: cuml)\n",
      "13:59:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:59:47 [INFO]   Training abgeschlossen in 25.29s (Backend: cuml)\n",
      "14:00:13 [INFO]     48,000 labeled → Accuracy: 0.9658 (Train: 25.3s, Query: 14.34s) | GPU: 2.8/8.0 GB\n",
      "14:00:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:00:39 [INFO]   Training abgeschlossen in 25.50s (Backend: cuml)\n",
      "14:00:50 [INFO]     Final: 48,000 labeled → Accuracy: 0.9659, F1: 0.9657\n",
      "14:00:51 [INFO]   Run 4/5\n",
      "14:00:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:00:56 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "14:02:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:02:07 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "14:03:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:03:19 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "14:04:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "14:04:31 [INFO]   Training abgeschlossen in 5.06s (Backend: cuml)\n",
      "14:05:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:05:44 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "14:06:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:06:57 [INFO]   Training abgeschlossen in 5.61s (Backend: cuml)\n",
      "14:08:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:08:10 [INFO]   Training abgeschlossen in 5.96s (Backend: cuml)\n",
      "14:09:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:09:23 [INFO]   Training abgeschlossen in 6.40s (Backend: cuml)\n",
      "14:10:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:10:37 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "14:11:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:11:51 [INFO]   Training abgeschlossen in 7.36s (Backend: cuml)\n",
      "14:12:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:13:05 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "14:14:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:14:20 [INFO]   Training abgeschlossen in 7.99s (Backend: cuml)\n",
      "14:15:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:15:35 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "14:16:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:16:49 [INFO]   Training abgeschlossen in 8.36s (Backend: cuml)\n",
      "14:17:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:18:04 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "14:19:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:19:20 [INFO]   Training abgeschlossen in 8.90s (Backend: cuml)\n",
      "14:20:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:20:34 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "14:21:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:21:48 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "14:22:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:23:01 [INFO]   Training abgeschlossen in 9.57s (Backend: cuml)\n",
      "14:24:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:24:15 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "14:25:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:25:29 [INFO]   Training abgeschlossen in 9.91s (Backend: cuml)\n",
      "14:26:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:26:42 [INFO]   Training abgeschlossen in 10.16s (Backend: cuml)\n",
      "14:27:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:27:56 [INFO]   Training abgeschlossen in 10.48s (Backend: cuml)\n",
      "14:28:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:29:09 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "14:30:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:30:21 [INFO]   Training abgeschlossen in 10.75s (Backend: cuml)\n",
      "14:31:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:31:33 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "14:32:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:32:46 [INFO]   Training abgeschlossen in 11.36s (Backend: cuml)\n",
      "14:33:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:33:58 [INFO]   Training abgeschlossen in 11.38s (Backend: cuml)\n",
      "14:34:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:35:10 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "14:36:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:36:21 [INFO]   Training abgeschlossen in 11.83s (Backend: cuml)\n",
      "14:37:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:37:34 [INFO]   Training abgeschlossen in 12.16s (Backend: cuml)\n",
      "14:38:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:38:46 [INFO]   Training abgeschlossen in 12.24s (Backend: cuml)\n",
      "14:39:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:39:58 [INFO]   Training abgeschlossen in 12.47s (Backend: cuml)\n",
      "14:40:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:41:10 [INFO]   Training abgeschlossen in 12.75s (Backend: cuml)\n",
      "14:42:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:42:21 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "14:43:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:43:31 [INFO]   Training abgeschlossen in 13.10s (Backend: cuml)\n",
      "14:44:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:44:41 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "14:45:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:45:51 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "14:46:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:47:01 [INFO]   Training abgeschlossen in 13.84s (Backend: cuml)\n",
      "14:47:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:48:10 [INFO]   Training abgeschlossen in 13.96s (Backend: cuml)\n",
      "14:49:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:49:19 [INFO]   Training abgeschlossen in 14.11s (Backend: cuml)\n",
      "14:50:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:50:27 [INFO]   Training abgeschlossen in 14.35s (Backend: cuml)\n",
      "14:51:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:51:35 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "14:52:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:52:43 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "14:53:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:53:51 [INFO]   Training abgeschlossen in 14.63s (Backend: cuml)\n",
      "14:54:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:54:58 [INFO]   Training abgeschlossen in 14.88s (Backend: cuml)\n",
      "14:55:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:56:04 [INFO]   Training abgeschlossen in 15.15s (Backend: cuml)\n",
      "14:56:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:57:11 [INFO]   Training abgeschlossen in 15.37s (Backend: cuml)\n",
      "14:58:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:58:18 [INFO]   Training abgeschlossen in 15.69s (Backend: cuml)\n",
      "14:59:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:59:24 [INFO]   Training abgeschlossen in 15.77s (Backend: cuml)\n",
      "15:00:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:00:30 [INFO]   Training abgeschlossen in 16.24s (Backend: cuml)\n",
      "15:01:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:01:35 [INFO]   Training abgeschlossen in 16.12s (Backend: cuml)\n",
      "15:02:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:02:40 [INFO]   Training abgeschlossen in 16.44s (Backend: cuml)\n",
      "15:03:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:03:46 [INFO]   Training abgeschlossen in 16.89s (Backend: cuml)\n",
      "15:04:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:04:52 [INFO]   Training abgeschlossen in 16.98s (Backend: cuml)\n",
      "15:05:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:05:57 [INFO]   Training abgeschlossen in 16.97s (Backend: cuml)\n",
      "15:06:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:07:02 [INFO]   Training abgeschlossen in 17.17s (Backend: cuml)\n",
      "15:07:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:08:06 [INFO]   Training abgeschlossen in 17.46s (Backend: cuml)\n",
      "15:08:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:09:10 [INFO]   Training abgeschlossen in 17.58s (Backend: cuml)\n",
      "15:09:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:10:13 [INFO]   Training abgeschlossen in 17.85s (Backend: cuml)\n",
      "15:10:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:11:15 [INFO]   Training abgeschlossen in 18.06s (Backend: cuml)\n",
      "15:11:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:12:18 [INFO]   Training abgeschlossen in 18.40s (Backend: cuml)\n",
      "15:13:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:13:20 [INFO]   Training abgeschlossen in 18.83s (Backend: cuml)\n",
      "15:14:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:14:22 [INFO]   Training abgeschlossen in 18.75s (Backend: cuml)\n",
      "15:15:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:15:24 [INFO]   Training abgeschlossen in 19.04s (Backend: cuml)\n",
      "15:16:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:16:25 [INFO]   Training abgeschlossen in 19.20s (Backend: cuml)\n",
      "15:17:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:17:26 [INFO]   Training abgeschlossen in 19.55s (Backend: cuml)\n",
      "15:18:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:18:27 [INFO]   Training abgeschlossen in 19.71s (Backend: cuml)\n",
      "15:19:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:19:27 [INFO]   Training abgeschlossen in 19.76s (Backend: cuml)\n",
      "15:20:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:20:27 [INFO]   Training abgeschlossen in 20.04s (Backend: cuml)\n",
      "15:21:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:21:27 [INFO]   Training abgeschlossen in 20.30s (Backend: cuml)\n",
      "15:22:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:22:26 [INFO]   Training abgeschlossen in 20.49s (Backend: cuml)\n",
      "15:23:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:23:25 [INFO]   Training abgeschlossen in 20.62s (Backend: cuml)\n",
      "15:24:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:24:24 [INFO]   Training abgeschlossen in 20.97s (Backend: cuml)\n",
      "15:25:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:25:23 [INFO]   Training abgeschlossen in 21.14s (Backend: cuml)\n",
      "15:26:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:26:21 [INFO]   Training abgeschlossen in 21.44s (Backend: cuml)\n",
      "15:26:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:27:19 [INFO]   Training abgeschlossen in 21.56s (Backend: cuml)\n",
      "15:27:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:28:17 [INFO]   Training abgeschlossen in 21.91s (Backend: cuml)\n",
      "15:28:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:29:14 [INFO]   Training abgeschlossen in 21.99s (Backend: cuml)\n",
      "15:29:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:30:12 [INFO]   Training abgeschlossen in 22.27s (Backend: cuml)\n",
      "15:30:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:31:08 [INFO]   Training abgeschlossen in 22.42s (Backend: cuml)\n",
      "15:31:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:32:05 [INFO]   Training abgeschlossen in 22.58s (Backend: cuml)\n",
      "15:32:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:33:01 [INFO]   Training abgeschlossen in 22.92s (Backend: cuml)\n",
      "15:33:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:33:56 [INFO]   Training abgeschlossen in 22.93s (Backend: cuml)\n",
      "15:34:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:34:51 [INFO]   Training abgeschlossen in 23.12s (Backend: cuml)\n",
      "15:35:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:35:46 [INFO]   Training abgeschlossen in 23.39s (Backend: cuml)\n",
      "15:36:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:36:41 [INFO]   Training abgeschlossen in 23.57s (Backend: cuml)\n",
      "15:37:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:37:35 [INFO]   Training abgeschlossen in 23.92s (Backend: cuml)\n",
      "15:38:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:38:29 [INFO]   Training abgeschlossen in 24.06s (Backend: cuml)\n",
      "15:38:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:39:23 [INFO]   Training abgeschlossen in 24.30s (Backend: cuml)\n",
      "15:39:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:40:16 [INFO]   Training abgeschlossen in 24.54s (Backend: cuml)\n",
      "15:40:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:41:09 [INFO]   Training abgeschlossen in 24.68s (Backend: cuml)\n",
      "15:41:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:42:02 [INFO]   Training abgeschlossen in 24.86s (Backend: cuml)\n",
      "15:42:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:42:54 [INFO]   Training abgeschlossen in 25.17s (Backend: cuml)\n",
      "15:43:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:43:46 [INFO]   Training abgeschlossen in 25.30s (Backend: cuml)\n",
      "15:44:12 [INFO]     48,000 labeled → Accuracy: 0.9666 (Train: 25.3s, Query: 14.38s) | GPU: 2.8/8.0 GB\n",
      "15:44:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:44:38 [INFO]   Training abgeschlossen in 25.42s (Backend: cuml)\n",
      "15:44:49 [INFO]     Final: 48,000 labeled → Accuracy: 0.9663, F1: 0.9661\n",
      "15:44:49 [INFO]   Run 5/5\n",
      "15:44:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:44:54 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "15:46:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:46:06 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "15:47:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:47:17 [INFO]   Training abgeschlossen in 5.04s (Backend: cuml)\n",
      "15:48:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "15:48:30 [INFO]   Training abgeschlossen in 5.35s (Backend: cuml)\n",
      "15:49:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:49:42 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "15:50:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:50:55 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "15:52:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:52:09 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "15:53:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:53:22 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "15:54:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:54:36 [INFO]   Training abgeschlossen in 6.91s (Backend: cuml)\n",
      "15:55:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:55:50 [INFO]   Training abgeschlossen in 7.17s (Backend: cuml)\n",
      "15:56:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:57:04 [INFO]   Training abgeschlossen in 7.52s (Backend: cuml)\n",
      "15:58:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:58:18 [INFO]   Training abgeschlossen in 7.94s (Backend: cuml)\n",
      "15:59:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:59:33 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "16:00:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:00:47 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "16:01:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:02:01 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "16:03:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:03:17 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "16:04:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:04:31 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "16:05:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:05:45 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "16:06:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:06:59 [INFO]   Training abgeschlossen in 9.48s (Backend: cuml)\n",
      "16:08:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:08:12 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "16:09:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:09:26 [INFO]   Training abgeschlossen in 9.88s (Backend: cuml)\n",
      "16:10:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:10:40 [INFO]   Training abgeschlossen in 10.15s (Backend: cuml)\n",
      "16:11:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:11:54 [INFO]   Training abgeschlossen in 10.34s (Backend: cuml)\n",
      "16:12:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:13:08 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "16:14:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:14:21 [INFO]   Training abgeschlossen in 10.79s (Backend: cuml)\n",
      "16:15:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:15:35 [INFO]   Training abgeschlossen in 11.05s (Backend: cuml)\n",
      "16:16:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:16:48 [INFO]   Training abgeschlossen in 11.27s (Backend: cuml)\n",
      "16:17:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:18:02 [INFO]   Training abgeschlossen in 11.45s (Backend: cuml)\n",
      "16:19:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:19:15 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "16:20:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:20:27 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "16:21:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:21:40 [INFO]   Training abgeschlossen in 12.05s (Backend: cuml)\n",
      "16:22:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:22:51 [INFO]   Training abgeschlossen in 12.21s (Backend: cuml)\n",
      "16:23:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:24:02 [INFO]   Training abgeschlossen in 12.66s (Backend: cuml)\n",
      "16:25:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:25:13 [INFO]   Training abgeschlossen in 12.64s (Backend: cuml)\n",
      "16:26:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:26:23 [INFO]   Training abgeschlossen in 12.86s (Backend: cuml)\n",
      "16:27:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:27:34 [INFO]   Training abgeschlossen in 13.09s (Backend: cuml)\n",
      "16:28:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:28:45 [INFO]   Training abgeschlossen in 13.42s (Backend: cuml)\n",
      "16:29:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:29:55 [INFO]   Training abgeschlossen in 13.51s (Backend: cuml)\n",
      "16:30:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:31:06 [INFO]   Training abgeschlossen in 13.68s (Backend: cuml)\n",
      "16:32:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:32:16 [INFO]   Training abgeschlossen in 13.89s (Backend: cuml)\n",
      "16:33:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:33:25 [INFO]   Training abgeschlossen in 14.15s (Backend: cuml)\n",
      "16:34:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:34:35 [INFO]   Training abgeschlossen in 14.33s (Backend: cuml)\n",
      "16:35:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:35:44 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "16:36:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:36:53 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "16:37:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:38:01 [INFO]   Training abgeschlossen in 14.79s (Backend: cuml)\n",
      "16:38:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:39:08 [INFO]   Training abgeschlossen in 15.01s (Backend: cuml)\n",
      "16:40:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:40:15 [INFO]   Training abgeschlossen in 15.11s (Backend: cuml)\n",
      "16:41:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:41:21 [INFO]   Training abgeschlossen in 15.25s (Backend: cuml)\n",
      "16:42:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:42:28 [INFO]   Training abgeschlossen in 15.58s (Backend: cuml)\n",
      "16:43:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:43:34 [INFO]   Training abgeschlossen in 15.76s (Backend: cuml)\n",
      "16:44:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:44:39 [INFO]   Training abgeschlossen in 16.15s (Backend: cuml)\n",
      "16:45:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:45:45 [INFO]   Training abgeschlossen in 16.37s (Backend: cuml)\n",
      "16:46:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:46:51 [INFO]   Training abgeschlossen in 16.33s (Backend: cuml)\n",
      "16:47:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:47:56 [INFO]   Training abgeschlossen in 16.57s (Backend: cuml)\n",
      "16:48:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:49:02 [INFO]   Training abgeschlossen in 16.86s (Backend: cuml)\n",
      "16:49:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:50:06 [INFO]   Training abgeschlossen in 16.98s (Backend: cuml)\n",
      "16:50:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:51:11 [INFO]   Training abgeschlossen in 17.27s (Backend: cuml)\n",
      "16:51:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:52:16 [INFO]   Training abgeschlossen in 17.58s (Backend: cuml)\n",
      "16:53:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:53:20 [INFO]   Training abgeschlossen in 17.86s (Backend: cuml)\n",
      "16:54:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:54:24 [INFO]   Training abgeschlossen in 17.96s (Backend: cuml)\n",
      "16:55:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:55:27 [INFO]   Training abgeschlossen in 18.24s (Backend: cuml)\n",
      "16:56:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:56:29 [INFO]   Training abgeschlossen in 18.45s (Backend: cuml)\n",
      "16:57:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:57:32 [INFO]   Training abgeschlossen in 18.62s (Backend: cuml)\n",
      "16:58:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:58:33 [INFO]   Training abgeschlossen in 18.72s (Backend: cuml)\n",
      "16:59:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:59:35 [INFO]   Training abgeschlossen in 18.93s (Backend: cuml)\n",
      "17:00:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:00:36 [INFO]   Training abgeschlossen in 19.19s (Backend: cuml)\n",
      "17:01:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:01:38 [INFO]   Training abgeschlossen in 19.55s (Backend: cuml)\n",
      "17:02:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:02:39 [INFO]   Training abgeschlossen in 19.85s (Backend: cuml)\n",
      "17:03:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:03:39 [INFO]   Training abgeschlossen in 19.91s (Backend: cuml)\n",
      "17:04:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:04:40 [INFO]   Training abgeschlossen in 20.17s (Backend: cuml)\n",
      "17:05:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:05:39 [INFO]   Training abgeschlossen in 20.19s (Backend: cuml)\n",
      "17:06:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:06:38 [INFO]   Training abgeschlossen in 20.42s (Backend: cuml)\n",
      "17:07:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:07:38 [INFO]   Training abgeschlossen in 20.58s (Backend: cuml)\n",
      "17:08:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:08:36 [INFO]   Training abgeschlossen in 20.90s (Backend: cuml)\n",
      "17:09:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:09:35 [INFO]   Training abgeschlossen in 21.17s (Backend: cuml)\n",
      "17:10:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:10:33 [INFO]   Training abgeschlossen in 21.31s (Backend: cuml)\n",
      "17:11:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:11:31 [INFO]   Training abgeschlossen in 21.58s (Backend: cuml)\n",
      "17:12:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:12:28 [INFO]   Training abgeschlossen in 21.67s (Backend: cuml)\n",
      "17:13:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:13:26 [INFO]   Training abgeschlossen in 21.98s (Backend: cuml)\n",
      "17:14:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:14:23 [INFO]   Training abgeschlossen in 22.16s (Backend: cuml)\n",
      "17:14:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:15:20 [INFO]   Training abgeschlossen in 22.36s (Backend: cuml)\n",
      "17:15:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:16:16 [INFO]   Training abgeschlossen in 22.39s (Backend: cuml)\n",
      "17:16:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:17:11 [INFO]   Training abgeschlossen in 22.76s (Backend: cuml)\n",
      "17:17:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:18:07 [INFO]   Training abgeschlossen in 23.00s (Backend: cuml)\n",
      "17:18:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:19:03 [INFO]   Training abgeschlossen in 23.27s (Backend: cuml)\n",
      "17:19:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:19:58 [INFO]   Training abgeschlossen in 23.37s (Backend: cuml)\n",
      "17:20:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:20:52 [INFO]   Training abgeschlossen in 23.55s (Backend: cuml)\n",
      "17:21:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:21:46 [INFO]   Training abgeschlossen in 23.79s (Backend: cuml)\n",
      "17:22:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:22:40 [INFO]   Training abgeschlossen in 23.93s (Backend: cuml)\n",
      "17:23:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:23:34 [INFO]   Training abgeschlossen in 24.16s (Backend: cuml)\n",
      "17:24:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:24:28 [INFO]   Training abgeschlossen in 24.48s (Backend: cuml)\n",
      "17:24:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:25:20 [INFO]   Training abgeschlossen in 24.71s (Backend: cuml)\n",
      "17:25:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:26:13 [INFO]   Training abgeschlossen in 24.82s (Backend: cuml)\n",
      "17:26:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:27:05 [INFO]   Training abgeschlossen in 25.13s (Backend: cuml)\n",
      "17:27:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:27:57 [INFO]   Training abgeschlossen in 25.36s (Backend: cuml)\n",
      "17:28:23 [INFO]     48,000 labeled → Accuracy: 0.9669 (Train: 25.4s, Query: 14.17s) | GPU: 2.8/8.0 GB\n",
      "17:28:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:28:49 [INFO]   Training abgeschlossen in 25.62s (Backend: cuml)\n",
      "17:29:00 [INFO]     Final: 48,000 labeled → Accuracy: 0.9667, F1: 0.9665\n",
      "17:29:00 [INFO] \n",
      "GPU-SVM + Least Confidence - Budget: 100% (60,000 Samples)\n",
      "17:29:00 [INFO]   Run 1/5\n",
      "17:29:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:29:05 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "17:30:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "17:30:17 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "17:31:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "17:31:29 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "17:32:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "17:32:42 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "17:33:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:33:55 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "17:35:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:35:07 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "17:36:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:36:21 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "17:37:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:37:34 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "17:38:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:38:48 [INFO]   Training abgeschlossen in 6.87s (Backend: cuml)\n",
      "17:39:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:40:02 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "17:41:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:41:16 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "17:42:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:42:31 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "17:43:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:43:45 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "17:44:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:45:00 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "17:46:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:46:14 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "17:47:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:47:28 [INFO]   Training abgeschlossen in 8.91s (Backend: cuml)\n",
      "17:48:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:48:43 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "17:49:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:49:57 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "17:51:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:51:10 [INFO]   Training abgeschlossen in 9.53s (Backend: cuml)\n",
      "17:52:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:52:24 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "17:53:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:53:38 [INFO]   Training abgeschlossen in 9.90s (Backend: cuml)\n",
      "17:54:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:54:52 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "17:55:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:56:07 [INFO]   Training abgeschlossen in 10.37s (Backend: cuml)\n",
      "17:57:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:57:20 [INFO]   Training abgeschlossen in 10.58s (Backend: cuml)\n",
      "17:58:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:58:32 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "17:59:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:59:45 [INFO]   Training abgeschlossen in 11.11s (Backend: cuml)\n",
      "18:00:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:00:57 [INFO]   Training abgeschlossen in 11.24s (Backend: cuml)\n",
      "18:01:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:02:09 [INFO]   Training abgeschlossen in 11.39s (Backend: cuml)\n",
      "18:03:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:03:21 [INFO]   Training abgeschlossen in 11.66s (Backend: cuml)\n",
      "18:04:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:04:33 [INFO]   Training abgeschlossen in 11.87s (Backend: cuml)\n",
      "18:05:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:05:46 [INFO]   Training abgeschlossen in 12.03s (Backend: cuml)\n",
      "18:06:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:06:57 [INFO]   Training abgeschlossen in 12.28s (Backend: cuml)\n",
      "18:07:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:08:08 [INFO]   Training abgeschlossen in 12.50s (Backend: cuml)\n",
      "18:09:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:09:19 [INFO]   Training abgeschlossen in 12.82s (Backend: cuml)\n",
      "18:10:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:10:29 [INFO]   Training abgeschlossen in 12.98s (Backend: cuml)\n",
      "18:11:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:11:39 [INFO]   Training abgeschlossen in 13.16s (Backend: cuml)\n",
      "18:12:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:12:49 [INFO]   Training abgeschlossen in 13.25s (Backend: cuml)\n",
      "18:13:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:13:59 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "18:14:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:15:08 [INFO]   Training abgeschlossen in 13.74s (Backend: cuml)\n",
      "18:16:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:16:17 [INFO]   Training abgeschlossen in 13.90s (Backend: cuml)\n",
      "18:17:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:17:26 [INFO]   Training abgeschlossen in 14.10s (Backend: cuml)\n",
      "18:18:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:18:34 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "18:19:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:19:43 [INFO]   Training abgeschlossen in 14.71s (Backend: cuml)\n",
      "18:20:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:20:50 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "18:21:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:21:58 [INFO]   Training abgeschlossen in 14.74s (Backend: cuml)\n",
      "18:22:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:23:05 [INFO]   Training abgeschlossen in 14.91s (Backend: cuml)\n",
      "18:23:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:24:12 [INFO]   Training abgeschlossen in 15.30s (Backend: cuml)\n",
      "18:25:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:25:19 [INFO]   Training abgeschlossen in 15.43s (Backend: cuml)\n",
      "18:26:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:26:25 [INFO]   Training abgeschlossen in 15.57s (Backend: cuml)\n",
      "18:27:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:27:31 [INFO]   Training abgeschlossen in 15.64s (Backend: cuml)\n",
      "18:28:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:28:37 [INFO]   Training abgeschlossen in 16.14s (Backend: cuml)\n",
      "18:29:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:29:42 [INFO]   Training abgeschlossen in 16.15s (Backend: cuml)\n",
      "18:30:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:30:47 [INFO]   Training abgeschlossen in 16.42s (Backend: cuml)\n",
      "18:31:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:31:53 [INFO]   Training abgeschlossen in 16.69s (Backend: cuml)\n",
      "18:32:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:32:57 [INFO]   Training abgeschlossen in 16.82s (Backend: cuml)\n",
      "18:33:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:34:01 [INFO]   Training abgeschlossen in 16.95s (Backend: cuml)\n",
      "18:34:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:35:05 [INFO]   Training abgeschlossen in 17.22s (Backend: cuml)\n",
      "18:35:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:36:10 [INFO]   Training abgeschlossen in 17.52s (Backend: cuml)\n",
      "18:36:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:37:13 [INFO]   Training abgeschlossen in 17.76s (Backend: cuml)\n",
      "18:37:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:38:17 [INFO]   Training abgeschlossen in 18.17s (Backend: cuml)\n",
      "18:39:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:39:20 [INFO]   Training abgeschlossen in 18.17s (Backend: cuml)\n",
      "18:40:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:40:22 [INFO]   Training abgeschlossen in 18.43s (Backend: cuml)\n",
      "18:41:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:41:24 [INFO]   Training abgeschlossen in 18.58s (Backend: cuml)\n",
      "18:42:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:42:26 [INFO]   Training abgeschlossen in 18.69s (Backend: cuml)\n",
      "18:43:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:43:28 [INFO]   Training abgeschlossen in 18.98s (Backend: cuml)\n",
      "18:44:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:44:29 [INFO]   Training abgeschlossen in 19.18s (Backend: cuml)\n",
      "18:45:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:45:31 [INFO]   Training abgeschlossen in 19.41s (Backend: cuml)\n",
      "18:46:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:46:31 [INFO]   Training abgeschlossen in 19.59s (Backend: cuml)\n",
      "18:47:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:47:32 [INFO]   Training abgeschlossen in 19.82s (Backend: cuml)\n",
      "18:48:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:48:32 [INFO]   Training abgeschlossen in 20.03s (Backend: cuml)\n",
      "18:49:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:49:31 [INFO]   Training abgeschlossen in 20.39s (Backend: cuml)\n",
      "18:50:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:50:31 [INFO]   Training abgeschlossen in 20.62s (Backend: cuml)\n",
      "18:51:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:51:30 [INFO]   Training abgeschlossen in 20.76s (Backend: cuml)\n",
      "18:52:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:52:29 [INFO]   Training abgeschlossen in 21.12s (Backend: cuml)\n",
      "18:53:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:53:28 [INFO]   Training abgeschlossen in 21.36s (Backend: cuml)\n",
      "18:54:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:54:26 [INFO]   Training abgeschlossen in 21.22s (Backend: cuml)\n",
      "18:55:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:55:24 [INFO]   Training abgeschlossen in 21.47s (Backend: cuml)\n",
      "18:56:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:56:21 [INFO]   Training abgeschlossen in 21.65s (Backend: cuml)\n",
      "18:56:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:57:19 [INFO]   Training abgeschlossen in 21.99s (Backend: cuml)\n",
      "18:57:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:58:16 [INFO]   Training abgeschlossen in 22.07s (Backend: cuml)\n",
      "18:58:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:59:12 [INFO]   Training abgeschlossen in 22.37s (Backend: cuml)\n",
      "18:59:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:00:09 [INFO]   Training abgeschlossen in 22.73s (Backend: cuml)\n",
      "19:00:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:01:05 [INFO]   Training abgeschlossen in 22.85s (Backend: cuml)\n",
      "19:01:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:02:01 [INFO]   Training abgeschlossen in 23.09s (Backend: cuml)\n",
      "19:02:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:02:56 [INFO]   Training abgeschlossen in 23.34s (Backend: cuml)\n",
      "19:03:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:03:51 [INFO]   Training abgeschlossen in 23.45s (Backend: cuml)\n",
      "19:04:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:04:46 [INFO]   Training abgeschlossen in 23.69s (Backend: cuml)\n",
      "19:05:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:05:41 [INFO]   Training abgeschlossen in 23.85s (Backend: cuml)\n",
      "19:06:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:06:35 [INFO]   Training abgeschlossen in 24.18s (Backend: cuml)\n",
      "19:07:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:07:29 [INFO]   Training abgeschlossen in 24.33s (Backend: cuml)\n",
      "19:07:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:08:22 [INFO]   Training abgeschlossen in 24.47s (Backend: cuml)\n",
      "19:08:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:09:15 [INFO]   Training abgeschlossen in 24.79s (Backend: cuml)\n",
      "19:09:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:10:07 [INFO]   Training abgeschlossen in 24.89s (Backend: cuml)\n",
      "19:10:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:11:00 [INFO]   Training abgeschlossen in 25.18s (Backend: cuml)\n",
      "19:11:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:11:52 [INFO]   Training abgeschlossen in 25.31s (Backend: cuml)\n",
      "19:12:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:12:43 [INFO]   Training abgeschlossen in 25.39s (Backend: cuml)\n",
      "19:13:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:13:34 [INFO]   Training abgeschlossen in 25.72s (Backend: cuml)\n",
      "19:13:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:14:25 [INFO]   Training abgeschlossen in 25.80s (Backend: cuml)\n",
      "19:14:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:15:15 [INFO]   Training abgeschlossen in 26.13s (Backend: cuml)\n",
      "19:15:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:16:19 [INFO]   Training abgeschlossen in 40.02s (Backend: cuml)\n",
      "19:16:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:17:22 [INFO]   Training abgeschlossen in 39.34s (Backend: cuml)\n",
      "19:17:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:18:23 [INFO]   Training abgeschlossen in 38.40s (Backend: cuml)\n",
      "19:18:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:19:25 [INFO]   Training abgeschlossen in 39.80s (Backend: cuml)\n",
      "19:19:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:20:29 [INFO]   Training abgeschlossen in 43.12s (Backend: cuml)\n",
      "19:20:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:21:30 [INFO]   Training abgeschlossen in 39.88s (Backend: cuml)\n",
      "19:21:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:22:33 [INFO]   Training abgeschlossen in 42.74s (Backend: cuml)\n",
      "19:22:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:23:35 [INFO]   Training abgeschlossen in 42.06s (Backend: cuml)\n",
      "19:23:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:24:36 [INFO]   Training abgeschlossen in 42.03s (Backend: cuml)\n",
      "19:24:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:25:37 [INFO]   Training abgeschlossen in 42.06s (Backend: cuml)\n",
      "19:25:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:26:36 [INFO]   Training abgeschlossen in 40.59s (Backend: cuml)\n",
      "19:26:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:27:36 [INFO]   Training abgeschlossen in 42.12s (Backend: cuml)\n",
      "19:27:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:28:37 [INFO]   Training abgeschlossen in 44.01s (Backend: cuml)\n",
      "19:28:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:29:36 [INFO]   Training abgeschlossen in 42.47s (Backend: cuml)\n",
      "19:29:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:30:34 [INFO]   Training abgeschlossen in 42.61s (Backend: cuml)\n",
      "19:30:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:31:33 [INFO]   Training abgeschlossen in 43.03s (Backend: cuml)\n",
      "19:31:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:32:31 [INFO]   Training abgeschlossen in 43.77s (Backend: cuml)\n",
      "19:32:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:33:28 [INFO]   Training abgeschlossen in 42.30s (Backend: cuml)\n",
      "19:33:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:34:26 [INFO]   Training abgeschlossen in 44.65s (Backend: cuml)\n",
      "19:34:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:35:22 [INFO]   Training abgeschlossen in 43.41s (Backend: cuml)\n",
      "19:35:35 [INFO]     60,000 labeled → Accuracy: 0.9664 (Train: 43.4s, Query: 0.67s) | GPU: 2.8/8.0 GB\n",
      "19:35:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:36:20 [INFO]   Training abgeschlossen in 45.01s (Backend: cuml)\n",
      "19:36:32 [INFO]     Final: 60,000 labeled → Accuracy: 0.9663, F1: 0.9660\n",
      "19:36:32 [INFO]   Run 2/5\n",
      "19:36:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:36:37 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "19:37:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:37:48 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "19:38:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:39:00 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "19:40:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "19:40:13 [INFO]   Training abgeschlossen in 5.36s (Backend: cuml)\n",
      "19:41:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:41:25 [INFO]   Training abgeschlossen in 5.39s (Backend: cuml)\n",
      "19:42:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:42:38 [INFO]   Training abgeschlossen in 5.72s (Backend: cuml)\n",
      "19:43:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:43:52 [INFO]   Training abgeschlossen in 6.01s (Backend: cuml)\n",
      "19:44:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:45:05 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "19:46:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:46:19 [INFO]   Training abgeschlossen in 6.80s (Backend: cuml)\n",
      "19:47:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:47:33 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "19:48:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:48:48 [INFO]   Training abgeschlossen in 7.79s (Backend: cuml)\n",
      "19:49:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:50:02 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "19:51:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:51:17 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "19:52:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:52:32 [INFO]   Training abgeschlossen in 8.48s (Backend: cuml)\n",
      "19:53:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:53:47 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "19:54:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:55:01 [INFO]   Training abgeschlossen in 8.75s (Backend: cuml)\n",
      "19:56:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:56:15 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "19:57:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:57:30 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "19:58:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:58:43 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "19:59:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:59:57 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "20:01:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:01:11 [INFO]   Training abgeschlossen in 10.01s (Backend: cuml)\n",
      "20:02:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:02:24 [INFO]   Training abgeschlossen in 10.12s (Backend: cuml)\n",
      "20:03:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:03:37 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "20:04:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:04:50 [INFO]   Training abgeschlossen in 10.54s (Backend: cuml)\n",
      "20:05:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:06:03 [INFO]   Training abgeschlossen in 10.81s (Backend: cuml)\n",
      "20:07:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:07:15 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "20:08:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:08:28 [INFO]   Training abgeschlossen in 11.25s (Backend: cuml)\n",
      "20:09:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:09:40 [INFO]   Training abgeschlossen in 11.48s (Backend: cuml)\n",
      "20:10:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:10:52 [INFO]   Training abgeschlossen in 11.65s (Backend: cuml)\n",
      "20:11:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:12:04 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "20:13:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:13:16 [INFO]   Training abgeschlossen in 12.12s (Backend: cuml)\n",
      "20:14:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:14:28 [INFO]   Training abgeschlossen in 12.42s (Backend: cuml)\n",
      "20:15:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:15:39 [INFO]   Training abgeschlossen in 12.50s (Backend: cuml)\n",
      "20:16:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:16:49 [INFO]   Training abgeschlossen in 12.66s (Backend: cuml)\n",
      "20:17:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:18:00 [INFO]   Training abgeschlossen in 12.93s (Backend: cuml)\n",
      "20:18:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:19:10 [INFO]   Training abgeschlossen in 13.21s (Backend: cuml)\n",
      "20:20:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:20:20 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "20:21:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:21:31 [INFO]   Training abgeschlossen in 13.47s (Backend: cuml)\n",
      "20:22:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:22:41 [INFO]   Training abgeschlossen in 13.67s (Backend: cuml)\n",
      "20:23:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:23:51 [INFO]   Training abgeschlossen in 13.99s (Backend: cuml)\n",
      "20:24:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:25:01 [INFO]   Training abgeschlossen in 14.10s (Backend: cuml)\n",
      "20:25:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:26:10 [INFO]   Training abgeschlossen in 14.29s (Backend: cuml)\n",
      "20:27:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:27:20 [INFO]   Training abgeschlossen in 14.53s (Backend: cuml)\n",
      "20:28:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:28:27 [INFO]   Training abgeschlossen in 14.38s (Backend: cuml)\n",
      "20:29:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:29:35 [INFO]   Training abgeschlossen in 14.75s (Backend: cuml)\n",
      "20:30:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:30:42 [INFO]   Training abgeschlossen in 14.99s (Backend: cuml)\n",
      "20:31:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:31:49 [INFO]   Training abgeschlossen in 15.11s (Backend: cuml)\n",
      "20:32:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:32:55 [INFO]   Training abgeschlossen in 15.26s (Backend: cuml)\n",
      "20:33:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:34:01 [INFO]   Training abgeschlossen in 15.43s (Backend: cuml)\n",
      "20:34:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:35:07 [INFO]   Training abgeschlossen in 15.67s (Backend: cuml)\n",
      "20:35:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:36:13 [INFO]   Training abgeschlossen in 16.21s (Backend: cuml)\n",
      "20:37:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:37:18 [INFO]   Training abgeschlossen in 16.26s (Backend: cuml)\n",
      "20:38:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:38:24 [INFO]   Training abgeschlossen in 16.29s (Backend: cuml)\n",
      "20:39:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:39:29 [INFO]   Training abgeschlossen in 16.53s (Backend: cuml)\n",
      "20:40:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:40:33 [INFO]   Training abgeschlossen in 16.73s (Backend: cuml)\n",
      "20:41:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:41:38 [INFO]   Training abgeschlossen in 16.96s (Backend: cuml)\n",
      "20:42:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:42:41 [INFO]   Training abgeschlossen in 17.18s (Backend: cuml)\n",
      "20:43:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:43:45 [INFO]   Training abgeschlossen in 17.47s (Backend: cuml)\n",
      "20:44:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:44:49 [INFO]   Training abgeschlossen in 17.72s (Backend: cuml)\n",
      "20:45:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:45:53 [INFO]   Training abgeschlossen in 17.88s (Backend: cuml)\n",
      "20:46:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:46:55 [INFO]   Training abgeschlossen in 18.06s (Backend: cuml)\n",
      "20:47:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:47:58 [INFO]   Training abgeschlossen in 18.26s (Backend: cuml)\n",
      "20:48:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:49:00 [INFO]   Training abgeschlossen in 18.42s (Backend: cuml)\n",
      "20:49:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:50:02 [INFO]   Training abgeschlossen in 18.65s (Backend: cuml)\n",
      "20:50:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:51:03 [INFO]   Training abgeschlossen in 18.83s (Backend: cuml)\n",
      "20:51:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:52:04 [INFO]   Training abgeschlossen in 19.07s (Backend: cuml)\n",
      "20:52:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:53:05 [INFO]   Training abgeschlossen in 19.38s (Backend: cuml)\n",
      "20:53:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:54:06 [INFO]   Training abgeschlossen in 19.57s (Backend: cuml)\n",
      "20:54:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:55:07 [INFO]   Training abgeschlossen in 19.87s (Backend: cuml)\n",
      "20:55:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:56:07 [INFO]   Training abgeschlossen in 20.19s (Backend: cuml)\n",
      "20:56:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:57:06 [INFO]   Training abgeschlossen in 20.30s (Backend: cuml)\n",
      "20:57:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:58:06 [INFO]   Training abgeschlossen in 20.55s (Backend: cuml)\n",
      "20:58:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:59:05 [INFO]   Training abgeschlossen in 20.77s (Backend: cuml)\n",
      "20:59:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:00:04 [INFO]   Training abgeschlossen in 20.91s (Backend: cuml)\n",
      "21:00:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:01:02 [INFO]   Training abgeschlossen in 21.09s (Backend: cuml)\n",
      "21:01:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:02:00 [INFO]   Training abgeschlossen in 21.20s (Backend: cuml)\n",
      "21:02:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:02:58 [INFO]   Training abgeschlossen in 21.40s (Backend: cuml)\n",
      "21:03:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:03:56 [INFO]   Training abgeschlossen in 21.62s (Backend: cuml)\n",
      "21:04:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:04:53 [INFO]   Training abgeschlossen in 21.85s (Backend: cuml)\n",
      "21:05:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:05:50 [INFO]   Training abgeschlossen in 22.07s (Backend: cuml)\n",
      "21:06:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:06:47 [INFO]   Training abgeschlossen in 22.35s (Backend: cuml)\n",
      "21:07:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:07:43 [INFO]   Training abgeschlossen in 22.64s (Backend: cuml)\n",
      "21:08:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:08:39 [INFO]   Training abgeschlossen in 22.84s (Backend: cuml)\n",
      "21:09:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:09:35 [INFO]   Training abgeschlossen in 22.93s (Backend: cuml)\n",
      "21:10:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:10:30 [INFO]   Training abgeschlossen in 23.23s (Backend: cuml)\n",
      "21:11:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:11:25 [INFO]   Training abgeschlossen in 23.33s (Backend: cuml)\n",
      "21:11:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:12:20 [INFO]   Training abgeschlossen in 23.59s (Backend: cuml)\n",
      "21:12:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:13:14 [INFO]   Training abgeschlossen in 23.90s (Backend: cuml)\n",
      "21:13:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:14:08 [INFO]   Training abgeschlossen in 23.91s (Backend: cuml)\n",
      "21:14:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:15:02 [INFO]   Training abgeschlossen in 24.18s (Backend: cuml)\n",
      "21:15:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:15:55 [INFO]   Training abgeschlossen in 24.39s (Backend: cuml)\n",
      "21:16:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:16:47 [INFO]   Training abgeschlossen in 24.51s (Backend: cuml)\n",
      "21:17:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:17:40 [INFO]   Training abgeschlossen in 24.67s (Backend: cuml)\n",
      "21:18:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:18:32 [INFO]   Training abgeschlossen in 24.98s (Backend: cuml)\n",
      "21:18:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:19:24 [INFO]   Training abgeschlossen in 25.20s (Backend: cuml)\n",
      "21:19:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:20:15 [INFO]   Training abgeschlossen in 25.34s (Backend: cuml)\n",
      "21:20:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:21:06 [INFO]   Training abgeschlossen in 25.59s (Backend: cuml)\n",
      "21:21:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:21:57 [INFO]   Training abgeschlossen in 25.77s (Backend: cuml)\n",
      "21:22:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:22:47 [INFO]   Training abgeschlossen in 26.13s (Backend: cuml)\n",
      "21:23:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:23:52 [INFO]   Training abgeschlossen in 40.58s (Backend: cuml)\n",
      "21:24:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:24:56 [INFO]   Training abgeschlossen in 40.58s (Backend: cuml)\n",
      "21:25:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:25:57 [INFO]   Training abgeschlossen in 39.43s (Backend: cuml)\n",
      "21:26:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:27:01 [INFO]   Training abgeschlossen in 42.17s (Backend: cuml)\n",
      "21:27:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:28:04 [INFO]   Training abgeschlossen in 41.18s (Backend: cuml)\n",
      "21:28:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:29:07 [INFO]   Training abgeschlossen in 41.60s (Backend: cuml)\n",
      "21:29:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:30:08 [INFO]   Training abgeschlossen in 41.47s (Backend: cuml)\n",
      "21:30:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:31:09 [INFO]   Training abgeschlossen in 41.22s (Backend: cuml)\n",
      "21:31:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:32:11 [INFO]   Training abgeschlossen in 42.06s (Backend: cuml)\n",
      "21:32:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:33:10 [INFO]   Training abgeschlossen in 40.58s (Backend: cuml)\n",
      "21:33:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:34:08 [INFO]   Training abgeschlossen in 40.32s (Backend: cuml)\n",
      "21:34:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:35:08 [INFO]   Training abgeschlossen in 42.33s (Backend: cuml)\n",
      "21:35:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:36:07 [INFO]   Training abgeschlossen in 41.49s (Backend: cuml)\n",
      "21:36:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:37:05 [INFO]   Training abgeschlossen in 41.84s (Backend: cuml)\n",
      "21:37:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:38:04 [INFO]   Training abgeschlossen in 42.67s (Backend: cuml)\n",
      "21:38:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:39:03 [INFO]   Training abgeschlossen in 43.89s (Backend: cuml)\n",
      "21:39:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:40:01 [INFO]   Training abgeschlossen in 42.81s (Backend: cuml)\n",
      "21:40:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:41:00 [INFO]   Training abgeschlossen in 44.29s (Backend: cuml)\n",
      "21:41:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:41:59 [INFO]   Training abgeschlossen in 45.78s (Backend: cuml)\n",
      "21:42:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:42:53 [INFO]   Training abgeschlossen in 40.05s (Backend: cuml)\n",
      "21:43:05 [INFO]     60,000 labeled → Accuracy: 0.9670 (Train: 40.1s, Query: 0.69s) | GPU: 2.8/8.0 GB\n",
      "21:43:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:43:49 [INFO]   Training abgeschlossen in 43.94s (Backend: cuml)\n",
      "21:44:01 [INFO]     Final: 60,000 labeled → Accuracy: 0.9665, F1: 0.9663\n",
      "21:44:01 [INFO]   Run 3/5\n",
      "21:44:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:44:06 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "21:45:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:45:17 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "21:46:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:46:29 [INFO]   Training abgeschlossen in 5.02s (Backend: cuml)\n",
      "21:47:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "21:47:41 [INFO]   Training abgeschlossen in 5.16s (Backend: cuml)\n",
      "21:48:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:48:53 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "21:50:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:50:06 [INFO]   Training abgeschlossen in 5.65s (Backend: cuml)\n",
      "21:51:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:51:20 [INFO]   Training abgeschlossen in 5.88s (Backend: cuml)\n",
      "21:52:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:52:33 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "21:53:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:53:46 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "21:54:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:55:00 [INFO]   Training abgeschlossen in 7.21s (Backend: cuml)\n",
      "21:56:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:56:14 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "21:57:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:57:29 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "21:58:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:58:43 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "21:59:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:59:57 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "22:01:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:01:12 [INFO]   Training abgeschlossen in 8.66s (Backend: cuml)\n",
      "22:02:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:02:26 [INFO]   Training abgeschlossen in 8.78s (Backend: cuml)\n",
      "22:03:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:03:41 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "22:04:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:04:55 [INFO]   Training abgeschlossen in 9.29s (Backend: cuml)\n",
      "22:05:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:06:08 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "22:07:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:07:22 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "22:08:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:08:36 [INFO]   Training abgeschlossen in 9.89s (Backend: cuml)\n",
      "22:09:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:09:50 [INFO]   Training abgeschlossen in 10.16s (Backend: cuml)\n",
      "22:10:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:11:03 [INFO]   Training abgeschlossen in 10.37s (Backend: cuml)\n",
      "22:12:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:12:17 [INFO]   Training abgeschlossen in 10.63s (Backend: cuml)\n",
      "22:13:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:13:31 [INFO]   Training abgeschlossen in 10.93s (Backend: cuml)\n",
      "22:14:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:14:43 [INFO]   Training abgeschlossen in 10.94s (Backend: cuml)\n",
      "22:15:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:15:55 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "22:16:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:17:07 [INFO]   Training abgeschlossen in 11.35s (Backend: cuml)\n",
      "22:18:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:18:19 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "22:19:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:19:31 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "22:20:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:20:44 [INFO]   Training abgeschlossen in 11.99s (Backend: cuml)\n",
      "22:21:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:21:56 [INFO]   Training abgeschlossen in 12.24s (Backend: cuml)\n",
      "22:22:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:23:08 [INFO]   Training abgeschlossen in 12.55s (Backend: cuml)\n",
      "22:24:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:24:18 [INFO]   Training abgeschlossen in 12.70s (Backend: cuml)\n",
      "22:25:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:25:29 [INFO]   Training abgeschlossen in 12.95s (Backend: cuml)\n",
      "22:26:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:26:40 [INFO]   Training abgeschlossen in 13.18s (Backend: cuml)\n",
      "22:27:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:27:51 [INFO]   Training abgeschlossen in 13.42s (Backend: cuml)\n",
      "22:28:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:29:02 [INFO]   Training abgeschlossen in 13.50s (Backend: cuml)\n",
      "22:29:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:30:12 [INFO]   Training abgeschlossen in 13.66s (Backend: cuml)\n",
      "22:31:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:31:22 [INFO]   Training abgeschlossen in 13.96s (Backend: cuml)\n",
      "22:32:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:32:32 [INFO]   Training abgeschlossen in 14.21s (Backend: cuml)\n",
      "22:33:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:33:41 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "22:34:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:34:51 [INFO]   Training abgeschlossen in 14.59s (Backend: cuml)\n",
      "22:35:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:35:58 [INFO]   Training abgeschlossen in 14.41s (Backend: cuml)\n",
      "22:36:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:37:06 [INFO]   Training abgeschlossen in 14.62s (Backend: cuml)\n",
      "22:37:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:38:13 [INFO]   Training abgeschlossen in 14.80s (Backend: cuml)\n",
      "22:39:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:39:19 [INFO]   Training abgeschlossen in 15.10s (Backend: cuml)\n",
      "22:40:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:40:26 [INFO]   Training abgeschlossen in 15.38s (Backend: cuml)\n",
      "22:41:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:41:32 [INFO]   Training abgeschlossen in 15.63s (Backend: cuml)\n",
      "22:42:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:42:38 [INFO]   Training abgeschlossen in 15.76s (Backend: cuml)\n",
      "22:43:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:43:44 [INFO]   Training abgeschlossen in 16.13s (Backend: cuml)\n",
      "22:44:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:44:50 [INFO]   Training abgeschlossen in 16.11s (Backend: cuml)\n",
      "22:45:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:45:54 [INFO]   Training abgeschlossen in 16.39s (Backend: cuml)\n",
      "22:46:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:46:59 [INFO]   Training abgeschlossen in 16.68s (Backend: cuml)\n",
      "22:47:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:48:04 [INFO]   Training abgeschlossen in 16.82s (Backend: cuml)\n",
      "22:48:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:49:08 [INFO]   Training abgeschlossen in 17.10s (Backend: cuml)\n",
      "22:49:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:50:13 [INFO]   Training abgeschlossen in 17.59s (Backend: cuml)\n",
      "22:51:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:51:18 [INFO]   Training abgeschlossen in 17.71s (Backend: cuml)\n",
      "22:52:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:52:22 [INFO]   Training abgeschlossen in 17.79s (Backend: cuml)\n",
      "22:53:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:53:26 [INFO]   Training abgeschlossen in 18.06s (Backend: cuml)\n",
      "22:54:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:54:29 [INFO]   Training abgeschlossen in 18.12s (Backend: cuml)\n",
      "22:55:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:55:32 [INFO]   Training abgeschlossen in 18.44s (Backend: cuml)\n",
      "22:56:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:56:34 [INFO]   Training abgeschlossen in 18.61s (Backend: cuml)\n",
      "22:57:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:57:36 [INFO]   Training abgeschlossen in 18.68s (Backend: cuml)\n",
      "22:58:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:58:37 [INFO]   Training abgeschlossen in 18.88s (Backend: cuml)\n",
      "22:59:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:59:38 [INFO]   Training abgeschlossen in 19.08s (Backend: cuml)\n",
      "23:00:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:00:39 [INFO]   Training abgeschlossen in 19.32s (Backend: cuml)\n",
      "23:01:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:01:40 [INFO]   Training abgeschlossen in 19.50s (Backend: cuml)\n",
      "23:02:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:02:40 [INFO]   Training abgeschlossen in 19.72s (Backend: cuml)\n",
      "23:03:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:03:40 [INFO]   Training abgeschlossen in 20.03s (Backend: cuml)\n",
      "23:04:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:04:40 [INFO]   Training abgeschlossen in 20.38s (Backend: cuml)\n",
      "23:05:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:05:39 [INFO]   Training abgeschlossen in 20.65s (Backend: cuml)\n",
      "23:06:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:06:39 [INFO]   Training abgeschlossen in 20.82s (Backend: cuml)\n",
      "23:07:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:07:37 [INFO]   Training abgeschlossen in 20.83s (Backend: cuml)\n",
      "23:08:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:08:36 [INFO]   Training abgeschlossen in 21.12s (Backend: cuml)\n",
      "23:09:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:09:34 [INFO]   Training abgeschlossen in 21.31s (Backend: cuml)\n",
      "23:10:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:10:32 [INFO]   Training abgeschlossen in 21.46s (Backend: cuml)\n",
      "23:11:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:11:29 [INFO]   Training abgeschlossen in 21.73s (Backend: cuml)\n",
      "23:12:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:12:27 [INFO]   Training abgeschlossen in 21.90s (Backend: cuml)\n",
      "23:13:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:13:24 [INFO]   Training abgeschlossen in 22.09s (Backend: cuml)\n",
      "23:13:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:14:20 [INFO]   Training abgeschlossen in 22.31s (Backend: cuml)\n",
      "23:14:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:15:17 [INFO]   Training abgeschlossen in 22.53s (Backend: cuml)\n",
      "23:15:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:16:13 [INFO]   Training abgeschlossen in 22.81s (Backend: cuml)\n",
      "23:16:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:17:08 [INFO]   Training abgeschlossen in 23.08s (Backend: cuml)\n",
      "23:17:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:18:04 [INFO]   Training abgeschlossen in 23.29s (Backend: cuml)\n",
      "23:18:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:18:59 [INFO]   Training abgeschlossen in 23.49s (Backend: cuml)\n",
      "23:19:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:19:53 [INFO]   Training abgeschlossen in 23.68s (Backend: cuml)\n",
      "23:20:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:20:48 [INFO]   Training abgeschlossen in 23.91s (Backend: cuml)\n",
      "23:21:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:21:42 [INFO]   Training abgeschlossen in 24.16s (Backend: cuml)\n",
      "23:22:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:22:36 [INFO]   Training abgeschlossen in 24.38s (Backend: cuml)\n",
      "23:23:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:23:29 [INFO]   Training abgeschlossen in 24.40s (Backend: cuml)\n",
      "23:23:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:24:22 [INFO]   Training abgeschlossen in 24.49s (Backend: cuml)\n",
      "23:24:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:25:14 [INFO]   Training abgeschlossen in 24.63s (Backend: cuml)\n",
      "23:25:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:26:06 [INFO]   Training abgeschlossen in 24.90s (Backend: cuml)\n",
      "23:26:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:26:58 [INFO]   Training abgeschlossen in 25.12s (Backend: cuml)\n",
      "23:27:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:27:49 [INFO]   Training abgeschlossen in 25.38s (Backend: cuml)\n",
      "23:28:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:28:40 [INFO]   Training abgeschlossen in 25.57s (Backend: cuml)\n",
      "23:29:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:29:31 [INFO]   Training abgeschlossen in 25.86s (Backend: cuml)\n",
      "23:29:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:30:21 [INFO]   Training abgeschlossen in 26.09s (Backend: cuml)\n",
      "23:30:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:31:22 [INFO]   Training abgeschlossen in 37.56s (Backend: cuml)\n",
      "23:31:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:32:26 [INFO]   Training abgeschlossen in 40.84s (Backend: cuml)\n",
      "23:32:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:33:32 [INFO]   Training abgeschlossen in 42.82s (Backend: cuml)\n",
      "23:33:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:34:36 [INFO]   Training abgeschlossen in 41.92s (Backend: cuml)\n",
      "23:34:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:35:39 [INFO]   Training abgeschlossen in 41.91s (Backend: cuml)\n",
      "23:36:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:36:40 [INFO]   Training abgeschlossen in 40.19s (Backend: cuml)\n",
      "23:37:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:37:44 [INFO]   Training abgeschlossen in 43.14s (Backend: cuml)\n",
      "23:38:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:38:47 [INFO]   Training abgeschlossen in 43.75s (Backend: cuml)\n",
      "23:39:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:39:48 [INFO]   Training abgeschlossen in 41.64s (Backend: cuml)\n",
      "23:40:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:40:49 [INFO]   Training abgeschlossen in 41.85s (Backend: cuml)\n",
      "23:41:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:41:48 [INFO]   Training abgeschlossen in 41.06s (Backend: cuml)\n",
      "23:42:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:42:46 [INFO]   Training abgeschlossen in 40.64s (Backend: cuml)\n",
      "23:43:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:43:47 [INFO]   Training abgeschlossen in 44.07s (Backend: cuml)\n",
      "23:44:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:44:47 [INFO]   Training abgeschlossen in 43.59s (Backend: cuml)\n",
      "23:45:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:45:48 [INFO]   Training abgeschlossen in 44.66s (Backend: cuml)\n",
      "23:46:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:46:48 [INFO]   Training abgeschlossen in 44.17s (Backend: cuml)\n",
      "23:47:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:47:47 [INFO]   Training abgeschlossen in 44.66s (Backend: cuml)\n",
      "23:48:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:48:47 [INFO]   Training abgeschlossen in 44.62s (Backend: cuml)\n",
      "23:49:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:49:46 [INFO]   Training abgeschlossen in 45.47s (Backend: cuml)\n",
      "23:49:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:50:41 [INFO]   Training abgeschlossen in 42.28s (Backend: cuml)\n",
      "23:50:54 [INFO]     60,000 labeled → Accuracy: 0.9669 (Train: 42.3s, Query: 0.68s) | GPU: 2.8/8.0 GB\n",
      "23:50:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:51:38 [INFO]   Training abgeschlossen in 43.79s (Backend: cuml)\n",
      "23:51:49 [INFO]     Final: 60,000 labeled → Accuracy: 0.9669, F1: 0.9666\n",
      "23:51:49 [INFO]   Run 4/5\n",
      "23:51:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:51:54 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "23:53:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:53:06 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "23:54:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:54:17 [INFO]   Training abgeschlossen in 5.06s (Backend: cuml)\n",
      "23:55:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "23:55:29 [INFO]   Training abgeschlossen in 5.16s (Backend: cuml)\n",
      "23:56:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:56:42 [INFO]   Training abgeschlossen in 5.57s (Backend: cuml)\n",
      "23:57:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:57:55 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "23:59:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:59:07 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "00:00:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:00:21 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "00:01:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:01:34 [INFO]   Training abgeschlossen in 6.77s (Backend: cuml)\n",
      "00:02:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:02:48 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "00:03:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:04:03 [INFO]   Training abgeschlossen in 7.73s (Backend: cuml)\n",
      "00:05:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:05:17 [INFO]   Training abgeschlossen in 7.90s (Backend: cuml)\n",
      "00:06:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:06:32 [INFO]   Training abgeschlossen in 8.10s (Backend: cuml)\n",
      "00:07:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:07:46 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "00:08:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:09:00 [INFO]   Training abgeschlossen in 8.67s (Backend: cuml)\n",
      "00:10:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:10:14 [INFO]   Training abgeschlossen in 8.74s (Backend: cuml)\n",
      "00:11:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:11:29 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "00:12:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:12:43 [INFO]   Training abgeschlossen in 9.29s (Backend: cuml)\n",
      "00:13:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:13:56 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "00:15:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:15:10 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "00:16:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:16:23 [INFO]   Training abgeschlossen in 9.91s (Backend: cuml)\n",
      "00:17:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:17:37 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "00:18:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:18:50 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "00:19:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:20:03 [INFO]   Training abgeschlossen in 10.62s (Backend: cuml)\n",
      "00:21:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:21:16 [INFO]   Training abgeschlossen in 10.74s (Backend: cuml)\n",
      "00:22:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:22:28 [INFO]   Training abgeschlossen in 10.90s (Backend: cuml)\n",
      "00:23:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:23:40 [INFO]   Training abgeschlossen in 11.25s (Backend: cuml)\n",
      "00:24:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:24:53 [INFO]   Training abgeschlossen in 11.36s (Backend: cuml)\n",
      "00:25:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:26:04 [INFO]   Training abgeschlossen in 11.58s (Backend: cuml)\n",
      "00:27:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:27:15 [INFO]   Training abgeschlossen in 11.83s (Backend: cuml)\n",
      "00:28:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:28:27 [INFO]   Training abgeschlossen in 12.04s (Backend: cuml)\n",
      "00:29:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:29:38 [INFO]   Training abgeschlossen in 12.20s (Backend: cuml)\n",
      "00:30:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:30:48 [INFO]   Training abgeschlossen in 12.40s (Backend: cuml)\n",
      "00:31:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:31:59 [INFO]   Training abgeschlossen in 12.81s (Backend: cuml)\n",
      "00:32:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:33:09 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "00:34:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:34:19 [INFO]   Training abgeschlossen in 13.08s (Backend: cuml)\n",
      "00:35:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:35:29 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "00:36:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:36:39 [INFO]   Training abgeschlossen in 13.56s (Backend: cuml)\n",
      "00:37:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:37:48 [INFO]   Training abgeschlossen in 13.73s (Backend: cuml)\n",
      "00:38:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:38:57 [INFO]   Training abgeschlossen in 13.91s (Backend: cuml)\n",
      "00:39:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:40:06 [INFO]   Training abgeschlossen in 14.13s (Backend: cuml)\n",
      "00:41:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:41:14 [INFO]   Training abgeschlossen in 14.41s (Backend: cuml)\n",
      "00:42:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:42:23 [INFO]   Training abgeschlossen in 14.59s (Backend: cuml)\n",
      "00:43:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:43:30 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "00:44:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:44:38 [INFO]   Training abgeschlossen in 14.71s (Backend: cuml)\n",
      "00:45:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:45:45 [INFO]   Training abgeschlossen in 14.94s (Backend: cuml)\n",
      "00:46:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:46:52 [INFO]   Training abgeschlossen in 15.08s (Backend: cuml)\n",
      "00:47:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:47:58 [INFO]   Training abgeschlossen in 15.28s (Backend: cuml)\n",
      "00:48:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:49:05 [INFO]   Training abgeschlossen in 15.46s (Backend: cuml)\n",
      "00:49:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:50:11 [INFO]   Training abgeschlossen in 15.69s (Backend: cuml)\n",
      "00:51:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:51:17 [INFO]   Training abgeschlossen in 16.15s (Backend: cuml)\n",
      "00:52:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:52:22 [INFO]   Training abgeschlossen in 16.18s (Backend: cuml)\n",
      "00:53:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:53:27 [INFO]   Training abgeschlossen in 16.40s (Backend: cuml)\n",
      "00:54:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:54:32 [INFO]   Training abgeschlossen in 16.65s (Backend: cuml)\n",
      "00:55:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:55:37 [INFO]   Training abgeschlossen in 17.00s (Backend: cuml)\n",
      "00:56:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:56:41 [INFO]   Training abgeschlossen in 17.16s (Backend: cuml)\n",
      "00:57:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:57:45 [INFO]   Training abgeschlossen in 17.41s (Backend: cuml)\n",
      "00:58:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:58:49 [INFO]   Training abgeschlossen in 17.51s (Backend: cuml)\n",
      "00:59:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:59:53 [INFO]   Training abgeschlossen in 17.74s (Backend: cuml)\n",
      "01:00:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:00:56 [INFO]   Training abgeschlossen in 17.98s (Backend: cuml)\n",
      "01:01:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:01:59 [INFO]   Training abgeschlossen in 18.20s (Backend: cuml)\n",
      "01:02:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:03:01 [INFO]   Training abgeschlossen in 18.41s (Backend: cuml)\n",
      "01:03:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:04:03 [INFO]   Training abgeschlossen in 18.61s (Backend: cuml)\n",
      "01:04:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:05:05 [INFO]   Training abgeschlossen in 18.86s (Backend: cuml)\n",
      "01:05:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:06:07 [INFO]   Training abgeschlossen in 19.15s (Backend: cuml)\n",
      "01:06:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:07:08 [INFO]   Training abgeschlossen in 19.20s (Backend: cuml)\n",
      "01:07:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:08:10 [INFO]   Training abgeschlossen in 19.50s (Backend: cuml)\n",
      "01:08:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:09:10 [INFO]   Training abgeschlossen in 19.67s (Backend: cuml)\n",
      "01:09:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:10:11 [INFO]   Training abgeschlossen in 19.72s (Backend: cuml)\n",
      "01:10:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:11:11 [INFO]   Training abgeschlossen in 20.00s (Backend: cuml)\n",
      "01:11:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:12:10 [INFO]   Training abgeschlossen in 20.22s (Backend: cuml)\n",
      "01:12:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:13:10 [INFO]   Training abgeschlossen in 20.45s (Backend: cuml)\n",
      "01:13:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:14:09 [INFO]   Training abgeschlossen in 20.69s (Backend: cuml)\n",
      "01:14:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:15:08 [INFO]   Training abgeschlossen in 20.88s (Backend: cuml)\n",
      "01:15:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:16:06 [INFO]   Training abgeschlossen in 21.16s (Backend: cuml)\n",
      "01:16:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:17:05 [INFO]   Training abgeschlossen in 21.46s (Backend: cuml)\n",
      "01:17:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:18:03 [INFO]   Training abgeschlossen in 21.63s (Backend: cuml)\n",
      "01:18:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:19:01 [INFO]   Training abgeschlossen in 21.95s (Backend: cuml)\n",
      "01:19:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:19:58 [INFO]   Training abgeschlossen in 22.07s (Backend: cuml)\n",
      "01:20:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:20:55 [INFO]   Training abgeschlossen in 22.42s (Backend: cuml)\n",
      "01:21:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:21:52 [INFO]   Training abgeschlossen in 22.62s (Backend: cuml)\n",
      "01:22:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:22:49 [INFO]   Training abgeschlossen in 22.75s (Backend: cuml)\n",
      "01:23:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:23:45 [INFO]   Training abgeschlossen in 22.85s (Backend: cuml)\n",
      "01:24:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:24:41 [INFO]   Training abgeschlossen in 23.23s (Backend: cuml)\n",
      "01:25:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:25:36 [INFO]   Training abgeschlossen in 23.28s (Backend: cuml)\n",
      "01:26:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:26:31 [INFO]   Training abgeschlossen in 23.51s (Backend: cuml)\n",
      "01:27:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:27:26 [INFO]   Training abgeschlossen in 23.73s (Backend: cuml)\n",
      "01:27:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:28:21 [INFO]   Training abgeschlossen in 23.96s (Backend: cuml)\n",
      "01:28:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:29:15 [INFO]   Training abgeschlossen in 23.95s (Backend: cuml)\n",
      "01:29:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:30:08 [INFO]   Training abgeschlossen in 24.22s (Backend: cuml)\n",
      "01:30:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:31:01 [INFO]   Training abgeschlossen in 24.42s (Backend: cuml)\n",
      "01:31:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:31:54 [INFO]   Training abgeschlossen in 24.59s (Backend: cuml)\n",
      "01:32:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:32:47 [INFO]   Training abgeschlossen in 24.73s (Backend: cuml)\n",
      "01:33:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:33:39 [INFO]   Training abgeschlossen in 25.03s (Backend: cuml)\n",
      "01:34:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:34:31 [INFO]   Training abgeschlossen in 25.17s (Backend: cuml)\n",
      "01:34:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:35:23 [INFO]   Training abgeschlossen in 25.52s (Backend: cuml)\n",
      "01:35:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:36:14 [INFO]   Training abgeschlossen in 25.76s (Backend: cuml)\n",
      "01:36:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:37:05 [INFO]   Training abgeschlossen in 25.95s (Backend: cuml)\n",
      "01:37:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:37:55 [INFO]   Training abgeschlossen in 26.21s (Backend: cuml)\n",
      "01:38:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:39:00 [INFO]   Training abgeschlossen in 40.84s (Backend: cuml)\n",
      "01:39:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:40:02 [INFO]   Training abgeschlossen in 39.23s (Backend: cuml)\n",
      "01:40:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:41:06 [INFO]   Training abgeschlossen in 40.99s (Backend: cuml)\n",
      "01:41:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:42:07 [INFO]   Training abgeschlossen in 39.89s (Backend: cuml)\n",
      "01:42:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:43:09 [INFO]   Training abgeschlossen in 40.28s (Backend: cuml)\n",
      "01:43:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:44:12 [INFO]   Training abgeschlossen in 41.54s (Backend: cuml)\n",
      "01:44:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:45:12 [INFO]   Training abgeschlossen in 40.21s (Backend: cuml)\n",
      "01:45:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:46:11 [INFO]   Training abgeschlossen in 39.68s (Backend: cuml)\n",
      "01:46:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:47:11 [INFO]   Training abgeschlossen in 40.54s (Backend: cuml)\n",
      "01:47:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:48:10 [INFO]   Training abgeschlossen in 39.75s (Backend: cuml)\n",
      "01:48:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:49:09 [INFO]   Training abgeschlossen in 41.41s (Backend: cuml)\n",
      "01:49:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:50:09 [INFO]   Training abgeschlossen in 42.11s (Backend: cuml)\n",
      "01:50:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:51:09 [INFO]   Training abgeschlossen in 43.23s (Backend: cuml)\n",
      "01:51:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:52:09 [INFO]   Training abgeschlossen in 42.76s (Backend: cuml)\n",
      "01:52:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:53:08 [INFO]   Training abgeschlossen in 42.78s (Backend: cuml)\n",
      "01:53:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:54:07 [INFO]   Training abgeschlossen in 43.77s (Backend: cuml)\n",
      "01:54:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:55:07 [INFO]   Training abgeschlossen in 44.90s (Backend: cuml)\n",
      "01:55:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:56:06 [INFO]   Training abgeschlossen in 44.55s (Backend: cuml)\n",
      "01:56:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:57:04 [INFO]   Training abgeschlossen in 44.33s (Backend: cuml)\n",
      "01:57:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:58:02 [INFO]   Training abgeschlossen in 45.47s (Backend: cuml)\n",
      "01:58:14 [INFO]     60,000 labeled → Accuracy: 0.9673 (Train: 45.5s, Query: 0.67s) | GPU: 2.8/8.0 GB\n",
      "01:58:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:58:57 [INFO]   Training abgeschlossen in 42.68s (Backend: cuml)\n",
      "01:59:09 [INFO]     Final: 60,000 labeled → Accuracy: 0.9671, F1: 0.9669\n",
      "01:59:09 [INFO]   Run 5/5\n",
      "01:59:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:59:14 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "02:00:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:00:26 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "02:01:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:01:38 [INFO]   Training abgeschlossen in 5.01s (Backend: cuml)\n",
      "02:02:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.0/8.0 GB)\n",
      "02:02:50 [INFO]   Training abgeschlossen in 5.16s (Backend: cuml)\n",
      "02:03:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:04:02 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "02:05:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:05:15 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "02:06:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:06:27 [INFO]   Training abgeschlossen in 5.87s (Backend: cuml)\n",
      "02:07:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:07:40 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "02:08:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:08:54 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "02:10:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:10:07 [INFO]   Training abgeschlossen in 7.12s (Backend: cuml)\n",
      "02:11:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:11:22 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "02:12:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:12:36 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "02:13:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:13:50 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "02:14:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:15:04 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "02:16:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:16:19 [INFO]   Training abgeschlossen in 8.57s (Backend: cuml)\n",
      "02:17:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:17:33 [INFO]   Training abgeschlossen in 8.71s (Backend: cuml)\n",
      "02:18:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:18:47 [INFO]   Training abgeschlossen in 9.09s (Backend: cuml)\n",
      "02:19:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:20:02 [INFO]   Training abgeschlossen in 9.34s (Backend: cuml)\n",
      "02:21:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:21:15 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "02:22:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:22:29 [INFO]   Training abgeschlossen in 9.82s (Backend: cuml)\n",
      "02:23:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:23:43 [INFO]   Training abgeschlossen in 9.97s (Backend: cuml)\n",
      "02:24:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:24:56 [INFO]   Training abgeschlossen in 10.18s (Backend: cuml)\n",
      "02:25:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:26:10 [INFO]   Training abgeschlossen in 10.54s (Backend: cuml)\n",
      "02:27:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:27:24 [INFO]   Training abgeschlossen in 10.69s (Backend: cuml)\n",
      "02:28:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:28:38 [INFO]   Training abgeschlossen in 10.89s (Backend: cuml)\n",
      "02:29:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:29:52 [INFO]   Training abgeschlossen in 11.30s (Backend: cuml)\n",
      "02:30:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:31:05 [INFO]   Training abgeschlossen in 11.40s (Backend: cuml)\n",
      "02:32:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:32:18 [INFO]   Training abgeschlossen in 11.44s (Backend: cuml)\n",
      "02:33:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:33:31 [INFO]   Training abgeschlossen in 11.90s (Backend: cuml)\n",
      "02:34:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:34:44 [INFO]   Training abgeschlossen in 11.84s (Backend: cuml)\n",
      "02:35:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:35:56 [INFO]   Training abgeschlossen in 11.95s (Backend: cuml)\n",
      "02:36:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:37:07 [INFO]   Training abgeschlossen in 12.16s (Backend: cuml)\n",
      "02:38:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:38:18 [INFO]   Training abgeschlossen in 12.42s (Backend: cuml)\n",
      "02:39:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:39:28 [INFO]   Training abgeschlossen in 12.61s (Backend: cuml)\n",
      "02:40:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:40:38 [INFO]   Training abgeschlossen in 12.89s (Backend: cuml)\n",
      "02:41:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:41:49 [INFO]   Training abgeschlossen in 13.08s (Backend: cuml)\n",
      "02:42:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:42:59 [INFO]   Training abgeschlossen in 13.30s (Backend: cuml)\n",
      "02:43:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:44:09 [INFO]   Training abgeschlossen in 13.42s (Backend: cuml)\n",
      "02:45:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:45:18 [INFO]   Training abgeschlossen in 13.62s (Backend: cuml)\n",
      "02:46:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:46:27 [INFO]   Training abgeschlossen in 13.94s (Backend: cuml)\n",
      "02:47:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:47:35 [INFO]   Training abgeschlossen in 14.11s (Backend: cuml)\n",
      "02:48:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:48:44 [INFO]   Training abgeschlossen in 14.27s (Backend: cuml)\n",
      "02:49:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:49:52 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "02:50:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:51:00 [INFO]   Training abgeschlossen in 14.38s (Backend: cuml)\n",
      "02:51:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:52:07 [INFO]   Training abgeschlossen in 14.79s (Backend: cuml)\n",
      "02:52:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:53:14 [INFO]   Training abgeschlossen in 15.04s (Backend: cuml)\n",
      "02:54:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:54:21 [INFO]   Training abgeschlossen in 15.15s (Backend: cuml)\n",
      "02:55:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:55:28 [INFO]   Training abgeschlossen in 15.57s (Backend: cuml)\n",
      "02:56:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:56:35 [INFO]   Training abgeschlossen in 15.68s (Backend: cuml)\n",
      "02:57:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:57:41 [INFO]   Training abgeschlossen in 15.78s (Backend: cuml)\n",
      "02:58:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:58:47 [INFO]   Training abgeschlossen in 16.13s (Backend: cuml)\n",
      "02:59:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:59:52 [INFO]   Training abgeschlossen in 16.06s (Backend: cuml)\n",
      "03:00:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:00:57 [INFO]   Training abgeschlossen in 16.37s (Backend: cuml)\n",
      "03:01:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:02:02 [INFO]   Training abgeschlossen in 16.67s (Backend: cuml)\n",
      "03:02:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:03:06 [INFO]   Training abgeschlossen in 16.77s (Backend: cuml)\n",
      "03:03:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:04:10 [INFO]   Training abgeschlossen in 17.01s (Backend: cuml)\n",
      "03:04:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:05:14 [INFO]   Training abgeschlossen in 17.21s (Backend: cuml)\n",
      "03:06:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:06:19 [INFO]   Training abgeschlossen in 17.35s (Backend: cuml)\n",
      "03:07:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:07:23 [INFO]   Training abgeschlossen in 17.70s (Backend: cuml)\n",
      "03:08:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:08:26 [INFO]   Training abgeschlossen in 17.87s (Backend: cuml)\n",
      "03:09:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:09:29 [INFO]   Training abgeschlossen in 18.21s (Backend: cuml)\n",
      "03:10:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:10:32 [INFO]   Training abgeschlossen in 18.34s (Backend: cuml)\n",
      "03:11:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:11:34 [INFO]   Training abgeschlossen in 18.53s (Backend: cuml)\n",
      "03:12:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:12:36 [INFO]   Training abgeschlossen in 18.64s (Backend: cuml)\n",
      "03:13:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:13:37 [INFO]   Training abgeschlossen in 18.85s (Backend: cuml)\n",
      "03:14:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:14:39 [INFO]   Training abgeschlossen in 19.06s (Backend: cuml)\n",
      "03:15:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:15:40 [INFO]   Training abgeschlossen in 19.38s (Backend: cuml)\n",
      "03:16:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:16:40 [INFO]   Training abgeschlossen in 19.50s (Backend: cuml)\n",
      "03:17:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:17:41 [INFO]   Training abgeschlossen in 19.88s (Backend: cuml)\n",
      "03:18:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:18:41 [INFO]   Training abgeschlossen in 20.10s (Backend: cuml)\n",
      "03:19:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:19:40 [INFO]   Training abgeschlossen in 20.16s (Backend: cuml)\n",
      "03:20:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:20:40 [INFO]   Training abgeschlossen in 20.35s (Backend: cuml)\n",
      "03:21:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:21:39 [INFO]   Training abgeschlossen in 20.64s (Backend: cuml)\n",
      "03:22:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:22:38 [INFO]   Training abgeschlossen in 20.92s (Backend: cuml)\n",
      "03:23:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:23:36 [INFO]   Training abgeschlossen in 21.05s (Backend: cuml)\n",
      "03:24:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:24:34 [INFO]   Training abgeschlossen in 21.22s (Backend: cuml)\n",
      "03:25:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:25:32 [INFO]   Training abgeschlossen in 21.40s (Backend: cuml)\n",
      "03:26:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:26:29 [INFO]   Training abgeschlossen in 21.58s (Backend: cuml)\n",
      "03:27:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:27:26 [INFO]   Training abgeschlossen in 21.79s (Backend: cuml)\n",
      "03:28:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:28:23 [INFO]   Training abgeschlossen in 22.02s (Backend: cuml)\n",
      "03:28:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:29:20 [INFO]   Training abgeschlossen in 22.20s (Backend: cuml)\n",
      "03:29:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:30:16 [INFO]   Training abgeschlossen in 22.47s (Backend: cuml)\n",
      "03:30:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:31:12 [INFO]   Training abgeschlossen in 22.67s (Backend: cuml)\n",
      "03:31:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:32:07 [INFO]   Training abgeschlossen in 22.83s (Backend: cuml)\n",
      "03:32:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:33:02 [INFO]   Training abgeschlossen in 23.03s (Backend: cuml)\n",
      "03:33:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:33:57 [INFO]   Training abgeschlossen in 23.24s (Backend: cuml)\n",
      "03:34:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:34:52 [INFO]   Training abgeschlossen in 23.53s (Backend: cuml)\n",
      "03:35:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:35:46 [INFO]   Training abgeschlossen in 23.68s (Backend: cuml)\n",
      "03:36:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:36:40 [INFO]   Training abgeschlossen in 23.83s (Backend: cuml)\n",
      "03:37:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:37:33 [INFO]   Training abgeschlossen in 24.04s (Backend: cuml)\n",
      "03:38:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:38:26 [INFO]   Training abgeschlossen in 24.29s (Backend: cuml)\n",
      "03:38:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:39:19 [INFO]   Training abgeschlossen in 24.47s (Backend: cuml)\n",
      "03:39:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:40:11 [INFO]   Training abgeschlossen in 24.66s (Backend: cuml)\n",
      "03:40:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:41:03 [INFO]   Training abgeschlossen in 25.00s (Backend: cuml)\n",
      "03:41:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:41:55 [INFO]   Training abgeschlossen in 25.14s (Backend: cuml)\n",
      "03:42:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:42:46 [INFO]   Training abgeschlossen in 25.38s (Backend: cuml)\n",
      "03:43:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:43:37 [INFO]   Training abgeschlossen in 25.57s (Backend: cuml)\n",
      "03:44:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:44:28 [INFO]   Training abgeschlossen in 25.75s (Backend: cuml)\n",
      "03:44:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:45:18 [INFO]   Training abgeschlossen in 25.99s (Backend: cuml)\n",
      "03:45:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:46:23 [INFO]   Training abgeschlossen in 40.97s (Backend: cuml)\n",
      "03:46:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:47:25 [INFO]   Training abgeschlossen in 39.31s (Backend: cuml)\n",
      "03:47:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:48:30 [INFO]   Training abgeschlossen in 42.71s (Backend: cuml)\n",
      "03:48:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:49:34 [INFO]   Training abgeschlossen in 41.12s (Backend: cuml)\n",
      "03:49:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:50:35 [INFO]   Training abgeschlossen in 40.35s (Backend: cuml)\n",
      "03:50:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:51:35 [INFO]   Training abgeschlossen in 39.13s (Backend: cuml)\n",
      "03:51:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:52:35 [INFO]   Training abgeschlossen in 39.55s (Backend: cuml)\n",
      "03:52:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:53:37 [INFO]   Training abgeschlossen in 41.84s (Backend: cuml)\n",
      "03:53:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:54:38 [INFO]   Training abgeschlossen in 41.64s (Backend: cuml)\n",
      "03:54:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:55:40 [INFO]   Training abgeschlossen in 43.39s (Backend: cuml)\n",
      "03:55:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:56:40 [INFO]   Training abgeschlossen in 41.47s (Backend: cuml)\n",
      "03:56:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:57:38 [INFO]   Training abgeschlossen in 40.75s (Backend: cuml)\n",
      "03:57:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:58:36 [INFO]   Training abgeschlossen in 41.28s (Backend: cuml)\n",
      "03:58:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:59:35 [INFO]   Training abgeschlossen in 41.94s (Backend: cuml)\n",
      "03:59:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:00:35 [INFO]   Training abgeschlossen in 44.16s (Backend: cuml)\n",
      "04:00:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:01:35 [INFO]   Training abgeschlossen in 44.69s (Backend: cuml)\n",
      "04:01:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:02:33 [INFO]   Training abgeschlossen in 42.82s (Backend: cuml)\n",
      "04:02:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:03:30 [INFO]   Training abgeschlossen in 42.85s (Backend: cuml)\n",
      "04:03:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:04:26 [INFO]   Training abgeschlossen in 42.66s (Backend: cuml)\n",
      "04:04:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:05:22 [INFO]   Training abgeschlossen in 42.50s (Backend: cuml)\n",
      "04:05:34 [INFO]     60,000 labeled → Accuracy: 0.9665 (Train: 42.5s, Query: 0.67s) | GPU: 2.8/8.0 GB\n",
      "04:05:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:06:18 [INFO]   Training abgeschlossen in 43.58s (Backend: cuml)\n",
      "04:06:30 [INFO]     Final: 60,000 labeled → Accuracy: 0.9663, F1: 0.9661\n",
      "\n",
      "✓ Alle Experimente abgeschlossen in 6645.6 Minuten\n",
      "\n",
      "Führe statistische Analyse durch...\n",
      "\n",
      "====================================================================================================\n",
      "DETAILLIERTER STATISTISCHER BERICHT - GPU-SVM ACTIVE LEARNING\n",
      "====================================================================================================\n",
      "Signifikanzniveau: 0.05 (mit Bonferroni-Korrektur)\n",
      "Anzahl Runs pro Experiment: 5\n",
      "Statistischer Test: Wilcoxon Signed-Rank Test\n",
      "Effektstärkemaß: Cliff's Delta\n",
      "\n",
      "\n",
      "Keine signifikanten Verbesserungen gefunden!\n",
      "\n",
      "\n",
      "ZUSAMMENFASSUNG NACH STRATEGIE:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Entropie-Auswahl:\n",
      "  - Signifikante Verbesserungen: 0/5 (0.0%)\n",
      "  - Durchschnittliche Verbesserung: 0.92%\n",
      "  - Durchschnittliche Effektstärke: 0.888\n",
      "\n",
      "Margin-Auswahl:\n",
      "  - Signifikante Verbesserungen: 0/5 (0.0%)\n",
      "  - Durchschnittliche Verbesserung: 1.02%\n",
      "  - Durchschnittliche Effektstärke: 1.000\n",
      "\n",
      "Geringste Konfidenz:\n",
      "  - Signifikante Verbesserungen: 0/5 (0.0%)\n",
      "  - Durchschnittliche Verbesserung: 0.99%\n",
      "  - Durchschnittliche Effektstärke: 0.920\n",
      "\n",
      "\n",
      "EMPFEHLUNG:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Die Active Learning Strategien zeigen keine signifikanten Verbesserungen\n",
      "gegenüber der zufälligen Auswahl in diesem Experiment.\n",
      "\n",
      "====================================================================================================\n",
      "04:06:30 [INFO] ✓ Statistischer Bericht gespeichert: reports/gpu_svm_statistischer_bericht.txt\n",
      "\n",
      "Erstelle Visualisierungen...\n",
      "04:06:30 [INFO] ✓ Visualisierung erstellt: plots/gpu_svm_active_learning_performance.png\n",
      "04:06:31 [INFO] ✓ Leistungsmetriken erstellt: plots/gpu_svm_leistungsmetriken.png\n",
      "04:06:31 [INFO] ✓ Detaillierte Analyse erstellt: plots/gpu_svm_detaillierte_analyse.png\n",
      "\n",
      "Berechne Label-Einsparungen...\n",
      "04:06:32 [INFO] ✓ Label-Einsparungs-Analyse erstellt: plots/gpu_svm_label_einsparung.png\n",
      "\n",
      "================================================================================\n",
      "LABEL-EINSPARUNGS-BERICHT - GPU-SVM ACTIVE LEARNING\n",
      "================================================================================\n",
      "\n",
      "HAUPTERGEBNIS:\n",
      "Die Geringste Konfidenz-Strategie\n",
      "benötigt nur 2,200 Labels\n",
      "um 95% der Baseline-Performance zu erreichen.\n",
      "Das entspricht einer Einsparung von 96.3%!\n",
      "\n",
      "\n",
      "ZIEL: 90% der Baseline-Performance\n",
      "------------------------------------------------------------\n",
      "Baseline-Genauigkeit (100% Daten): 0.9662\n",
      "Ziel-Genauigkeit: 0.8696\n",
      "\n",
      "Benötigte Labels:\n",
      "  - Geringste Konfidenz :  1,100 ±    0 ( 98.2% Einsparung)\n",
      "    → 21.4% weniger Labels als Zufällige Auswahl\n",
      "  - Margin-Auswahl      :  1,100 ±    0 ( 98.2% Einsparung)\n",
      "    → 21.4% weniger Labels als Zufällige Auswahl\n",
      "  - Entropie-Auswahl    :  1,400 ±  244 ( 97.7% Einsparung)\n",
      "  - Zufällige Auswahl   :  1,400 ±  244 ( 97.7% Einsparung)\n",
      "\n",
      "\n",
      "ZIEL: 95% der Baseline-Performance\n",
      "------------------------------------------------------------\n",
      "Baseline-Genauigkeit (100% Daten): 0.9662\n",
      "Ziel-Genauigkeit: 0.9179\n",
      "\n",
      "Benötigte Labels:\n",
      "  - Geringste Konfidenz :  2,200 ±  200 ( 96.3% Einsparung)\n",
      "    → 35.3% weniger Labels als Zufällige Auswahl\n",
      "  - Margin-Auswahl      :  2,500 ±  374 ( 95.8% Einsparung)\n",
      "    → 26.5% weniger Labels als Zufällige Auswahl\n",
      "  - Entropie-Auswahl    :  2,600 ±  316 ( 95.7% Einsparung)\n",
      "    → 23.5% weniger Labels als Zufällige Auswahl\n",
      "  - Zufällige Auswahl   :  3,400 ±  244 ( 94.3% Einsparung)\n",
      "\n",
      "\n",
      "ZIEL: 98% der Baseline-Performance\n",
      "------------------------------------------------------------\n",
      "Baseline-Genauigkeit (100% Daten): 0.9662\n",
      "Ziel-Genauigkeit: 0.9469\n",
      "\n",
      "Benötigte Labels:\n",
      "  - Geringste Konfidenz :  3,600 ±  316 ( 94.0% Einsparung)\n",
      "    → 84.7% weniger Labels als Zufällige Auswahl\n",
      "  - Entropie-Auswahl    :  4,200 ±  374 ( 93.0% Einsparung)\n",
      "    → 82.2% weniger Labels als Zufällige Auswahl\n",
      "  - Margin-Auswahl      :  4,300 ±  400 ( 92.8% Einsparung)\n",
      "    → 81.8% weniger Labels als Zufällige Auswahl\n",
      "  - Zufällige Auswahl   : 23,600 ± 18236 ( 60.7% Einsparung)\n",
      "\n",
      "\n",
      "GPU-PERFORMANCE:\n",
      "------------------------------------------------------------\n",
      "Backend: CUML\n",
      "GPU verfügbar: Ja\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "VRAM: 7.6 GB\n",
      "\n",
      "================================================================================\n",
      "04:06:32 [INFO] ✓ Label-Einsparungs-Bericht gespeichert: reports/gpu_svm_label_einsparungs_bericht.txt\n",
      "\n",
      "✓ Ergebnisse gespeichert: results/gpu_svm_active_learning_results.csv\n",
      "✓ Statistische Analyse gespeichert: results/gpu_svm_statistical_analysis.csv\n",
      "✓ Label-Einsparungen gespeichert: results/gpu_svm_label_savings.csv\n",
      "✓ Excel-Zusammenfassung gespeichert: results/gpu_svm_active_learning_summary.xlsx\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT ERFOLGREICH ABGESCHLOSSEN\n",
      "================================================================================\n",
      "GPU Backend verwendet: cuml\n",
      "Gesamtanzahl Experimente: 100\n",
      "Durchschnittliche Trainingszeit: 12.83s\n",
      "\n",
      "Signifikante Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "Output-Dateien:\n",
      "- Visualisierungen: plots/\n",
      "  - gpu_svm_active_learning_performance.png\n",
      "  - gpu_svm_leistungsmetriken.png\n",
      "  - gpu_svm_detaillierte_analyse.png\n",
      "  - gpu_svm_label_einsparung.png\n",
      "- Ergebnisse: results/\n",
      "  - gpu_svm_active_learning_results.csv\n",
      "  - gpu_svm_statistical_analysis.csv\n",
      "  - gpu_svm_label_savings.csv\n",
      "  - gpu_svm_active_learning_summary.xlsx\n",
      "- Berichte: reports/\n",
      "  - gpu_svm_statistischer_bericht.txt\n",
      "  - gpu_svm_label_einsparungs_bericht.txt\n",
      "- Logs: logs/\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "=================================================================\n",
    "GPU-Optimiertes Active Learning für SVM auf MNIST\n",
    "=================================================================\n",
    "Professionelles Framework für GPU-beschleunigte SVM Active Learning\n",
    "Experimente mit statistischer Analyse für Bachelorarbeit.\n",
    "\n",
    "Optimiert für NVIDIA RTX 4060 (8GB VRAM) mit RAPIDS cuML/ThunderSVM.\n",
    "\n",
    "Version: 1.0 - GPU-Optimiert mit Memory Management\n",
    "            \n",
    "GPU-SVM Implementierungen:\n",
    "- RAPIDS cuML SVC (primär)\n",
    "- ThunderSVM (Fallback)\n",
    "- Sklearn SVC (CPU Fallback)\n",
    "\n",
    "Query-Strategien:\n",
    "- Random Sampling (Baseline)\n",
    "- Entropy Sampling\n",
    "- Margin Sampling\n",
    "- Least Confidence\n",
    "\n",
    "Statistische Analyse:\n",
    "- Wilcoxon Signed-Rank Test\n",
    "- Cliff's Delta Effektstärke\n",
    "- Bonferroni-Korrektur für multiple Vergleiche\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Matplotlib Backend setzen\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Für Server ohne GUI\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn mit Fehlerbehandlung\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    try:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    except:\n",
    "        try:\n",
    "            plt.style.use('seaborn-whitegrid')\n",
    "        except:\n",
    "            plt.style.use('ggplot')\n",
    "except ImportError:\n",
    "    print(\"Warnung: Seaborn nicht installiert. Verwende Standard-Matplotlib.\")\n",
    "    sns = None\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC as SklearnSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "# Statistische Tests\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# GPU-spezifische Imports mit Fehlerbehandlung\n",
    "GPU_AVAILABLE = False\n",
    "CUML_AVAILABLE = False\n",
    "THUNDERSVM_AVAILABLE = False\n",
    "RMM_AVAILABLE = False\n",
    "\n",
    "# Versuche RAPIDS cuML zu importieren\n",
    "try:\n",
    "    import cupy as cp\n",
    "    import cuml\n",
    "    from cuml.svm import SVC as cuMLSVC\n",
    "    CUML_AVAILABLE = True\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"✓ RAPIDS cuML verfügbar - primäre GPU-Beschleunigung aktiviert\")\n",
    "    \n",
    "    # RMM ist optional\n",
    "    try:\n",
    "        import rmm\n",
    "        from rmm.allocators.cupy import rmm_cupy_allocator\n",
    "        RMM_AVAILABLE = True\n",
    "    except:\n",
    "        RMM_AVAILABLE = False\n",
    "        print(\"  Info: RMM Memory Manager nicht verfügbar, verwende Standard CuPy Memory\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"⚠ RAPIDS cuML nicht verfügbar: {e}\")\n",
    "\n",
    "# Versuche ThunderSVM zu importieren (mit besserer Fehlerbehandlung)\n",
    "try:\n",
    "    # Prüfe CUDA Version Kompatibilität\n",
    "    import subprocess\n",
    "    try:\n",
    "        cuda_version = subprocess.check_output(['nvcc', '--version']).decode()\n",
    "        print(f\"CUDA Version gefunden: {cuda_version.split('release')[-1].split(',')[0].strip()}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    from thundersvm import SVC as ThunderSVC\n",
    "    # Test ob ThunderSVM wirklich funktioniert\n",
    "    test = ThunderSVC()\n",
    "    THUNDERSVM_AVAILABLE = True\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"✓ ThunderSVM verfügbar - alternative GPU-Beschleunigung aktiviert\")\n",
    "except (ImportError, OSError) as e:\n",
    "    if \"libcusparse\" in str(e):\n",
    "        print(\"⚠ ThunderSVM benötigt ältere CUDA-Version (9.x/10.x). Aktuelle CUDA-Version inkompatibel.\")\n",
    "        print(\"  Tipp: Verwenden Sie RAPIDS cuML stattdessen für moderne GPUs.\")\n",
    "    else:\n",
    "        print(f\"⚠ ThunderSVM nicht verfügbar: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ ThunderSVM Test fehlgeschlagen: {e}\")\n",
    "\n",
    "if not GPU_AVAILABLE:\n",
    "    print(\"\\n⚠ WARNUNG: Keine GPU-Beschleunigung verfügbar! Verwende CPU-basiertes sklearn.\")\n",
    "    print(\"\\nEmpfohlene Installation für RTX 4060:\")\n",
    "    print(\"conda create -n rapids-gpu python=3.11\")\n",
    "    print(\"conda activate rapids-gpu\")\n",
    "    print(\"conda install -c rapidsai -c conda-forge -c nvidia rapids=24.12 python=3.11 cudatoolkit=12.0\")\n",
    "    print(\"\\nAlternativ (wenn RAPIDS nicht funktioniert):\")\n",
    "    print(\"pip install cupy-cuda12x\")\n",
    "    print(\"conda install -c conda-forge cuml\")\n",
    "\n",
    "# Excel-Export\n",
    "try:\n",
    "    import openpyxl\n",
    "    EXCEL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warnung: openpyxl nicht installiert. Excel-Export wird deaktiviert.\")\n",
    "    EXCEL_AVAILABLE = False\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Konfiguration\n",
    "# -------------------------------------------------------------------------------\n",
    "USE_MEMORY_POOL = False  # Memory Pool deaktivieren bei Problemen\n",
    "BUDGET_PERCENTAGES = [0.2, 0.4, 0.6, 0.8, 1.0]  # 20%, 40%, 60%, 80%, 100%\n",
    "BATCH_SIZE = 500  # Größere Batches für effizienteres GPU Training\n",
    "N_RUNS = 5  # Anzahl Wiederholungen\n",
    "INITIAL_PERCENTAGE = 0.01  # 1% initial labeling\n",
    "SIGNIFICANCE_LEVEL = 0.05  # Für statistische Tests\n",
    "SEED = 42\n",
    "\n",
    "# SVM-spezifische Konfiguration\n",
    "SVM_CONFIGS = {\n",
    "    'cuml': {\n",
    "        'kernel': 'rbf',\n",
    "        'gamma': 'scale',\n",
    "        'C': 1.0,\n",
    "        'cache_size': 1000,\n",
    "        'probability': True,\n",
    "        'max_iter': 5000,\n",
    "        'tol': 1e-3  # Toleranz hinzugefügt\n",
    "    },\n",
    "    'thundersvm': {\n",
    "        'kernel': 'rbf',\n",
    "        'gamma': 'auto',\n",
    "        'C': 1.0,\n",
    "        'gpu_id': 0,\n",
    "        'max_iter': 5000\n",
    "    },\n",
    "    'sklearn': {\n",
    "        'kernel': 'rbf',\n",
    "        'gamma': 'scale',\n",
    "        'C': 1.0,\n",
    "        'cache_size': 2000,\n",
    "        'probability': True,\n",
    "        'max_iter': 5000,\n",
    "        'decision_function_shape': 'ovr'\n",
    "    }\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# GPU Memory Management\n",
    "# -------------------------------------------------------------------------------\n",
    "def setup_gpu_memory():\n",
    "    \"\"\"Konfiguriert optimales GPU Memory Management für RTX 4060.\"\"\"\n",
    "    if not CUML_AVAILABLE:\n",
    "        return False\n",
    "        \n",
    "    if not USE_MEMORY_POOL or not RMM_AVAILABLE:\n",
    "        if not RMM_AVAILABLE and USE_MEMORY_POOL:\n",
    "            print(\"✓ RMM nicht verfügbar, verwende Standard GPU Memory Management\")\n",
    "        else:\n",
    "            print(\"✓ Verwende Standard GPU Memory Management (RMM Pool deaktiviert)\")\n",
    "            \n",
    "        # Zeige GPU Info wenn möglich\n",
    "        try:\n",
    "            import subprocess\n",
    "            result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', \n",
    "                                   '--format=csv,noheader'], \n",
    "                                  capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                gpu_info = result.stdout.strip()\n",
    "                print(f\"  GPU: {gpu_info}\")\n",
    "        except:\n",
    "            pass\n",
    "        return True\n",
    "    \n",
    "    # RMM Pool Setup (wenn aktiviert und verfügbar)\n",
    "    try:\n",
    "        # Alte Allocations bereinigen\n",
    "        if hasattr(cp, 'get_default_memory_pool'):\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        gc.collect()\n",
    "        \n",
    "        # RMM mit optimierten Einstellungen für 8GB VRAM\n",
    "        rmm.reinitialize(\n",
    "            pool_allocator=True,\n",
    "            initial_pool_size=\"5GB\",    # Konservativ für SVM\n",
    "            maximum_pool_size=\"6.5GB\",  # 1.5GB Reserve\n",
    "            managed_memory=False        # Bessere Performance\n",
    "        )\n",
    "        \n",
    "        # CuPy mit RMM verknüpfen\n",
    "        cp.cuda.set_allocator(rmm_cupy_allocator)\n",
    "        \n",
    "        print(f\"✓ RMM Memory Pool konfiguriert (5GB initial, 6.5GB max)\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ RMM Pool Setup fehlgeschlagen: {e}\")\n",
    "        print(\"  Verwende Standard GPU Memory Management\")\n",
    "        return True\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Räumt GPU-Speicher auf.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    if CUML_AVAILABLE:\n",
    "        try:\n",
    "            mempool = cp.get_default_memory_pool()\n",
    "            pinned_mempool = cp.get_default_pinned_memory_pool()\n",
    "            mempool.free_all_blocks()\n",
    "            pinned_mempool.free_all_blocks()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "def get_gpu_memory_info():\n",
    "    \"\"\"Gibt aktuelle GPU-Speichernutzung zurück.\"\"\"\n",
    "    info = {}\n",
    "    \n",
    "    # Versuche nvidia-smi (funktioniert fast immer)\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.total', \n",
    "                               '--format=csv,noheader,nounits'], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            values = result.stdout.strip().split(', ')\n",
    "            info['gpu_used'] = float(values[0]) / 1024  # MB to GB\n",
    "            info['gpu_total'] = float(values[1]) / 1024\n",
    "            info['gpu_free'] = info['gpu_total'] - info['gpu_used']\n",
    "            return info\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback: Keine GPU Info verfügbar\n",
    "    return {'gpu_used': 0.0, 'gpu_total': 0.0, 'gpu_free': 0.0}\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Reproduzierbarkeit\n",
    "# -------------------------------------------------------------------------------\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Logging konfigurieren\n",
    "# -------------------------------------------------------------------------------\n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            os.path.join(log_dir, f\"gpu_svm_active_learning_{time.strftime('%Y%m%d_%H%M%S')}.log\"),\n",
    "            encoding='utf-8'\n",
    "        ),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Erstelle Output-Verzeichnisse\n",
    "output_dirs = [\"plots\", \"results\", \"reports\"]\n",
    "for dir_name in output_dirs:\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "        logger.info(f\"Erstellt Verzeichnis: {dir_name}\")\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# MNIST Daten laden\n",
    "# -------------------------------------------------------------------------------\n",
    "def load_mnist_data():\n",
    "    \"\"\"Lädt MNIST-Datensatz optimiert für GPU-Verarbeitung.\"\"\"\n",
    "    logger.info(\"Lade MNIST-Datensatz...\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    data_dir = './data'\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    try:\n",
    "        train_dataset = torchvision.datasets.MNIST(\n",
    "            root=data_dir, train=True, download=True, transform=transform\n",
    "        )\n",
    "        test_dataset = torchvision.datasets.MNIST(\n",
    "            root=data_dir, train=False, download=True, transform=transform\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Laden des MNIST-Datensatzes: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Konvertiere zu numpy arrays\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    \n",
    "    X_train, y_train = next(iter(train_loader))\n",
    "    X_test, y_test = next(iter(test_loader))\n",
    "    \n",
    "    # Flatten für SVM (2D: batch, features)\n",
    "    X_train_flat = X_train.view(X_train.size(0), -1).numpy()\n",
    "    X_test_flat = X_test.view(X_test.size(0), -1).numpy()\n",
    "    \n",
    "    y_train = y_train.numpy()\n",
    "    y_test = y_test.numpy()\n",
    "    \n",
    "    logger.info(f\"✓ Datensatz geladen: {len(X_train_flat):,} Trainingsbilder, {len(X_test_flat):,} Testbilder\")\n",
    "    logger.info(f\"  Feature-Dimensionen: {X_train_flat.shape[1]}\")\n",
    "    logger.info(f\"  Klassen: {len(np.unique(y_train))}\")\n",
    "    logger.info(f\"  Speicherbedarf: {(X_train_flat.nbytes + X_test_flat.nbytes) / 1024**2:.1f} MB\")\n",
    "    \n",
    "    return X_train_flat, y_train, X_test_flat, y_test\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# GPU-SVM Wrapper Klasse\n",
    "# -------------------------------------------------------------------------------\n",
    "class GPUOptimizedSVM:\n",
    "    \"\"\"\n",
    "    Wrapper für verschiedene SVM-Implementierungen mit automatischer GPU-Auswahl.\n",
    "    Priorisiert RAPIDS cuML > ThunderSVM > sklearn basierend auf Verfügbarkeit.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_samples=None):\n",
    "        self.n_samples = n_samples\n",
    "        self.backend = None\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_fitted = False\n",
    "        \n",
    "        # Wähle Backend basierend auf Verfügbarkeit\n",
    "        self._select_backend()\n",
    "        \n",
    "    def _select_backend(self):\n",
    "        \"\"\"Wählt optimales Backend basierend auf Verfügbarkeit.\"\"\"\n",
    "        if CUML_AVAILABLE:\n",
    "            try:\n",
    "                # Test ob cuML wirklich funktioniert\n",
    "                test_data = cp.random.rand(100, 10, dtype=cp.float32)\n",
    "                test_labels = cp.random.randint(0, 2, 100, dtype=cp.int32)\n",
    "                test_model = cuMLSVC(max_iter=1)\n",
    "                test_model.fit(test_data, test_labels)\n",
    "                self.backend = 'cuml'\n",
    "                \n",
    "                # Zeige Memory Info\n",
    "                mem_info = get_gpu_memory_info()\n",
    "                if 'gpu_total' in mem_info:\n",
    "                    logger.info(f\"✓ Verwende RAPIDS cuML SVM (GPU: {mem_info.get('gpu_used', 0):.1f}/{mem_info.get('gpu_total', 0):.1f} GB)\")\n",
    "                else:\n",
    "                    logger.info(\"✓ Verwende RAPIDS cuML SVM\")\n",
    "                    \n",
    "                del test_data, test_labels, test_model\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"cuML Test fehlgeschlagen: {e}\")\n",
    "                \n",
    "        if self.backend is None and THUNDERSVM_AVAILABLE:\n",
    "            try:\n",
    "                # Einfacher Test ohne Daten\n",
    "                test_model = ThunderSVC(max_iter=1)\n",
    "                self.backend = 'thundersvm'\n",
    "                logger.info(\"✓ Verwende ThunderSVM (GPU)\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"ThunderSVM Test fehlgeschlagen: {e}\")\n",
    "        \n",
    "        if self.backend is None:\n",
    "            self.backend = 'sklearn'\n",
    "            logger.warning(\"⚠ Verwende sklearn SVM (CPU) - keine GPU-Beschleunigung verfügbar!\")\n",
    "            logger.info(\"  Dies wird deutlich langsamer sein als GPU-beschleunigte Alternativen.\")\n",
    "            logger.info(\"  Empfehlung: Installieren Sie RAPIDS cuML für optimale Performance.\")\n",
    "    \n",
    "    def _create_model(self):\n",
    "        \"\"\"Erstellt SVM-Modell basierend auf gewähltem Backend.\"\"\"\n",
    "        if self.backend == 'cuml':\n",
    "            return cuMLSVC(**SVM_CONFIGS['cuml'])\n",
    "        elif self.backend == 'thundersvm':\n",
    "            return ThunderSVC(**SVM_CONFIGS['thundersvm'])\n",
    "        else:\n",
    "            return SklearnSVC(**SVM_CONFIGS['sklearn'])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Trainiert SVM mit automatischer GPU-Optimierung.\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Feature Scaling\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Deaktiviere Chunked Training bei Problemen\n",
    "        if self.backend == 'cuml' and len(X) > 100000:  # Höhere Schwelle\n",
    "            logger.info(f\"  Verwende Chunked Training für {len(X):,} Samples...\")\n",
    "            self._fit_chunked_gpu(X_scaled, y)\n",
    "        else:\n",
    "            # Normales Training mit Error Handling\n",
    "            try:\n",
    "                self.model = self._create_model()\n",
    "                \n",
    "                if self.backend == 'cuml':\n",
    "                    # Konvertiere zu CuPy Arrays\n",
    "                    X_gpu = cp.asarray(X_scaled, dtype=cp.float32)\n",
    "                    y_gpu = cp.asarray(y, dtype=cp.int32)\n",
    "                    \n",
    "                    # Explizite CUDA Synchronisation\n",
    "                    cp.cuda.Stream.null.synchronize()\n",
    "                    \n",
    "                    self.model.fit(X_gpu, y_gpu)\n",
    "                    \n",
    "                    # Cleanup\n",
    "                    del X_gpu, y_gpu\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                else:\n",
    "                    self.model.fit(X_scaled, y)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if self.backend == 'cuml':\n",
    "                    logger.warning(f\"  GPU Training fehlgeschlagen: {e}\")\n",
    "                    logger.info(\"  Fallback zu CPU...\")\n",
    "                    \n",
    "                    # Fallback zu sklearn\n",
    "                    self.backend = 'sklearn'\n",
    "                    self.model = self._create_model()\n",
    "                    self.model.fit(X_scaled, y)\n",
    "                else:\n",
    "                    raise\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        logger.info(f\"  Training abgeschlossen in {train_time:.2f}s (Backend: {self.backend})\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _fit_chunked_gpu(self, X, y, chunk_size=30000):\n",
    "        \"\"\"Chunked Training für große Datensätze auf GPU.\"\"\"\n",
    "        # Fallback zu normalem Training bei Problemen\n",
    "        try:\n",
    "            # Normales Training ohne Chunks versuchen\n",
    "            self.model = self._create_model()\n",
    "            X_gpu = cp.asarray(X, dtype=cp.float32)\n",
    "            y_gpu = cp.asarray(y, dtype=cp.int32)\n",
    "            \n",
    "            # Explizite CUDA Synchronisation\n",
    "            cp.cuda.Stream.null.synchronize()\n",
    "            \n",
    "            self.model.fit(X_gpu, y_gpu)\n",
    "            \n",
    "            # Cleanup\n",
    "            del X_gpu, y_gpu\n",
    "            clear_gpu_memory()\n",
    "            \n",
    "            logger.info(\"  Training erfolgreich (ohne Chunks)\")\n",
    "            return\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"  GPU Training fehlgeschlagen: {e}\")\n",
    "            logger.info(\"  Fallback zu CPU Training...\")\n",
    "            \n",
    "            # Fallback zu sklearn\n",
    "            self.backend = 'sklearn'\n",
    "            self.model = self._create_model()\n",
    "            self.model.fit(X, y)\n",
    "            \n",
    "            logger.info(\"  CPU Training erfolgreich\")\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Gibt Wahrscheinlichkeiten zurück.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model not fitted!\")\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        if self.backend == 'cuml':\n",
    "            X_gpu = cp.asarray(X_scaled, dtype=cp.float32)\n",
    "            probs = self.model.predict_proba(X_gpu)\n",
    "            return cp.asnumpy(probs)\n",
    "        elif self.backend == 'thundersvm':\n",
    "            # ThunderSVM probability prediction\n",
    "            if hasattr(self.model, 'predict_proba'):\n",
    "                return self.model.predict_proba(X_scaled)\n",
    "            else:\n",
    "                # Fallback für ThunderSVM ohne probability\n",
    "                predictions = self.model.predict(X_scaled)\n",
    "                n_classes = 10  # MNIST\n",
    "                probs = np.zeros((len(predictions), n_classes))\n",
    "                for i, pred in enumerate(predictions):\n",
    "                    probs[i, int(pred)] = 1.0\n",
    "                return probs\n",
    "        else:\n",
    "            return self.model.predict_proba(X_scaled)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Gibt Vorhersagen zurück.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model not fitted!\")\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        if self.backend == 'cuml':\n",
    "            X_gpu = cp.asarray(X_scaled, dtype=cp.float32)\n",
    "            predictions = self.model.predict(X_gpu)\n",
    "            return cp.asnumpy(predictions).astype(int)\n",
    "        else:\n",
    "            return self.model.predict(X_scaled)\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Query-Strategien\n",
    "# -------------------------------------------------------------------------------\n",
    "def entropy_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"Wählt Samples mit höchster Entropie aus.\"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        epsilon = 1e-10\n",
    "        probs = np.clip(probs, epsilon, 1.0 - epsilon)\n",
    "        entropies = -np.sum(probs * np.log(probs), axis=1)\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        return np.argsort(entropies)[-n_instances:]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Entropy Sampling: {e}\")\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def margin_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"Wählt Samples mit kleinstem Margin zwischen Top-2 Klassen.\"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        sorted_probs = np.sort(probs, axis=1)\n",
    "        \n",
    "        if sorted_probs.shape[1] >= 2:\n",
    "            margins = sorted_probs[:, -1] - sorted_probs[:, -2]\n",
    "        else:\n",
    "            margins = 1.0 - sorted_probs[:, -1]\n",
    "        \n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        return np.argsort(margins)[:n_instances]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Margin Sampling: {e}\")\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def least_confidence_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"Wählt Samples mit geringster Konfidenz.\"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        return np.argsort(confidences)[:n_instances]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Least Confidence Sampling: {e}\")\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def random_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"Zufällige Auswahl (Baseline).\"\"\"\n",
    "    try:\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        if n_instances <= 0:\n",
    "            return np.array([], dtype=int)\n",
    "        return np.random.choice(len(X_pool), size=n_instances, replace=False)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Random Sampling: {e}\")\n",
    "        return np.arange(min(n_instances, len(X_pool)))\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Active Learning Hauptfunktion\n",
    "# -------------------------------------------------------------------------------\n",
    "def run_gpu_svm_active_learning(X_train, y_train, X_test, y_test,\n",
    "                               strategy_name, strategy_func,\n",
    "                               budget_percentages, batch_size=500):\n",
    "    \"\"\"\n",
    "    Führt GPU-optimiertes Active Learning Experiment mit SVM durch.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    n_total = len(y_train)\n",
    "    \n",
    "    for budget_pct in budget_percentages:\n",
    "        n_budget = int(budget_pct * n_total)\n",
    "        \n",
    "        logger.info(f\"\\nGPU-SVM + {strategy_name} - Budget: {budget_pct:.0%} ({n_budget:,} Samples)\")\n",
    "        \n",
    "        for run in range(N_RUNS):\n",
    "            logger.info(f\"  Run {run+1}/{N_RUNS}\")\n",
    "            \n",
    "            try:\n",
    "                # Set seed for reproducibility\n",
    "                np.random.seed(SEED + run)\n",
    "                \n",
    "                # Initialisierung\n",
    "                pool_indices = np.arange(n_total)\n",
    "                labeled_indices = []\n",
    "                \n",
    "                # Initiale zufällige Auswahl\n",
    "                n_initial = max(100, int(INITIAL_PERCENTAGE * n_total))\n",
    "                n_initial = min(n_initial, len(pool_indices))\n",
    "                \n",
    "                initial_indices = np.random.choice(pool_indices, size=n_initial, replace=False)\n",
    "                labeled_indices = list(initial_indices)\n",
    "                pool_indices = np.setdiff1d(pool_indices, labeled_indices)\n",
    "                \n",
    "                # Tracking\n",
    "                accuracies = []\n",
    "                n_labeled_list = []\n",
    "                query_times = []\n",
    "                train_times = []\n",
    "                \n",
    "                while len(labeled_indices) < n_budget and len(pool_indices) > 0:\n",
    "                    # Clear GPU memory before training\n",
    "                    clear_gpu_memory()\n",
    "                    \n",
    "                    # Modell erstellen und trainieren\n",
    "                    model = GPUOptimizedSVM(n_samples=len(labeled_indices))\n",
    "                    \n",
    "                    train_start = time.time()\n",
    "                    model.fit(X_train[labeled_indices], y_train[labeled_indices])\n",
    "                    train_time = time.time() - train_start\n",
    "                    train_times.append(train_time)\n",
    "                    \n",
    "                    # Evaluation\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    acc = accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    accuracies.append(acc)\n",
    "                    n_labeled_list.append(len(labeled_indices))\n",
    "                    \n",
    "                    # Nächste Batch auswählen\n",
    "                    n_query = min(batch_size, n_budget - len(labeled_indices), len(pool_indices))\n",
    "                    if n_query <= 0:\n",
    "                        break\n",
    "                    \n",
    "                    # Query mit Zeitmessung\n",
    "                    query_start = time.time()\n",
    "                    query_indices = strategy_func(model, X_train[pool_indices], n_query)\n",
    "                    query_time = time.time() - query_start\n",
    "                    query_times.append(query_time)\n",
    "                    \n",
    "                    # Validierung der Query-Indizes\n",
    "                    query_indices = np.asarray(query_indices)\n",
    "                    query_indices = query_indices[query_indices < len(pool_indices)]\n",
    "                    \n",
    "                    if len(query_indices) == 0:\n",
    "                        logger.warning(f\"Keine gültigen Query-Indizes in Run {run+1}\")\n",
    "                        break\n",
    "                    \n",
    "                    selected_indices = pool_indices[query_indices]\n",
    "                    \n",
    "                    # Update\n",
    "                    labeled_indices.extend(selected_indices)\n",
    "                    pool_indices = np.setdiff1d(pool_indices, selected_indices)\n",
    "                    \n",
    "                    # Progress logging - nur bei wichtigen Meilensteinen\n",
    "                    if len(labeled_indices) % 10000 == 0 or len(labeled_indices) == n_budget:\n",
    "                        mem_info = get_gpu_memory_info()\n",
    "                        gpu_mem_str = \"\"\n",
    "                        if model.backend in ['cuml', 'thundersvm'] and 'gpu_used' in mem_info:\n",
    "                            gpu_mem_str = f\" | GPU: {mem_info['gpu_used']:.1f}/{mem_info['gpu_total']:.1f} GB\"\n",
    "                        \n",
    "                        logger.info(f\"    {len(labeled_indices):,} labeled → Accuracy: {acc:.4f} \"\n",
    "                                  f\"(Train: {train_time:.1f}s, Query: {query_time:.2f}s){gpu_mem_str}\")\n",
    "                \n",
    "                # Finale Evaluation mit mehr Training\n",
    "                if len(labeled_indices) > 0:\n",
    "                    clear_gpu_memory()\n",
    "                    model = GPUOptimizedSVM(n_samples=len(labeled_indices))\n",
    "                    model.fit(X_train[labeled_indices], y_train[labeled_indices])\n",
    "                    \n",
    "                    y_pred = model.predict(X_test)\n",
    "                    final_acc = accuracy_score(y_test, y_pred)\n",
    "                    final_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                    \n",
    "                    results.append({\n",
    "                        'strategy': strategy_name,\n",
    "                        'budget_pct': budget_pct,\n",
    "                        'run': run,\n",
    "                        'n_labeled': len(labeled_indices),\n",
    "                        'accuracy': final_acc,\n",
    "                        'f1_score': final_f1,\n",
    "                        'accuracies': accuracies,\n",
    "                        'n_labeled_list': n_labeled_list,\n",
    "                        'avg_query_time': np.mean(query_times) if query_times else 0,\n",
    "                        'avg_train_time': np.mean(train_times) if train_times else 0,\n",
    "                        'backend': model.backend\n",
    "                    })\n",
    "                    \n",
    "                    logger.info(f\"    Final: {len(labeled_indices):,} labeled → \"\n",
    "                              f\"Accuracy: {final_acc:.4f}, F1: {final_f1:.4f}\")\n",
    "                \n",
    "                # Cleanup\n",
    "                clear_gpu_memory()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Fehler in Run {run+1}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Statistische Analyse\n",
    "# -------------------------------------------------------------------------------\n",
    "def cliffs_delta(x, y):\n",
    "    \"\"\"Berechnet Cliff's Delta als Effektstärkemaß.\"\"\"\n",
    "    try:\n",
    "        nx = len(x)\n",
    "        ny = len(y)\n",
    "        \n",
    "        if nx == 0 or ny == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        greater = 0\n",
    "        less = 0\n",
    "        \n",
    "        for xi in x:\n",
    "            greater += np.sum(xi > y)\n",
    "            less += np.sum(xi < y)\n",
    "        \n",
    "        d = (greater - less) / (nx * ny)\n",
    "        d = np.clip(d, -1.0, 1.0)\n",
    "        \n",
    "        return d\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Cliff's Delta: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def interpret_cliffs_delta(d):\n",
    "    \"\"\"Interpretiert die Effektstärke.\"\"\"\n",
    "    try:\n",
    "        abs_d = abs(float(d))\n",
    "        if abs_d < 0.147:\n",
    "            return \"negligible\"\n",
    "        elif abs_d < 0.33:\n",
    "            return \"small\"\n",
    "        elif abs_d < 0.474:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"large\"\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "def perform_statistical_analysis(results_df, metric='accuracy'):\n",
    "    \"\"\"Führt statistische Analyse durch.\"\"\"\n",
    "    statistical_results = []\n",
    "    \n",
    "    try:\n",
    "        strategies = results_df['strategy'].unique()\n",
    "        budget_levels = results_df['budget_pct'].unique()\n",
    "        \n",
    "        for budget_pct in budget_levels:\n",
    "            # Random Sampling als Baseline\n",
    "            baseline_data = results_df[\n",
    "                (results_df['strategy'] == 'Random Sampling') & \n",
    "                (results_df['budget_pct'] == budget_pct)\n",
    "            ][metric].values\n",
    "            \n",
    "            for strategy in strategies:\n",
    "                if strategy == 'Random Sampling':\n",
    "                    continue\n",
    "                    \n",
    "                strategy_data = results_df[\n",
    "                    (results_df['strategy'] == strategy) & \n",
    "                    (results_df['budget_pct'] == budget_pct)\n",
    "                ][metric].values\n",
    "                \n",
    "                if len(baseline_data) >= N_RUNS and len(strategy_data) >= N_RUNS:\n",
    "                    # Wilcoxon Test\n",
    "                    try:\n",
    "                        if np.allclose(strategy_data, baseline_data):\n",
    "                            statistic, p_value = 0.0, 1.0\n",
    "                        else:\n",
    "                            statistic, p_value = wilcoxon(\n",
    "                                strategy_data, baseline_data, \n",
    "                                alternative='greater',\n",
    "                                zero_method='zsplit'\n",
    "                            )\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Wilcoxon Test fehlgeschlagen: {e}\")\n",
    "                        statistic, p_value = 0.0, 1.0\n",
    "                    \n",
    "                    # Effektstärke\n",
    "                    effect_size = cliffs_delta(strategy_data, baseline_data)\n",
    "                    effect_interpretation = interpret_cliffs_delta(effect_size)\n",
    "                    \n",
    "                    # Statistiken\n",
    "                    baseline_mean = np.mean(baseline_data)\n",
    "                    baseline_std = np.std(baseline_data)\n",
    "                    strategy_mean = np.mean(strategy_data)\n",
    "                    strategy_std = np.std(strategy_data)\n",
    "                    \n",
    "                    improvement = strategy_mean - baseline_mean\n",
    "                    improvement_pct = ((improvement / baseline_mean) * 100) if baseline_mean > 0 else 0\n",
    "                    \n",
    "                    statistical_results.append({\n",
    "                        'strategy': strategy,\n",
    "                        'budget_pct': budget_pct,\n",
    "                        'baseline_mean': baseline_mean,\n",
    "                        'baseline_std': baseline_std,\n",
    "                        'strategy_mean': strategy_mean,\n",
    "                        'strategy_std': strategy_std,\n",
    "                        'improvement': improvement,\n",
    "                        'improvement_pct': improvement_pct,\n",
    "                        'wilcoxon_statistic': float(statistic),\n",
    "                        'p_value': float(p_value),\n",
    "                        'cliffs_delta': float(effect_size),\n",
    "                        'effect_size': effect_interpretation,\n",
    "                        'n_samples': len(strategy_data)\n",
    "                    })\n",
    "        \n",
    "        stat_df = pd.DataFrame(statistical_results)\n",
    "        \n",
    "        if len(stat_df) > 0:\n",
    "            # Bonferroni-Korrektur\n",
    "            n_comparisons = len(stat_df)\n",
    "            stat_df['p_value_corrected'] = np.minimum(stat_df['p_value'] * n_comparisons, 1.0)\n",
    "            stat_df['significant'] = stat_df['p_value_corrected'] < SIGNIFICANCE_LEVEL\n",
    "        \n",
    "        return stat_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei statistischer Analyse: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def create_statistical_report(stat_results):\n",
    "    \"\"\"Erstellt deutschen statistischen Bericht.\"\"\"\n",
    "    strategy_labels_de = {\n",
    "        'Random Sampling': 'Zufällige Auswahl',\n",
    "        'Entropy Sampling': 'Entropie-Auswahl',\n",
    "        'Margin Sampling': 'Margin-Auswahl',\n",
    "        'Least Confidence': 'Geringste Konfidenz'\n",
    "    }\n",
    "    \n",
    "    effect_labels_de = {\n",
    "        'negligible': 'vernachlässigbar',\n",
    "        'small': 'klein',\n",
    "        'medium': 'mittel',\n",
    "        'large': 'groß'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Sortiere nach Effektstärke\n",
    "        if not stat_results.empty and 'cliffs_delta' in stat_results.columns:\n",
    "            stat_results_sorted = stat_results.sort_values('cliffs_delta', ascending=False)\n",
    "        else:\n",
    "            stat_results_sorted = stat_results\n",
    "        \n",
    "        # Erstelle formatierten Bericht\n",
    "        report = []\n",
    "        report.append(\"\\n\" + \"=\"*100)\n",
    "        report.append(\"DETAILLIERTER STATISTISCHER BERICHT - GPU-SVM ACTIVE LEARNING\")\n",
    "        report.append(\"=\"*100)\n",
    "        report.append(f\"Signifikanzniveau: {SIGNIFICANCE_LEVEL} (mit Bonferroni-Korrektur)\")\n",
    "        report.append(f\"Anzahl Runs pro Experiment: {N_RUNS}\")\n",
    "        report.append(f\"Statistischer Test: Wilcoxon Signed-Rank Test\")\n",
    "        report.append(f\"Effektstärkemaß: Cliff's Delta\")\n",
    "        report.append(\"\\n\")\n",
    "        \n",
    "        # Signifikante Ergebnisse\n",
    "        if 'significant' in stat_results_sorted.columns:\n",
    "            sig_results = stat_results_sorted[stat_results_sorted['significant']]\n",
    "        else:\n",
    "            sig_results = pd.DataFrame()\n",
    "        \n",
    "        if not sig_results.empty:\n",
    "            report.append(\"SIGNIFIKANTE VERBESSERUNGEN GEGENÜBER ZUFÄLLIGER AUSWAHL:\")\n",
    "            report.append(\"-\"*100)\n",
    "            report.append(f\"{'Strategie':<20} {'Budget':<10} {'Verbesserung':<15} \"\n",
    "                         f\"{'p-Wert':<12} {'Effekt':<15} {'Interpretation':<20}\")\n",
    "            report.append(\"-\"*100)\n",
    "            \n",
    "            for _, row in sig_results.iterrows():\n",
    "                strategy_de = strategy_labels_de.get(row['strategy'], row['strategy'])\n",
    "                effect_de = effect_labels_de.get(row['effect_size'], row['effect_size'])\n",
    "                \n",
    "                report.append(f\"{strategy_de:<20} \"\n",
    "                             f\"{int(row['budget_pct']*100):>8}% \"\n",
    "                             f\"{row['improvement_pct']:>13.2f}% \"\n",
    "                             f\"{row['p_value_corrected']:>11.4f} \"\n",
    "                             f\"{row['cliffs_delta']:>14.3f} \"\n",
    "                             f\"{effect_de:<20}\")\n",
    "        else:\n",
    "            report.append(\"Keine signifikanten Verbesserungen gefunden!\")\n",
    "        \n",
    "        # Zusammenfassung nach Strategie\n",
    "        report.append(\"\\n\\nZUSAMMENFASSUNG NACH STRATEGIE:\")\n",
    "        report.append(\"-\"*100)\n",
    "        \n",
    "        for strategy in ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "            if 'strategy' in stat_results.columns:\n",
    "                strategy_data = stat_results[stat_results['strategy'] == strategy]\n",
    "                if not strategy_data.empty:\n",
    "                    sig_count = strategy_data['significant'].sum() if 'significant' in strategy_data.columns else 0\n",
    "                    avg_improvement = strategy_data['improvement_pct'].mean() if 'improvement_pct' in strategy_data.columns else 0\n",
    "                    avg_effect = strategy_data['cliffs_delta'].mean() if 'cliffs_delta' in strategy_data.columns else 0\n",
    "                    \n",
    "                    strategy_de = strategy_labels_de.get(strategy, strategy)\n",
    "                    report.append(f\"\\n{strategy_de}:\")\n",
    "                    report.append(f\"  - Signifikante Verbesserungen: {sig_count}/{len(strategy_data)} \"\n",
    "                                 f\"({sig_count/len(strategy_data)*100:.1f}%)\")\n",
    "                    report.append(f\"  - Durchschnittliche Verbesserung: {avg_improvement:.2f}%\")\n",
    "                    report.append(f\"  - Durchschnittliche Effektstärke: {avg_effect:.3f}\")\n",
    "        \n",
    "        # Empfehlung\n",
    "        report.append(\"\\n\\nEMPFEHLUNG:\")\n",
    "        report.append(\"-\"*100)\n",
    "        \n",
    "        if not sig_results.empty:\n",
    "            best_row = sig_results.iloc[0]\n",
    "            strategy_de = strategy_labels_de.get(best_row['strategy'], best_row['strategy'])\n",
    "            report.append(f\"Die beste Active Learning Strategie ist {strategy_de}\")\n",
    "            report.append(f\"mit einer durchschnittlichen Verbesserung von {best_row['improvement_pct']:.2f}%\")\n",
    "            report.append(f\"und einer {effect_labels_de.get(best_row['effect_size'], best_row['effect_size'])}en Effektstärke.\")\n",
    "        else:\n",
    "            report.append(\"Die Active Learning Strategien zeigen keine signifikanten Verbesserungen\")\n",
    "            report.append(\"gegenüber der zufälligen Auswahl in diesem Experiment.\")\n",
    "        \n",
    "        report.append(\"\\n\" + \"=\"*100)\n",
    "        \n",
    "        # Ausgabe\n",
    "        report_text = \"\\n\".join(report)\n",
    "        print(report_text)\n",
    "        \n",
    "        # Speichern\n",
    "        report_filename = 'reports/gpu_svm_statistischer_bericht.txt'\n",
    "        try:\n",
    "            with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(report_text)\n",
    "            logger.info(f\"✓ Statistischer Bericht gespeichert: {report_filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern des Berichts: {e}\")\n",
    "        \n",
    "        return report_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei create_statistical_report: {e}\")\n",
    "        return \"Fehler bei der Berichterstellung\"\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Visualisierungen (Deutsch)\n",
    "# -------------------------------------------------------------------------------\n",
    "def plot_gpu_svm_results(all_results, stat_results):\n",
    "    \"\"\"Erstellt GPU-SVM spezifische Visualisierungen auf Deutsch.\"\"\"\n",
    "    # Deutsche Matplotlib Konfiguration\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    try:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    except:\n",
    "        plt.style.use('ggplot')\n",
    "    \n",
    "    # Farben für Strategien\n",
    "    strategy_colors = {\n",
    "        'Random Sampling': '#808080',\n",
    "        'Entropy Sampling': '#1f77b4',\n",
    "        'Margin Sampling': '#ff7f0e',\n",
    "        'Least Confidence': '#2ca02c'\n",
    "    }\n",
    "    \n",
    "    # Deutsche Labels\n",
    "    strategy_labels_de = {\n",
    "        'Random Sampling': 'Zufällige Auswahl',\n",
    "        'Entropy Sampling': 'Entropie-Auswahl',\n",
    "        'Margin Sampling': 'Margin-Auswahl',\n",
    "        'Least Confidence': 'Geringste Konfidenz'\n",
    "    }\n",
    "    \n",
    "    effect_labels_de = {\n",
    "        'negligible': 'vernachlässigbar',\n",
    "        'small': 'klein',\n",
    "        'medium': 'mittel',\n",
    "        'large': 'groß'\n",
    "    }\n",
    "    \n",
    "    # 1. Hauptvisualisierung: Lernkurven mit Signifikanz\n",
    "    fig, axes = plt.subplots(1, len(BUDGET_PERCENTAGES), figsize=(20, 5))\n",
    "    \n",
    "    if len(BUDGET_PERCENTAGES) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    fig.suptitle('GPU-optimierte SVM Active Learning Performance', fontsize=16, y=1.02)\n",
    "    \n",
    "    # Sammle alle y-Werte für dynamische Skalierung\n",
    "    all_y_values = []\n",
    "    \n",
    "    for budget_idx, budget_pct in enumerate(BUDGET_PERCENTAGES):\n",
    "        ax = axes[budget_idx]\n",
    "        \n",
    "        for strategy, color in strategy_colors.items():\n",
    "            strategy_results = [r for r in all_results \n",
    "                              if r['strategy'] == strategy \n",
    "                              and r['budget_pct'] == budget_pct]\n",
    "            \n",
    "            if strategy_results:\n",
    "                # Lernkurven aggregieren\n",
    "                max_samples = int(budget_pct * 60000)\n",
    "                x_common = np.linspace(100, max_samples, 100)\n",
    "                y_interpolated = []\n",
    "                \n",
    "                for r in strategy_results:\n",
    "                    if len(r['n_labeled_list']) > 1:\n",
    "                        try:\n",
    "                            y_interp = np.interp(x_common, r['n_labeled_list'], r['accuracies'])\n",
    "                            y_interpolated.append(y_interp)\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                if y_interpolated:\n",
    "                    y_mean = np.mean(y_interpolated, axis=0)\n",
    "                    y_std = np.std(y_interpolated, axis=0)\n",
    "                    \n",
    "                    # Sammle Werte für Skalierung\n",
    "                    all_y_values.extend(y_mean - y_std)\n",
    "                    all_y_values.extend(y_mean + y_std)\n",
    "                    \n",
    "                    # Signifikanz prüfen\n",
    "                    is_significant = False\n",
    "                    effect_size = \"\"\n",
    "                    if strategy != 'Random Sampling' and not stat_results.empty:\n",
    "                        sig_data = stat_results[\n",
    "                            (stat_results['strategy'] == strategy) & \n",
    "                            (stat_results['budget_pct'] == budget_pct)\n",
    "                        ]\n",
    "                        if not sig_data.empty:\n",
    "                            is_significant = sig_data.iloc[0]['significant']\n",
    "                            effect_size = effect_labels_de.get(\n",
    "                                sig_data.iloc[0]['effect_size'], \n",
    "                                sig_data.iloc[0]['effect_size']\n",
    "                            )\n",
    "                    \n",
    "                    label = strategy_labels_de.get(strategy, strategy)\n",
    "                    if is_significant:\n",
    "                        label += f\" *({effect_size})\"\n",
    "                    \n",
    "                    # Backend info\n",
    "                    backend = strategy_results[0].get('backend', 'unknown')\n",
    "                    if strategy == 'Random Sampling':\n",
    "                        label += f\" [{backend}]\"\n",
    "                    \n",
    "                    ax.plot(x_common, y_mean, \n",
    "                           label=label, \n",
    "                           color=color, \n",
    "                           linewidth=2.5,\n",
    "                           linestyle='-' if not is_significant or strategy == 'Random Sampling' else '--')\n",
    "                    \n",
    "                    ax.fill_between(x_common, \n",
    "                                  y_mean - y_std, \n",
    "                                  y_mean + y_std, \n",
    "                                  color=color, \n",
    "                                  alpha=0.2)\n",
    "        \n",
    "        ax.set_xlabel('Anzahl gelabelter Beispiele', fontsize=12)\n",
    "        ax.set_ylabel('Test-Genauigkeit', fontsize=12)\n",
    "        ax.set_title(f'Budget: {int(budget_pct*100)}%', fontsize=13)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Dynamische Y-Achsen-Skalierung\n",
    "        if all_y_values:\n",
    "            y_min = min(all_y_values)\n",
    "            y_max = max(all_y_values)\n",
    "            y_range = y_max - y_min\n",
    "            \n",
    "            # Füge 10% Padding hinzu\n",
    "            y_min_adj = y_min - 0.1 * y_range\n",
    "            y_max_adj = y_max + 0.1 * y_range\n",
    "            \n",
    "            # Stelle sicher, dass die Skalierung sinnvoll ist\n",
    "            if y_range < 0.05:  # Wenn Bereich sehr klein\n",
    "                center = (y_min + y_max) / 2\n",
    "                y_min_adj = center - 0.03\n",
    "                y_max_adj = center + 0.03\n",
    "            \n",
    "            ax.set_ylim([max(0.0, y_min_adj), min(1.0, y_max_adj)])\n",
    "        \n",
    "        # X-Achse formatieren\n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}k'))\n",
    "        \n",
    "        if budget_idx == 0:\n",
    "            ax.legend(loc='lower right', fontsize=10, framealpha=0.9)\n",
    "        \n",
    "        # Reset für nächste Iteration\n",
    "        all_y_values = []\n",
    "    \n",
    "    fig.text(0.5, -0.05, \n",
    "            '* = statistisch signifikant (p < 0,05); Effektstärke: vernachlässigbar/klein/mittel/groß',\n",
    "            ha='center', fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = 'plots/gpu_svm_active_learning_performance.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"✓ Visualisierung erstellt: {filename}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. GPU Performance Metriken\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('GPU-SVM Leistungsmetriken', fontsize=16)\n",
    "    \n",
    "    # Training Zeit Vergleich\n",
    "    ax1 = axes[0, 0]\n",
    "    train_times = []\n",
    "    for strategy in strategy_colors.keys():\n",
    "        times = [r['avg_train_time'] for r in all_results if r['strategy'] == strategy]\n",
    "        if times:\n",
    "            train_times.append({\n",
    "                'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                'Zeit': np.mean(times),\n",
    "                'Std': np.std(times)\n",
    "            })\n",
    "    \n",
    "    if train_times:\n",
    "        df_times = pd.DataFrame(train_times)\n",
    "        bars = ax1.bar(df_times['Strategie'], df_times['Zeit'], \n",
    "                       yerr=df_times['Std'], capsize=5, color='steelblue')\n",
    "        ax1.set_title('Durchschnittliche Trainingszeit pro Batch', fontsize=13)\n",
    "        ax1.set_ylabel('Zeit (Sekunden)', fontsize=11)\n",
    "        ax1.set_xlabel('')\n",
    "        ax1.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Rotiere Labels für bessere Lesbarkeit\n",
    "        ax1.set_xticklabels(df_times['Strategie'], rotation=25, ha='right')\n",
    "        \n",
    "        # Dynamische Y-Achsen-Skalierung\n",
    "        if df_times['Zeit'].max() > 0:\n",
    "            ax1.set_ylim([0, df_times['Zeit'].max() * 1.2])\n",
    "    \n",
    "    # Query Zeit Vergleich\n",
    "    ax2 = axes[0, 1]\n",
    "    query_times = []\n",
    "    for strategy in strategy_colors.keys():\n",
    "        times = [r['avg_query_time'] for r in all_results if r['strategy'] == strategy]\n",
    "        if times:\n",
    "            query_times.append({\n",
    "                'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                'Zeit': np.mean(times),\n",
    "                'Std': np.std(times)\n",
    "            })\n",
    "    \n",
    "    if query_times:\n",
    "        df_query = pd.DataFrame(query_times)\n",
    "        bars = ax2.bar(df_query['Strategie'], df_query['Zeit'], \n",
    "                       yerr=df_query['Std'], capsize=5, color='darkorange')\n",
    "        ax2.set_title('Durchschnittliche Query-Zeit pro Batch', fontsize=13)\n",
    "        ax2.set_ylabel('Zeit (Sekunden)', fontsize=11)\n",
    "        ax2.set_xlabel('')\n",
    "        ax2.grid(axis='y', alpha=0.3)\n",
    "        ax2.set_xticklabels(df_query['Strategie'], rotation=25, ha='right')\n",
    "        \n",
    "        # Dynamische Y-Achsen-Skalierung\n",
    "        if df_query['Zeit'].max() > 0:\n",
    "            ax2.set_ylim([0, df_query['Zeit'].max() * 1.2])\n",
    "    \n",
    "    # Finale Accuracy Heatmap\n",
    "    ax3 = axes[1, 0]\n",
    "    final_acc = []\n",
    "    for strategy in strategy_colors.keys():\n",
    "        for budget in BUDGET_PERCENTAGES:\n",
    "            results = [r for r in all_results \n",
    "                      if r['strategy'] == strategy and r['budget_pct'] == budget]\n",
    "            if results:\n",
    "                final_acc.append({\n",
    "                    'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                    'Budget': f\"{int(budget*100)}%\",\n",
    "                    'Genauigkeit': np.mean([r['accuracy'] for r in results])\n",
    "                })\n",
    "    \n",
    "    if final_acc:\n",
    "        df_acc = pd.DataFrame(final_acc)\n",
    "        pivot_acc = df_acc.pivot(index='Strategie', columns='Budget', values='Genauigkeit')\n",
    "        \n",
    "        # Dynamische Skalierung für Heatmap\n",
    "        vmin = pivot_acc.min().min()\n",
    "        vmax = pivot_acc.max().max()\n",
    "        vcenter = (vmin + vmax) / 2\n",
    "        \n",
    "        # Wenn Unterschiede sehr klein sind, passe Skala an\n",
    "        if vmax - vmin < 0.02:\n",
    "            vmin = vcenter - 0.01\n",
    "            vmax = vcenter + 0.01\n",
    "        \n",
    "        if sns is not None:\n",
    "            sns.heatmap(pivot_acc, annot=True, fmt='.4f', cmap='RdYlGn', \n",
    "                       vmin=vmin, vmax=vmax, center=vcenter,\n",
    "                       ax=ax3, cbar_kws={'label': 'Genauigkeit'})\n",
    "        ax3.set_title('Finale Test-Genauigkeit', fontsize=13)\n",
    "        ax3.set_xlabel('Budget', fontsize=11)\n",
    "        ax3.set_ylabel('Strategie', fontsize=11)\n",
    "    \n",
    "    # Backend Info (auf Deutsch)\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('off')\n",
    "    backend_info = all_results[0].get('backend', 'unknown') if all_results else 'unknown'\n",
    "    \n",
    "    info_text = f\"\"\"GPU-SVM Backend-Informationen:\n",
    "    \n",
    "Primäres Backend: {backend_info.upper()}\n",
    "GPU verfügbar: {'Ja' if GPU_AVAILABLE else 'Nein'}\n",
    "RAPIDS cuML: {'Ja' if CUML_AVAILABLE else 'Nein'}\n",
    "ThunderSVM: {'Ja' if THUNDERSVM_AVAILABLE else 'Nein'}\n",
    "\n",
    "Konfiguration:\n",
    "- Kernel: RBF\n",
    "- C: 1.0\n",
    "- Batch-Größe: {BATCH_SIZE}\n",
    "- Initiale Auswahl: {int(INITIAL_PERCENTAGE * 100)}%\n",
    "\n",
    "Hardware:\n",
    "- Gerät: {'GPU' if GPU_AVAILABLE else 'CPU'}\n",
    "\"\"\"\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        info_text += f\"- GPU: {torch.cuda.get_device_name(0)}\\n\"\n",
    "        info_text += f\"- VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\\n\"\n",
    "    \n",
    "    ax4.text(0.1, 0.9, info_text, transform=ax4.transAxes, \n",
    "            fontsize=11, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = 'plots/gpu_svm_leistungsmetriken.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"✓ Leistungsmetriken erstellt: {filename}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Detaillierte Vergleichsvisualisierung mit Zoom\n",
    "    if len(all_results) > 0:\n",
    "        create_detailed_comparison_plot(all_results, stat_results)\n",
    "\n",
    "def create_detailed_comparison_plot(all_results, stat_results):\n",
    "    \"\"\"Erstellt detaillierte Vergleichsplots mit Zoom für kleine Unterschiede.\"\"\"\n",
    "    # Deutsche Labels\n",
    "    strategy_labels_de = {\n",
    "        'Random Sampling': 'Zufällige Auswahl',\n",
    "        'Entropy Sampling': 'Entropie-Auswahl',\n",
    "        'Margin Sampling': 'Margin-Auswahl',\n",
    "        'Least Confidence': 'Geringste Konfidenz'\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Detaillierte Active Learning Analyse', fontsize=16)\n",
    "    \n",
    "    # 1. Verbesserung über Random Sampling\n",
    "    ax1 = axes[0, 0]\n",
    "    improvements = []\n",
    "    \n",
    "    for budget_pct in BUDGET_PERCENTAGES:\n",
    "        random_results = [r['accuracy'] for r in all_results \n",
    "                         if r['strategy'] == 'Random Sampling' and r['budget_pct'] == budget_pct]\n",
    "        \n",
    "        if random_results:\n",
    "            random_mean = np.mean(random_results)\n",
    "            \n",
    "            for strategy in ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "                strategy_results = [r['accuracy'] for r in all_results \n",
    "                                  if r['strategy'] == strategy and r['budget_pct'] == budget_pct]\n",
    "                \n",
    "                if strategy_results:\n",
    "                    strategy_mean = np.mean(strategy_results)\n",
    "                    improvement = (strategy_mean - random_mean) * 100  # In Prozentpunkten\n",
    "                    \n",
    "                    improvements.append({\n",
    "                        'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                        'Budget': int(budget_pct * 100),\n",
    "                        'Verbesserung': improvement\n",
    "                    })\n",
    "    \n",
    "    if improvements:\n",
    "        df_imp = pd.DataFrame(improvements)\n",
    "        \n",
    "        # Gruppierter Barplot\n",
    "        strategies = df_imp['Strategie'].unique()\n",
    "        x = np.arange(len(BUDGET_PERCENTAGES))\n",
    "        width = 0.25\n",
    "        \n",
    "        for i, strategy in enumerate(strategies):\n",
    "            data = df_imp[df_imp['Strategie'] == strategy]\n",
    "            values = []\n",
    "            for b in BUDGET_PERCENTAGES:\n",
    "                budget_data = data[data['Budget'] == int(b*100)]\n",
    "                if not budget_data.empty:\n",
    "                    values.append(budget_data['Verbesserung'].values[0])\n",
    "                else:\n",
    "                    values.append(0)\n",
    "            \n",
    "            bars = ax1.bar(x + i*width - width, values, width, \n",
    "                           label=strategy, alpha=0.8)\n",
    "            \n",
    "            # Werte auf Balken\n",
    "            for bar, value in zip(bars, values):\n",
    "                if value != 0:\n",
    "                    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "                            f'{value:.2f}%', ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        ax1.set_xlabel('Budget (%)', fontsize=11)\n",
    "        ax1.set_ylabel('Verbesserung (Prozentpunkte)', fontsize=11)\n",
    "        ax1.set_title('Verbesserung gegenüber zufälliger Auswahl', fontsize=13)\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels([f'{int(b*100)}%' for b in BUDGET_PERCENTAGES])\n",
    "        ax1.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. Box Plots für finale Genauigkeit\n",
    "    ax2 = axes[0, 1]\n",
    "    final_data = []\n",
    "    \n",
    "    for strategy in ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "        results_100 = [r['accuracy'] for r in all_results \n",
    "                      if r['strategy'] == strategy and r['budget_pct'] == 1.0]\n",
    "        if results_100:\n",
    "            for acc in results_100:\n",
    "                final_data.append({\n",
    "                    'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                    'Genauigkeit': acc\n",
    "                })\n",
    "    \n",
    "    if final_data:\n",
    "        df_final = pd.DataFrame(final_data)\n",
    "        \n",
    "        # Box Plot\n",
    "        box_plot = df_final.boxplot(column='Genauigkeit', by='Strategie', ax=ax2, \n",
    "                                    patch_artist=True, return_type='dict')\n",
    "        \n",
    "        # Farben für Boxen\n",
    "        colors = ['lightgray', 'lightblue', 'lightcoral', 'lightgreen']\n",
    "        for patch, color in zip(box_plot['Genauigkeit']['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "        ax2.set_title('Verteilung der finalen Genauigkeit (100% Budget)', fontsize=13)\n",
    "        ax2.set_xlabel('')\n",
    "        ax2.set_ylabel('Test-Genauigkeit', fontsize=11)\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Entferne automatischen Titel\n",
    "        ax2.get_figure().suptitle('')\n",
    "        \n",
    "        # Dynamische Y-Achsen-Skalierung für Box Plot\n",
    "        y_data = df_final['Genauigkeit'].values\n",
    "        y_min, y_max = y_data.min(), y_data.max()\n",
    "        y_range = y_max - y_min\n",
    "        \n",
    "        if y_range < 0.02:  # Sehr kleine Unterschiede\n",
    "            center = (y_min + y_max) / 2\n",
    "            ax2.set_ylim([center - 0.015, center + 0.015])\n",
    "        else:\n",
    "            ax2.set_ylim([y_min - 0.1*y_range, y_max + 0.1*y_range])\n",
    "    \n",
    "    # 3. Lerngeschwindigkeit (Samples bis 95% Genauigkeit)\n",
    "    ax3 = axes[1, 0]\n",
    "    learning_speed = []\n",
    "    \n",
    "    # Ziel: 95% der Random Sampling Performance bei 100%\n",
    "    random_100_results = [r['accuracy'] for r in all_results \n",
    "                         if r['strategy'] == 'Random Sampling' and r['budget_pct'] == 1.0]\n",
    "    \n",
    "    if random_100_results:\n",
    "        target_acc = np.mean(random_100_results) * 0.95\n",
    "        \n",
    "        for strategy in ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "            strategy_results = [r for r in all_results if r['strategy'] == strategy]\n",
    "            \n",
    "            samples_needed = []\n",
    "            for r in strategy_results:\n",
    "                if 'n_labeled_list' in r and 'accuracies' in r:\n",
    "                    for i, acc in enumerate(r['accuracies']):\n",
    "                        if acc >= target_acc:\n",
    "                            samples_needed.append(r['n_labeled_list'][i])\n",
    "                            break\n",
    "            \n",
    "            if samples_needed:\n",
    "                learning_speed.append({\n",
    "                    'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                    'Samples': np.mean(samples_needed),\n",
    "                    'Std': np.std(samples_needed)\n",
    "                })\n",
    "    \n",
    "    if learning_speed:\n",
    "        df_speed = pd.DataFrame(learning_speed)\n",
    "        bars = ax3.bar(df_speed['Strategie'], df_speed['Samples'], \n",
    "                       yerr=df_speed['Std'], capsize=5, color='purple', alpha=0.7)\n",
    "        \n",
    "        # Werte auf Balken\n",
    "        for bar, (_, row) in zip(bars, df_speed.iterrows()):\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "                    f'{int(row[\"Samples\"]):,}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        ax3.set_title('Benötigte Samples für 95% der Baseline-Performance', fontsize=13)\n",
    "        ax3.set_ylabel('Anzahl Samples', fontsize=11)\n",
    "        ax3.set_xlabel('')\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "        ax3.set_xticklabels(df_speed['Strategie'], rotation=25, ha='right')\n",
    "        \n",
    "        # Referenzlinie\n",
    "        ax3.axhline(y=60000, color='red', linestyle='--', alpha=0.5, \n",
    "                   label='Vollständiger Datensatz')\n",
    "        ax3.legend()\n",
    "    \n",
    "    # 4. Effizienz-Matrix\n",
    "    ax4 = axes[1, 1]\n",
    "    efficiency_data = []\n",
    "    \n",
    "    for strategy in ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "        for budget_pct in BUDGET_PERCENTAGES:\n",
    "            results = [r for r in all_results \n",
    "                      if r['strategy'] == strategy and r['budget_pct'] == budget_pct]\n",
    "            \n",
    "            if results:\n",
    "                avg_acc = np.mean([r['accuracy'] for r in results])\n",
    "                avg_time = np.mean([r['avg_train_time'] + r['avg_query_time'] for r in results])\n",
    "                \n",
    "                # Effizienz = Genauigkeit / Zeit (normalisiert)\n",
    "                efficiency = avg_acc / avg_time if avg_time > 0 else 0\n",
    "                \n",
    "                efficiency_data.append({\n",
    "                    'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                    'Budget': f\"{int(budget_pct*100)}%\",\n",
    "                    'Effizienz': efficiency\n",
    "                })\n",
    "    \n",
    "    if efficiency_data:\n",
    "        df_eff = pd.DataFrame(efficiency_data)\n",
    "        pivot_eff = df_eff.pivot(index='Strategie', columns='Budget', values='Effizienz')\n",
    "        \n",
    "        # Normalisiere Effizienz für bessere Visualisierung\n",
    "        pivot_eff_norm = (pivot_eff - pivot_eff.min().min()) / (pivot_eff.max().max() - pivot_eff.min().min())\n",
    "        \n",
    "        if sns is not None:\n",
    "            sns.heatmap(pivot_eff_norm, annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "                       ax=ax4, cbar_kws={'label': 'Relative Effizienz'})\n",
    "        ax4.set_title('Effizienz-Matrix (Genauigkeit/Zeit)', fontsize=13)\n",
    "        ax4.set_xlabel('Budget', fontsize=11)\n",
    "        ax4.set_ylabel('Strategie', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = 'plots/gpu_svm_detaillierte_analyse.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"✓ Detaillierte Analyse erstellt: {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Label-Einsparungs-Analyse\n",
    "# -------------------------------------------------------------------------------\n",
    "def calculate_label_savings(all_results, target_performance_percentages=[0.90, 0.95, 0.98]):\n",
    "    \"\"\"Berechnet Label-Einsparung für GPU-SVM.\"\"\"\n",
    "    savings_results = []\n",
    "    \n",
    "    # Random Sampling Performance bei 100% als Referenz\n",
    "    random_100_results = [r for r in all_results \n",
    "                        if r['strategy'] == 'Random Sampling' \n",
    "                        and r['budget_pct'] == 1.0]\n",
    "    \n",
    "    if not random_100_results:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    random_100_acc = np.mean([r['accuracy'] for r in random_100_results])\n",
    "    \n",
    "    for target_pct in target_performance_percentages:\n",
    "        target_accuracy = random_100_acc * target_pct\n",
    "        \n",
    "        for strategy in ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "            strategy_results = [r for r in all_results if r['strategy'] == strategy]\n",
    "            \n",
    "            if not strategy_results:\n",
    "                continue\n",
    "            \n",
    "            # Aggregiere Lernkurven\n",
    "            all_curves = []\n",
    "            for r in strategy_results:\n",
    "                if 'n_labeled_list' in r and 'accuracies' in r:\n",
    "                    all_curves.append((r['n_labeled_list'], r['accuracies']))\n",
    "            \n",
    "            if not all_curves:\n",
    "                continue\n",
    "            \n",
    "            # Finde minimale Labels für Ziel-Accuracy\n",
    "            labels_needed = []\n",
    "            \n",
    "            for n_labeled_list, accuracies in all_curves:\n",
    "                if len(accuracies) > 0 and max(accuracies) >= target_accuracy:\n",
    "                    for i, acc in enumerate(accuracies):\n",
    "                        if acc >= target_accuracy:\n",
    "                            labels_needed.append(n_labeled_list[i])\n",
    "                            break\n",
    "                else:\n",
    "                    labels_needed.append(60000)\n",
    "            \n",
    "            if labels_needed:\n",
    "                avg_labels_needed = np.mean(labels_needed)\n",
    "                std_labels_needed = np.std(labels_needed)\n",
    "                \n",
    "                savings_pct = ((60000 - avg_labels_needed) / 60000) * 100\n",
    "                \n",
    "                if strategy != 'Random Sampling':\n",
    "                    random_labels = next((s['avg_labels_needed'] for s in savings_results \n",
    "                                        if s['strategy'] == 'Random Sampling' \n",
    "                                        and s['target_performance'] == int(target_pct*100)), 60000)\n",
    "                    relative_savings_pct = ((random_labels - avg_labels_needed) / random_labels) * 100 if random_labels > 0 else 0\n",
    "                else:\n",
    "                    relative_savings_pct = 0\n",
    "                \n",
    "                savings_results.append({\n",
    "                    'strategy': strategy,\n",
    "                    'target_performance': int(target_pct * 100),\n",
    "                    'target_accuracy': target_accuracy,\n",
    "                    'avg_labels_needed': avg_labels_needed,\n",
    "                    'std_labels_needed': std_labels_needed,\n",
    "                    'savings_pct': savings_pct,\n",
    "                    'relative_savings_pct': relative_savings_pct,\n",
    "                    'random_100_acc': random_100_acc\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(savings_results)\n",
    "\n",
    "def plot_label_savings(savings_df):\n",
    "    \"\"\"Visualisiert Label-Einsparungen auf Deutsch.\"\"\"\n",
    "    # Deutsche Labels\n",
    "    strategy_labels_de = {\n",
    "        'Random Sampling': 'Zufällige Auswahl',\n",
    "        'Entropy Sampling': 'Entropie-Auswahl',\n",
    "        'Margin Sampling': 'Margin-Auswahl',\n",
    "        'Least Confidence': 'Geringste Konfidenz'\n",
    "    }\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Label-Einsparungs-Analyse für GPU-SVM Active Learning', fontsize=16)\n",
    "    \n",
    "    # 1. Benötigte Labels für verschiedene Performance-Level\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    for target in savings_df['target_performance'].unique():\n",
    "        data = savings_df[savings_df['target_performance'] == target]\n",
    "        \n",
    "        if not data.empty:\n",
    "            strategies = [strategy_labels_de.get(s, s) for s in data['strategy'].values]\n",
    "            labels_needed = data['avg_labels_needed'].values\n",
    "            errors = data['std_labels_needed'].values\n",
    "            \n",
    "            x = np.arange(len(strategies))\n",
    "            width = 0.25\n",
    "            offset = (target - 95) * width / 3\n",
    "            \n",
    "            bars = ax1.bar(x + offset, labels_needed, width, \n",
    "                           yerr=errors, capsize=5,\n",
    "                           label=f'{target}% der Baseline',\n",
    "                           alpha=0.8)\n",
    "            \n",
    "            # Werte auf Balken\n",
    "            for bar, value in zip(bars, labels_needed):\n",
    "                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "                        f'{int(value):,}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    ax1.set_xlabel('Strategie', fontsize=11)\n",
    "    ax1.set_ylabel('Benötigte Labels', fontsize=11)\n",
    "    ax1.set_title('Benötigte Labels für Ziel-Performance', fontsize=13)\n",
    "    ax1.set_xticks(np.arange(len(strategies)))\n",
    "    ax1.set_xticklabels(strategies, rotation=25, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Referenzlinie\n",
    "    ax1.axhline(y=60000, color='red', linestyle='--', alpha=0.5)\n",
    "    ax1.text(0.02, 60000, 'Vollständiger Datensatz', transform=ax1.get_yaxis_transform(), \n",
    "            va='bottom', ha='left', color='red', fontsize=9)\n",
    "    \n",
    "    # 2. Relative Einsparung Heatmap\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    # Pivot für Heatmap\n",
    "    savings_pivot = []\n",
    "    for strategy in ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "        row = []\n",
    "        for target in [90, 95, 98]:\n",
    "            data = savings_df[(savings_df['strategy'] == strategy) & \n",
    "                            (savings_df['target_performance'] == target)]\n",
    "            if not data.empty:\n",
    "                row.append(data['relative_savings_pct'].values[0])\n",
    "            else:\n",
    "                row.append(0)\n",
    "        savings_pivot.append(row)\n",
    "    \n",
    "    savings_array = np.array(savings_pivot)\n",
    "    \n",
    "    if sns is not None:\n",
    "        im = ax2.imshow(savings_array, cmap='RdYlGn', aspect='auto')\n",
    "        \n",
    "        # Labels\n",
    "        ax2.set_xticks(np.arange(3))\n",
    "        ax2.set_yticks(np.arange(3))\n",
    "        ax2.set_xticklabels(['90%', '95%', '98%'])\n",
    "        ax2.set_yticklabels([strategy_labels_de.get(s, s) for s in \n",
    "                           ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']])\n",
    "        \n",
    "        # Werte in Zellen\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                text = ax2.text(j, i, f'{savings_array[i, j]:.1f}%',\n",
    "                              ha=\"center\", va=\"center\", color=\"black\", fontsize=11)\n",
    "        \n",
    "        # Colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax2)\n",
    "        cbar.set_label('Einsparung ggü. Zufälliger Auswahl (%)', fontsize=10)\n",
    "        \n",
    "    ax2.set_title('Relative Label-Einsparung', fontsize=13)\n",
    "    ax2.set_xlabel('Ziel-Performance', fontsize=11)\n",
    "    ax2.set_ylabel('Strategie', fontsize=11)\n",
    "    \n",
    "    # 3. Label-Einsparung über Performance-Level\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    for strategy in ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "        data = savings_df[savings_df['strategy'] == strategy]\n",
    "        if not data.empty:\n",
    "            targets = data['target_performance'].values\n",
    "            savings = data['savings_pct'].values\n",
    "            \n",
    "            ax3.plot(targets, savings, marker='o', linewidth=2, markersize=8,\n",
    "                    label=strategy_labels_de.get(strategy, strategy))\n",
    "            \n",
    "            # Werte an Punkten\n",
    "            for t, s in zip(targets, savings):\n",
    "                ax3.text(t, s+1, f'{s:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    ax3.set_xlabel('Ziel-Performance (%)', fontsize=11)\n",
    "    ax3.set_ylabel('Label-Einsparung (%)', fontsize=11)\n",
    "    ax3.set_title('Label-Einsparung bei verschiedenen Performance-Zielen', fontsize=13)\n",
    "    ax3.set_xticks([90, 95, 98])\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Zusammenfassungstabelle\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('tight')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Erstelle Zusammenfassungstabelle für 95% Performance\n",
    "    data_95 = savings_df[savings_df['target_performance'] == 95]\n",
    "    \n",
    "    if not data_95.empty:\n",
    "        table_data = []\n",
    "        for _, row in data_95.iterrows():\n",
    "            strategy = strategy_labels_de.get(row['strategy'], row['strategy'])\n",
    "            labels = int(row['avg_labels_needed'])\n",
    "            savings = row['savings_pct']\n",
    "            rel_savings = row['relative_savings_pct']\n",
    "            \n",
    "            table_data.append([\n",
    "                strategy,\n",
    "                f\"{labels:,} ± {int(row['std_labels_needed']):,}\",\n",
    "                f\"{savings:.1f}%\",\n",
    "                f\"{rel_savings:.1f}%\" if row['strategy'] != 'Random Sampling' else \"-\"\n",
    "            ])\n",
    "        \n",
    "        table = ax4.table(cellText=table_data,\n",
    "                         colLabels=['Strategie', 'Benötigte Labels', 'Absolute Einsparung', 'Relative Einsparung'],\n",
    "                         cellLoc='center',\n",
    "                         loc='center')\n",
    "        \n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.scale(1.2, 2)\n",
    "        \n",
    "        # Style header\n",
    "        for i in range(4):\n",
    "            table[(0, i)].set_facecolor('#40466e')\n",
    "            table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "        \n",
    "        # Färbe beste Strategie\n",
    "        min_labels_idx = data_95['avg_labels_needed'].argmin()\n",
    "        for i in range(4):\n",
    "            table[(min_labels_idx + 1, i)].set_facecolor('#90EE90')\n",
    "    \n",
    "    ax4.set_title('Zusammenfassung für 95% Ziel-Performance', fontsize=13, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = 'plots/gpu_svm_label_einsparung.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"✓ Label-Einsparungs-Analyse erstellt: {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "def create_label_savings_report(savings_df, all_results):\n",
    "    \"\"\"Erstellt deutschen Bericht über Label-Einsparungen.\"\"\"\n",
    "    strategy_labels_de = {\n",
    "        'Random Sampling': 'Zufällige Auswahl',\n",
    "        'Entropy Sampling': 'Entropie-Auswahl',\n",
    "        'Margin Sampling': 'Margin-Auswahl',\n",
    "        'Least Confidence': 'Geringste Konfidenz'\n",
    "    }\n",
    "    \n",
    "    report = []\n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(\"LABEL-EINSPARUNGS-BERICHT - GPU-SVM ACTIVE LEARNING\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    # Zusammenfassung\n",
    "    data_95 = savings_df[savings_df['target_performance'] == 95]\n",
    "    if not data_95.empty:\n",
    "        best_strategy = data_95.loc[data_95['avg_labels_needed'].idxmin()]\n",
    "        \n",
    "        report.append(f\"\\nHAUPTERGEBNIS:\")\n",
    "        report.append(f\"Die {strategy_labels_de.get(best_strategy['strategy'], best_strategy['strategy'])}-Strategie\")\n",
    "        report.append(f\"benötigt nur {int(best_strategy['avg_labels_needed']):,} Labels\")\n",
    "        report.append(f\"um 95% der Baseline-Performance zu erreichen.\")\n",
    "        report.append(f\"Das entspricht einer Einsparung von {best_strategy['savings_pct']:.1f}%!\")\n",
    "    \n",
    "    # Detaillierte Ergebnisse\n",
    "    for target_perf in sorted(savings_df['target_performance'].unique()):\n",
    "        report.append(f\"\\n\\nZIEL: {target_perf}% der Baseline-Performance\")\n",
    "        report.append(\"-\"*60)\n",
    "        \n",
    "        target_data = savings_df[savings_df['target_performance'] == target_perf]\n",
    "        \n",
    "        if not target_data.empty:\n",
    "            baseline_acc = target_data['random_100_acc'].iloc[0]\n",
    "            target_acc = target_data['target_accuracy'].iloc[0]\n",
    "            \n",
    "            report.append(f\"Baseline-Genauigkeit (100% Daten): {baseline_acc:.4f}\")\n",
    "            report.append(f\"Ziel-Genauigkeit: {target_acc:.4f}\")\n",
    "            report.append(f\"\\nBenötigte Labels:\")\n",
    "            \n",
    "            # Sortiere nach Labels\n",
    "            sorted_data = target_data.sort_values('avg_labels_needed')\n",
    "            \n",
    "            for _, row in sorted_data.iterrows():\n",
    "                strategy = strategy_labels_de.get(row['strategy'], row['strategy'])\n",
    "                labels = row['avg_labels_needed']\n",
    "                std = row['std_labels_needed']\n",
    "                savings = row['savings_pct']\n",
    "                rel_savings = row['relative_savings_pct']\n",
    "                \n",
    "                report.append(f\"  - {strategy:<20}: {int(labels):>6,} ± {int(std):>4} \"\n",
    "                            f\"({savings:>5.1f}% Einsparung)\")\n",
    "                \n",
    "                if row['strategy'] != 'Random Sampling' and rel_savings > 0:\n",
    "                    report.append(f\"    → {rel_savings:.1f}% weniger Labels als Zufällige Auswahl\")\n",
    "    \n",
    "    # GPU-spezifische Informationen\n",
    "    report.append(\"\\n\\nGPU-PERFORMANCE:\")\n",
    "    report.append(\"-\"*60)\n",
    "    report.append(f\"Backend: {all_results[0].get('backend', 'unknown').upper() if all_results else 'N/A'}\")\n",
    "    report.append(f\"GPU verfügbar: {'Ja' if GPU_AVAILABLE else 'Nein'}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        report.append(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        report.append(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Ausgabe und Speichern\n",
    "    report_text = \"\\n\".join(report)\n",
    "    print(report_text)\n",
    "    \n",
    "    filename = 'reports/gpu_svm_label_einsparungs_bericht.txt'\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    logger.info(f\"✓ Label-Einsparungs-Bericht gespeichert: {filename}\")\n",
    "    \n",
    "    return report_text\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Hauptprogramm\n",
    "# -------------------------------------------------------------------------------\n",
    "def main():\n",
    "    \"\"\"Haupteinstiegspunkt für GPU-optimierte SVM Active Learning.\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"GPU-OPTIMIERTES ACTIVE LEARNING FÜR SVM - BACHELORARBEIT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # System Info\n",
    "    print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"NumPy Version: {np.__version__}\")\n",
    "    print(f\"Scikit-learn Version: {sklearn.__version__}\")\n",
    "    \n",
    "    # GPU Setup\n",
    "    print(\"\\nGPU Setup:\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✓ CUDA verfügbar: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    else:\n",
    "        print(\"✗ Keine CUDA GPU gefunden\")\n",
    "    \n",
    "    # Prüfe ob GPU-Beschleunigung verfügbar ist\n",
    "    if not GPU_AVAILABLE:\n",
    "        print(\"\\n\" + \"!\"*80)\n",
    "        print(\"WICHTIG: Keine GPU-Beschleunigung verfügbar!\")\n",
    "        print(\"Das Programm läuft im CPU-Modus, was DEUTLICH langsamer ist.\")\n",
    "        print(\"\\nFür Ihre RTX 4060 empfehle ich folgende Installation:\")\n",
    "        print(\"-\"*80)\n",
    "        print(\"# Option 1: RAPIDS cuML (empfohlen)\")\n",
    "        print(\"conda create -n rapids python=3.11\")\n",
    "        print(\"conda activate rapids\")\n",
    "        print(\"conda install -c rapidsai -c conda-forge -c nvidia \\\\\")\n",
    "        print(\"    rapids=24.12 python=3.11 cudatoolkit=12.0\")\n",
    "        print(\"\\n# Option 2: Wenn RAPIDS nicht funktioniert\")\n",
    "        print(\"pip install cupy-cuda12x\")\n",
    "        print(\"conda install -c conda-forge cuml\")\n",
    "        print(\"!\"*80)\n",
    "        \n",
    "        # Frage ob fortfahren\n",
    "        response = input(\"\\nMöchten Sie trotzdem im CPU-Modus fortfahren? (j/n): \")\n",
    "        if response.lower() != 'j':\n",
    "            print(\"Programm beendet. Bitte installieren Sie GPU-Unterstützung.\")\n",
    "            return 0\n",
    "    \n",
    "    # Initialisiere GPU Memory Pool\n",
    "    if CUML_AVAILABLE:\n",
    "        print(\"\\nGPU Memory Setup:\")\n",
    "        gpu_setup_success = setup_gpu_memory()\n",
    "        if not gpu_setup_success:\n",
    "            print(\"\\n⚠ GPU Memory Setup fehlgeschlagen, aber RAPIDS cuML wird trotzdem verwendet.\")\n",
    "        \n",
    "        if not USE_MEMORY_POOL:\n",
    "            print(\"\\nHinweis: RMM Memory Pool ist deaktiviert (USE_MEMORY_POOL = False)\")\n",
    "            print(\"Falls Sie Speicherprobleme haben, können Sie den Pool aktivieren:\")\n",
    "            print(\"  Setzen Sie USE_MEMORY_POOL = True in der Konfiguration\")\n",
    "            print(\"\\nFür GPU Monitoring installieren Sie:\")\n",
    "            print(\"  pip install nvidia-ml-py gpustat\")\n",
    "            print(\"  Dann verwenden Sie: gpustat -i 1\")\n",
    "    \n",
    "    print(f\"\\nExperiment-Konfiguration:\")\n",
    "    print(f\"- Anzahl Runs: {N_RUNS}\")\n",
    "    print(f\"- Budget-Stufen: {[f'{int(b*100)}%' for b in BUDGET_PERCENTAGES]}\")\n",
    "    print(f\"- Batch-Größe: {BATCH_SIZE}\")\n",
    "    print(f\"- GPU Backends: cuML={CUML_AVAILABLE}, ThunderSVM={THUNDERSVM_AVAILABLE}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Daten laden\n",
    "    try:\n",
    "        X_train, y_train, X_test, y_test = load_mnist_data()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Kritischer Fehler beim Laden der Daten: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    # Query-Strategien\n",
    "    strategies = [\n",
    "        ('Random Sampling', random_sampling),\n",
    "        ('Entropy Sampling', entropy_sampling),\n",
    "        ('Margin Sampling', margin_sampling),\n",
    "        ('Least Confidence', least_confidence_sampling)\n",
    "    ]\n",
    "    \n",
    "    # Experimente durchführen\n",
    "    all_results = []\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    for strategy_name, strategy_func in strategies:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Strategie: {strategy_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            results = run_gpu_svm_active_learning(\n",
    "                X_train, y_train, X_test, y_test,\n",
    "                strategy_name, strategy_func,\n",
    "                BUDGET_PERCENTAGES, BATCH_SIZE\n",
    "            )\n",
    "            all_results.extend(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Kritischer Fehler bei {strategy_name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Gesamtzeit\n",
    "    total_time = time.time() - total_start_time\n",
    "    print(f\"\\n✓ Alle Experimente abgeschlossen in {total_time/60:.1f} Minuten\")\n",
    "    \n",
    "    # Ergebnisse verarbeiten\n",
    "    if not all_results:\n",
    "        logger.error(\"Keine Experimenteergebnisse vorhanden!\")\n",
    "        return 1\n",
    "    \n",
    "    # DataFrame für Analyse\n",
    "    results_df = pd.DataFrame([{\n",
    "        'strategy': r['strategy'],\n",
    "        'budget_pct': r['budget_pct'],\n",
    "        'run': r['run'],\n",
    "        'n_labeled': r['n_labeled'],\n",
    "        'accuracy': r['accuracy'],\n",
    "        'f1_score': r['f1_score'],\n",
    "        'avg_query_time': r.get('avg_query_time', 0),\n",
    "        'avg_train_time': r.get('avg_train_time', 0),\n",
    "        'backend': r.get('backend', 'unknown')\n",
    "    } for r in all_results])\n",
    "    \n",
    "    # Statistische Analyse\n",
    "    print(\"\\nFühre statistische Analyse durch...\")\n",
    "    stat_results = perform_statistical_analysis(results_df)\n",
    "    create_statistical_report(stat_results)\n",
    "    \n",
    "    # Visualisierungen\n",
    "    print(\"\\nErstelle Visualisierungen...\")\n",
    "    plot_gpu_svm_results(all_results, stat_results)\n",
    "    \n",
    "    # Label-Einsparungsanalyse\n",
    "    print(\"\\nBerechne Label-Einsparungen...\")\n",
    "    savings_df = calculate_label_savings(all_results)\n",
    "    \n",
    "    if not savings_df.empty:\n",
    "        plot_label_savings(savings_df)\n",
    "        create_label_savings_report(savings_df, all_results)\n",
    "    \n",
    "    # Ergebnisse speichern\n",
    "    csv_filename = 'results/gpu_svm_active_learning_results.csv'\n",
    "    results_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"\\n✓ Ergebnisse gespeichert: {csv_filename}\")\n",
    "    \n",
    "    if not stat_results.empty:\n",
    "        stat_csv = 'results/gpu_svm_statistical_analysis.csv'\n",
    "        stat_results.to_csv(stat_csv, index=False)\n",
    "        print(f\"✓ Statistische Analyse gespeichert: {stat_csv}\")\n",
    "    \n",
    "    if not savings_df.empty:\n",
    "        savings_csv = 'results/gpu_svm_label_savings.csv'\n",
    "        savings_df.to_csv(savings_csv, index=False)\n",
    "        print(f\"✓ Label-Einsparungen gespeichert: {savings_csv}\")\n",
    "    \n",
    "    # Excel Export\n",
    "    if EXCEL_AVAILABLE:\n",
    "        excel_filename = 'results/gpu_svm_active_learning_summary.xlsx'\n",
    "        try:\n",
    "            with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "                results_df.to_excel(writer, sheet_name='Raw Results', index=False)\n",
    "                \n",
    "                if not stat_results.empty:\n",
    "                    stat_results.to_excel(writer, sheet_name='Statistical Analysis', index=False)\n",
    "                \n",
    "                if not savings_df.empty:\n",
    "                    savings_df.to_excel(writer, sheet_name='Label Savings', index=False)\n",
    "                \n",
    "                # Summary\n",
    "                summary = results_df.groupby(['strategy', 'budget_pct'])[['accuracy', 'f1_score']].agg(['mean', 'std'])\n",
    "                summary.to_excel(writer, sheet_name='Summary Statistics')\n",
    "            \n",
    "            print(f\"✓ Excel-Zusammenfassung gespeichert: {excel_filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Excel-Export fehlgeschlagen: {e}\")\n",
    "    \n",
    "    # Abschlusszusammenfassung\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPERIMENT ERFOLGREICH ABGESCHLOSSEN\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"GPU Backend verwendet: {all_results[0].get('backend', 'unknown') if all_results else 'unknown'}\")\n",
    "    print(f\"Gesamtanzahl Experimente: {len(all_results)}\")\n",
    "    print(f\"Durchschnittliche Trainingszeit: {np.mean([r['avg_train_time'] for r in all_results]):.2f}s\")\n",
    "    \n",
    "    if not stat_results.empty and 'significant' in stat_results.columns:\n",
    "        sig_count = stat_results['significant'].sum()\n",
    "        print(f\"\\nSignifikante Verbesserungen: {sig_count}/{len(stat_results)} ({sig_count/len(stat_results)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nOutput-Dateien:\")\n",
    "    print(\"- Visualisierungen: plots/\")\n",
    "    print(\"  - gpu_svm_active_learning_performance.png\")\n",
    "    print(\"  - gpu_svm_leistungsmetriken.png\")\n",
    "    print(\"  - gpu_svm_detaillierte_analyse.png\")\n",
    "    print(\"  - gpu_svm_label_einsparung.png\")\n",
    "    print(\"- Ergebnisse: results/\")\n",
    "    print(\"  - gpu_svm_active_learning_results.csv\")\n",
    "    print(\"  - gpu_svm_statistical_analysis.csv\")\n",
    "    print(\"  - gpu_svm_label_savings.csv\")\n",
    "    print(\"  - gpu_svm_active_learning_summary.xlsx\")\n",
    "    print(\"- Berichte: reports/\")\n",
    "    print(\"  - gpu_svm_statistischer_bericht.txt\")\n",
    "    print(\"  - gpu_svm_label_einsparungs_bericht.txt\")\n",
    "    print(\"- Logs: logs/\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        exit_code = main()\n",
    "        sys.exit(exit_code)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unerwarteter Fehler: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
