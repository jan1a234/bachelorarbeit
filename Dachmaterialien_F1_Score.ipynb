{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70075094-8b7b-47b7-ab66-31bde6593fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACTIVE LEARNING AUF DACHMATERIAL - F1-SCORE VERSION MIT DEUTSCHEN PLOTS\n",
      "================================================================================\n",
      "Python Version: 3.13.5\n",
      "PyTorch Version: 2.7.1+cu126\n",
      "NumPy Version: 2.2.6\n",
      "Pandas Version: 2.2.3\n",
      "Scikit-learn Version: 1.7.1\n",
      "SciPy Version: 1.16.0\n",
      "Verwende GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "GPU Memory: 7.6 GB\n",
      "\n",
      "Experiment-Konfiguration:\n",
      "- Hauptmetrik: F1-Score (Macro Average)\n",
      "- Anzahl Runs: 5\n",
      "- Budget-Stufen: ['20%', '40%', '60%', '80%', '100%']\n",
      "- Batch-Größe: 500\n",
      "- Signifikanzniveau: 0.05\n",
      "- Mindest-Samples pro Klasse: 20\n",
      "- Visualisierungen: Deutsch mit adaptiver Skalierung\n",
      "================================================================================\n",
      "10:14:11 [INFO] Lade vollständigen Dachmaterial-Datensatz...\n",
      "10:14:11 [INFO] [ok] Datensatz geladen: 8,213 Zeilen, 10 Spalten\n",
      "10:14:11 [INFO] Ursprüngliche Klassen-Verteilung:\n",
      "mat_qgis\n",
      "Ziegel                4112\n",
      "Metallbahn            1212\n",
      "Asbest|Faserzement     892\n",
      "Beton                  838\n",
      "Bitumen                734\n",
      "PVC|Polycarbonat       140\n",
      "Schiefer               128\n",
      "Glas                   119\n",
      "Dachbegrünung           24\n",
      "Kunststoffbahn          12\n",
      "Kupfer                   2\n",
      "Name: count, dtype: int64\n",
      "10:14:11 [WARNING] Entferne Klassen mit weniger als 20 Samples:\n",
      "10:14:11 [WARNING]   - Kunststoffbahn: 12 Samples\n",
      "10:14:11 [WARNING]   - Kupfer: 2 Samples\n",
      "10:14:11 [INFO] Gefilterte Klassen-Verteilung:\n",
      "mat_qgis\n",
      "Ziegel                4112\n",
      "Metallbahn            1212\n",
      "Asbest|Faserzement     892\n",
      "Beton                  838\n",
      "Bitumen                734\n",
      "PVC|Polycarbonat       140\n",
      "Schiefer               128\n",
      "Glas                   119\n",
      "Dachbegrünung           24\n",
      "Name: count, dtype: int64\n",
      "10:14:11 [INFO] [ok] Dachmaterial-Datensatz vorbereitet: 8,199 Samples\n",
      "10:14:11 [INFO]   Klassen: 9 - Asbest|Faserzement, Beton, Bitumen, Dachbegrünung, Glas, Metallbahn, PVC|Polycarbonat, Schiefer, Ziegel\n",
      "10:14:11 [INFO] Klassen im Trainingsset: 9\n",
      "10:14:11 [INFO] Klassen im Testset: 9\n",
      "10:14:11 [INFO] [ok] Daten vorbereitet: 6,559 Trainingssamples, 1,640 Testsamples\n",
      "10:14:11 [INFO]   Feature-Dimension nach Preprocessing: 28\n",
      "10:14:11 [INFO]   Klassen: 9 im Training, 9 im Test\n",
      "10:14:11 [INFO]   Speicherbedarf: 0.9 MB\n",
      "\n",
      "============================================================\n",
      "Experiment 1/20: Neural Network + Random Sampling\n",
      "============================================================\n",
      "10:14:11 [INFO] \n",
      "Neural Network + Random Sampling - Budget: 20% (1,311 Samples)\n",
      "10:14:11 [INFO]   Run 1/5\n",
      "10:14:13 [INFO]     1,311 labeled -> F1-Score: 0.1895 (Train: 0.1s, Query: 0.00s)\n",
      "10:14:13 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5274, F1: 0.1897\n",
      "10:14:13 [INFO]   Run 2/5\n",
      "10:14:13 [INFO]     1,311 labeled -> F1-Score: 0.1986 (Train: 0.1s, Query: 0.00s)\n",
      "10:14:13 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5348, F1: 0.1771\n",
      "10:14:13 [INFO]   Run 3/5\n",
      "10:14:14 [INFO]     1,311 labeled -> F1-Score: 0.1651 (Train: 0.1s, Query: 0.00s)\n",
      "10:14:14 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5171, F1: 0.1747\n",
      "10:14:14 [INFO]   Run 4/5\n",
      "10:14:14 [INFO]     1,311 labeled -> F1-Score: 0.1582 (Train: 0.1s, Query: 0.00s)\n",
      "10:14:15 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5268, F1: 0.1670\n",
      "10:14:15 [INFO]   Run 5/5\n",
      "10:14:15 [INFO]     1,311 labeled -> F1-Score: 0.1836 (Train: 0.1s, Query: 0.00s)\n",
      "10:14:15 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5140, F1: 0.1604\n",
      "10:14:15 [INFO] \n",
      "Neural Network + Random Sampling - Budget: 40% (2,623 Samples)\n",
      "10:14:15 [INFO]   Run 1/5\n",
      "10:14:16 [INFO]     2,623 labeled -> F1-Score: 0.1808 (Train: 0.2s, Query: 0.00s)\n",
      "10:14:16 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5366, F1: 0.1827\n",
      "10:14:16 [INFO]   Run 2/5\n",
      "10:14:17 [INFO]     2,623 labeled -> F1-Score: 0.1767 (Train: 0.2s, Query: 0.00s)\n",
      "10:14:18 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5433, F1: 0.1753\n",
      "10:14:18 [INFO]   Run 3/5\n",
      "10:14:18 [INFO]     2,623 labeled -> F1-Score: 0.1688 (Train: 0.2s, Query: 0.00s)\n",
      "10:14:19 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5390, F1: 0.1728\n",
      "10:14:19 [INFO]   Run 4/5\n",
      "10:14:20 [INFO]     2,623 labeled -> F1-Score: 0.1786 (Train: 0.2s, Query: 0.00s)\n",
      "10:14:20 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5378, F1: 0.1796\n",
      "10:14:20 [INFO]   Run 5/5\n",
      "10:14:21 [INFO]     2,623 labeled -> F1-Score: 0.1838 (Train: 0.2s, Query: 0.00s)\n",
      "10:14:21 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5323, F1: 0.1668\n",
      "10:14:21 [INFO] \n",
      "Neural Network + Random Sampling - Budget: 60% (3,935 Samples)\n",
      "10:14:21 [INFO]   Run 1/5\n",
      "10:14:22 [INFO]     3,935 labeled -> F1-Score: 0.1696 (Train: 0.3s, Query: 0.00s)\n",
      "10:14:23 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5427, F1: 0.1710\n",
      "10:14:23 [INFO]   Run 2/5\n",
      "10:14:24 [INFO]     3,935 labeled -> F1-Score: 0.1867 (Train: 0.3s, Query: 0.00s)\n",
      "10:14:25 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5409, F1: 0.1774\n",
      "10:14:25 [INFO]   Run 3/5\n",
      "10:14:26 [INFO]     3,935 labeled -> F1-Score: 0.1823 (Train: 0.3s, Query: 0.00s)\n",
      "10:14:27 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5421, F1: 0.1700\n",
      "10:14:27 [INFO]   Run 4/5\n",
      "10:14:28 [INFO]     3,935 labeled -> F1-Score: 0.1843 (Train: 0.3s, Query: 0.00s)\n",
      "10:14:28 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5427, F1: 0.1859\n",
      "10:14:28 [INFO]   Run 5/5\n",
      "10:14:30 [INFO]     3,935 labeled -> F1-Score: 0.1554 (Train: 0.3s, Query: 0.00s)\n",
      "10:14:30 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5305, F1: 0.1669\n",
      "10:14:30 [INFO] \n",
      "Neural Network + Random Sampling - Budget: 80% (5,247 Samples)\n",
      "10:14:30 [INFO]   Run 1/5\n",
      "10:14:32 [INFO]     5,247 labeled -> F1-Score: 0.1762 (Train: 0.3s, Query: 0.00s)\n",
      "10:14:33 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5427, F1: 0.1757\n",
      "10:14:33 [INFO]   Run 2/5\n",
      "10:14:35 [INFO]     5,247 labeled -> F1-Score: 0.1904 (Train: 0.3s, Query: 0.00s)\n",
      "10:14:36 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5402, F1: 0.1675\n",
      "10:14:36 [INFO]   Run 3/5\n",
      "10:14:38 [INFO]     5,247 labeled -> F1-Score: 0.1785 (Train: 0.3s, Query: 0.00s)\n",
      "10:14:39 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5415, F1: 0.1786\n",
      "10:14:39 [INFO]   Run 4/5\n",
      "10:14:41 [INFO]     5,247 labeled -> F1-Score: 0.1685 (Train: 0.4s, Query: 0.00s)\n",
      "10:14:42 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5439, F1: 0.1757\n",
      "10:14:42 [INFO]   Run 5/5\n",
      "10:14:44 [INFO]     5,247 labeled -> F1-Score: 0.1722 (Train: 0.3s, Query: 0.00s)\n",
      "10:14:45 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5378, F1: 0.1730\n",
      "10:14:45 [INFO] \n",
      "Neural Network + Random Sampling - Budget: 100% (6,559 Samples)\n",
      "10:14:45 [INFO]   Run 1/5\n",
      "10:14:48 [INFO]     6,559 labeled -> F1-Score: 0.1646 (Train: 0.4s, Query: 0.00s)\n",
      "10:14:49 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5463, F1: 0.1781\n",
      "10:14:49 [INFO]   Run 2/5\n",
      "10:14:52 [INFO]     6,559 labeled -> F1-Score: 0.1951 (Train: 0.4s, Query: 0.00s)\n",
      "10:14:52 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5445, F1: 0.1836\n",
      "10:14:52 [INFO]   Run 3/5\n",
      "10:14:55 [INFO]     6,559 labeled -> F1-Score: 0.1639 (Train: 0.4s, Query: 0.00s)\n",
      "10:14:56 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5360, F1: 0.1538\n",
      "10:14:56 [INFO]   Run 4/5\n",
      "10:15:00 [INFO]     6,559 labeled -> F1-Score: 0.1731 (Train: 0.4s, Query: 0.00s)\n",
      "10:15:00 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1876\n",
      "10:15:00 [INFO]   Run 5/5\n",
      "10:15:03 [INFO]     6,559 labeled -> F1-Score: 0.1885 (Train: 0.4s, Query: 0.00s)\n",
      "10:15:04 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5433, F1: 0.1774\n",
      "\n",
      "[ok] Neural Network + Random Sampling abgeschlossen in 0.9 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 2/20: Neural Network + Entropy Sampling\n",
      "============================================================\n",
      "10:15:04 [INFO] \n",
      "Neural Network + Entropy Sampling - Budget: 20% (1,311 Samples)\n",
      "10:15:04 [INFO]   Run 1/5\n",
      "10:15:05 [INFO]     1,311 labeled -> F1-Score: 0.1573 (Train: 0.1s, Query: 0.00s)\n",
      "10:15:05 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4915, F1: 0.1838\n",
      "10:15:05 [INFO]   Run 2/5\n",
      "10:15:05 [INFO]     1,311 labeled -> F1-Score: 0.1477 (Train: 0.1s, Query: 0.00s)\n",
      "10:15:05 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4256, F1: 0.1445\n",
      "10:15:05 [INFO]   Run 3/5\n",
      "10:15:06 [INFO]     1,311 labeled -> F1-Score: 0.1648 (Train: 0.1s, Query: 0.00s)\n",
      "10:15:06 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5043, F1: 0.1593\n",
      "10:15:06 [INFO]   Run 4/5\n",
      "10:15:06 [INFO]     1,311 labeled -> F1-Score: 0.1618 (Train: 0.1s, Query: 0.00s)\n",
      "10:15:07 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4872, F1: 0.1971\n",
      "10:15:07 [INFO]   Run 5/5\n",
      "10:15:07 [INFO]     1,311 labeled -> F1-Score: 0.1689 (Train: 0.1s, Query: 0.00s)\n",
      "10:15:07 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5134, F1: 0.1783\n",
      "10:15:07 [INFO] \n",
      "Neural Network + Entropy Sampling - Budget: 40% (2,623 Samples)\n",
      "10:15:07 [INFO]   Run 1/5\n",
      "10:15:08 [INFO]     2,623 labeled -> F1-Score: 0.1817 (Train: 0.2s, Query: 0.00s)\n",
      "10:15:08 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5311, F1: 0.1879\n",
      "10:15:08 [INFO]   Run 2/5\n",
      "10:15:09 [INFO]     2,623 labeled -> F1-Score: 0.1688 (Train: 0.2s, Query: 0.00s)\n",
      "10:15:10 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5220, F1: 0.1658\n",
      "10:15:10 [INFO]   Run 3/5\n",
      "10:15:10 [INFO]     2,623 labeled -> F1-Score: 0.1718 (Train: 0.2s, Query: 0.00s)\n",
      "10:15:11 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5280, F1: 0.1719\n",
      "10:15:11 [INFO]   Run 4/5\n",
      "10:15:12 [INFO]     2,623 labeled -> F1-Score: 0.1804 (Train: 0.2s, Query: 0.00s)\n",
      "10:15:12 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5366, F1: 0.1817\n",
      "10:15:12 [INFO]   Run 5/5\n",
      "10:15:13 [INFO]     2,623 labeled -> F1-Score: 0.1933 (Train: 0.2s, Query: 0.00s)\n",
      "10:15:13 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5463, F1: 0.1881\n",
      "10:15:13 [INFO] \n",
      "Neural Network + Entropy Sampling - Budget: 60% (3,935 Samples)\n",
      "10:15:13 [INFO]   Run 1/5\n",
      "10:15:15 [INFO]     3,935 labeled -> F1-Score: 0.1810 (Train: 0.3s, Query: 0.00s)\n",
      "10:15:15 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1888\n",
      "10:15:15 [INFO]   Run 2/5\n",
      "10:15:16 [INFO]     3,935 labeled -> F1-Score: 0.1867 (Train: 0.3s, Query: 0.00s)\n",
      "10:15:17 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5287, F1: 0.1695\n",
      "10:15:17 [INFO]   Run 3/5\n",
      "10:15:18 [INFO]     3,935 labeled -> F1-Score: 0.1765 (Train: 0.3s, Query: 0.00s)\n",
      "10:15:19 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5390, F1: 0.1916\n",
      "10:15:19 [INFO]   Run 4/5\n",
      "10:15:20 [INFO]     3,935 labeled -> F1-Score: 0.1941 (Train: 0.3s, Query: 0.00s)\n",
      "10:15:21 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5372, F1: 0.1767\n",
      "10:15:21 [INFO]   Run 5/5\n",
      "10:15:22 [INFO]     3,935 labeled -> F1-Score: 0.1914 (Train: 0.3s, Query: 0.00s)\n",
      "10:15:23 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5415, F1: 0.1843\n",
      "10:15:23 [INFO] \n",
      "Neural Network + Entropy Sampling - Budget: 80% (5,247 Samples)\n",
      "10:15:23 [INFO]   Run 1/5\n",
      "10:15:25 [INFO]     5,247 labeled -> F1-Score: 0.1838 (Train: 0.3s, Query: 0.00s)\n",
      "10:15:25 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1979\n",
      "10:15:25 [INFO]   Run 2/5\n",
      "10:15:28 [INFO]     5,247 labeled -> F1-Score: 0.1909 (Train: 0.3s, Query: 0.01s)\n",
      "10:15:28 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5482, F1: 0.1962\n",
      "10:15:28 [INFO]   Run 3/5\n",
      "10:15:31 [INFO]     5,247 labeled -> F1-Score: 0.1894 (Train: 0.3s, Query: 0.00s)\n",
      "10:15:31 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5494, F1: 0.1939\n",
      "10:15:31 [INFO]   Run 4/5\n",
      "10:15:33 [INFO]     5,247 labeled -> F1-Score: 0.1853 (Train: 0.4s, Query: 0.00s)\n",
      "10:15:34 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5482, F1: 0.1988\n",
      "10:15:34 [INFO]   Run 5/5\n",
      "10:15:36 [INFO]     5,247 labeled -> F1-Score: 0.1783 (Train: 0.3s, Query: 0.00s)\n",
      "10:15:37 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5543, F1: 0.1995\n",
      "10:15:37 [INFO] \n",
      "Neural Network + Entropy Sampling - Budget: 100% (6,559 Samples)\n",
      "10:15:37 [INFO]   Run 1/5\n",
      "10:15:40 [INFO]     6,559 labeled -> F1-Score: 0.1958 (Train: 0.4s, Query: 0.00s)\n",
      "10:15:41 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5579, F1: 0.1925\n",
      "10:15:41 [INFO]   Run 2/5\n",
      "10:15:44 [INFO]     6,559 labeled -> F1-Score: 0.1954 (Train: 0.4s, Query: 0.00s)\n",
      "10:15:45 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5518, F1: 0.1831\n",
      "10:15:45 [INFO]   Run 3/5\n",
      "10:15:48 [INFO]     6,559 labeled -> F1-Score: 0.1909 (Train: 0.4s, Query: 0.00s)\n",
      "10:15:48 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5390, F1: 0.1600\n",
      "10:15:48 [INFO]   Run 4/5\n",
      "10:15:51 [INFO]     6,559 labeled -> F1-Score: 0.1924 (Train: 0.4s, Query: 0.00s)\n",
      "10:15:52 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5402, F1: 0.1889\n",
      "10:15:52 [INFO]   Run 5/5\n",
      "10:15:55 [INFO]     6,559 labeled -> F1-Score: 0.1908 (Train: 0.4s, Query: 0.00s)\n",
      "10:15:56 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5384, F1: 0.1792\n",
      "\n",
      "[ok] Neural Network + Entropy Sampling abgeschlossen in 0.9 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 3/20: Neural Network + Margin Sampling\n",
      "============================================================\n",
      "10:15:56 [INFO] \n",
      "Neural Network + Margin Sampling - Budget: 20% (1,311 Samples)\n",
      "10:15:56 [INFO]   Run 1/5\n",
      "10:15:56 [INFO]     1,311 labeled -> F1-Score: 0.1642 (Train: 0.1s, Query: 0.00s)\n",
      "10:15:57 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4665, F1: 0.1744\n",
      "10:15:57 [INFO]   Run 2/5\n",
      "10:15:57 [INFO]     1,311 labeled -> F1-Score: 0.1682 (Train: 0.1s, Query: 0.00s)\n",
      "10:15:57 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5146, F1: 0.1952\n",
      "10:15:57 [INFO]   Run 3/5\n",
      "10:15:58 [INFO]     1,311 labeled -> F1-Score: 0.1574 (Train: 0.1s, Query: 0.00s)\n",
      "10:15:58 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4909, F1: 0.1745\n",
      "10:15:58 [INFO]   Run 4/5\n",
      "10:15:58 [INFO]     1,311 labeled -> F1-Score: 0.1880 (Train: 0.1s, Query: 0.00s)\n",
      "10:15:58 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5274, F1: 0.1864\n",
      "10:15:58 [INFO]   Run 5/5\n",
      "10:15:59 [INFO]     1,311 labeled -> F1-Score: 0.1638 (Train: 0.1s, Query: 0.00s)\n",
      "10:15:59 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5238, F1: 0.1639\n",
      "10:15:59 [INFO] \n",
      "Neural Network + Margin Sampling - Budget: 40% (2,623 Samples)\n",
      "10:15:59 [INFO]   Run 1/5\n",
      "10:16:00 [INFO]     2,623 labeled -> F1-Score: 0.1882 (Train: 0.2s, Query: 0.00s)\n",
      "10:16:00 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5244, F1: 0.2132\n",
      "10:16:00 [INFO]   Run 2/5\n",
      "10:16:01 [INFO]     2,623 labeled -> F1-Score: 0.1678 (Train: 0.2s, Query: 0.00s)\n",
      "10:16:01 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5415, F1: 0.1741\n",
      "10:16:01 [INFO]   Run 3/5\n",
      "10:16:02 [INFO]     2,623 labeled -> F1-Score: 0.1834 (Train: 0.2s, Query: 0.00s)\n",
      "10:16:03 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5305, F1: 0.1946\n",
      "10:16:03 [INFO]   Run 4/5\n",
      "10:16:03 [INFO]     2,623 labeled -> F1-Score: 0.1988 (Train: 0.2s, Query: 0.00s)\n",
      "10:16:04 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5433, F1: 0.1925\n",
      "10:16:04 [INFO]   Run 5/5\n",
      "10:16:05 [INFO]     2,623 labeled -> F1-Score: 0.1682 (Train: 0.2s, Query: 0.01s)\n",
      "10:16:05 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5445, F1: 0.2064\n",
      "10:16:05 [INFO] \n",
      "Neural Network + Margin Sampling - Budget: 60% (3,935 Samples)\n",
      "10:16:05 [INFO]   Run 1/5\n",
      "10:16:06 [INFO]     3,935 labeled -> F1-Score: 0.1968 (Train: 0.2s, Query: 0.00s)\n",
      "10:16:07 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5433, F1: 0.1937\n",
      "10:16:07 [INFO]   Run 2/5\n",
      "10:16:08 [INFO]     3,935 labeled -> F1-Score: 0.1825 (Train: 0.3s, Query: 0.00s)\n",
      "10:16:09 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5457, F1: 0.1883\n",
      "10:16:09 [INFO]   Run 3/5\n",
      "10:16:10 [INFO]     3,935 labeled -> F1-Score: 0.1867 (Train: 0.3s, Query: 0.00s)\n",
      "10:16:11 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5524, F1: 0.1946\n",
      "10:16:11 [INFO]   Run 4/5\n",
      "10:16:12 [INFO]     3,935 labeled -> F1-Score: 0.1853 (Train: 0.3s, Query: 0.00s)\n",
      "10:16:12 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5518, F1: 0.1890\n",
      "10:16:12 [INFO]   Run 5/5\n",
      "10:16:14 [INFO]     3,935 labeled -> F1-Score: 0.1915 (Train: 0.3s, Query: 0.00s)\n",
      "10:16:14 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5506, F1: 0.1931\n",
      "10:16:14 [INFO] \n",
      "Neural Network + Margin Sampling - Budget: 80% (5,247 Samples)\n",
      "10:16:14 [INFO]   Run 1/5\n",
      "10:16:17 [INFO]     5,247 labeled -> F1-Score: 0.1888 (Train: 0.4s, Query: 0.00s)\n",
      "10:16:17 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5396, F1: 0.1871\n",
      "10:16:17 [INFO]   Run 2/5\n",
      "10:16:20 [INFO]     5,247 labeled -> F1-Score: 0.1874 (Train: 0.3s, Query: 0.00s)\n",
      "10:16:20 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5488, F1: 0.1893\n",
      "10:16:20 [INFO]   Run 3/5\n",
      "10:16:23 [INFO]     5,247 labeled -> F1-Score: 0.1819 (Train: 0.3s, Query: 0.00s)\n",
      "10:16:23 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5463, F1: 0.1897\n",
      "10:16:23 [INFO]   Run 4/5\n",
      "10:16:26 [INFO]     5,247 labeled -> F1-Score: 0.1769 (Train: 0.4s, Query: 0.00s)\n",
      "10:16:26 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5482, F1: 0.1871\n",
      "10:16:26 [INFO]   Run 5/5\n",
      "10:16:28 [INFO]     5,247 labeled -> F1-Score: 0.1727 (Train: 0.3s, Query: 0.00s)\n",
      "10:16:29 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5482, F1: 0.1963\n",
      "10:16:29 [INFO] \n",
      "Neural Network + Margin Sampling - Budget: 100% (6,559 Samples)\n",
      "10:16:29 [INFO]   Run 1/5\n",
      "10:16:32 [INFO]     6,559 labeled -> F1-Score: 0.1884 (Train: 0.4s, Query: 0.00s)\n",
      "10:16:33 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5433, F1: 0.1919\n",
      "10:16:33 [INFO]   Run 2/5\n",
      "10:16:36 [INFO]     6,559 labeled -> F1-Score: 0.1922 (Train: 0.4s, Query: 0.00s)\n",
      "10:16:37 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5317, F1: 0.1582\n",
      "10:16:37 [INFO]   Run 3/5\n",
      "10:16:40 [INFO]     6,559 labeled -> F1-Score: 0.1932 (Train: 0.4s, Query: 0.00s)\n",
      "10:16:41 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5421, F1: 0.1732\n",
      "10:16:41 [INFO]   Run 4/5\n",
      "10:16:44 [INFO]     6,559 labeled -> F1-Score: 0.1944 (Train: 0.4s, Query: 0.00s)\n",
      "10:16:45 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5402, F1: 0.1843\n",
      "10:16:45 [INFO]   Run 5/5\n",
      "10:16:48 [INFO]     6,559 labeled -> F1-Score: 0.1849 (Train: 0.4s, Query: 0.00s)\n",
      "10:16:49 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5439, F1: 0.1697\n",
      "\n",
      "[ok] Neural Network + Margin Sampling abgeschlossen in 0.9 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 4/20: Neural Network + Least Confidence\n",
      "============================================================\n",
      "10:16:49 [INFO] \n",
      "Neural Network + Least Confidence - Budget: 20% (1,311 Samples)\n",
      "10:16:49 [INFO]   Run 1/5\n",
      "10:16:49 [INFO]     1,311 labeled -> F1-Score: 0.1380 (Train: 0.1s, Query: 0.00s)\n",
      "10:16:50 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4695, F1: 0.1724\n",
      "10:16:50 [INFO]   Run 2/5\n",
      "10:16:50 [INFO]     1,311 labeled -> F1-Score: 0.1661 (Train: 0.1s, Query: 0.00s)\n",
      "10:16:50 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4921, F1: 0.1910\n",
      "10:16:50 [INFO]   Run 3/5\n",
      "10:16:51 [INFO]     1,311 labeled -> F1-Score: 0.1376 (Train: 0.1s, Query: 0.00s)\n",
      "10:16:51 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5134, F1: 0.1810\n",
      "10:16:51 [INFO]   Run 4/5\n",
      "10:16:51 [INFO]     1,311 labeled -> F1-Score: 0.1446 (Train: 0.1s, Query: 0.00s)\n",
      "10:16:51 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4567, F1: 0.1691\n",
      "10:16:51 [INFO]   Run 5/5\n",
      "10:16:52 [INFO]     1,311 labeled -> F1-Score: 0.1577 (Train: 0.1s, Query: 0.00s)\n",
      "10:16:52 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4756, F1: 0.1951\n",
      "10:16:52 [INFO] \n",
      "Neural Network + Least Confidence - Budget: 40% (2,623 Samples)\n",
      "10:16:52 [INFO]   Run 1/5\n",
      "10:16:53 [INFO]     2,623 labeled -> F1-Score: 0.1861 (Train: 0.2s, Query: 0.00s)\n",
      "10:16:53 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5317, F1: 0.1778\n",
      "10:16:53 [INFO]   Run 2/5\n",
      "10:16:54 [INFO]     2,623 labeled -> F1-Score: 0.1867 (Train: 0.2s, Query: 0.00s)\n",
      "10:16:55 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5476, F1: 0.1871\n",
      "10:16:55 [INFO]   Run 3/5\n",
      "10:16:55 [INFO]     2,623 labeled -> F1-Score: 0.1819 (Train: 0.2s, Query: 0.00s)\n",
      "10:16:56 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5384, F1: 0.1914\n",
      "10:16:56 [INFO]   Run 4/5\n",
      "10:16:57 [INFO]     2,623 labeled -> F1-Score: 0.1916 (Train: 0.2s, Query: 0.00s)\n",
      "10:16:57 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5335, F1: 0.1574\n",
      "10:16:57 [INFO]   Run 5/5\n",
      "10:16:58 [INFO]     2,623 labeled -> F1-Score: 0.1810 (Train: 0.2s, Query: 0.00s)\n",
      "10:16:58 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5366, F1: 0.1952\n",
      "10:16:58 [INFO] \n",
      "Neural Network + Least Confidence - Budget: 60% (3,935 Samples)\n",
      "10:16:58 [INFO]   Run 1/5\n",
      "10:17:00 [INFO]     3,935 labeled -> F1-Score: 0.1878 (Train: 0.3s, Query: 0.00s)\n",
      "10:17:00 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1879\n",
      "10:17:00 [INFO]   Run 2/5\n",
      "10:17:01 [INFO]     3,935 labeled -> F1-Score: 0.1971 (Train: 0.3s, Query: 0.00s)\n",
      "10:17:02 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5439, F1: 0.1876\n",
      "10:17:02 [INFO]   Run 3/5\n",
      "10:17:03 [INFO]     3,935 labeled -> F1-Score: 0.1917 (Train: 0.3s, Query: 0.00s)\n",
      "10:17:04 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1935\n",
      "10:17:04 [INFO]   Run 4/5\n",
      "10:17:05 [INFO]     3,935 labeled -> F1-Score: 0.1711 (Train: 0.3s, Query: 0.00s)\n",
      "10:17:06 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5396, F1: 0.1802\n",
      "10:17:06 [INFO]   Run 5/5\n",
      "10:17:07 [INFO]     3,935 labeled -> F1-Score: 0.1787 (Train: 0.3s, Query: 0.00s)\n",
      "10:17:08 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5470, F1: 0.1982\n",
      "10:17:08 [INFO] \n",
      "Neural Network + Least Confidence - Budget: 80% (5,247 Samples)\n",
      "10:17:08 [INFO]   Run 1/5\n",
      "10:17:10 [INFO]     5,247 labeled -> F1-Score: 0.1979 (Train: 0.3s, Query: 0.00s)\n",
      "10:17:11 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1920\n",
      "10:17:11 [INFO]   Run 2/5\n",
      "10:17:13 [INFO]     5,247 labeled -> F1-Score: 0.1949 (Train: 0.3s, Query: 0.00s)\n",
      "10:17:13 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5488, F1: 0.1810\n",
      "10:17:13 [INFO]   Run 3/5\n",
      "10:17:16 [INFO]     5,247 labeled -> F1-Score: 0.1900 (Train: 0.3s, Query: 0.00s)\n",
      "10:17:16 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1966\n",
      "10:17:16 [INFO]   Run 4/5\n",
      "10:17:19 [INFO]     5,247 labeled -> F1-Score: 0.1776 (Train: 0.3s, Query: 0.00s)\n",
      "10:17:19 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5409, F1: 0.1931\n",
      "10:17:19 [INFO]   Run 5/5\n",
      "10:17:21 [INFO]     5,247 labeled -> F1-Score: 0.1804 (Train: 0.3s, Query: 0.00s)\n",
      "10:17:22 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5512, F1: 0.1968\n",
      "10:17:22 [INFO] \n",
      "Neural Network + Least Confidence - Budget: 100% (6,559 Samples)\n",
      "10:17:22 [INFO]   Run 1/5\n",
      "10:17:25 [INFO]     6,559 labeled -> F1-Score: 0.1885 (Train: 0.4s, Query: 0.00s)\n",
      "10:17:26 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5494, F1: 0.1935\n",
      "10:17:26 [INFO]   Run 2/5\n",
      "10:17:29 [INFO]     6,559 labeled -> F1-Score: 0.1892 (Train: 0.4s, Query: 0.00s)\n",
      "10:17:30 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1764\n",
      "10:17:30 [INFO]   Run 3/5\n",
      "10:17:33 [INFO]     6,559 labeled -> F1-Score: 0.1858 (Train: 0.4s, Query: 0.00s)\n",
      "10:17:33 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5579, F1: 0.1984\n",
      "10:17:33 [INFO]   Run 4/5\n",
      "10:17:36 [INFO]     6,559 labeled -> F1-Score: 0.1883 (Train: 0.4s, Query: 0.00s)\n",
      "10:17:37 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5543, F1: 0.1886\n",
      "10:17:37 [INFO]   Run 5/5\n",
      "10:17:40 [INFO]     6,559 labeled -> F1-Score: 0.1896 (Train: 0.4s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5384, F1: 0.1707\n",
      "\n",
      "[ok] Neural Network + Least Confidence abgeschlossen in 0.9 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 5/20: Naive Bayes + Random Sampling\n",
      "============================================================\n",
      "10:17:41 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 20% (1,311 Samples)\n",
      "10:17:41 [INFO]   Run 1/5\n",
      "10:17:41 [INFO]     1,311 labeled -> F1-Score: 0.0576 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0640, F1: 0.0640\n",
      "10:17:41 [INFO]   Run 2/5\n",
      "10:17:41 [INFO]     1,311 labeled -> F1-Score: 0.0682 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0659, F1: 0.0626\n",
      "10:17:41 [INFO]   Run 3/5\n",
      "10:17:41 [INFO]     1,311 labeled -> F1-Score: 0.0502 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0567, F1: 0.0539\n",
      "10:17:41 [INFO]   Run 4/5\n",
      "10:17:41 [INFO]     1,311 labeled -> F1-Score: 0.0498 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0488, F1: 0.0581\n",
      "10:17:41 [INFO]   Run 5/5\n",
      "10:17:41 [INFO]     1,311 labeled -> F1-Score: 0.0689 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0506, F1: 0.0500\n",
      "10:17:41 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 40% (2,623 Samples)\n",
      "10:17:41 [INFO]   Run 1/5\n",
      "10:17:41 [INFO]     2,623 labeled -> F1-Score: 0.0347 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0396, F1: 0.0347\n",
      "10:17:41 [INFO]   Run 2/5\n",
      "10:17:41 [INFO]     2,623 labeled -> F1-Score: 0.0407 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0378, F1: 0.0408\n",
      "10:17:41 [INFO]   Run 3/5\n",
      "10:17:41 [INFO]     2,623 labeled -> F1-Score: 0.0324 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0378, F1: 0.0327\n",
      "10:17:41 [INFO]   Run 4/5\n",
      "10:17:41 [INFO]     2,623 labeled -> F1-Score: 0.0385 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0348, F1: 0.0385\n",
      "10:17:41 [INFO]   Run 5/5\n",
      "10:17:41 [INFO]     2,623 labeled -> F1-Score: 0.0252 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0287, F1: 0.0252\n",
      "10:17:41 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 60% (3,935 Samples)\n",
      "10:17:41 [INFO]   Run 1/5\n",
      "10:17:41 [INFO]     3,935 labeled -> F1-Score: 0.0262 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0268, F1: 0.0318\n",
      "10:17:41 [INFO]   Run 2/5\n",
      "10:17:41 [INFO]     3,935 labeled -> F1-Score: 0.0308 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0280, F1: 0.0292\n",
      "10:17:41 [INFO]   Run 3/5\n",
      "10:17:41 [INFO]     3,935 labeled -> F1-Score: 0.0247 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0244, F1: 0.0227\n",
      "10:17:41 [INFO]   Run 4/5\n",
      "10:17:41 [INFO]     3,935 labeled -> F1-Score: 0.0230 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0244, F1: 0.0239\n",
      "10:17:41 [INFO]   Run 5/5\n",
      "10:17:41 [INFO]     3,935 labeled -> F1-Score: 0.0273 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0299, F1: 0.0279\n",
      "10:17:41 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 80% (5,247 Samples)\n",
      "10:17:41 [INFO]   Run 1/5\n",
      "10:17:41 [INFO]     5,247 labeled -> F1-Score: 0.0192 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0250, F1: 0.0243\n",
      "10:17:41 [INFO]   Run 2/5\n",
      "10:17:41 [INFO]     5,247 labeled -> F1-Score: 0.0299 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0262, F1: 0.0310\n",
      "10:17:41 [INFO]   Run 3/5\n",
      "10:17:41 [INFO]     5,247 labeled -> F1-Score: 0.0178 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:41 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0268, F1: 0.0252\n",
      "10:17:41 [INFO]   Run 4/5\n",
      "10:17:42 [INFO]     5,247 labeled -> F1-Score: 0.0283 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0250, F1: 0.0258\n",
      "10:17:42 [INFO]   Run 5/5\n",
      "10:17:42 [INFO]     5,247 labeled -> F1-Score: 0.0269 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0287, F1: 0.0282\n",
      "10:17:42 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 100% (6,559 Samples)\n",
      "10:17:42 [INFO]   Run 1/5\n",
      "10:17:42 [INFO]     6,559 labeled -> F1-Score: 0.0289 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:42 [INFO]   Run 2/5\n",
      "10:17:42 [INFO]     6,559 labeled -> F1-Score: 0.0291 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:42 [INFO]   Run 3/5\n",
      "10:17:42 [INFO]     6,559 labeled -> F1-Score: 0.0327 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:42 [INFO]   Run 4/5\n",
      "10:17:42 [INFO]     6,559 labeled -> F1-Score: 0.0288 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:42 [INFO]   Run 5/5\n",
      "10:17:42 [INFO]     6,559 labeled -> F1-Score: 0.0277 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "\n",
      "[ok] Naive Bayes + Random Sampling abgeschlossen in 0.0 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 6/20: Naive Bayes + Entropy Sampling\n",
      "============================================================\n",
      "10:17:42 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 20% (1,311 Samples)\n",
      "10:17:42 [INFO]   Run 1/5\n",
      "10:17:42 [INFO]     1,311 labeled -> F1-Score: 0.0761 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0701, F1: 0.0718\n",
      "10:17:42 [INFO]   Run 2/5\n",
      "10:17:42 [INFO]     1,311 labeled -> F1-Score: 0.0937 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0848, F1: 0.0704\n",
      "10:17:42 [INFO]   Run 3/5\n",
      "10:17:42 [INFO]     1,311 labeled -> F1-Score: 0.0854 (Train: 0.0s, Query: 0.01s)\n",
      "10:17:42 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1024, F1: 0.0630\n",
      "10:17:42 [INFO]   Run 4/5\n",
      "10:17:42 [INFO]     1,311 labeled -> F1-Score: 0.1060 (Train: 0.0s, Query: 0.01s)\n",
      "10:17:42 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1701, F1: 0.1154\n",
      "10:17:42 [INFO]   Run 5/5\n",
      "10:17:42 [INFO]     1,311 labeled -> F1-Score: 0.0556 (Train: 0.0s, Query: 0.01s)\n",
      "10:17:42 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0524, F1: 0.0473\n",
      "10:17:42 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 40% (2,623 Samples)\n",
      "10:17:42 [INFO]   Run 1/5\n",
      "10:17:42 [INFO]     2,623 labeled -> F1-Score: 0.0284 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0311, F1: 0.0221\n",
      "10:17:42 [INFO]   Run 2/5\n",
      "10:17:42 [INFO]     2,623 labeled -> F1-Score: 0.0386 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0567, F1: 0.0386\n",
      "10:17:42 [INFO]   Run 3/5\n",
      "10:17:42 [INFO]     2,623 labeled -> F1-Score: 0.0590 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1012, F1: 0.0599\n",
      "10:17:42 [INFO]   Run 4/5\n",
      "10:17:42 [INFO]     2,623 labeled -> F1-Score: 0.0792 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1268, F1: 0.0792\n",
      "10:17:42 [INFO]   Run 5/5\n",
      "10:17:42 [INFO]     2,623 labeled -> F1-Score: 0.0448 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0494, F1: 0.0458\n",
      "10:17:42 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 60% (3,935 Samples)\n",
      "10:17:42 [INFO]   Run 1/5\n",
      "10:17:42 [INFO]     3,935 labeled -> F1-Score: 0.0253 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0329, F1: 0.0236\n",
      "10:17:42 [INFO]   Run 2/5\n",
      "10:17:42 [INFO]     3,935 labeled -> F1-Score: 0.0408 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0610, F1: 0.0515\n",
      "10:17:42 [INFO]   Run 3/5\n",
      "10:17:42 [INFO]     3,935 labeled -> F1-Score: 0.0613 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0927, F1: 0.0606\n",
      "10:17:42 [INFO]   Run 4/5\n",
      "10:17:42 [INFO]     3,935 labeled -> F1-Score: 0.0785 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:42 [INFO]     Final: 3,935 labeled -> Accuracy: 0.1195, F1: 0.0799\n",
      "10:17:42 [INFO]   Run 5/5\n",
      "10:17:43 [INFO]     3,935 labeled -> F1-Score: 0.0421 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0470, F1: 0.0446\n",
      "10:17:43 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 80% (5,247 Samples)\n",
      "10:17:43 [INFO]   Run 1/5\n",
      "10:17:43 [INFO]     5,247 labeled -> F1-Score: 0.0339 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0311, F1: 0.0340\n",
      "10:17:43 [INFO]   Run 2/5\n",
      "10:17:43 [INFO]     5,247 labeled -> F1-Score: 0.0478 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0579, F1: 0.0485\n",
      "10:17:43 [INFO]   Run 3/5\n",
      "10:17:43 [INFO]     5,247 labeled -> F1-Score: 0.0553 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0921, F1: 0.0587\n",
      "10:17:43 [INFO]   Run 4/5\n",
      "10:17:43 [INFO]     5,247 labeled -> F1-Score: 0.0600 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 5,247 labeled -> Accuracy: 0.1000, F1: 0.0548\n",
      "10:17:43 [INFO]   Run 5/5\n",
      "10:17:43 [INFO]     5,247 labeled -> F1-Score: 0.0734 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0427, F1: 0.0347\n",
      "10:17:43 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 100% (6,559 Samples)\n",
      "10:17:43 [INFO]   Run 1/5\n",
      "10:17:43 [INFO]     6,559 labeled -> F1-Score: 0.0266 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:43 [INFO]   Run 2/5\n",
      "10:17:43 [INFO]     6,559 labeled -> F1-Score: 0.0544 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:43 [INFO]   Run 3/5\n",
      "10:17:43 [INFO]     6,559 labeled -> F1-Score: 0.0424 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:43 [INFO]   Run 4/5\n",
      "10:17:43 [INFO]     6,559 labeled -> F1-Score: 0.0262 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:43 [INFO]   Run 5/5\n",
      "10:17:43 [INFO]     6,559 labeled -> F1-Score: 0.0300 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "\n",
      "[ok] Naive Bayes + Entropy Sampling abgeschlossen in 0.0 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 7/20: Naive Bayes + Margin Sampling\n",
      "============================================================\n",
      "10:17:43 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 20% (1,311 Samples)\n",
      "10:17:43 [INFO]   Run 1/5\n",
      "10:17:43 [INFO]     1,311 labeled -> F1-Score: 0.0761 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0695, F1: 0.0727\n",
      "10:17:43 [INFO]   Run 2/5\n",
      "10:17:43 [INFO]     1,311 labeled -> F1-Score: 0.0937 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0902, F1: 0.0842\n",
      "10:17:43 [INFO]   Run 3/5\n",
      "10:17:43 [INFO]     1,311 labeled -> F1-Score: 0.0854 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1024, F1: 0.0619\n",
      "10:17:43 [INFO]   Run 4/5\n",
      "10:17:43 [INFO]     1,311 labeled -> F1-Score: 0.1166 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:43 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1488, F1: 0.1033\n",
      "10:17:43 [INFO]   Run 5/5\n",
      "10:17:44 [INFO]     1,311 labeled -> F1-Score: 0.0556 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0524, F1: 0.0473\n",
      "10:17:44 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 40% (2,623 Samples)\n",
      "10:17:44 [INFO]   Run 1/5\n",
      "10:17:44 [INFO]     2,623 labeled -> F1-Score: 0.0593 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0585, F1: 0.0593\n",
      "10:17:44 [INFO]   Run 2/5\n",
      "10:17:44 [INFO]     2,623 labeled -> F1-Score: 0.0518 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0646, F1: 0.0518\n",
      "10:17:44 [INFO]   Run 3/5\n",
      "10:17:44 [INFO]     2,623 labeled -> F1-Score: 0.0590 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1012, F1: 0.0599\n",
      "10:17:44 [INFO]   Run 4/5\n",
      "10:17:44 [INFO]     2,623 labeled -> F1-Score: 0.0740 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1226, F1: 0.0740\n",
      "10:17:44 [INFO]   Run 5/5\n",
      "10:17:44 [INFO]     2,623 labeled -> F1-Score: 0.0448 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0494, F1: 0.0458\n",
      "10:17:44 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 60% (3,935 Samples)\n",
      "10:17:44 [INFO]   Run 1/5\n",
      "10:17:44 [INFO]     3,935 labeled -> F1-Score: 0.0558 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0543, F1: 0.0558\n",
      "10:17:44 [INFO]   Run 2/5\n",
      "10:17:44 [INFO]     3,935 labeled -> F1-Score: 0.0670 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0738, F1: 0.0666\n",
      "10:17:44 [INFO]   Run 3/5\n",
      "10:17:44 [INFO]     3,935 labeled -> F1-Score: 0.0613 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0927, F1: 0.0606\n",
      "10:17:44 [INFO]   Run 4/5\n",
      "10:17:44 [INFO]     3,935 labeled -> F1-Score: 0.0444 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0463, F1: 0.0452\n",
      "10:17:44 [INFO]   Run 5/5\n",
      "10:17:44 [INFO]     3,935 labeled -> F1-Score: 0.0421 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0470, F1: 0.0446\n",
      "10:17:44 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 80% (5,247 Samples)\n",
      "10:17:44 [INFO]   Run 1/5\n",
      "10:17:44 [INFO]     5,247 labeled -> F1-Score: 0.0594 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0530, F1: 0.0565\n",
      "10:17:44 [INFO]   Run 2/5\n",
      "10:17:44 [INFO]     5,247 labeled -> F1-Score: 0.0529 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0622, F1: 0.0585\n",
      "10:17:44 [INFO]   Run 3/5\n",
      "10:17:44 [INFO]     5,247 labeled -> F1-Score: 0.0394 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0329, F1: 0.0369\n",
      "10:17:44 [INFO]   Run 4/5\n",
      "10:17:44 [INFO]     5,247 labeled -> F1-Score: 0.0525 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0482, F1: 0.0511\n",
      "10:17:44 [INFO]   Run 5/5\n",
      "10:17:44 [INFO]     5,247 labeled -> F1-Score: 0.0607 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:44 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0671, F1: 0.0706\n",
      "10:17:44 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 100% (6,559 Samples)\n",
      "10:17:44 [INFO]   Run 1/5\n",
      "10:17:45 [INFO]     6,559 labeled -> F1-Score: 0.0338 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:45 [INFO]   Run 2/5\n",
      "10:17:45 [INFO]     6,559 labeled -> F1-Score: 0.0304 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:45 [INFO]   Run 3/5\n",
      "10:17:45 [INFO]     6,559 labeled -> F1-Score: 0.0252 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:45 [INFO]   Run 4/5\n",
      "10:17:45 [INFO]     6,559 labeled -> F1-Score: 0.0245 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:45 [INFO]   Run 5/5\n",
      "10:17:45 [INFO]     6,559 labeled -> F1-Score: 0.0366 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "\n",
      "[ok] Naive Bayes + Margin Sampling abgeschlossen in 0.0 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 8/20: Naive Bayes + Least Confidence\n",
      "============================================================\n",
      "10:17:45 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 20% (1,311 Samples)\n",
      "10:17:45 [INFO]   Run 1/5\n",
      "10:17:45 [INFO]     1,311 labeled -> F1-Score: 0.0761 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0695, F1: 0.0727\n",
      "10:17:45 [INFO]   Run 2/5\n",
      "10:17:45 [INFO]     1,311 labeled -> F1-Score: 0.0937 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0854, F1: 0.0724\n",
      "10:17:45 [INFO]   Run 3/5\n",
      "10:17:45 [INFO]     1,311 labeled -> F1-Score: 0.0854 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1024, F1: 0.0619\n",
      "10:17:45 [INFO]   Run 4/5\n",
      "10:17:45 [INFO]     1,311 labeled -> F1-Score: 0.1168 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1488, F1: 0.1032\n",
      "10:17:45 [INFO]   Run 5/5\n",
      "10:17:45 [INFO]     1,311 labeled -> F1-Score: 0.0556 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0524, F1: 0.0473\n",
      "10:17:45 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 40% (2,623 Samples)\n",
      "10:17:45 [INFO]   Run 1/5\n",
      "10:17:45 [INFO]     2,623 labeled -> F1-Score: 0.0593 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0585, F1: 0.0593\n",
      "10:17:45 [INFO]   Run 2/5\n",
      "10:17:45 [INFO]     2,623 labeled -> F1-Score: 0.0386 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0567, F1: 0.0386\n",
      "10:17:45 [INFO]   Run 3/5\n",
      "10:17:45 [INFO]     2,623 labeled -> F1-Score: 0.0590 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1012, F1: 0.0599\n",
      "10:17:45 [INFO]   Run 4/5\n",
      "10:17:45 [INFO]     2,623 labeled -> F1-Score: 0.0600 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1159, F1: 0.0603\n",
      "10:17:45 [INFO]   Run 5/5\n",
      "10:17:45 [INFO]     2,623 labeled -> F1-Score: 0.0448 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0494, F1: 0.0458\n",
      "10:17:45 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 60% (3,935 Samples)\n",
      "10:17:45 [INFO]   Run 1/5\n",
      "10:17:45 [INFO]     3,935 labeled -> F1-Score: 0.0558 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0543, F1: 0.0558\n",
      "10:17:45 [INFO]   Run 2/5\n",
      "10:17:45 [INFO]     3,935 labeled -> F1-Score: 0.0408 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:45 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0610, F1: 0.0518\n",
      "10:17:45 [INFO]   Run 3/5\n",
      "10:17:45 [INFO]     3,935 labeled -> F1-Score: 0.0613 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0927, F1: 0.0606\n",
      "10:17:46 [INFO]   Run 4/5\n",
      "10:17:46 [INFO]     3,935 labeled -> F1-Score: 0.0657 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 3,935 labeled -> Accuracy: 0.1165, F1: 0.0640\n",
      "10:17:46 [INFO]   Run 5/5\n",
      "10:17:46 [INFO]     3,935 labeled -> F1-Score: 0.0421 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0470, F1: 0.0446\n",
      "10:17:46 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 80% (5,247 Samples)\n",
      "10:17:46 [INFO]   Run 1/5\n",
      "10:17:46 [INFO]     5,247 labeled -> F1-Score: 0.0594 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0366, F1: 0.0391\n",
      "10:17:46 [INFO]   Run 2/5\n",
      "10:17:46 [INFO]     5,247 labeled -> F1-Score: 0.0570 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0500, F1: 0.0480\n",
      "10:17:46 [INFO]   Run 3/5\n",
      "10:17:46 [INFO]     5,247 labeled -> F1-Score: 0.0394 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0335, F1: 0.0362\n",
      "10:17:46 [INFO]   Run 4/5\n",
      "10:17:46 [INFO]     5,247 labeled -> F1-Score: 0.0592 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 5,247 labeled -> Accuracy: 0.1061, F1: 0.0616\n",
      "10:17:46 [INFO]   Run 5/5\n",
      "10:17:46 [INFO]     5,247 labeled -> F1-Score: 0.0665 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0604, F1: 0.0648\n",
      "10:17:46 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 100% (6,559 Samples)\n",
      "10:17:46 [INFO]   Run 1/5\n",
      "10:17:46 [INFO]     6,559 labeled -> F1-Score: 0.0330 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:46 [INFO]   Run 2/5\n",
      "10:17:46 [INFO]     6,559 labeled -> F1-Score: 0.0243 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:46 [INFO]   Run 3/5\n",
      "10:17:46 [INFO]     6,559 labeled -> F1-Score: 0.0244 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:46 [INFO]   Run 4/5\n",
      "10:17:46 [INFO]     6,559 labeled -> F1-Score: 0.0219 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "10:17:46 [INFO]   Run 5/5\n",
      "10:17:46 [INFO]     6,559 labeled -> F1-Score: 0.0362 (Train: 0.0s, Query: 0.00s)\n",
      "10:17:46 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "\n",
      "[ok] Naive Bayes + Least Confidence abgeschlossen in 0.0 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 9/20: Random Forest + Random Sampling\n",
      "============================================================\n",
      "10:17:46 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 20% (1,311 Samples)\n",
      "10:17:46 [INFO]   Run 1/5\n",
      "10:17:47 [INFO]     1,311 labeled -> F1-Score: 0.2103 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:47 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4811, F1: 0.2031\n",
      "10:17:47 [INFO]   Run 2/5\n",
      "10:17:47 [INFO]     1,311 labeled -> F1-Score: 0.2108 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:47 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4659, F1: 0.2231\n",
      "10:17:47 [INFO]   Run 3/5\n",
      "10:17:48 [INFO]     1,311 labeled -> F1-Score: 0.2338 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:48 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4823, F1: 0.2358\n",
      "10:17:48 [INFO]   Run 4/5\n",
      "10:17:48 [INFO]     1,311 labeled -> F1-Score: 0.2318 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:48 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4677, F1: 0.2366\n",
      "10:17:48 [INFO]   Run 5/5\n",
      "10:17:48 [INFO]     1,311 labeled -> F1-Score: 0.2360 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:48 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4610, F1: 0.2208\n",
      "10:17:48 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 40% (2,623 Samples)\n",
      "10:17:48 [INFO]   Run 1/5\n",
      "10:17:49 [INFO]     2,623 labeled -> F1-Score: 0.2179 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:49 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4799, F1: 0.2166\n",
      "10:17:49 [INFO]   Run 2/5\n",
      "10:17:50 [INFO]     2,623 labeled -> F1-Score: 0.2026 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:50 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4537, F1: 0.2016\n",
      "10:17:50 [INFO]   Run 3/5\n",
      "10:17:51 [INFO]     2,623 labeled -> F1-Score: 0.2383 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:51 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4659, F1: 0.2373\n",
      "10:17:51 [INFO]   Run 4/5\n",
      "10:17:51 [INFO]     2,623 labeled -> F1-Score: 0.2396 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:51 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4793, F1: 0.2383\n",
      "10:17:51 [INFO]   Run 5/5\n",
      "10:17:52 [INFO]     2,623 labeled -> F1-Score: 0.2231 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:52 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4604, F1: 0.2214\n",
      "10:17:52 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 60% (3,935 Samples)\n",
      "10:17:52 [INFO]   Run 1/5\n",
      "10:17:53 [INFO]     3,935 labeled -> F1-Score: 0.2127 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:53 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4689, F1: 0.2164\n",
      "10:17:53 [INFO]   Run 2/5\n",
      "10:17:54 [INFO]     3,935 labeled -> F1-Score: 0.2070 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:54 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4591, F1: 0.2065\n",
      "10:17:54 [INFO]   Run 3/5\n",
      "10:17:55 [INFO]     3,935 labeled -> F1-Score: 0.2279 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:55 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4750, F1: 0.2299\n",
      "10:17:55 [INFO]   Run 4/5\n",
      "10:17:56 [INFO]     3,935 labeled -> F1-Score: 0.2333 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:56 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4732, F1: 0.2243\n",
      "10:17:56 [INFO]   Run 5/5\n",
      "10:17:57 [INFO]     3,935 labeled -> F1-Score: 0.2360 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:57 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4793, F1: 0.2328\n",
      "10:17:57 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 80% (5,247 Samples)\n",
      "10:17:57 [INFO]   Run 1/5\n",
      "10:17:58 [INFO]     5,247 labeled -> F1-Score: 0.2253 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:58 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4701, F1: 0.2246\n",
      "10:17:58 [INFO]   Run 2/5\n",
      "10:17:59 [INFO]     5,247 labeled -> F1-Score: 0.2254 (Train: 0.1s, Query: 0.00s)\n",
      "10:17:59 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4561, F1: 0.2270\n",
      "10:17:59 [INFO]   Run 3/5\n",
      "10:18:01 [INFO]     5,247 labeled -> F1-Score: 0.2279 (Train: 0.1s, Query: 0.00s)\n",
      "10:18:01 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4732, F1: 0.2255\n",
      "10:18:01 [INFO]   Run 4/5\n",
      "10:18:02 [INFO]     5,247 labeled -> F1-Score: 0.2185 (Train: 0.1s, Query: 0.00s)\n",
      "10:18:02 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4604, F1: 0.2162\n",
      "10:18:02 [INFO]   Run 5/5\n",
      "10:18:03 [INFO]     5,247 labeled -> F1-Score: 0.2227 (Train: 0.1s, Query: 0.00s)\n",
      "10:18:03 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4720, F1: 0.2251\n",
      "10:18:03 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 100% (6,559 Samples)\n",
      "10:18:03 [INFO]   Run 1/5\n",
      "10:18:05 [INFO]     6,559 labeled -> F1-Score: 0.2365 (Train: 0.1s, Query: 0.00s)\n",
      "10:18:05 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4726, F1: 0.2328\n",
      "10:18:05 [INFO]   Run 2/5\n",
      "10:18:06 [INFO]     6,559 labeled -> F1-Score: 0.2328 (Train: 0.1s, Query: 0.00s)\n",
      "10:18:06 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4707, F1: 0.2304\n",
      "10:18:06 [INFO]   Run 3/5\n",
      "10:18:08 [INFO]     6,559 labeled -> F1-Score: 0.2238 (Train: 0.1s, Query: 0.00s)\n",
      "10:18:08 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4713, F1: 0.2342\n",
      "10:18:08 [INFO]   Run 4/5\n",
      "10:18:09 [INFO]     6,559 labeled -> F1-Score: 0.2237 (Train: 0.1s, Query: 0.00s)\n",
      "10:18:09 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4713, F1: 0.2305\n",
      "10:18:09 [INFO]   Run 5/5\n",
      "10:18:11 [INFO]     6,559 labeled -> F1-Score: 0.2305 (Train: 0.1s, Query: 0.00s)\n",
      "10:18:11 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4707, F1: 0.2297\n",
      "\n",
      "[ok] Random Forest + Random Sampling abgeschlossen in 0.4 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 10/20: Random Forest + Entropy Sampling\n",
      "============================================================\n",
      "10:18:11 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 20% (1,311 Samples)\n",
      "10:18:11 [INFO]   Run 1/5\n",
      "10:18:11 [INFO]     1,311 labeled -> F1-Score: 0.2404 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:11 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4793, F1: 0.2353\n",
      "10:18:11 [INFO]   Run 2/5\n",
      "10:18:12 [INFO]     1,311 labeled -> F1-Score: 0.2098 (Train: 0.1s, Query: 0.02s)\n",
      "10:18:12 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4585, F1: 0.2179\n",
      "10:18:12 [INFO]   Run 3/5\n",
      "10:18:12 [INFO]     1,311 labeled -> F1-Score: 0.2577 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:12 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4933, F1: 0.2554\n",
      "10:18:12 [INFO]   Run 4/5\n",
      "10:18:13 [INFO]     1,311 labeled -> F1-Score: 0.2097 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:13 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4945, F1: 0.2121\n",
      "10:18:13 [INFO]   Run 5/5\n",
      "10:18:13 [INFO]     1,311 labeled -> F1-Score: 0.1874 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:13 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4634, F1: 0.2126\n",
      "10:18:13 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 40% (2,623 Samples)\n",
      "10:18:13 [INFO]   Run 1/5\n",
      "10:18:14 [INFO]     2,623 labeled -> F1-Score: 0.2344 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:14 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5061, F1: 0.2338\n",
      "10:18:14 [INFO]   Run 2/5\n",
      "10:18:15 [INFO]     2,623 labeled -> F1-Score: 0.2227 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:15 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5104, F1: 0.2244\n",
      "10:18:15 [INFO]   Run 3/5\n",
      "10:18:15 [INFO]     2,623 labeled -> F1-Score: 0.2391 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:16 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5000, F1: 0.2381\n",
      "10:18:16 [INFO]   Run 4/5\n",
      "10:18:16 [INFO]     2,623 labeled -> F1-Score: 0.2178 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:16 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4841, F1: 0.2185\n",
      "10:18:16 [INFO]   Run 5/5\n",
      "10:18:17 [INFO]     2,623 labeled -> F1-Score: 0.2099 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:17 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4604, F1: 0.2112\n",
      "10:18:17 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 60% (3,935 Samples)\n",
      "10:18:17 [INFO]   Run 1/5\n",
      "10:18:18 [INFO]     3,935 labeled -> F1-Score: 0.2196 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:18 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5079, F1: 0.2219\n",
      "10:18:18 [INFO]   Run 2/5\n",
      "10:18:19 [INFO]     3,935 labeled -> F1-Score: 0.2145 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:19 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5128, F1: 0.2221\n",
      "10:18:19 [INFO]   Run 3/5\n",
      "10:18:20 [INFO]     3,935 labeled -> F1-Score: 0.2344 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:20 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5134, F1: 0.2305\n",
      "10:18:20 [INFO]   Run 4/5\n",
      "10:18:21 [INFO]     3,935 labeled -> F1-Score: 0.2296 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:21 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5098, F1: 0.2441\n",
      "10:18:21 [INFO]   Run 5/5\n",
      "10:18:22 [INFO]     3,935 labeled -> F1-Score: 0.2084 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:23 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4902, F1: 0.2169\n",
      "10:18:23 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 80% (5,247 Samples)\n",
      "10:18:23 [INFO]   Run 1/5\n",
      "10:18:24 [INFO]     5,247 labeled -> F1-Score: 0.2324 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:24 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4933, F1: 0.2369\n",
      "10:18:24 [INFO]   Run 2/5\n",
      "10:18:25 [INFO]     5,247 labeled -> F1-Score: 0.2254 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:25 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5030, F1: 0.2249\n",
      "10:18:25 [INFO]   Run 3/5\n",
      "10:18:27 [INFO]     5,247 labeled -> F1-Score: 0.2164 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:27 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4933, F1: 0.2155\n",
      "10:18:27 [INFO]   Run 4/5\n",
      "10:18:28 [INFO]     5,247 labeled -> F1-Score: 0.2393 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:28 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5049, F1: 0.2363\n",
      "10:18:28 [INFO]   Run 5/5\n",
      "10:18:30 [INFO]     5,247 labeled -> F1-Score: 0.2390 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:30 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4921, F1: 0.2305\n",
      "10:18:30 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 100% (6,559 Samples)\n",
      "10:18:30 [INFO]   Run 1/5\n",
      "10:18:31 [INFO]     6,559 labeled -> F1-Score: 0.2314 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:31 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4713, F1: 0.2309\n",
      "10:18:31 [INFO]   Run 2/5\n",
      "10:18:33 [INFO]     6,559 labeled -> F1-Score: 0.2371 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:33 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4732, F1: 0.2363\n",
      "10:18:33 [INFO]   Run 3/5\n",
      "10:18:35 [INFO]     6,559 labeled -> F1-Score: 0.2266 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:35 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4720, F1: 0.2305\n",
      "10:18:35 [INFO]   Run 4/5\n",
      "10:18:36 [INFO]     6,559 labeled -> F1-Score: 0.2376 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:36 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4720, F1: 0.2355\n",
      "10:18:36 [INFO]   Run 5/5\n",
      "10:18:38 [INFO]     6,559 labeled -> F1-Score: 0.2262 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:38 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4695, F1: 0.2253\n",
      "\n",
      "[ok] Random Forest + Entropy Sampling abgeschlossen in 0.5 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 11/20: Random Forest + Margin Sampling\n",
      "============================================================\n",
      "10:18:38 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 20% (1,311 Samples)\n",
      "10:18:38 [INFO]   Run 1/5\n",
      "10:18:39 [INFO]     1,311 labeled -> F1-Score: 0.2236 (Train: 0.1s, Query: 0.02s)\n",
      "10:18:39 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4683, F1: 0.2241\n",
      "10:18:39 [INFO]   Run 2/5\n",
      "10:18:39 [INFO]     1,311 labeled -> F1-Score: 0.2139 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:39 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4988, F1: 0.2162\n",
      "10:18:39 [INFO]   Run 3/5\n",
      "10:18:39 [INFO]     1,311 labeled -> F1-Score: 0.2248 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:40 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5012, F1: 0.2246\n",
      "10:18:40 [INFO]   Run 4/5\n",
      "10:18:40 [INFO]     1,311 labeled -> F1-Score: 0.2433 (Train: 0.1s, Query: 0.02s)\n",
      "10:18:40 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5213, F1: 0.2449\n",
      "10:18:40 [INFO]   Run 5/5\n",
      "10:18:40 [INFO]     1,311 labeled -> F1-Score: 0.1987 (Train: 0.1s, Query: 0.02s)\n",
      "10:18:41 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4848, F1: 0.2053\n",
      "10:18:41 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 40% (2,623 Samples)\n",
      "10:18:41 [INFO]   Run 1/5\n",
      "10:18:41 [INFO]     2,623 labeled -> F1-Score: 0.2392 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:41 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5171, F1: 0.2388\n",
      "10:18:41 [INFO]   Run 2/5\n",
      "10:18:42 [INFO]     2,623 labeled -> F1-Score: 0.2247 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:42 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5213, F1: 0.2247\n",
      "10:18:42 [INFO]   Run 3/5\n",
      "10:18:43 [INFO]     2,623 labeled -> F1-Score: 0.2349 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:43 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5213, F1: 0.2357\n",
      "10:18:43 [INFO]   Run 4/5\n",
      "10:18:44 [INFO]     2,623 labeled -> F1-Score: 0.2297 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:44 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5280, F1: 0.2282\n",
      "10:18:44 [INFO]   Run 5/5\n",
      "10:18:44 [INFO]     2,623 labeled -> F1-Score: 0.2172 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:45 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5165, F1: 0.2189\n",
      "10:18:45 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 60% (3,935 Samples)\n",
      "10:18:45 [INFO]   Run 1/5\n",
      "10:18:46 [INFO]     3,935 labeled -> F1-Score: 0.2384 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:46 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5226, F1: 0.2424\n",
      "10:18:46 [INFO]   Run 2/5\n",
      "10:18:47 [INFO]     3,935 labeled -> F1-Score: 0.2239 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:47 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5195, F1: 0.2317\n",
      "10:18:47 [INFO]   Run 3/5\n",
      "10:18:48 [INFO]     3,935 labeled -> F1-Score: 0.2335 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:48 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5085, F1: 0.2382\n",
      "10:18:48 [INFO]   Run 4/5\n",
      "10:18:49 [INFO]     3,935 labeled -> F1-Score: 0.2309 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:49 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5165, F1: 0.2280\n",
      "10:18:49 [INFO]   Run 5/5\n",
      "10:18:50 [INFO]     3,935 labeled -> F1-Score: 0.2140 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:50 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5122, F1: 0.2201\n",
      "10:18:50 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 80% (5,247 Samples)\n",
      "10:18:50 [INFO]   Run 1/5\n",
      "10:18:51 [INFO]     5,247 labeled -> F1-Score: 0.2328 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:51 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4970, F1: 0.2379\n",
      "10:18:51 [INFO]   Run 2/5\n",
      "10:18:53 [INFO]     5,247 labeled -> F1-Score: 0.2119 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:53 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4982, F1: 0.2228\n",
      "10:18:53 [INFO]   Run 3/5\n",
      "10:18:54 [INFO]     5,247 labeled -> F1-Score: 0.2228 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:54 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4945, F1: 0.2184\n",
      "10:18:54 [INFO]   Run 4/5\n",
      "10:18:55 [INFO]     5,247 labeled -> F1-Score: 0.2206 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:56 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4878, F1: 0.2182\n",
      "10:18:56 [INFO]   Run 5/5\n",
      "10:18:57 [INFO]     5,247 labeled -> F1-Score: 0.2278 (Train: 0.1s, Query: 0.02s)\n",
      "10:18:57 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4994, F1: 0.2288\n",
      "10:18:57 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 100% (6,559 Samples)\n",
      "10:18:57 [INFO]   Run 1/5\n",
      "10:18:59 [INFO]     6,559 labeled -> F1-Score: 0.2370 (Train: 0.1s, Query: 0.01s)\n",
      "10:18:59 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4701, F1: 0.2347\n",
      "10:18:59 [INFO]   Run 2/5\n",
      "10:19:00 [INFO]     6,559 labeled -> F1-Score: 0.2221 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:00 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4713, F1: 0.2272\n",
      "10:19:00 [INFO]   Run 3/5\n",
      "10:19:02 [INFO]     6,559 labeled -> F1-Score: 0.2283 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:02 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4732, F1: 0.2324\n",
      "10:19:02 [INFO]   Run 4/5\n",
      "10:19:04 [INFO]     6,559 labeled -> F1-Score: 0.2294 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:04 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4707, F1: 0.2265\n",
      "10:19:04 [INFO]   Run 5/5\n",
      "10:19:05 [INFO]     6,559 labeled -> F1-Score: 0.2207 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:06 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4701, F1: 0.2307\n",
      "\n",
      "[ok] Random Forest + Margin Sampling abgeschlossen in 0.5 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 12/20: Random Forest + Least Confidence\n",
      "============================================================\n",
      "10:19:06 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 20% (1,311 Samples)\n",
      "10:19:06 [INFO]   Run 1/5\n",
      "10:19:06 [INFO]     1,311 labeled -> F1-Score: 0.2354 (Train: 0.1s, Query: 0.02s)\n",
      "10:19:06 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4927, F1: 0.2380\n",
      "10:19:06 [INFO]   Run 2/5\n",
      "10:19:06 [INFO]     1,311 labeled -> F1-Score: 0.2129 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:07 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5000, F1: 0.2266\n",
      "10:19:07 [INFO]   Run 3/5\n",
      "10:19:07 [INFO]     1,311 labeled -> F1-Score: 0.2300 (Train: 0.1s, Query: 0.02s)\n",
      "10:19:07 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4768, F1: 0.2201\n",
      "10:19:07 [INFO]   Run 4/5\n",
      "10:19:07 [INFO]     1,311 labeled -> F1-Score: 0.1980 (Train: 0.1s, Query: 0.02s)\n",
      "10:19:07 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5024, F1: 0.2015\n",
      "10:19:07 [INFO]   Run 5/5\n",
      "10:19:08 [INFO]     1,311 labeled -> F1-Score: 0.2082 (Train: 0.1s, Query: 0.02s)\n",
      "10:19:08 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4811, F1: 0.2200\n",
      "10:19:08 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 40% (2,623 Samples)\n",
      "10:19:08 [INFO]   Run 1/5\n",
      "10:19:09 [INFO]     2,623 labeled -> F1-Score: 0.2568 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:09 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5183, F1: 0.2582\n",
      "10:19:09 [INFO]   Run 2/5\n",
      "10:19:09 [INFO]     2,623 labeled -> F1-Score: 0.2210 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:10 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5171, F1: 0.2218\n",
      "10:19:10 [INFO]   Run 3/5\n",
      "10:19:10 [INFO]     2,623 labeled -> F1-Score: 0.2382 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:10 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5018, F1: 0.2402\n",
      "10:19:10 [INFO]   Run 4/5\n",
      "10:19:11 [INFO]     2,623 labeled -> F1-Score: 0.2176 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:11 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5104, F1: 0.2180\n",
      "10:19:11 [INFO]   Run 5/5\n",
      "10:19:12 [INFO]     2,623 labeled -> F1-Score: 0.2146 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:12 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4970, F1: 0.2137\n",
      "10:19:12 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 60% (3,935 Samples)\n",
      "10:19:12 [INFO]   Run 1/5\n",
      "10:19:13 [INFO]     3,935 labeled -> F1-Score: 0.2359 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:13 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5128, F1: 0.2309\n",
      "10:19:13 [INFO]   Run 2/5\n",
      "10:19:14 [INFO]     3,935 labeled -> F1-Score: 0.2350 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:14 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5183, F1: 0.2280\n",
      "10:19:14 [INFO]   Run 3/5\n",
      "10:19:15 [INFO]     3,935 labeled -> F1-Score: 0.2376 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:15 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5091, F1: 0.2265\n",
      "10:19:15 [INFO]   Run 4/5\n",
      "10:19:16 [INFO]     3,935 labeled -> F1-Score: 0.2211 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:16 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5171, F1: 0.2217\n",
      "10:19:16 [INFO]   Run 5/5\n",
      "10:19:17 [INFO]     3,935 labeled -> F1-Score: 0.2305 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:17 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5091, F1: 0.2326\n",
      "10:19:17 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 80% (5,247 Samples)\n",
      "10:19:17 [INFO]   Run 1/5\n",
      "10:19:19 [INFO]     5,247 labeled -> F1-Score: 0.2345 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:19 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4957, F1: 0.2371\n",
      "10:19:19 [INFO]   Run 2/5\n",
      "10:19:20 [INFO]     5,247 labeled -> F1-Score: 0.2212 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:20 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5018, F1: 0.2172\n",
      "10:19:20 [INFO]   Run 3/5\n",
      "10:19:21 [INFO]     5,247 labeled -> F1-Score: 0.2088 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:22 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4945, F1: 0.2093\n",
      "10:19:22 [INFO]   Run 4/5\n",
      "10:19:23 [INFO]     5,247 labeled -> F1-Score: 0.2207 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:23 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5018, F1: 0.2260\n",
      "10:19:23 [INFO]   Run 5/5\n",
      "10:19:24 [INFO]     5,247 labeled -> F1-Score: 0.2248 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:24 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4933, F1: 0.2264\n",
      "10:19:24 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 100% (6,559 Samples)\n",
      "10:19:24 [INFO]   Run 1/5\n",
      "10:19:26 [INFO]     6,559 labeled -> F1-Score: 0.2374 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:26 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4701, F1: 0.2291\n",
      "10:19:26 [INFO]   Run 2/5\n",
      "10:19:28 [INFO]     6,559 labeled -> F1-Score: 0.2302 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:28 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4695, F1: 0.2255\n",
      "10:19:28 [INFO]   Run 3/5\n",
      "10:19:29 [INFO]     6,559 labeled -> F1-Score: 0.2295 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:30 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4720, F1: 0.2306\n",
      "10:19:30 [INFO]   Run 4/5\n",
      "10:19:31 [INFO]     6,559 labeled -> F1-Score: 0.2223 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:31 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4726, F1: 0.2281\n",
      "10:19:31 [INFO]   Run 5/5\n",
      "10:19:33 [INFO]     6,559 labeled -> F1-Score: 0.2354 (Train: 0.1s, Query: 0.01s)\n",
      "10:19:33 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4707, F1: 0.2294\n",
      "\n",
      "[ok] Random Forest + Least Confidence abgeschlossen in 0.5 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 13/20: Logistic Regression + Random Sampling\n",
      "============================================================\n",
      "10:19:33 [INFO] \n",
      "Logistic Regression + Random Sampling - Budget: 20% (1,311 Samples)\n",
      "10:19:33 [INFO]   Run 1/5\n",
      "10:19:34 [INFO]     1,311 labeled -> F1-Score: 0.1700 (Train: 0.6s, Query: 0.00s)\n",
      "10:19:35 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5354, F1: 0.1839\n",
      "10:19:35 [INFO]   Run 2/5\n",
      "10:19:35 [INFO]     1,311 labeled -> F1-Score: 0.1783 (Train: 0.4s, Query: 0.00s)\n",
      "10:19:36 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5439, F1: 0.1784\n",
      "10:19:36 [INFO]   Run 3/5\n",
      "10:19:37 [INFO]     1,311 labeled -> F1-Score: 0.1857 (Train: 0.6s, Query: 0.00s)\n",
      "10:19:38 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5488, F1: 0.1879\n",
      "10:19:38 [INFO]   Run 4/5\n",
      "10:19:38 [INFO]     1,311 labeled -> F1-Score: 0.1789 (Train: 0.6s, Query: 0.00s)\n",
      "10:19:39 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5543, F1: 0.1845\n",
      "10:19:39 [INFO]   Run 5/5\n",
      "10:19:40 [INFO]     1,311 labeled -> F1-Score: 0.1724 (Train: 0.6s, Query: 0.00s)\n",
      "10:19:41 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5354, F1: 0.1736\n",
      "10:19:41 [INFO] \n",
      "Logistic Regression + Random Sampling - Budget: 40% (2,623 Samples)\n",
      "10:19:41 [INFO]   Run 1/5\n",
      "10:19:45 [INFO]     2,623 labeled -> F1-Score: 0.1797 (Train: 1.4s, Query: 0.00s)\n",
      "10:19:47 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5311, F1: 0.1789\n",
      "10:19:47 [INFO]   Run 2/5\n",
      "10:19:51 [INFO]     2,623 labeled -> F1-Score: 0.1943 (Train: 1.4s, Query: 0.00s)\n",
      "10:19:52 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5530, F1: 0.1956\n",
      "10:19:52 [INFO]   Run 3/5\n",
      "10:19:56 [INFO]     2,623 labeled -> F1-Score: 0.1847 (Train: 1.4s, Query: 0.00s)\n",
      "10:19:58 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5518, F1: 0.1848\n",
      "10:19:58 [INFO]   Run 4/5\n",
      "10:20:02 [INFO]     2,623 labeled -> F1-Score: 0.1859 (Train: 1.4s, Query: 0.00s)\n",
      "10:20:03 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5518, F1: 0.1856\n",
      "10:20:03 [INFO]   Run 5/5\n",
      "10:20:07 [INFO]     2,623 labeled -> F1-Score: 0.1853 (Train: 1.4s, Query: 0.00s)\n",
      "10:20:09 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5445, F1: 0.1848\n",
      "10:20:09 [INFO] \n",
      "Logistic Regression + Random Sampling - Budget: 60% (3,935 Samples)\n",
      "10:20:09 [INFO]   Run 1/5\n",
      "10:20:17 [INFO]     3,935 labeled -> F1-Score: 0.1860 (Train: 1.9s, Query: 0.00s)\n",
      "10:20:19 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5372, F1: 0.1835\n",
      "10:20:19 [INFO]   Run 2/5\n",
      "10:20:26 [INFO]     3,935 labeled -> F1-Score: 0.1946 (Train: 1.9s, Query: 0.00s)\n",
      "10:20:28 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5402, F1: 0.1930\n",
      "10:20:28 [INFO]   Run 3/5\n",
      "10:20:36 [INFO]     3,935 labeled -> F1-Score: 0.1830 (Train: 1.9s, Query: 0.00s)\n",
      "10:20:38 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5445, F1: 0.1831\n",
      "10:20:38 [INFO]   Run 4/5\n",
      "10:20:46 [INFO]     3,935 labeled -> F1-Score: 0.1891 (Train: 1.9s, Query: 0.00s)\n",
      "10:20:48 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5591, F1: 0.1925\n",
      "10:20:48 [INFO]   Run 5/5\n",
      "10:20:56 [INFO]     3,935 labeled -> F1-Score: 0.1886 (Train: 2.2s, Query: 0.00s)\n",
      "10:20:58 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1882\n",
      "10:20:58 [INFO] \n",
      "Logistic Regression + Random Sampling - Budget: 80% (5,247 Samples)\n",
      "10:20:58 [INFO]   Run 1/5\n",
      "10:21:13 [INFO]     5,247 labeled -> F1-Score: 0.1836 (Train: 2.7s, Query: 0.00s)\n",
      "10:21:16 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5348, F1: 0.1839\n",
      "10:21:16 [INFO]   Run 2/5\n",
      "10:21:31 [INFO]     5,247 labeled -> F1-Score: 0.1856 (Train: 2.6s, Query: 0.00s)\n",
      "10:21:33 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5372, F1: 0.1890\n",
      "10:21:33 [INFO]   Run 3/5\n",
      "10:21:49 [INFO]     5,247 labeled -> F1-Score: 0.1850 (Train: 2.7s, Query: 0.00s)\n",
      "10:21:51 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1858\n",
      "10:21:51 [INFO]   Run 4/5\n",
      "10:22:06 [INFO]     5,247 labeled -> F1-Score: 0.1905 (Train: 2.7s, Query: 0.00s)\n",
      "10:22:09 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5500, F1: 0.1931\n",
      "10:22:09 [INFO]   Run 5/5\n",
      "10:22:24 [INFO]     5,247 labeled -> F1-Score: 0.1867 (Train: 2.7s, Query: 0.00s)\n",
      "10:22:27 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5384, F1: 0.1862\n",
      "10:22:27 [INFO] \n",
      "Logistic Regression + Random Sampling - Budget: 100% (6,559 Samples)\n",
      "10:22:27 [INFO]   Run 1/5\n",
      "10:22:48 [INFO]     6,559 labeled -> F1-Score: 0.1858 (Train: 3.2s, Query: 0.00s)\n",
      "10:22:51 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:22:51 [INFO]   Run 2/5\n",
      "10:23:12 [INFO]     6,559 labeled -> F1-Score: 0.1848 (Train: 3.2s, Query: 0.00s)\n",
      "10:23:16 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:23:16 [INFO]   Run 3/5\n",
      "10:23:37 [INFO]     6,559 labeled -> F1-Score: 0.1866 (Train: 3.2s, Query: 0.00s)\n",
      "10:23:40 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:23:40 [INFO]   Run 4/5\n",
      "10:24:01 [INFO]     6,559 labeled -> F1-Score: 0.1849 (Train: 3.2s, Query: 0.00s)\n",
      "10:24:05 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:24:05 [INFO]   Run 5/5\n",
      "10:24:26 [INFO]     6,559 labeled -> F1-Score: 0.1869 (Train: 3.2s, Query: 0.00s)\n",
      "10:24:30 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "\n",
      "[ok] Logistic Regression + Random Sampling abgeschlossen in 4.9 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 14/20: Logistic Regression + Entropy Sampling\n",
      "============================================================\n",
      "10:24:30 [INFO] \n",
      "Logistic Regression + Entropy Sampling - Budget: 20% (1,311 Samples)\n",
      "10:24:30 [INFO]   Run 1/5\n",
      "10:24:30 [INFO]     1,311 labeled -> F1-Score: 0.2048 (Train: 0.6s, Query: 0.00s)\n",
      "10:24:31 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4817, F1: 0.2015\n",
      "10:24:31 [INFO]   Run 2/5\n",
      "10:24:32 [INFO]     1,311 labeled -> F1-Score: 0.1552 (Train: 0.6s, Query: 0.00s)\n",
      "10:24:33 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4689, F1: 0.1633\n",
      "10:24:33 [INFO]   Run 3/5\n",
      "10:24:34 [INFO]     1,311 labeled -> F1-Score: 0.1641 (Train: 0.6s, Query: 0.00s)\n",
      "10:24:34 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5030, F1: 0.1607\n",
      "10:24:34 [INFO]   Run 4/5\n",
      "10:24:35 [INFO]     1,311 labeled -> F1-Score: 0.1938 (Train: 0.6s, Query: 0.00s)\n",
      "10:24:36 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5000, F1: 0.1931\n",
      "10:24:36 [INFO]   Run 5/5\n",
      "10:24:37 [INFO]     1,311 labeled -> F1-Score: 0.1755 (Train: 0.6s, Query: 0.00s)\n",
      "10:24:38 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5220, F1: 0.1773\n",
      "10:24:38 [INFO] \n",
      "Logistic Regression + Entropy Sampling - Budget: 40% (2,623 Samples)\n",
      "10:24:38 [INFO]   Run 1/5\n",
      "10:24:42 [INFO]     2,623 labeled -> F1-Score: 0.1857 (Train: 1.4s, Query: 0.00s)\n",
      "10:24:44 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4927, F1: 0.1967\n",
      "10:24:44 [INFO]   Run 2/5\n",
      "10:24:48 [INFO]     2,623 labeled -> F1-Score: 0.1757 (Train: 1.4s, Query: 0.00s)\n",
      "10:24:49 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5165, F1: 0.1758\n",
      "10:24:49 [INFO]   Run 3/5\n",
      "10:24:54 [INFO]     2,623 labeled -> F1-Score: 0.1835 (Train: 1.4s, Query: 0.00s)\n",
      "10:24:55 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5463, F1: 0.1836\n",
      "10:24:55 [INFO]   Run 4/5\n",
      "10:24:59 [INFO]     2,623 labeled -> F1-Score: 0.1740 (Train: 1.4s, Query: 0.00s)\n",
      "10:25:01 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5439, F1: 0.1746\n",
      "10:25:01 [INFO]   Run 5/5\n",
      "10:25:05 [INFO]     2,623 labeled -> F1-Score: 0.1931 (Train: 1.4s, Query: 0.00s)\n",
      "10:25:06 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5305, F1: 0.1904\n",
      "10:25:06 [INFO] \n",
      "Logistic Regression + Entropy Sampling - Budget: 60% (3,935 Samples)\n",
      "10:25:06 [INFO]   Run 1/5\n",
      "10:25:14 [INFO]     3,935 labeled -> F1-Score: 0.1948 (Train: 1.9s, Query: 0.00s)\n",
      "10:25:16 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5341, F1: 0.1781\n",
      "10:25:16 [INFO]   Run 2/5\n",
      "10:25:24 [INFO]     3,935 labeled -> F1-Score: 0.1782 (Train: 1.9s, Query: 0.00s)\n",
      "10:25:26 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5329, F1: 0.1757\n",
      "10:25:26 [INFO]   Run 3/5\n",
      "10:25:34 [INFO]     3,935 labeled -> F1-Score: 0.1805 (Train: 1.9s, Query: 0.00s)\n",
      "10:25:36 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5433, F1: 0.1871\n",
      "10:25:36 [INFO]   Run 4/5\n",
      "10:25:44 [INFO]     3,935 labeled -> F1-Score: 0.1756 (Train: 1.9s, Query: 0.00s)\n",
      "10:25:46 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5421, F1: 0.1739\n",
      "10:25:46 [INFO]   Run 5/5\n",
      "10:25:54 [INFO]     3,935 labeled -> F1-Score: 0.1928 (Train: 1.9s, Query: 0.00s)\n",
      "10:25:56 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5427, F1: 0.1912\n",
      "10:25:56 [INFO] \n",
      "Logistic Regression + Entropy Sampling - Budget: 80% (5,247 Samples)\n",
      "10:25:56 [INFO]   Run 1/5\n",
      "10:26:11 [INFO]     5,247 labeled -> F1-Score: 0.1951 (Train: 2.7s, Query: 0.00s)\n",
      "10:26:14 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5317, F1: 0.1983\n",
      "10:26:14 [INFO]   Run 2/5\n",
      "10:26:29 [INFO]     5,247 labeled -> F1-Score: 0.1933 (Train: 2.7s, Query: 0.00s)\n",
      "10:26:32 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5463, F1: 0.1971\n",
      "10:26:32 [INFO]   Run 3/5\n",
      "10:26:47 [INFO]     5,247 labeled -> F1-Score: 0.1870 (Train: 2.7s, Query: 0.00s)\n",
      "10:26:50 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5482, F1: 0.1866\n",
      "10:26:50 [INFO]   Run 4/5\n",
      "10:27:05 [INFO]     5,247 labeled -> F1-Score: 0.1877 (Train: 2.7s, Query: 0.00s)\n",
      "10:27:08 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5433, F1: 0.1878\n",
      "10:27:08 [INFO]   Run 5/5\n",
      "10:27:22 [INFO]     5,247 labeled -> F1-Score: 0.2047 (Train: 2.7s, Query: 0.00s)\n",
      "10:27:25 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5506, F1: 0.2025\n",
      "10:27:25 [INFO] \n",
      "Logistic Regression + Entropy Sampling - Budget: 100% (6,559 Samples)\n",
      "10:27:25 [INFO]   Run 1/5\n",
      "10:27:46 [INFO]     6,559 labeled -> F1-Score: 0.1860 (Train: 3.2s, Query: 0.00s)\n",
      "10:27:50 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:27:50 [INFO]   Run 2/5\n",
      "10:28:11 [INFO]     6,559 labeled -> F1-Score: 0.1878 (Train: 3.2s, Query: 0.00s)\n",
      "10:28:14 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:28:14 [INFO]   Run 3/5\n",
      "10:28:35 [INFO]     6,559 labeled -> F1-Score: 0.1878 (Train: 3.2s, Query: 0.00s)\n",
      "10:28:39 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:28:39 [INFO]   Run 4/5\n",
      "10:29:00 [INFO]     6,559 labeled -> F1-Score: 0.1870 (Train: 3.2s, Query: 0.00s)\n",
      "10:29:03 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:29:03 [INFO]   Run 5/5\n",
      "10:29:25 [INFO]     6,559 labeled -> F1-Score: 0.1940 (Train: 3.2s, Query: 0.00s)\n",
      "10:29:28 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "\n",
      "[ok] Logistic Regression + Entropy Sampling abgeschlossen in 5.0 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 15/20: Logistic Regression + Margin Sampling\n",
      "============================================================\n",
      "10:29:28 [INFO] \n",
      "Logistic Regression + Margin Sampling - Budget: 20% (1,311 Samples)\n",
      "10:29:28 [INFO]   Run 1/5\n",
      "10:29:29 [INFO]     1,311 labeled -> F1-Score: 0.1718 (Train: 0.6s, Query: 0.00s)\n",
      "10:29:30 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5030, F1: 0.1518\n",
      "10:29:30 [INFO]   Run 2/5\n",
      "10:29:30 [INFO]     1,311 labeled -> F1-Score: 0.1588 (Train: 0.6s, Query: 0.00s)\n",
      "10:29:31 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5280, F1: 0.1724\n",
      "10:29:31 [INFO]   Run 3/5\n",
      "10:29:32 [INFO]     1,311 labeled -> F1-Score: 0.1722 (Train: 0.6s, Query: 0.00s)\n",
      "10:29:33 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5250, F1: 0.1791\n",
      "10:29:33 [INFO]   Run 4/5\n",
      "10:29:34 [INFO]     1,311 labeled -> F1-Score: 0.2064 (Train: 0.6s, Query: 0.00s)\n",
      "10:29:34 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5335, F1: 0.1926\n",
      "10:29:34 [INFO]   Run 5/5\n",
      "10:29:35 [INFO]     1,311 labeled -> F1-Score: 0.1817 (Train: 0.6s, Query: 0.00s)\n",
      "10:29:36 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5329, F1: 0.1813\n",
      "10:29:36 [INFO] \n",
      "Logistic Regression + Margin Sampling - Budget: 40% (2,623 Samples)\n",
      "10:29:36 [INFO]   Run 1/5\n",
      "10:29:40 [INFO]     2,623 labeled -> F1-Score: 0.1864 (Train: 1.4s, Query: 0.00s)\n",
      "10:29:42 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5323, F1: 0.1870\n",
      "10:29:42 [INFO]   Run 2/5\n",
      "10:29:46 [INFO]     2,623 labeled -> F1-Score: 0.1766 (Train: 1.4s, Query: 0.00s)\n",
      "10:29:47 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5354, F1: 0.1790\n",
      "10:29:47 [INFO]   Run 3/5\n",
      "10:29:51 [INFO]     2,623 labeled -> F1-Score: 0.1907 (Train: 1.4s, Query: 0.00s)\n",
      "10:29:53 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5463, F1: 0.1912\n",
      "10:29:53 [INFO]   Run 4/5\n",
      "10:29:57 [INFO]     2,623 labeled -> F1-Score: 0.1908 (Train: 1.4s, Query: 0.00s)\n",
      "10:29:59 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5555, F1: 0.1929\n",
      "10:29:59 [INFO]   Run 5/5\n",
      "10:30:03 [INFO]     2,623 labeled -> F1-Score: 0.1898 (Train: 1.4s, Query: 0.00s)\n",
      "10:30:04 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5409, F1: 0.1900\n",
      "10:30:04 [INFO] \n",
      "Logistic Regression + Margin Sampling - Budget: 60% (3,935 Samples)\n",
      "10:30:04 [INFO]   Run 1/5\n",
      "10:30:12 [INFO]     3,935 labeled -> F1-Score: 0.1885 (Train: 1.9s, Query: 0.00s)\n",
      "10:30:14 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5232, F1: 0.1871\n",
      "10:30:14 [INFO]   Run 2/5\n",
      "10:30:22 [INFO]     3,935 labeled -> F1-Score: 0.1771 (Train: 1.9s, Query: 0.00s)\n",
      "10:30:24 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5250, F1: 0.1782\n",
      "10:30:24 [INFO]   Run 3/5\n",
      "10:30:32 [INFO]     3,935 labeled -> F1-Score: 0.1905 (Train: 1.9s, Query: 0.00s)\n",
      "10:30:34 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5396, F1: 0.1844\n",
      "10:30:34 [INFO]   Run 4/5\n",
      "10:30:42 [INFO]     3,935 labeled -> F1-Score: 0.1952 (Train: 1.9s, Query: 0.00s)\n",
      "10:30:44 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5427, F1: 0.1848\n",
      "10:30:44 [INFO]   Run 5/5\n",
      "10:30:51 [INFO]     3,935 labeled -> F1-Score: 0.1851 (Train: 1.9s, Query: 0.00s)\n",
      "10:30:54 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5354, F1: 0.1839\n",
      "10:30:54 [INFO] \n",
      "Logistic Regression + Margin Sampling - Budget: 80% (5,247 Samples)\n",
      "10:30:54 [INFO]   Run 1/5\n",
      "10:31:08 [INFO]     5,247 labeled -> F1-Score: 0.1883 (Train: 2.7s, Query: 0.00s)\n",
      "10:31:11 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5287, F1: 0.1894\n",
      "10:31:11 [INFO]   Run 2/5\n",
      "10:31:26 [INFO]     5,247 labeled -> F1-Score: 0.1874 (Train: 2.7s, Query: 0.00s)\n",
      "10:31:29 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5378, F1: 0.1872\n",
      "10:31:29 [INFO]   Run 3/5\n",
      "10:31:44 [INFO]     5,247 labeled -> F1-Score: 0.1961 (Train: 2.7s, Query: 0.00s)\n",
      "10:31:47 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5518, F1: 0.1959\n",
      "10:31:47 [INFO]   Run 4/5\n",
      "10:32:02 [INFO]     5,247 labeled -> F1-Score: 0.1823 (Train: 2.7s, Query: 0.00s)\n",
      "10:32:04 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5451, F1: 0.1824\n",
      "10:32:04 [INFO]   Run 5/5\n",
      "10:32:19 [INFO]     5,247 labeled -> F1-Score: 0.1981 (Train: 2.7s, Query: 0.00s)\n",
      "10:32:22 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1930\n",
      "10:32:22 [INFO] \n",
      "Logistic Regression + Margin Sampling - Budget: 100% (6,559 Samples)\n",
      "10:32:22 [INFO]   Run 1/5\n",
      "10:32:43 [INFO]     6,559 labeled -> F1-Score: 0.1888 (Train: 3.2s, Query: 0.00s)\n",
      "10:32:47 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:32:47 [INFO]   Run 2/5\n",
      "10:33:08 [INFO]     6,559 labeled -> F1-Score: 0.1821 (Train: 3.2s, Query: 0.00s)\n",
      "10:33:11 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:33:11 [INFO]   Run 3/5\n",
      "10:33:32 [INFO]     6,559 labeled -> F1-Score: 0.1883 (Train: 3.2s, Query: 0.00s)\n",
      "10:33:36 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:33:36 [INFO]   Run 4/5\n",
      "10:33:57 [INFO]     6,559 labeled -> F1-Score: 0.1880 (Train: 3.2s, Query: 0.00s)\n",
      "10:34:01 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:34:01 [INFO]   Run 5/5\n",
      "10:34:22 [INFO]     6,559 labeled -> F1-Score: 0.1855 (Train: 3.2s, Query: 0.00s)\n",
      "10:34:25 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "\n",
      "[ok] Logistic Regression + Margin Sampling abgeschlossen in 5.0 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 16/20: Logistic Regression + Least Confidence\n",
      "============================================================\n",
      "10:34:25 [INFO] \n",
      "Logistic Regression + Least Confidence - Budget: 20% (1,311 Samples)\n",
      "10:34:25 [INFO]   Run 1/5\n",
      "10:34:26 [INFO]     1,311 labeled -> F1-Score: 0.1954 (Train: 0.6s, Query: 0.00s)\n",
      "10:34:27 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4902, F1: 0.2067\n",
      "10:34:27 [INFO]   Run 2/5\n",
      "10:34:28 [INFO]     1,311 labeled -> F1-Score: 0.1738 (Train: 0.6s, Query: 0.00s)\n",
      "10:34:28 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5341, F1: 0.1787\n",
      "10:34:28 [INFO]   Run 3/5\n",
      "10:34:29 [INFO]     1,311 labeled -> F1-Score: 0.1628 (Train: 0.6s, Query: 0.00s)\n",
      "10:34:30 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5293, F1: 0.1695\n",
      "10:34:30 [INFO]   Run 4/5\n",
      "10:34:31 [INFO]     1,311 labeled -> F1-Score: 0.1796 (Train: 0.6s, Query: 0.00s)\n",
      "10:34:32 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5177, F1: 0.1799\n",
      "10:34:32 [INFO]   Run 5/5\n",
      "10:34:32 [INFO]     1,311 labeled -> F1-Score: 0.1881 (Train: 0.5s, Query: 0.00s)\n",
      "10:34:33 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5366, F1: 0.1878\n",
      "10:34:33 [INFO] \n",
      "Logistic Regression + Least Confidence - Budget: 40% (2,623 Samples)\n",
      "10:34:33 [INFO]   Run 1/5\n",
      "10:34:37 [INFO]     2,623 labeled -> F1-Score: 0.1801 (Train: 1.4s, Query: 0.00s)\n",
      "10:34:39 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5128, F1: 0.1829\n",
      "10:34:39 [INFO]   Run 2/5\n",
      "10:34:43 [INFO]     2,623 labeled -> F1-Score: 0.1861 (Train: 1.7s, Query: 0.00s)\n",
      "10:34:45 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5378, F1: 0.1870\n",
      "10:34:45 [INFO]   Run 3/5\n",
      "10:34:49 [INFO]     2,623 labeled -> F1-Score: 0.1878 (Train: 1.4s, Query: 0.00s)\n",
      "10:34:50 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5470, F1: 0.1888\n",
      "10:34:50 [INFO]   Run 4/5\n",
      "10:34:55 [INFO]     2,623 labeled -> F1-Score: 0.1777 (Train: 1.4s, Query: 0.00s)\n",
      "10:34:56 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5305, F1: 0.1776\n",
      "10:34:56 [INFO]   Run 5/5\n",
      "10:35:00 [INFO]     2,623 labeled -> F1-Score: 0.1949 (Train: 1.4s, Query: 0.00s)\n",
      "10:35:02 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5439, F1: 0.1935\n",
      "10:35:02 [INFO] \n",
      "Logistic Regression + Least Confidence - Budget: 60% (3,935 Samples)\n",
      "10:35:02 [INFO]   Run 1/5\n",
      "10:35:09 [INFO]     3,935 labeled -> F1-Score: 0.2018 (Train: 1.9s, Query: 0.00s)\n",
      "10:35:11 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5317, F1: 0.1985\n",
      "10:35:11 [INFO]   Run 2/5\n",
      "10:35:19 [INFO]     3,935 labeled -> F1-Score: 0.1933 (Train: 1.9s, Query: 0.00s)\n",
      "10:35:21 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5488, F1: 0.1930\n",
      "10:35:21 [INFO]   Run 3/5\n",
      "10:35:29 [INFO]     3,935 labeled -> F1-Score: 0.1892 (Train: 1.9s, Query: 0.00s)\n",
      "10:35:31 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5439, F1: 0.1823\n",
      "10:35:31 [INFO]   Run 4/5\n",
      "10:35:39 [INFO]     3,935 labeled -> F1-Score: 0.1831 (Train: 1.9s, Query: 0.00s)\n",
      "10:35:41 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5451, F1: 0.1866\n",
      "10:35:41 [INFO]   Run 5/5\n",
      "10:35:49 [INFO]     3,935 labeled -> F1-Score: 0.1935 (Train: 1.9s, Query: 0.00s)\n",
      "10:35:51 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5402, F1: 0.1887\n",
      "10:35:51 [INFO] \n",
      "Logistic Regression + Least Confidence - Budget: 80% (5,247 Samples)\n",
      "10:35:51 [INFO]   Run 1/5\n",
      "10:36:06 [INFO]     5,247 labeled -> F1-Score: 0.2033 (Train: 2.7s, Query: 0.00s)\n",
      "10:36:09 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5372, F1: 0.2060\n",
      "10:36:09 [INFO]   Run 2/5\n",
      "10:36:24 [INFO]     5,247 labeled -> F1-Score: 0.1887 (Train: 2.7s, Query: 0.00s)\n",
      "10:36:26 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5427, F1: 0.1880\n",
      "10:36:26 [INFO]   Run 3/5\n",
      "10:36:42 [INFO]     5,247 labeled -> F1-Score: 0.1881 (Train: 2.7s, Query: 0.00s)\n",
      "10:36:45 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5457, F1: 0.1874\n",
      "10:36:45 [INFO]   Run 4/5\n",
      "10:37:00 [INFO]     5,247 labeled -> F1-Score: 0.1991 (Train: 2.7s, Query: 0.00s)\n",
      "10:37:02 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5476, F1: 0.1969\n",
      "10:37:02 [INFO]   Run 5/5\n",
      "10:37:18 [INFO]     5,247 labeled -> F1-Score: 0.1839 (Train: 2.7s, Query: 0.00s)\n",
      "10:37:20 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5366, F1: 0.1846\n",
      "10:37:20 [INFO] \n",
      "Logistic Regression + Least Confidence - Budget: 100% (6,559 Samples)\n",
      "10:37:20 [INFO]   Run 1/5\n",
      "10:37:42 [INFO]     6,559 labeled -> F1-Score: 0.1895 (Train: 3.2s, Query: 0.00s)\n",
      "10:37:45 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:37:45 [INFO]   Run 2/5\n",
      "10:38:07 [INFO]     6,559 labeled -> F1-Score: 0.1921 (Train: 3.2s, Query: 0.00s)\n",
      "10:38:10 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:38:10 [INFO]   Run 3/5\n",
      "10:38:31 [INFO]     6,559 labeled -> F1-Score: 0.1882 (Train: 3.2s, Query: 0.00s)\n",
      "10:38:34 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:38:34 [INFO]   Run 4/5\n",
      "10:38:56 [INFO]     6,559 labeled -> F1-Score: 0.1917 (Train: 3.2s, Query: 0.00s)\n",
      "10:38:59 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "10:38:59 [INFO]   Run 5/5\n",
      "10:39:20 [INFO]     6,559 labeled -> F1-Score: 0.1899 (Train: 3.2s, Query: 0.00s)\n",
      "10:39:24 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "\n",
      "[ok] Logistic Regression + Least Confidence abgeschlossen in 5.0 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 17/20: SVM + Random Sampling\n",
      "============================================================\n",
      "10:39:24 [INFO] \n",
      "SVM + Random Sampling - Budget: 20% (1,311 Samples)\n",
      "10:39:24 [INFO]   Run 1/5\n",
      "10:39:24 [INFO]     1,311 labeled -> F1-Score: 0.1729 (Train: 0.1s, Query: 0.00s)\n",
      "10:39:24 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5390, F1: 0.1683\n",
      "10:39:24 [INFO]   Run 2/5\n",
      "10:39:25 [INFO]     1,311 labeled -> F1-Score: 0.1608 (Train: 0.1s, Query: 0.00s)\n",
      "10:39:25 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5335, F1: 0.1599\n",
      "10:39:25 [INFO]   Run 3/5\n",
      "10:39:25 [INFO]     1,311 labeled -> F1-Score: 0.1675 (Train: 0.1s, Query: 0.00s)\n",
      "10:39:25 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5390, F1: 0.1648\n",
      "10:39:25 [INFO]   Run 4/5\n",
      "10:39:26 [INFO]     1,311 labeled -> F1-Score: 0.1431 (Train: 0.1s, Query: 0.00s)\n",
      "10:39:26 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5226, F1: 0.1449\n",
      "10:39:26 [INFO]   Run 5/5\n",
      "10:39:26 [INFO]     1,311 labeled -> F1-Score: 0.1427 (Train: 0.1s, Query: 0.00s)\n",
      "10:39:26 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5421, F1: 0.1767\n",
      "10:39:26 [INFO] \n",
      "SVM + Random Sampling - Budget: 40% (2,623 Samples)\n",
      "10:39:26 [INFO]   Run 1/5\n",
      "10:39:28 [INFO]     2,623 labeled -> F1-Score: 0.1838 (Train: 0.7s, Query: 0.00s)\n",
      "10:39:29 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5476, F1: 0.1832\n",
      "10:39:29 [INFO]   Run 2/5\n",
      "10:39:31 [INFO]     2,623 labeled -> F1-Score: 0.1814 (Train: 0.6s, Query: 0.00s)\n",
      "10:39:32 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5482, F1: 0.1814\n",
      "10:39:32 [INFO]   Run 3/5\n",
      "10:39:33 [INFO]     2,623 labeled -> F1-Score: 0.1823 (Train: 0.6s, Query: 0.00s)\n",
      "10:39:34 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5488, F1: 0.1823\n",
      "10:39:34 [INFO]   Run 4/5\n",
      "10:39:36 [INFO]     2,623 labeled -> F1-Score: 0.1696 (Train: 0.7s, Query: 0.00s)\n",
      "10:39:37 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5451, F1: 0.1796\n",
      "10:39:37 [INFO]   Run 5/5\n",
      "10:39:39 [INFO]     2,623 labeled -> F1-Score: 0.1730 (Train: 0.7s, Query: 0.00s)\n",
      "10:39:40 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5451, F1: 0.1730\n",
      "10:39:40 [INFO] \n",
      "SVM + Random Sampling - Budget: 60% (3,935 Samples)\n",
      "10:39:40 [INFO]   Run 1/5\n",
      "10:39:44 [INFO]     3,935 labeled -> F1-Score: 0.1854 (Train: 1.2s, Query: 0.00s)\n",
      "10:39:45 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5494, F1: 0.1852\n",
      "10:39:45 [INFO]   Run 2/5\n",
      "10:39:50 [INFO]     3,935 labeled -> F1-Score: 0.1789 (Train: 1.2s, Query: 0.00s)\n",
      "10:39:51 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5518, F1: 0.1869\n",
      "10:39:51 [INFO]   Run 3/5\n",
      "10:39:55 [INFO]     3,935 labeled -> F1-Score: 0.1754 (Train: 1.2s, Query: 0.00s)\n",
      "10:39:57 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5445, F1: 0.1754\n",
      "10:39:57 [INFO]   Run 4/5\n",
      "10:40:01 [INFO]     3,935 labeled -> F1-Score: 0.1853 (Train: 1.2s, Query: 0.00s)\n",
      "10:40:03 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5488, F1: 0.1881\n",
      "10:40:03 [INFO]   Run 5/5\n",
      "10:40:07 [INFO]     3,935 labeled -> F1-Score: 0.1779 (Train: 1.2s, Query: 0.00s)\n",
      "10:40:09 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "10:40:09 [INFO] \n",
      "SVM + Random Sampling - Budget: 80% (5,247 Samples)\n",
      "10:40:09 [INFO]   Run 1/5\n",
      "10:40:19 [INFO]     5,247 labeled -> F1-Score: 0.1782 (Train: 2.4s, Query: 0.00s)\n",
      "10:40:22 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5463, F1: 0.1768\n",
      "10:40:22 [INFO]   Run 2/5\n",
      "10:40:33 [INFO]     5,247 labeled -> F1-Score: 0.1858 (Train: 2.4s, Query: 0.00s)\n",
      "10:40:35 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5506, F1: 0.1855\n",
      "10:40:35 [INFO]   Run 3/5\n",
      "10:40:46 [INFO]     5,247 labeled -> F1-Score: 0.1838 (Train: 2.4s, Query: 0.00s)\n",
      "10:40:49 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5488, F1: 0.1838\n",
      "10:40:49 [INFO]   Run 4/5\n",
      "10:41:00 [INFO]     5,247 labeled -> F1-Score: 0.1789 (Train: 2.5s, Query: 0.00s)\n",
      "10:41:02 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5488, F1: 0.1889\n",
      "10:41:02 [INFO]   Run 5/5\n",
      "10:41:13 [INFO]     5,247 labeled -> F1-Score: 0.1773 (Train: 2.4s, Query: 0.00s)\n",
      "10:41:16 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5476, F1: 0.1781\n",
      "10:41:16 [INFO] \n",
      "SVM + Random Sampling - Budget: 100% (6,559 Samples)\n",
      "10:41:16 [INFO]   Run 1/5\n",
      "10:41:33 [INFO]     6,559 labeled -> F1-Score: 0.1768 (Train: 3.4s, Query: 0.00s)\n",
      "10:41:38 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:41:38 [INFO]   Run 2/5\n",
      "10:41:55 [INFO]     6,559 labeled -> F1-Score: 0.1786 (Train: 3.4s, Query: 0.00s)\n",
      "10:41:59 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:41:59 [INFO]   Run 3/5\n",
      "10:42:16 [INFO]     6,559 labeled -> F1-Score: 0.1761 (Train: 3.4s, Query: 0.00s)\n",
      "10:42:21 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:42:21 [INFO]   Run 4/5\n",
      "10:42:38 [INFO]     6,559 labeled -> F1-Score: 0.1767 (Train: 3.4s, Query: 0.00s)\n",
      "10:42:42 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:42:42 [INFO]   Run 5/5\n",
      "10:43:00 [INFO]     6,559 labeled -> F1-Score: 0.1775 (Train: 3.4s, Query: 0.00s)\n",
      "10:43:04 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "\n",
      "[ok] SVM + Random Sampling abgeschlossen in 3.7 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 18/20: SVM + Entropy Sampling\n",
      "============================================================\n",
      "10:43:04 [INFO] \n",
      "SVM + Entropy Sampling - Budget: 20% (1,311 Samples)\n",
      "10:43:04 [INFO]   Run 1/5\n",
      "10:43:05 [INFO]     1,311 labeled -> F1-Score: 0.1897 (Train: 0.1s, Query: 0.17s)\n",
      "10:43:05 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5433, F1: 0.1809\n",
      "10:43:05 [INFO]   Run 2/5\n",
      "10:43:06 [INFO]     1,311 labeled -> F1-Score: 0.1386 (Train: 0.1s, Query: 0.17s)\n",
      "10:43:06 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4659, F1: 0.1477\n",
      "10:43:06 [INFO]   Run 3/5\n",
      "10:43:06 [INFO]     1,311 labeled -> F1-Score: 0.1578 (Train: 0.2s, Query: 0.19s)\n",
      "10:43:07 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5305, F1: 0.1719\n",
      "10:43:07 [INFO]   Run 4/5\n",
      "10:43:07 [INFO]     1,311 labeled -> F1-Score: 0.1622 (Train: 0.1s, Query: 0.18s)\n",
      "10:43:08 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5348, F1: 0.1604\n",
      "10:43:08 [INFO]   Run 5/5\n",
      "10:43:08 [INFO]     1,311 labeled -> F1-Score: 0.1401 (Train: 0.2s, Query: 0.18s)\n",
      "10:43:08 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5177, F1: 0.1414\n",
      "10:43:08 [INFO] \n",
      "SVM + Entropy Sampling - Budget: 40% (2,623 Samples)\n",
      "10:43:08 [INFO]   Run 1/5\n",
      "10:43:11 [INFO]     2,623 labeled -> F1-Score: 0.1781 (Train: 0.6s, Query: 0.28s)\n",
      "10:43:12 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5476, F1: 0.1781\n",
      "10:43:12 [INFO]   Run 2/5\n",
      "10:43:15 [INFO]     2,623 labeled -> F1-Score: 0.1617 (Train: 0.7s, Query: 0.27s)\n",
      "10:43:16 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5396, F1: 0.1617\n",
      "10:43:16 [INFO]   Run 3/5\n",
      "10:43:19 [INFO]     2,623 labeled -> F1-Score: 0.1738 (Train: 0.7s, Query: 0.29s)\n",
      "10:43:20 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5317, F1: 0.1671\n",
      "10:43:20 [INFO]   Run 4/5\n",
      "10:43:23 [INFO]     2,623 labeled -> F1-Score: 0.1732 (Train: 0.7s, Query: 0.28s)\n",
      "10:43:24 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5378, F1: 0.1769\n",
      "10:43:24 [INFO]   Run 5/5\n",
      "10:43:27 [INFO]     2,623 labeled -> F1-Score: 0.1645 (Train: 0.7s, Query: 0.30s)\n",
      "10:43:28 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4787, F1: 0.1870\n",
      "10:43:28 [INFO] \n",
      "SVM + Entropy Sampling - Budget: 60% (3,935 Samples)\n",
      "10:43:28 [INFO]   Run 1/5\n",
      "10:43:34 [INFO]     3,935 labeled -> F1-Score: 0.1796 (Train: 1.2s, Query: 0.26s)\n",
      "10:43:36 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5470, F1: 0.1772\n",
      "10:43:36 [INFO]   Run 2/5\n",
      "10:43:42 [INFO]     3,935 labeled -> F1-Score: 0.1781 (Train: 1.2s, Query: 0.28s)\n",
      "10:43:43 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5476, F1: 0.1782\n",
      "10:43:43 [INFO]   Run 3/5\n",
      "10:43:50 [INFO]     3,935 labeled -> F1-Score: 0.1788 (Train: 1.3s, Query: 0.30s)\n",
      "10:43:51 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5506, F1: 0.1943\n",
      "10:43:51 [INFO]   Run 4/5\n",
      "10:43:57 [INFO]     3,935 labeled -> F1-Score: 0.1759 (Train: 1.3s, Query: 0.29s)\n",
      "10:43:59 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1787\n",
      "10:43:59 [INFO]   Run 5/5\n",
      "10:44:06 [INFO]     3,935 labeled -> F1-Score: 0.1779 (Train: 1.3s, Query: 0.30s)\n",
      "10:44:08 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1769\n",
      "10:44:08 [INFO] \n",
      "SVM + Entropy Sampling - Budget: 80% (5,247 Samples)\n",
      "10:44:08 [INFO]   Run 1/5\n",
      "10:44:21 [INFO]     5,247 labeled -> F1-Score: 0.1773 (Train: 2.4s, Query: 0.19s)\n",
      "10:44:23 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "10:44:23 [INFO]   Run 2/5\n",
      "10:44:37 [INFO]     5,247 labeled -> F1-Score: 0.1861 (Train: 2.5s, Query: 0.19s)\n",
      "10:44:40 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5512, F1: 0.1861\n",
      "10:44:40 [INFO]   Run 3/5\n",
      "10:44:54 [INFO]     5,247 labeled -> F1-Score: 0.1773 (Train: 2.5s, Query: 0.19s)\n",
      "10:44:57 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "10:44:57 [INFO]   Run 4/5\n",
      "10:45:10 [INFO]     5,247 labeled -> F1-Score: 0.1782 (Train: 2.5s, Query: 0.19s)\n",
      "10:45:13 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "10:45:13 [INFO]   Run 5/5\n",
      "10:45:27 [INFO]     5,247 labeled -> F1-Score: 0.1861 (Train: 2.5s, Query: 0.19s)\n",
      "10:45:30 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5512, F1: 0.1861\n",
      "10:45:30 [INFO] \n",
      "SVM + Entropy Sampling - Budget: 100% (6,559 Samples)\n",
      "10:45:30 [INFO]   Run 1/5\n",
      "10:45:50 [INFO]     6,559 labeled -> F1-Score: 0.1861 (Train: 3.4s, Query: 0.07s)\n",
      "10:45:54 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:45:54 [INFO]   Run 2/5\n",
      "10:46:14 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 3.4s, Query: 0.07s)\n",
      "10:46:19 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:46:19 [INFO]   Run 3/5\n",
      "10:46:40 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 3.4s, Query: 0.07s)\n",
      "10:46:44 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:46:44 [INFO]   Run 4/5\n",
      "10:47:04 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 3.4s, Query: 0.07s)\n",
      "10:47:09 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:47:09 [INFO]   Run 5/5\n",
      "10:47:30 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 3.4s, Query: 0.07s)\n",
      "10:47:34 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "\n",
      "[ok] SVM + Entropy Sampling abgeschlossen in 4.5 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 19/20: SVM + Margin Sampling\n",
      "============================================================\n",
      "10:47:34 [INFO] \n",
      "SVM + Margin Sampling - Budget: 20% (1,311 Samples)\n",
      "10:47:34 [INFO]   Run 1/5\n",
      "10:47:34 [INFO]     1,311 labeled -> F1-Score: 0.1893 (Train: 0.1s, Query: 0.17s)\n",
      "10:47:35 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5409, F1: 0.1862\n",
      "10:47:35 [INFO]   Run 2/5\n",
      "10:47:35 [INFO]     1,311 labeled -> F1-Score: 0.1397 (Train: 0.1s, Query: 0.18s)\n",
      "10:47:36 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5360, F1: 0.1521\n",
      "10:47:36 [INFO]   Run 3/5\n",
      "10:47:36 [INFO]     1,311 labeled -> F1-Score: 0.1598 (Train: 0.2s, Query: 0.19s)\n",
      "10:47:36 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5354, F1: 0.1680\n",
      "10:47:36 [INFO]   Run 4/5\n",
      "10:47:37 [INFO]     1,311 labeled -> F1-Score: 0.1609 (Train: 0.1s, Query: 0.18s)\n",
      "10:47:37 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5390, F1: 0.1628\n",
      "10:47:37 [INFO]   Run 5/5\n",
      "10:47:38 [INFO]     1,311 labeled -> F1-Score: 0.1302 (Train: 0.1s, Query: 0.17s)\n",
      "10:47:38 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5085, F1: 0.1283\n",
      "10:47:38 [INFO] \n",
      "SVM + Margin Sampling - Budget: 40% (2,623 Samples)\n",
      "10:47:38 [INFO]   Run 1/5\n",
      "10:47:41 [INFO]     2,623 labeled -> F1-Score: 0.1665 (Train: 0.6s, Query: 0.27s)\n",
      "10:47:42 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5305, F1: 0.1664\n",
      "10:47:42 [INFO]   Run 2/5\n",
      "10:47:45 [INFO]     2,623 labeled -> F1-Score: 0.1780 (Train: 0.6s, Query: 0.28s)\n",
      "10:47:46 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5476, F1: 0.1780\n",
      "10:47:46 [INFO]   Run 3/5\n",
      "10:47:49 [INFO]     2,623 labeled -> F1-Score: 0.1749 (Train: 0.8s, Query: 0.30s)\n",
      "10:47:50 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5433, F1: 0.1756\n",
      "10:47:50 [INFO]   Run 4/5\n",
      "10:47:53 [INFO]     2,623 labeled -> F1-Score: 0.1742 (Train: 0.7s, Query: 0.28s)\n",
      "10:47:54 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5482, F1: 0.1768\n",
      "10:47:54 [INFO]   Run 5/5\n",
      "10:47:57 [INFO]     2,623 labeled -> F1-Score: 0.1717 (Train: 0.8s, Query: 0.31s)\n",
      "10:47:58 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4866, F1: 0.1560\n",
      "10:47:58 [INFO] \n",
      "SVM + Margin Sampling - Budget: 60% (3,935 Samples)\n",
      "10:47:58 [INFO]   Run 1/5\n",
      "10:48:04 [INFO]     3,935 labeled -> F1-Score: 0.1753 (Train: 1.2s, Query: 0.26s)\n",
      "10:48:06 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5445, F1: 0.1659\n",
      "10:48:06 [INFO]   Run 2/5\n",
      "10:48:11 [INFO]     3,935 labeled -> F1-Score: 0.1791 (Train: 1.2s, Query: 0.27s)\n",
      "10:48:13 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5524, F1: 0.1877\n",
      "10:48:13 [INFO]   Run 3/5\n",
      "10:48:20 [INFO]     3,935 labeled -> F1-Score: 0.1849 (Train: 1.3s, Query: 0.29s)\n",
      "10:48:21 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5500, F1: 0.1834\n",
      "10:48:21 [INFO]   Run 4/5\n",
      "10:48:28 [INFO]     3,935 labeled -> F1-Score: 0.1796 (Train: 1.3s, Query: 0.30s)\n",
      "10:48:29 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5470, F1: 0.1772\n",
      "10:48:29 [INFO]   Run 5/5\n",
      "10:48:36 [INFO]     3,935 labeled -> F1-Score: 0.1590 (Train: 1.3s, Query: 0.29s)\n",
      "10:48:38 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5415, F1: 0.1644\n",
      "10:48:38 [INFO] \n",
      "SVM + Margin Sampling - Budget: 80% (5,247 Samples)\n",
      "10:48:38 [INFO]   Run 1/5\n",
      "10:48:50 [INFO]     5,247 labeled -> F1-Score: 0.1642 (Train: 2.3s, Query: 0.17s)\n",
      "10:48:53 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5427, F1: 0.1642\n",
      "10:48:53 [INFO]   Run 2/5\n",
      "10:49:06 [INFO]     5,247 labeled -> F1-Score: 0.1782 (Train: 2.4s, Query: 0.19s)\n",
      "10:49:09 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "10:49:09 [INFO]   Run 3/5\n",
      "10:49:23 [INFO]     5,247 labeled -> F1-Score: 0.1835 (Train: 2.4s, Query: 0.19s)\n",
      "10:49:26 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5451, F1: 0.1851\n",
      "10:49:26 [INFO]   Run 4/5\n",
      "10:49:39 [INFO]     5,247 labeled -> F1-Score: 0.1861 (Train: 2.5s, Query: 0.19s)\n",
      "10:49:42 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "10:49:42 [INFO]   Run 5/5\n",
      "10:49:57 [INFO]     5,247 labeled -> F1-Score: 0.1774 (Train: 2.5s, Query: 0.19s)\n",
      "10:49:59 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:49:59 [INFO] \n",
      "SVM + Margin Sampling - Budget: 100% (6,559 Samples)\n",
      "10:49:59 [INFO]   Run 1/5\n",
      "10:50:19 [INFO]     6,559 labeled -> F1-Score: 0.1642 (Train: 3.4s, Query: 0.07s)\n",
      "10:50:23 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:50:23 [INFO]   Run 2/5\n",
      "10:50:43 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 3.4s, Query: 0.07s)\n",
      "10:50:47 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:50:47 [INFO]   Run 3/5\n",
      "10:51:08 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 3.4s, Query: 0.07s)\n",
      "10:51:12 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:51:12 [INFO]   Run 4/5\n",
      "10:51:33 [INFO]     6,559 labeled -> F1-Score: 0.1774 (Train: 3.4s, Query: 0.07s)\n",
      "10:51:37 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:51:37 [INFO]   Run 5/5\n",
      "10:51:59 [INFO]     6,559 labeled -> F1-Score: 0.1768 (Train: 3.5s, Query: 0.07s)\n",
      "10:52:03 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "\n",
      "[ok] SVM + Margin Sampling abgeschlossen in 4.5 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 20/20: SVM + Least Confidence\n",
      "============================================================\n",
      "10:52:03 [INFO] \n",
      "SVM + Least Confidence - Budget: 20% (1,311 Samples)\n",
      "10:52:03 [INFO]   Run 1/5\n",
      "10:52:03 [INFO]     1,311 labeled -> F1-Score: 0.1831 (Train: 0.1s, Query: 0.17s)\n",
      "10:52:04 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5384, F1: 0.1843\n",
      "10:52:04 [INFO]   Run 2/5\n",
      "10:52:04 [INFO]     1,311 labeled -> F1-Score: 0.1387 (Train: 0.1s, Query: 0.17s)\n",
      "10:52:04 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5421, F1: 0.1598\n",
      "10:52:04 [INFO]   Run 3/5\n",
      "10:52:05 [INFO]     1,311 labeled -> F1-Score: 0.1851 (Train: 0.2s, Query: 0.19s)\n",
      "10:52:05 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5317, F1: 0.1766\n",
      "10:52:05 [INFO]   Run 4/5\n",
      "10:52:06 [INFO]     1,311 labeled -> F1-Score: 0.1681 (Train: 0.1s, Query: 0.18s)\n",
      "10:52:06 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5293, F1: 0.1575\n",
      "10:52:06 [INFO]   Run 5/5\n",
      "10:52:07 [INFO]     1,311 labeled -> F1-Score: 0.1552 (Train: 0.2s, Query: 0.18s)\n",
      "10:52:07 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5152, F1: 0.1373\n",
      "10:52:07 [INFO] \n",
      "SVM + Least Confidence - Budget: 40% (2,623 Samples)\n",
      "10:52:07 [INFO]   Run 1/5\n",
      "10:52:10 [INFO]     2,623 labeled -> F1-Score: 0.1774 (Train: 0.6s, Query: 0.29s)\n",
      "10:52:11 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5445, F1: 0.1773\n",
      "10:52:11 [INFO]   Run 2/5\n",
      "10:52:14 [INFO]     2,623 labeled -> F1-Score: 0.1498 (Train: 0.6s, Query: 0.27s)\n",
      "10:52:15 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5341, F1: 0.1531\n",
      "10:52:15 [INFO]   Run 3/5\n",
      "10:52:18 [INFO]     2,623 labeled -> F1-Score: 0.1863 (Train: 0.7s, Query: 0.28s)\n",
      "10:52:19 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5427, F1: 0.1738\n",
      "10:52:19 [INFO]   Run 4/5\n",
      "10:52:22 [INFO]     2,623 labeled -> F1-Score: 0.1624 (Train: 0.6s, Query: 0.27s)\n",
      "10:52:23 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5390, F1: 0.1669\n",
      "10:52:23 [INFO]   Run 5/5\n",
      "10:52:26 [INFO]     2,623 labeled -> F1-Score: 0.1701 (Train: 0.7s, Query: 0.29s)\n",
      "10:52:27 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4963, F1: 0.1677\n",
      "10:52:27 [INFO] \n",
      "SVM + Least Confidence - Budget: 60% (3,935 Samples)\n",
      "10:52:27 [INFO]   Run 1/5\n",
      "10:52:33 [INFO]     3,935 labeled -> F1-Score: 0.1777 (Train: 1.1s, Query: 0.27s)\n",
      "10:52:34 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5470, F1: 0.1863\n",
      "10:52:34 [INFO]   Run 2/5\n",
      "10:52:40 [INFO]     3,935 labeled -> F1-Score: 0.1790 (Train: 1.2s, Query: 0.27s)\n",
      "10:52:42 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1790\n",
      "10:52:42 [INFO]   Run 3/5\n",
      "10:52:48 [INFO]     3,935 labeled -> F1-Score: 0.1852 (Train: 1.3s, Query: 0.29s)\n",
      "10:52:50 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5463, F1: 0.1746\n",
      "10:52:50 [INFO]   Run 4/5\n",
      "10:52:56 [INFO]     3,935 labeled -> F1-Score: 0.1804 (Train: 1.2s, Query: 0.28s)\n",
      "10:52:57 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5488, F1: 0.1796\n",
      "10:52:57 [INFO]   Run 5/5\n",
      "10:53:04 [INFO]     3,935 labeled -> F1-Score: 0.1749 (Train: 1.3s, Query: 0.29s)\n",
      "10:53:06 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5463, F1: 0.1777\n",
      "10:53:06 [INFO] \n",
      "SVM + Least Confidence - Budget: 80% (5,247 Samples)\n",
      "10:53:06 [INFO]   Run 1/5\n",
      "10:53:18 [INFO]     5,247 labeled -> F1-Score: 0.1861 (Train: 2.4s, Query: 0.19s)\n",
      "10:53:21 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5512, F1: 0.1861\n",
      "10:53:21 [INFO]   Run 2/5\n",
      "10:53:34 [INFO]     5,247 labeled -> F1-Score: 0.1782 (Train: 2.3s, Query: 0.18s)\n",
      "10:53:37 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "10:53:37 [INFO]   Run 3/5\n",
      "10:53:51 [INFO]     5,247 labeled -> F1-Score: 0.1773 (Train: 2.5s, Query: 0.19s)\n",
      "10:53:53 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "10:53:53 [INFO]   Run 4/5\n",
      "10:54:07 [INFO]     5,247 labeled -> F1-Score: 0.1782 (Train: 2.5s, Query: 0.19s)\n",
      "10:54:10 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5512, F1: 0.1861\n",
      "10:54:10 [INFO]   Run 5/5\n",
      "10:54:24 [INFO]     5,247 labeled -> F1-Score: 0.1782 (Train: 2.5s, Query: 0.19s)\n",
      "10:54:27 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "10:54:27 [INFO] \n",
      "SVM + Least Confidence - Budget: 100% (6,559 Samples)\n",
      "10:54:27 [INFO]   Run 1/5\n",
      "10:54:47 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 3.4s, Query: 0.07s)\n",
      "10:54:51 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:54:51 [INFO]   Run 2/5\n",
      "10:55:10 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 3.4s, Query: 0.07s)\n",
      "10:55:15 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:55:15 [INFO]   Run 3/5\n",
      "10:55:36 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 3.4s, Query: 0.07s)\n",
      "10:55:40 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:55:40 [INFO]   Run 4/5\n",
      "10:56:00 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 3.4s, Query: 0.07s)\n",
      "10:56:04 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "10:56:04 [INFO]   Run 5/5\n",
      "10:56:25 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 3.4s, Query: 0.07s)\n",
      "10:56:30 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "\n",
      "[ok] SVM + Least Confidence abgeschlossen in 4.4 Minuten\n",
      "\n",
      "[ok] Alle Experimente abgeschlossen in 42.3 Minuten\n",
      "\n",
      "============================================================\n",
      "Führe statistische Analyse durch (F1-Score)...\n",
      "============================================================\n",
      "\n",
      "====================================================================================================\n",
      "DETAILLIERTER STATISTISCHER BERICHT - DACHMATERIAL (F1-SCORE)\n",
      "====================================================================================================\n",
      "Primäre Metrik: F1-Score (Macro Average)\n",
      "Signifikanzniveau: 0.05 (mit Bonferroni-Korrektur)\n",
      "Anzahl Runs pro Experiment: 5\n",
      "Statistischer Test: Wilcoxon Signed-Rank Test\n",
      "Effektstärkemaß: Cliff's Delta\n",
      "\n",
      "\n",
      "Keine signifikanten F1-Score Verbesserungen gefunden!\n",
      "\n",
      "\n",
      "ZUSAMMENFASSUNG NACH STRATEGIE (F1-SCORE):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Entropy Sampling:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/25 (0.0%)\n",
      "  - Durchschnittliche F1-Score Verbesserung: 10.16%\n",
      "  - Durchschnittliche Effektstärke: 0.182\n",
      "\n",
      "Margin Sampling:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/25 (0.0%)\n",
      "  - Durchschnittliche F1-Score Verbesserung: 12.98%\n",
      "  - Durchschnittliche Effektstärke: 0.208\n",
      "\n",
      "Least Confidence:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/25 (0.0%)\n",
      "  - Durchschnittliche F1-Score Verbesserung: 11.95%\n",
      "  - Durchschnittliche Effektstärke: 0.218\n",
      "\n",
      "\n",
      "ZUSAMMENFASSUNG NACH KLASSIFIKATOR (F1-SCORE):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "Naive Bayes:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "Random Forest:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "Logistic Regression:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "SVM:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "====================================================================================================\n",
      "10:56:30 [INFO] [ok] Statistischer F1-Score Bericht gespeichert: reports/dachmaterial_f1_statistischer_bericht.txt\n",
      "\n",
      "============================================================\n",
      "Berechne Label-Einsparungen (F1-Score basiert)...\n",
      "============================================================\n",
      "10:56:31 [INFO] [ok] Deutsche F1-Score basierte Label-Einsparungsanalyse erstellt: plots/dachmaterial_f1_label_einsparungen_de.png\n",
      "\n",
      "================================================================================\n",
      "LABEL-EINSPARUNGS-BERICHT - Dachmaterial (F1-SCORE BASIERT)\n",
      "================================================================================\n",
      "\n",
      "ZIEL: 90% der Baseline F1-Score Performance\n",
      "------------------------------------------------------------\n",
      "\n",
      "Logistic Regression:\n",
      "  Baseline F1-Score (Random 100%): 0.1883\n",
      "  Ziel F1-Score: 0.1694\n",
      "  Labels benötigt:\n",
      "    - Least Confidence    :    400 ±  244 ( 93.9% gespart)\n",
      "      -> 20.0% weniger Labels als Random Sampling\n",
      "    - Margin Sampling     :    400 ±  244 ( 93.9% gespart)\n",
      "      -> 20.0% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :    500 ±  374 ( 92.4% gespart)\n",
      "    - Entropy Sampling    :    958 ± 1425 ( 85.4% gespart)\n",
      "\n",
      "Naive Bayes:\n",
      "  Baseline F1-Score (Random 100%): 0.0289\n",
      "  Ziel F1-Score: 0.0260\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Entropy Sampling    :    100 ±    0 ( 98.5% gespart)\n",
      "    - Margin Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Least Confidence    :    100 ±    0 ( 98.5% gespart)\n",
      "\n",
      "Neural Network:\n",
      "  Baseline F1-Score (Random 100%): 0.1761\n",
      "  Ziel F1-Score: 0.1585\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  1,398 ± 1069 ( 78.7% gespart)\n",
      "    - Margin Sampling     :  1,398 ± 1069 ( 78.7% gespart)\n",
      "    - Entropy Sampling    :  1,696 ± 1451 ( 74.1% gespart)\n",
      "    - Least Confidence    :  2,293 ± 1871 ( 65.0% gespart)\n",
      "\n",
      "Random Forest:\n",
      "  Baseline F1-Score (Random 100%): 0.2315\n",
      "  Ziel F1-Score: 0.2084\n",
      "  Labels benötigt:\n",
      "    - Margin Sampling     :    700 ±  200 ( 89.3% gespart)\n",
      "      -> 22.2% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :    900 ±  244 ( 86.3% gespart)\n",
      "    - Entropy Sampling    :  1,198 ± 1149 ( 81.7% gespart)\n",
      "    - Least Confidence    :  1,556 ± 1589 ( 76.3% gespart)\n",
      "\n",
      "SVM:\n",
      "  Baseline F1-Score (Random 100%): 0.1774\n",
      "  Ziel F1-Score: 0.1597\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  1,676 ± 1517 ( 74.4% gespart)\n",
      "    - Least Confidence    :  1,696 ± 1451 ( 74.1% gespart)\n",
      "    - Entropy Sampling    :  1,756 ± 1524 ( 73.2% gespart)\n",
      "    - Margin Sampling     :  1,756 ± 1550 ( 73.2% gespart)\n",
      "\n",
      "ZIEL: 95% der Baseline F1-Score Performance\n",
      "------------------------------------------------------------\n",
      "\n",
      "Logistic Regression:\n",
      "  Baseline F1-Score (Random 100%): 0.1883\n",
      "  Ziel F1-Score: 0.1788\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    998 ± 1233 ( 84.8% gespart)\n",
      "    - Margin Sampling     :  1,456 ± 1719 ( 77.8% gespart)\n",
      "    - Least Confidence    :  1,456 ± 1696 ( 77.8% gespart)\n",
      "    - Entropy Sampling    :  1,535 ± 2171 ( 76.6% gespart)\n",
      "\n",
      "Naive Bayes:\n",
      "  Baseline F1-Score (Random 100%): 0.0289\n",
      "  Ziel F1-Score: 0.0275\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Entropy Sampling    :    100 ±    0 ( 98.5% gespart)\n",
      "    - Margin Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Least Confidence    :    100 ±    0 ( 98.5% gespart)\n",
      "\n",
      "Neural Network:\n",
      "  Baseline F1-Score (Random 100%): 0.1761\n",
      "  Ziel F1-Score: 0.1673\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  1,696 ± 1451 ( 74.1% gespart)\n",
      "    - Margin Sampling     :  2,155 ± 1703 ( 67.1% gespart)\n",
      "    - Entropy Sampling    :  2,453 ± 1826 ( 62.6% gespart)\n",
      "    - Least Confidence    :  2,831 ± 1876 ( 56.8% gespart)\n",
      "\n",
      "Random Forest:\n",
      "  Baseline F1-Score (Random 100%): 0.2315\n",
      "  Ziel F1-Score: 0.2199\n",
      "  Labels benötigt:\n",
      "    - Margin Sampling     :  1,656 ± 1579 ( 74.7% gespart)\n",
      "      -> 42.3% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :  2,870 ± 2463 ( 56.2% gespart)\n",
      "    - Least Confidence    :  2,911 ± 2203 ( 55.6% gespart)\n",
      "    - Entropy Sampling    :  3,030 ± 2244 ( 53.8% gespart)\n",
      "\n",
      "SVM:\n",
      "  Baseline F1-Score (Random 100%): 0.1774\n",
      "  Ziel F1-Score: 0.1686\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  2,453 ± 1826 ( 62.6% gespart)\n",
      "    - Least Confidence    :  2,453 ± 1901 ( 62.6% gespart)\n",
      "    - Margin Sampling     :  2,613 ± 1810 ( 60.2% gespart)\n",
      "    - Entropy Sampling    :  2,871 ± 2112 ( 56.2% gespart)\n",
      "\n",
      "ZIEL: 98% der Baseline F1-Score Performance\n",
      "------------------------------------------------------------\n",
      "\n",
      "Logistic Regression:\n",
      "  Baseline F1-Score (Random 100%): 0.1883\n",
      "  Ziel F1-Score: 0.1845\n",
      "  Labels benötigt:\n",
      "    - Least Confidence    :  1,636 ± 1663 ( 75.0% gespart)\n",
      "      -> 46.4% weniger Labels als Random Sampling\n",
      "    - Margin Sampling     :  2,135 ± 1764 ( 67.4% gespart)\n",
      "      -> 30.0% weniger Labels als Random Sampling\n",
      "    - Entropy Sampling    :  2,670 ± 2614 ( 59.3% gespart)\n",
      "      -> 12.5% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :  3,051 ± 1892 ( 53.5% gespart)\n",
      "\n",
      "Naive Bayes:\n",
      "  Baseline F1-Score (Random 100%): 0.0289\n",
      "  Ziel F1-Score: 0.0283\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Entropy Sampling    :    100 ±    0 ( 98.5% gespart)\n",
      "    - Margin Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Least Confidence    :    100 ±    0 ( 98.5% gespart)\n",
      "\n",
      "Neural Network:\n",
      "  Baseline F1-Score (Random 100%): 0.1761\n",
      "  Ziel F1-Score: 0.1726\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  1,696 ± 1451 ( 74.1% gespart)\n",
      "    - Margin Sampling     :  2,453 ± 1848 ( 62.6% gespart)\n",
      "    - Entropy Sampling    :  2,751 ± 1916 ( 58.0% gespart)\n",
      "    - Least Confidence    :  2,991 ± 1827 ( 54.4% gespart)\n",
      "\n",
      "Random Forest:\n",
      "  Baseline F1-Score (Random 100%): 0.2315\n",
      "  Ziel F1-Score: 0.2269\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  2,988 ± 2572 ( 54.4% gespart)\n",
      "    - Margin Sampling     :  3,150 ± 2217 ( 52.0% gespart)\n",
      "    - Entropy Sampling    :  3,466 ± 2429 ( 47.1% gespart)\n",
      "    - Least Confidence    :  3,548 ± 2304 ( 45.9% gespart)\n",
      "\n",
      "SVM:\n",
      "  Baseline F1-Score (Random 100%): 0.1774\n",
      "  Ziel F1-Score: 0.1739\n",
      "  Labels benötigt:\n",
      "    - Margin Sampling     :  2,773 ± 1734 ( 57.7% gespart)\n",
      "      -> 15.2% weniger Labels als Random Sampling\n",
      "    - Least Confidence    :  2,831 ± 2020 ( 56.8% gespart)\n",
      "      -> 13.4% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :  3,270 ± 1947 ( 50.1% gespart)\n",
      "    - Entropy Sampling    :  3,866 ± 2017 ( 41.0% gespart)\n",
      "\n",
      "\n",
      "BESTE STRATEGIEN (bei 95% F1-Score Performance):\n",
      "------------------------------------------------------------\n",
      "Logistic Regression: Random Sampling (nur 998 Labels = 84.8% Einsparung)\n",
      "Naive Bayes: Random Sampling (nur 100 Labels = 98.5% Einsparung)\n",
      "Neural Network: Random Sampling (nur 1,696 Labels = 74.1% Einsparung)\n",
      "Random Forest: Margin Sampling (nur 1,656 Labels = 74.7% Einsparung)\n",
      "SVM: Random Sampling (nur 2,453 Labels = 62.6% Einsparung)\n",
      "\n",
      "\n",
      "DURCHSCHNITTLICHE EINSPARUNGEN ÜBER ALLE KLASSIFIKATOREN:\n",
      "------------------------------------------------------------\n",
      "Entropy Sampling: -24.2% weniger Labels als Random Sampling\n",
      "Least Confidence: -22.9% weniger Labels als Random Sampling\n",
      "Margin Sampling: -7.4% weniger Labels als Random Sampling\n",
      "\n",
      "================================================================================\n",
      "10:56:31 [INFO] [ok] F1-Score basierter Label-Einsparungsbericht gespeichert: reports/dachmaterial_f1_label_einsparungsbericht.txt\n",
      "[ok] F1-Score basierte Label-Einsparungen gespeichert: results/dachmaterial_f1_label_einsparungen.csv\n",
      "\n",
      "============================================================\n",
      "Erstelle Visualisierungen (F1-Score basiert, deutsche Beschriftungen)...\n",
      "============================================================\n",
      "10:56:31 [INFO] [ok] Deutsche Visualisierung mit F1-Score und Signifikanz für Logistic Regression erstellt: plots/dachmaterial_logistic_regression_f1_signifikanz_de.png\n",
      "10:56:32 [INFO] [ok] Deutsche Visualisierung mit F1-Score und Signifikanz für Naive Bayes erstellt: plots/dachmaterial_naive_bayes_f1_signifikanz_de.png\n",
      "10:56:32 [INFO] [ok] Deutsche Visualisierung mit F1-Score und Signifikanz für Neural Network erstellt: plots/dachmaterial_neural_network_f1_signifikanz_de.png\n",
      "10:56:33 [INFO] [ok] Deutsche Visualisierung mit F1-Score und Signifikanz für Random Forest erstellt: plots/dachmaterial_random_forest_f1_signifikanz_de.png\n",
      "10:56:33 [INFO] [ok] Deutsche Visualisierung mit F1-Score und Signifikanz für SVM erstellt: plots/dachmaterial_svm_f1_signifikanz_de.png\n",
      "10:56:33 [WARNING] Keine signifikanten Ergebnisse gefunden!\n",
      "10:56:34 [INFO] [ok] Statistische F1-Score Zusammenfassung (deutsch) erstellt: plots/dachmaterial_f1_statistische_zusammenfassung_de.png\n",
      "10:56:35 [INFO] [ok] Finale deutsche F1-Score Vergleichsvisualisierung erstellt: plots/dachmaterial_f1_finaler_vergleich_de.png\n",
      "\n",
      "============================================================\n",
      "BESTE KOMBINATION BEI 100% BUDGET (F1-SCORE):\n",
      "============================================================\n",
      "Klassifikator: Random Forest\n",
      "Query-Strategie: Entropie-basiert\n",
      "Test F1-Score: 0.2317 (±0.0039)\n",
      "Test Genauigkeit: 0.4716 (±0.0012)\n",
      "============================================================\n",
      "\n",
      "TOP 5 KOMBINATIONEN (F1-SCORE):\n",
      "------------------------------------------------------------\n",
      "1. Random Forest + Entropie-basiert: F1=0.2317, Genauigkeit=0.4716\n",
      "2. Random Forest + Zufällige Auswahl: F1=0.2315, Genauigkeit=0.4713\n",
      "3. Random Forest + Margin-basiert: F1=0.2303, Genauigkeit=0.4711\n",
      "4. Random Forest + Geringste Konfidenz: F1=0.2285, Genauigkeit=0.4710\n",
      "5. Logistic Regression + Zufällige Auswahl: F1=0.1883, Genauigkeit=0.5396\n",
      "10:56:35 [INFO] [ok] Deutsche F1-Score Verbesserungsanalyse erstellt: plots/dachmaterial_f1_verbesserungsanalyse_de.png\n",
      "[ok] Alle deutschen F1-Score basierten Visualisierungen mit adaptiver Skalierung erstellt\n",
      "\n",
      "[ok] F1-Score Ergebnisse gespeichert in: results/dachmaterial_f1_active_learning_ergebnisse.csv\n",
      "[ok] Statistische F1-Score Analyse gespeichert in: results/dachmaterial_f1_statistische_analyse.csv\n",
      "[ok] F1-Score Zusammenfassung gespeichert in: results/dachmaterial_f1_active_learning_zusammenfassung.xlsx\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT ERFOLGREICH ABGESCHLOSSEN (F1-SCORE VERSION MIT DEUTSCHEN PLOTS)\n",
      "Hauptmetrik: F1-Score (Macro Average)\n",
      "Gesamtanzahl Experimente: 500\n",
      "Datensatzgröße: 6,559 Trainingssamples\n",
      "Klassifikatoren: 5\n",
      "Query-Strategien: 4\n",
      "Budget-Stufen: 5\n",
      "Wiederholungen pro Experiment: 5\n",
      "\n",
      "Statistische Analyse (F1-Score):\n",
      "- Anzahl Vergleiche: 75\n",
      "- Signifikante F1-Score Verbesserungen: 0 (0.0%)\n",
      "- Verwendeter Test: Wilcoxon Signed-Rank Test\n",
      "- Effektstärkemaß: Cliff's Delta\n",
      "- Multiple Vergleiche: Bonferroni-Korrektur\n",
      "\n",
      "F1-Score basierte Label-Einsparungsanalyse durchgeführt!\n",
      "- Visualisierung: plots/dachmaterial_f1_label_einsparungen_de.png\n",
      "- Bericht: reports/dachmaterial_f1_label_einsparungsbericht.txt\n",
      "\n",
      "Alle Visualisierungen verwenden deutsche Beschriftungen und adaptive Skalierung!\n",
      "================================================================================\n",
      "\n",
      "Programm beendet mit Exit-Code: 0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Active Learning für Dachmaterial-Klassifikation mit F1-Score\n",
    "# \n",
    "# ## Robuste Version mit statistischer Analyse für unausgewogene Datensätze\n",
    "# \n",
    "# Dieses Notebook implementiert Active Learning Experimente für die Klassifikation von Dachmaterialien. \n",
    "# Da der Datensatz sehr unausgewogen ist, verwenden wir den **F1-Score (Macro)** als Hauptmetrik anstatt der Accuracy.\n",
    "# \n",
    "# ### Features:\n",
    "# - Verwendet den kompletten Dachmaterial-Datensatz\n",
    "# - F1-Score als primäre Evaluationsmetrik\n",
    "# - Statistische Analyse mit Wilcoxon Signed-Rank Test\n",
    "# - Cliff's Delta für Effektstärken\n",
    "# - Label-Einsparungs-Analyse\n",
    "# - Deutsche Plot-Beschriftungen\n",
    "# - Adaptive Skalierung für bessere Sichtbarkeit\n",
    "\n",
    "# ## 1. Import und Setup\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Matplotlib Backend setzen bevor pyplot importiert wird\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Für Server ohne GUI\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn mit Fehlerbehandlung\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    # Prüfe ob der Style verfügbar ist\n",
    "    try:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    except:\n",
    "        try:\n",
    "            plt.style.use('seaborn-whitegrid')\n",
    "        except:\n",
    "            plt.style.use('ggplot')\n",
    "except ImportError:\n",
    "    print(\"Warnung: Seaborn nicht installiert. Verwende Standard-Matplotlib.\")\n",
    "    sns = None\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import sklearn\n",
    "\n",
    "# Statistische Tests\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "import itertools\n",
    "\n",
    "# Excel-Export\n",
    "try:\n",
    "    import openpyxl\n",
    "    EXCEL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warnung: openpyxl nicht installiert. Excel-Export wird deaktiviert.\")\n",
    "    EXCEL_AVAILABLE = False\n",
    "\n",
    "# SSL-Fehler beim Download verhindern\n",
    "import ssl\n",
    "try:\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ## 2. Konfiguration und Reproduzierbarkeit\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Reproduzierbarkeit\n",
    "# -------------------------------------------------------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Konfiguration\n",
    "# -------------------------------------------------------------------------------\n",
    "BUDGET_PERCENTAGES = [0.2, 0.4, 0.6, 0.8, 1.0]  # 20%, 40%, 60%, 80%, 100%\n",
    "BATCH_SIZE = 500  # Größere Batches für effizienteres Training\n",
    "N_RUNS = 5  # Erhöht von 3 auf 5 für bessere statistische Aussagekraft\n",
    "INITIAL_PERCENTAGE = 0.01  # 1% initial labeling\n",
    "SIGNIFICANCE_LEVEL = 0.05  # Für statistische Tests\n",
    "MIN_SAMPLES_PER_CLASS = 20  # Mindestanzahl Samples pro Klasse\n",
    "\n",
    "# Dachmaterial Klassen (wird dynamisch geladen)\n",
    "DACHMATERIAL_CLASSES = []\n",
    "\n",
    "# Erstelle Output-Verzeichnisse\n",
    "output_dirs = [\"plots\", \"results\", \"reports\"]\n",
    "for dir_name in output_dirs:\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Logging konfigurieren mit UTF-8 Encoding\n",
    "# -------------------------------------------------------------------------------\n",
    "# Erstelle Log-Verzeichnis\n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Logging Setup mit UTF-8 Encoding für Windows\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            os.path.join(log_dir, f\"dachmaterial_active_learning_{time.strftime('%Y%m%d_%H%M%S')}.log\"),\n",
    "            encoding='utf-8'\n",
    "        ),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set encoding for stdout to handle Unicode - nur wenn möglich\n",
    "if sys.platform == 'win32':\n",
    "    # Prüfe ob wir in einer Jupyter/IPython Umgebung sind\n",
    "    try:\n",
    "        get_ipython()\n",
    "        # In Jupyter/IPython - keine Änderung nötig\n",
    "        logger.info(\"Jupyter/IPython Umgebung erkannt - UTF-8 Handling bereits aktiv\")\n",
    "    except NameError:\n",
    "        # Normales Python - versuche UTF-8 zu setzen\n",
    "        try:\n",
    "            import io\n",
    "            if hasattr(sys.stdout, 'buffer'):\n",
    "                sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
    "                sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Konnte UTF-8 Encoding nicht setzen: {e}\")\n",
    "\n",
    "# ## 3. Daten laden und vorbereiten\n",
    "\n",
    "def load_dachmaterial_data(filepath='umrisse_with_all_data_and_shape_and_patch_and_normal.csv'):\n",
    "    \"\"\"\n",
    "    Lädt den VOLLSTÄNDIGEN Dachmaterial-Datensatz.\n",
    "    Filtert Klassen mit zu wenigen Samples aus.\n",
    "    Gibt auch den Preprocessor zurück für konsistente Transformation.\n",
    "    \"\"\"\n",
    "    logger.info(\"Lade vollständigen Dachmaterial-Datensatz...\")\n",
    "    \n",
    "    try:\n",
    "        # Daten laden\n",
    "        df = pd.read_csv(filepath)\n",
    "        logger.info(f\"[ok] Datensatz geladen: {len(df):,} Zeilen, {len(df.columns)} Spalten\")\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Datei '{filepath}' nicht gefunden!\")\n",
    "        logger.error(\"Bitte stellen Sie sicher, dass die CSV-Datei im aktuellen Verzeichnis liegt.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Laden der Daten: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Zielvariable und Features definieren\n",
    "    target_col = 'mat_qgis'\n",
    "    feature_cols = ['area', 'area_type', 'Shape', 'ezg']\n",
    "    \n",
    "    # Nur Zeilen mit gültiger Zielvariable behalten\n",
    "    df = df[df[target_col].notna()].copy()\n",
    "    \n",
    "    # Klassen-Verteilung anzeigen\n",
    "    class_dist = df[target_col].value_counts()\n",
    "    logger.info(f\"Ursprüngliche Klassen-Verteilung:\\n{class_dist}\")\n",
    "    \n",
    "    # Filtere Klassen mit zu wenigen Samples\n",
    "    valid_classes = class_dist[class_dist >= MIN_SAMPLES_PER_CLASS].index.tolist()\n",
    "    removed_classes = class_dist[class_dist < MIN_SAMPLES_PER_CLASS].index.tolist()\n",
    "    \n",
    "    if removed_classes:\n",
    "        logger.warning(f\"Entferne Klassen mit weniger als {MIN_SAMPLES_PER_CLASS} Samples:\")\n",
    "        for cls in removed_classes:\n",
    "            logger.warning(f\"  - {cls}: {class_dist[cls]} Samples\")\n",
    "    \n",
    "    # Behalte nur Samples der gültigen Klassen\n",
    "    df = df[df[target_col].isin(valid_classes)].copy()\n",
    "    \n",
    "    # Aktualisierte Klassen-Verteilung\n",
    "    class_dist_filtered = df[target_col].value_counts()\n",
    "    logger.info(f\"Gefilterte Klassen-Verteilung:\\n{class_dist_filtered}\")\n",
    "    \n",
    "    # Features und Target trennen\n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[target_col].copy()\n",
    "    \n",
    "    # Label Encoding für Target\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Dachmaterial-Klassen speichern\n",
    "    global DACHMATERIAL_CLASSES\n",
    "    DACHMATERIAL_CLASSES = list(label_encoder.classes_)\n",
    "    \n",
    "    logger.info(f\"[ok] Dachmaterial-Datensatz vorbereitet: {len(X):,} Samples\")\n",
    "    logger.info(f\"  Klassen: {len(DACHMATERIAL_CLASSES)} - {', '.join(DACHMATERIAL_CLASSES)}\")\n",
    "    \n",
    "    # Feature-Typen analysieren\n",
    "    numeric_features = ['area']\n",
    "    categorical_features = ['area_type', 'Shape', 'ezg']\n",
    "    \n",
    "    # Preprocessing Pipeline erstellen\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Robuster Train/Test Split\n",
    "    # Verwende StratifiedShuffleSplit für bessere Kontrolle\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "    train_idx, test_idx = next(splitter.split(X, y_encoded))\n",
    "    \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_test = X.iloc[test_idx]\n",
    "    y_train = y_encoded[train_idx]\n",
    "    y_test = y_encoded[test_idx]\n",
    "    \n",
    "    # Preprocessing\n",
    "    X_train_processed = preprocessor.fit_transform(X_train).astype(np.float32)\n",
    "    X_test_processed = preprocessor.transform(X_test).astype(np.float32)\n",
    "    \n",
    "    # Validierung der Daten - mit verbesserter Prüfung\n",
    "    train_classes = set(np.unique(y_train))\n",
    "    test_classes = set(np.unique(y_test))\n",
    "    all_classes = set(range(len(DACHMATERIAL_CLASSES)))\n",
    "    \n",
    "    logger.info(f\"Klassen im Trainingsset: {len(train_classes)}\")\n",
    "    logger.info(f\"Klassen im Testset: {len(test_classes)}\")\n",
    "    \n",
    "    # Warnung wenn nicht alle Klassen im Test-Set sind\n",
    "    missing_in_test = all_classes - test_classes\n",
    "    if missing_in_test:\n",
    "        logger.warning(f\"Folgende Klassen fehlen im Test-Set: {[DACHMATERIAL_CLASSES[i] for i in missing_in_test]}\")\n",
    "        logger.warning(\"Dies kann bei sehr unbalancierten Datensätzen vorkommen.\")\n",
    "    \n",
    "    # Sicherstellen dass mindestens die Mehrheit der Klassen vertreten ist\n",
    "    if len(test_classes) < len(all_classes) * 0.7:\n",
    "        logger.error(\"Zu wenige Klassen im Test-Set! Versuche anderen Random State.\")\n",
    "        # Versuche mit anderem Random State\n",
    "        for attempt in range(5):\n",
    "            new_seed = SEED + attempt + 1\n",
    "            splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=new_seed)\n",
    "            train_idx, test_idx = next(splitter.split(X, y_encoded))\n",
    "            \n",
    "            y_train_temp = y_encoded[train_idx]\n",
    "            y_test_temp = y_encoded[test_idx]\n",
    "            \n",
    "            test_classes_temp = set(np.unique(y_test_temp))\n",
    "            if len(test_classes_temp) >= len(all_classes) * 0.8:\n",
    "                logger.info(f\"Besserer Split gefunden mit Seed {new_seed}\")\n",
    "                X_train = X.iloc[train_idx]\n",
    "                X_test = X.iloc[test_idx]\n",
    "                y_train = y_train_temp\n",
    "                y_test = y_test_temp\n",
    "                \n",
    "                # Re-fit preprocessing\n",
    "                X_train_processed = preprocessor.fit_transform(X_train).astype(np.float32)\n",
    "                X_test_processed = preprocessor.transform(X_test).astype(np.float32)\n",
    "                break\n",
    "    \n",
    "    logger.info(f\"[ok] Daten vorbereitet: {len(X_train):,} Trainingssamples, {len(X_test):,} Testsamples\")\n",
    "    logger.info(f\"  Feature-Dimension nach Preprocessing: {X_train_processed.shape[1]}\")\n",
    "    logger.info(f\"  Klassen: {len(np.unique(y_train))} im Training, {len(np.unique(y_test))} im Test\")\n",
    "    logger.info(f\"  Speicherbedarf: {(X_train_processed.nbytes + X_test_processed.nbytes) / 1024**2:.1f} MB\")\n",
    "    \n",
    "    return X_train_processed, y_train, X_test_processed, y_test, label_encoder, preprocessor\n",
    "\n",
    "# ## 4. Neural Network Modell\n",
    "\n",
    "class OptimizedTabularNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Optimierte NN-Architektur für tabellarische Dachmaterial-Daten.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, num_classes=11):\n",
    "        super(OptimizedTabularNN, self).__init__()\n",
    "        \n",
    "        # Architektur für tabellarische Daten\n",
    "        self.features = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(64, num_classes)\n",
    "        \n",
    "        # Device handling mit Fehlerbehandlung\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                self.device = torch.device('cuda')\n",
    "                # Test ob CUDA wirklich funktioniert\n",
    "                test_tensor = torch.zeros(1).cuda()\n",
    "                del test_tensor\n",
    "            except:\n",
    "                logger.warning(\"CUDA verfügbar aber nicht nutzbar. Verwende CPU.\")\n",
    "                self.device = torch.device('cpu')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self, X_np, y_np, epochs=10, lr=1e-3, batch_size=256, verbose=False):\n",
    "        \"\"\"\n",
    "        Trainiert das TabularNN mit optimierten Hyperparametern.\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "        \n",
    "        # Hyperparameter-Anpassung basierend auf Datensatzgröße\n",
    "        if len(X_np) < 1000:\n",
    "            batch_size = min(32, len(X_np))\n",
    "            lr = lr * 0.1\n",
    "        \n",
    "        optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Create dataset\n",
    "        try:\n",
    "            dataset = TensorDataset(\n",
    "                torch.from_numpy(X_np).float(),\n",
    "                torch.from_numpy(y_np).long()\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Erstellen des Datasets: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # DataLoader mit optimierten Settings\n",
    "        loader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=0,  # Immer 0 für Kompatibilität\n",
    "            pin_memory=(self.device.type == 'cuda'),\n",
    "            drop_last=False\n",
    "        )\n",
    "        \n",
    "        # Training loop mit Fehlerbehandlung\n",
    "        try:\n",
    "            for epoch in range(epochs):\n",
    "                total_loss = 0.0\n",
    "                batch_count = 0\n",
    "                \n",
    "                for xb, yb in loader:\n",
    "                    xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = self(xb)\n",
    "                    loss = loss_fn(outputs, yb)\n",
    "                    \n",
    "                    # Gradient clipping zur Stabilität\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    batch_count += 1\n",
    "                \n",
    "                scheduler.step()\n",
    "                \n",
    "                if verbose and (epoch + 1) % 2 == 0:\n",
    "                    avg_loss = total_loss / max(batch_count, 1)\n",
    "                    logger.info(f\"    Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler während des Trainings: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X_np, batch_size=1024):\n",
    "        \"\"\"\n",
    "        Gibt Wahrscheinlichkeiten für große Datenmengen zurück.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        probs = []\n",
    "        \n",
    "        # Anpassung der Batch-Größe bei wenig Speicher\n",
    "        if self.device.type == 'cuda':\n",
    "            try:\n",
    "                free_memory = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()\n",
    "                if free_memory < 1024**3:  # Weniger als 1GB frei\n",
    "                    batch_size = 256\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                for i in range(0, len(X_np), batch_size):\n",
    "                    batch = torch.from_numpy(X_np[i:i+batch_size]).float().to(self.device)\n",
    "                    logits = self(batch)\n",
    "                    batch_probs = F.softmax(logits, dim=1)\n",
    "                    probs.append(batch_probs.cpu().numpy())\n",
    "                    \n",
    "                    # Speicher freigeben\n",
    "                    del batch, logits, batch_probs\n",
    "                    if self.device.type == 'cuda':\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Fehler bei predict_proba: {e}\")\n",
    "                raise\n",
    "        \n",
    "        return np.vstack(probs) if probs else np.array([])\n",
    "\n",
    "    def predict(self, X_np, batch_size=1024):\n",
    "        \"\"\"\n",
    "        Gibt Vorhersagen zurück.\n",
    "        \"\"\"\n",
    "        probs = self.predict_proba(X_np, batch_size)\n",
    "        return np.argmax(probs, axis=1) if len(probs) > 0 else np.array([])\n",
    "\n",
    "# ## 5. Sklearn Wrapper und Klassifikator Factory\n",
    "\n",
    "class SklearnWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper-Klasse für sklearn-Klassifikatoren mit NN-ähnlicher API.\n",
    "    \"\"\"\n",
    "    def __init__(self, classifier, scaler=None):\n",
    "        self.classifier = classifier\n",
    "        self.scaler = scaler\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X_np, y_np, **kwargs):\n",
    "        \"\"\"Trainiert den Klassifikator mit Fehlerbehandlung.\"\"\"\n",
    "        try:\n",
    "            if self.scaler is not None:\n",
    "                X_scaled = self.scaler.fit_transform(X_np)\n",
    "            else:\n",
    "                X_scaled = X_np\n",
    "            \n",
    "            self.classifier.fit(X_scaled, y_np)\n",
    "            self.is_fitted = True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Training des sklearn-Modells: {e}\")\n",
    "            raise\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X_np):\n",
    "        \"\"\"Gibt Wahrscheinlichkeiten zurueck mit Fehlerbehandlung.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Modell wurde noch nicht trainiert!\")\n",
    "        \n",
    "        try:\n",
    "            if self.scaler is not None:\n",
    "                X_scaled = self.scaler.transform(X_np)\n",
    "            else:\n",
    "                X_scaled = X_np\n",
    "                \n",
    "            if hasattr(self.classifier, 'predict_proba'):\n",
    "                return self.classifier.predict_proba(X_scaled)\n",
    "            else:\n",
    "                # Für SVM mit probability=False oder andere Klassifikatoren\n",
    "                if hasattr(self.classifier, 'decision_function'):\n",
    "                    decision = self.classifier.decision_function(X_scaled)\n",
    "                    \n",
    "                    # Multi-class Fall\n",
    "                    if len(decision.shape) == 2:\n",
    "                        # Softmax auf decision values\n",
    "                        exp_decision = np.exp(decision - np.max(decision, axis=1, keepdims=True))\n",
    "                        probs = exp_decision / np.sum(exp_decision, axis=1, keepdims=True)\n",
    "                    else:\n",
    "                        # Binary Fall - konvertiere zu 2-Klassen-Wahrscheinlichkeiten\n",
    "                        probs = np.zeros((len(decision), 2))\n",
    "                        probs[:, 1] = 1 / (1 + np.exp(-decision))\n",
    "                        probs[:, 0] = 1 - probs[:, 1]\n",
    "                    return probs\n",
    "                else:\n",
    "                    # Fallback: One-hot encoding der Vorhersagen\n",
    "                    predictions = self.classifier.predict(X_scaled)\n",
    "                    n_classes = len(np.unique(predictions))\n",
    "                    probs = np.zeros((len(predictions), n_classes))\n",
    "                    for i, pred in enumerate(predictions):\n",
    "                        probs[i, int(pred)] = 1.0\n",
    "                    return probs\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler bei predict_proba: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def predict(self, X_np):\n",
    "        \"\"\"Gibt Vorhersagen zurück mit Fehlerbehandlung.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Modell wurde noch nicht trainiert!\")\n",
    "            \n",
    "        try:\n",
    "            if self.scaler is not None:\n",
    "                X_scaled = self.scaler.transform(X_np)\n",
    "            else:\n",
    "                X_scaled = X_np\n",
    "            return self.classifier.predict(X_scaled)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler bei predict: {e}\")\n",
    "            raise\n",
    "\n",
    "def create_classifier(classifier_name, input_dim=None, n_classes=None):\n",
    "    \"\"\"\n",
    "    Erstellt einen Klassifikator basierend auf dem Namen.\n",
    "    \n",
    "    Args:\n",
    "        classifier_name: Name des Klassifikators\n",
    "        input_dim: Input-Dimension für Neural Network\n",
    "        n_classes: Anzahl der Klassen\n",
    "    \n",
    "    Returns:\n",
    "        Klassifikator-Objekt mit einheitlicher API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if classifier_name == 'Neural Network':\n",
    "            if input_dim is None or n_classes is None:\n",
    "                raise ValueError(\"input_dim und n_classes müssen für Neural Network angegeben werden\")\n",
    "            return OptimizedTabularNN(input_dim=input_dim, num_classes=n_classes)\n",
    "        \n",
    "        elif classifier_name == 'Naive Bayes':\n",
    "            return SklearnWrapper(GaussianNB())\n",
    "        \n",
    "        elif classifier_name == 'Random Forest':\n",
    "            # Angepasste Parameter für bessere Performance\n",
    "            n_jobs = min(os.cpu_count() - 1, -1) if os.cpu_count() else -1\n",
    "            return SklearnWrapper(\n",
    "                RandomForestClassifier(\n",
    "                    n_estimators=100,\n",
    "                    max_depth=None,\n",
    "                    min_samples_split=2,\n",
    "                    min_samples_leaf=1,\n",
    "                    n_jobs=n_jobs,\n",
    "                    random_state=SEED,\n",
    "                    verbose=0\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        elif classifier_name == 'Logistic Regression':\n",
    "            return SklearnWrapper(\n",
    "                LogisticRegression(\n",
    "                    max_iter=1000,\n",
    "                    solver='saga',\n",
    "                    multi_class='multinomial',\n",
    "                    n_jobs=-1,\n",
    "                    random_state=SEED,\n",
    "                    verbose=0\n",
    "                ),\n",
    "                scaler=StandardScaler()\n",
    "            )\n",
    "        \n",
    "        elif classifier_name == 'SVM':\n",
    "            return SklearnWrapper(\n",
    "                SVC(\n",
    "                    kernel='rbf',\n",
    "                    gamma='scale',\n",
    "                    decision_function_shape='ovr',\n",
    "                    probability=True,\n",
    "                    cache_size=500,  # Mehr Cache für bessere Performance\n",
    "                    random_state=SEED,\n",
    "                    verbose=False\n",
    "                ),\n",
    "                scaler=StandardScaler()\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unbekannter Klassifikator: {classifier_name}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Erstellen des Klassifikators {classifier_name}: {e}\")\n",
    "        raise\n",
    "\n",
    "# ## 6. Query-Strategien\n",
    "\n",
    "def entropy_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Waehlt Samples mit hoechster Entropie aus.\n",
    "    H(x) = -Σ p(y|x) * log(p(y|x))\n",
    "    \"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        \n",
    "        # Kleine Konstante hinzufügen um log(0) zu vermeiden\n",
    "        epsilon = 1e-10\n",
    "        probs = np.clip(probs, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        # Entropie berechnen\n",
    "        entropies = -np.sum(probs * np.log(probs), axis=1)\n",
    "        \n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        # Indizes mit höchster Entropie\n",
    "        return np.argsort(entropies)[-n_instances:]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Entropy Sampling: {e}\")\n",
    "        # Fallback zu Random Sampling\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def margin_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Wählt Samples mit kleinstem Margin zwischen Top-2 Klassen.\n",
    "    margin = P(y1|x) - P(y2|x)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        \n",
    "        # Sortiere Wahrscheinlichkeiten\n",
    "        sorted_probs = np.sort(probs, axis=1)\n",
    "        \n",
    "        # Berechne Margin\n",
    "        if sorted_probs.shape[1] >= 2:\n",
    "            margins = sorted_probs[:, -1] - sorted_probs[:, -2]\n",
    "        else:\n",
    "            # Falls nur eine Klasse, verwende 1 - max_prob als Margin\n",
    "            margins = 1.0 - sorted_probs[:, -1]\n",
    "        \n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        # Indizes mit kleinstem Margin\n",
    "        return np.argsort(margins)[:n_instances]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Margin Sampling: {e}\")\n",
    "        # Fallback zu Random Sampling\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def least_confidence_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Wählt Samples mit geringster Konfidenz.\n",
    "    confidence = max P(y|x)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        \n",
    "        # Maximum-Wahrscheinlichkeit als Konfidenz\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        \n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        # Indizes mit geringster Konfidenz\n",
    "        return np.argsort(confidences)[:n_instances]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Least Confidence Sampling: {e}\")\n",
    "        # Fallback zu Random Sampling\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def random_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Zufällige Auswahl (Baseline).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        if n_instances <= 0:\n",
    "            return np.array([], dtype=int)\n",
    "            \n",
    "        return np.random.choice(len(X_pool), size=n_instances, replace=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Random Sampling: {e}\")\n",
    "        # Notfall-Fallback\n",
    "        return np.arange(min(n_instances, len(X_pool)))\n",
    "\n",
    "# ## 7. Statistische Analyse Funktionen\n",
    "\n",
    "def cliffs_delta(x, y):\n",
    "    \"\"\"\n",
    "    Berechnet Cliff's Delta als nicht-parametrisches Effektstaerkemaß.\n",
    "    \n",
    "    Interpretation:\n",
    "    |d| < 0.147 \"vernachlässigbar\"\n",
    "    |d| < 0.33  \"klein\" \n",
    "    |d| < 0.474 \"mittel\"\n",
    "    |d| >= 0.474 \"groß\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nx = len(x)\n",
    "        ny = len(y)\n",
    "        \n",
    "        if nx == 0 or ny == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Konvertiere zu numpy arrays falls nötig\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        # Berechne die Anzahl der Paare, wo x[i] > y[j]\n",
    "        greater = 0\n",
    "        less = 0\n",
    "        \n",
    "        # Vektorisierte Berechnung für bessere Performance\n",
    "        for xi in x:\n",
    "            greater += np.sum(xi > y)\n",
    "            less += np.sum(xi < y)\n",
    "        \n",
    "        # Cliff's Delta\n",
    "        d = (greater - less) / (nx * ny)\n",
    "        \n",
    "        # Sicherstellen, dass d im Bereich [-1, 1] liegt\n",
    "        d = np.clip(d, -1.0, 1.0)\n",
    "        \n",
    "        return d\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Cliff's Delta Berechnung: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def interpret_cliffs_delta(d):\n",
    "    \"\"\"\n",
    "    Interpretiert die Effektstärke nach Cliff's Delta.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        abs_d = abs(float(d))\n",
    "        if abs_d < 0.147:\n",
    "            return \"vernachlässigbar\"\n",
    "        elif abs_d < 0.33:\n",
    "            return \"klein\"\n",
    "        elif abs_d < 0.474:\n",
    "            return \"mittel\"\n",
    "        else:\n",
    "            return \"groß\"\n",
    "    except:\n",
    "        return \"unbekannt\"\n",
    "\n",
    "def perform_statistical_analysis(results_df, metric='f1_score'):\n",
    "    \"\"\"\n",
    "    Fuehrt statistische Analyse durch: Wilcoxon Signed-Rank Test mit Bonferroni-Korrektur.\n",
    "    \"\"\"\n",
    "    statistical_results = []\n",
    "    \n",
    "    try:\n",
    "        classifiers = results_df['classifier'].unique()\n",
    "        strategies = results_df['strategy'].unique()\n",
    "        budget_levels = results_df['budget_pct'].unique()\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            for budget_pct in budget_levels:\n",
    "                # Hole Random Sampling als Baseline\n",
    "                baseline_data = results_df[\n",
    "                    (results_df['classifier'] == classifier) & \n",
    "                    (results_df['strategy'] == 'Random Sampling') & \n",
    "                    (results_df['budget_pct'] == budget_pct)\n",
    "                ][metric].values\n",
    "                \n",
    "                # Vergleiche mit anderen Strategien\n",
    "                for strategy in strategies:\n",
    "                    if strategy == 'Random Sampling':\n",
    "                        continue\n",
    "                        \n",
    "                    strategy_data = results_df[\n",
    "                        (results_df['classifier'] == classifier) & \n",
    "                        (results_df['strategy'] == strategy) & \n",
    "                        (results_df['budget_pct'] == budget_pct)\n",
    "                    ][metric].values\n",
    "                    \n",
    "                    # Mindestens N_RUNS Datenpunkte für statistische Tests\n",
    "                    if len(baseline_data) >= N_RUNS and len(strategy_data) >= N_RUNS:\n",
    "                        # Wilcoxon Signed-Rank Test\n",
    "                        try:\n",
    "                            # Prüfe ob alle Werte gleich sind\n",
    "                            if np.allclose(strategy_data, baseline_data):\n",
    "                                statistic, p_value = 0.0, 1.0\n",
    "                            else:\n",
    "                                statistic, p_value = wilcoxon(\n",
    "                                    strategy_data, baseline_data, \n",
    "                                    alternative='greater',\n",
    "                                    zero_method='zsplit'\n",
    "                                )\n",
    "                        except Exception as e:\n",
    "                            logger.warning(f\"Wilcoxon Test fehlgeschlagen für {classifier}-{strategy}: {e}\")\n",
    "                            statistic, p_value = 0.0, 1.0\n",
    "                        \n",
    "                        # Effektstärke\n",
    "                        effect_size = cliffs_delta(strategy_data, baseline_data)\n",
    "                        effect_interpretation = interpret_cliffs_delta(effect_size)\n",
    "                        \n",
    "                        # Mittelwerte und Standardabweichungen\n",
    "                        baseline_mean = np.mean(baseline_data) if len(baseline_data) > 0 else 0\n",
    "                        baseline_std = np.std(baseline_data) if len(baseline_data) > 0 else 0\n",
    "                        strategy_mean = np.mean(strategy_data) if len(strategy_data) > 0 else 0\n",
    "                        strategy_std = np.std(strategy_data) if len(strategy_data) > 0 else 0\n",
    "                        \n",
    "                        # Verbesserung berechnen mit Division-by-Zero-Schutz\n",
    "                        improvement = strategy_mean - baseline_mean\n",
    "                        improvement_pct = ((improvement / baseline_mean) * 100) if baseline_mean > 0 else 0\n",
    "                        \n",
    "                        statistical_results.append({\n",
    "                            'classifier': classifier,\n",
    "                            'budget_pct': budget_pct,\n",
    "                            'strategy': strategy,\n",
    "                            'baseline_mean': baseline_mean,\n",
    "                            'baseline_std': baseline_std,\n",
    "                            'strategy_mean': strategy_mean,\n",
    "                            'strategy_std': strategy_std,\n",
    "                            'improvement': improvement,\n",
    "                            'improvement_pct': improvement_pct,\n",
    "                            'wilcoxon_statistic': float(statistic),\n",
    "                            'p_value': float(p_value),\n",
    "                            'cliffs_delta': float(effect_size),\n",
    "                            'effect_size': effect_interpretation,\n",
    "                            'n_samples': len(strategy_data)\n",
    "                        })\n",
    "        \n",
    "        # Konvertiere zu DataFrame\n",
    "        stat_df = pd.DataFrame(statistical_results)\n",
    "        \n",
    "        if len(stat_df) > 0:\n",
    "            # Bonferroni-Korrektur für multiple Vergleiche\n",
    "            n_comparisons = len(stat_df)\n",
    "            stat_df['p_value_corrected'] = np.minimum(stat_df['p_value'] * n_comparisons, 1.0)\n",
    "            stat_df['significant'] = stat_df['p_value_corrected'] < SIGNIFICANCE_LEVEL\n",
    "        else:\n",
    "            logger.warning(\"Keine statistischen Ergebnisse generiert!\")\n",
    "            \n",
    "        return stat_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der statistischen Analyse: {e}\")\n",
    "        return pd.DataFrame()  # Leerer DataFrame als Fallback\n",
    "\n",
    "# ## 8. Active Learning Hauptfunktion\n",
    "\n",
    "def run_active_learning_experiment(X_train, y_train, X_test, y_test,\n",
    "                                 classifier_name, strategy_name, strategy_func,\n",
    "                                 budget_percentages, batch_size=500,\n",
    "                                 input_dim=None, n_classes=None):\n",
    "    \"\"\"\n",
    "    Führt ein Active Learning Experiment durch mit umfassender Fehlerbehandlung.\n",
    "    Verwendet F1-Score als Hauptmetrik.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    n_total = len(y_train)\n",
    "    \n",
    "    # Input-Dimension und Anzahl Klassen ermitteln\n",
    "    if input_dim is None:\n",
    "        input_dim = X_train.shape[1]\n",
    "    if n_classes is None:\n",
    "        n_classes = len(np.unique(y_train))\n",
    "    \n",
    "    for budget_pct in budget_percentages:\n",
    "        n_budget = int(budget_pct * n_total)\n",
    "        \n",
    "        logger.info(f\"\\n{classifier_name} + {strategy_name} - Budget: {budget_pct:.0%} ({n_budget:,} Samples)\")\n",
    "        \n",
    "        for run in range(N_RUNS):\n",
    "            logger.info(f\"  Run {run+1}/{N_RUNS}\")\n",
    "            \n",
    "            try:\n",
    "                # Set seed for reproducibility\n",
    "                np.random.seed(SEED + run)\n",
    "                torch.manual_seed(SEED + run)\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.manual_seed(SEED + run)\n",
    "                \n",
    "                # Initialisierung\n",
    "                pool_indices = np.arange(n_total)\n",
    "                labeled_indices = []\n",
    "                \n",
    "                # Initiale zufällige Auswahl\n",
    "                n_initial = max(100, int(INITIAL_PERCENTAGE * n_total))\n",
    "                n_initial = min(n_initial, len(pool_indices))  # Sicherstellen dass genug Samples da sind\n",
    "                \n",
    "                initial_indices = np.random.choice(pool_indices, size=n_initial, replace=False)\n",
    "                labeled_indices = list(initial_indices)\n",
    "                pool_indices = np.setdiff1d(pool_indices, labeled_indices)\n",
    "                \n",
    "                # Tracking - verwende F1-Scores statt Accuracies\n",
    "                f1_scores = []\n",
    "                n_labeled_list = []\n",
    "                query_times = []\n",
    "                train_times = []\n",
    "                \n",
    "                while len(labeled_indices) < n_budget and len(pool_indices) > 0:\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    # Modell erstellen und trainieren\n",
    "                    model = create_classifier(classifier_name, input_dim=input_dim, n_classes=n_classes)\n",
    "                    \n",
    "                    train_start = time.time()\n",
    "                    \n",
    "                    # Training mit Fehlerbehandlung\n",
    "                    try:\n",
    "                        model.fit(X_train[labeled_indices], y_train[labeled_indices])\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler beim Training in Run {run+1}: {e}\")\n",
    "                        # Skip diesen Durchlauf\n",
    "                        break\n",
    "                    \n",
    "                    train_time = time.time() - train_start\n",
    "                    train_times.append(train_time)\n",
    "                    \n",
    "                    # Evaluation mit F1-Score\n",
    "                    try:\n",
    "                        y_pred = model.predict(X_test)\n",
    "                        # Verwende macro average F1-Score für unausgewogene Datensätze\n",
    "                        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler bei der Evaluation in Run {run+1}: {e}\")\n",
    "                        f1 = 0.0\n",
    "                    \n",
    "                    f1_scores.append(f1)\n",
    "                    n_labeled_list.append(len(labeled_indices))\n",
    "                    \n",
    "                    # Nächste Batch auswählen\n",
    "                    n_query = min(batch_size, n_budget - len(labeled_indices), len(pool_indices))\n",
    "                    if n_query <= 0:\n",
    "                        break\n",
    "                    \n",
    "                    # Query mit Zeitmessung und Fehlerbehandlung\n",
    "                    query_start = time.time()\n",
    "                    try:\n",
    "                        query_indices = strategy_func(model, X_train[pool_indices], n_query)\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler bei Query-Strategie {strategy_name}: {e}\")\n",
    "                        # Fallback zu Random Sampling\n",
    "                        query_indices = random_sampling(model, X_train[pool_indices], n_query)\n",
    "                    \n",
    "                    query_time = time.time() - query_start\n",
    "                    query_times.append(query_time)\n",
    "                    \n",
    "                    # Validierung der Query-Indizes\n",
    "                    query_indices = np.asarray(query_indices)\n",
    "                    query_indices = query_indices[query_indices < len(pool_indices)]  # Entferne ungültige Indizes\n",
    "                    \n",
    "                    if len(query_indices) == 0:\n",
    "                        logger.warning(f\"Keine gueltigen Query-Indizes in Run {run+1}\")\n",
    "                        break\n",
    "                    \n",
    "                    selected_indices = pool_indices[query_indices]\n",
    "                    \n",
    "                    # Update\n",
    "                    labeled_indices.extend(selected_indices)\n",
    "                    pool_indices = np.setdiff1d(pool_indices, selected_indices)\n",
    "                    \n",
    "                    # Progress logging - Unicode-Fix: Verwende -> statt →\n",
    "                    if len(labeled_indices) % 2000 == 0 or len(labeled_indices) == n_budget:\n",
    "                        logger.info(f\"    {len(labeled_indices):,} labeled -> F1-Score: {f1:.4f} \"\n",
    "                                  f\"(Train: {train_time:.1f}s, Query: {query_time:.2f}s)\")\n",
    "                    \n",
    "                    # Speicher freigeben bei NN\n",
    "                    if classifier_name == 'Neural Network' and hasattr(model, 'device') and model.device.type == 'cuda':\n",
    "                        torch.cuda.empty_cache()\n",
    "                \n",
    "                # Finale Evaluation mit mehr Training\n",
    "                if len(labeled_indices) > 0:\n",
    "                    try:\n",
    "                        model = create_classifier(classifier_name, input_dim=input_dim, n_classes=n_classes)\n",
    "                        \n",
    "                        # Mehr Epochs für finale Evaluation\n",
    "                        if classifier_name == 'Neural Network':\n",
    "                            model.fit(X_train[labeled_indices], y_train[labeled_indices], \n",
    "                                     epochs=20, verbose=False)\n",
    "                        else:\n",
    "                            model.fit(X_train[labeled_indices], y_train[labeled_indices])\n",
    "                        \n",
    "                        y_pred = model.predict(X_test)\n",
    "                        final_acc = accuracy_score(y_test, y_pred)\n",
    "                        final_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler bei finaler Evaluation in Run {run+1}: {e}\")\n",
    "                        final_acc = 0.0\n",
    "                        final_f1 = f1 if 'f1' in locals() else 0.0\n",
    "                    \n",
    "                    results.append({\n",
    "                        'classifier': classifier_name,\n",
    "                        'strategy': strategy_name,\n",
    "                        'budget_pct': budget_pct,\n",
    "                        'run': run,\n",
    "                        'n_labeled': len(labeled_indices),\n",
    "                        'accuracy': final_acc,\n",
    "                        'f1_score': final_f1,\n",
    "                        'f1_scores': f1_scores,  # Verwende f1_scores statt accuracies\n",
    "                        'n_labeled_list': n_labeled_list,\n",
    "                        'avg_query_time': np.mean(query_times) if query_times else 0,\n",
    "                        'avg_train_time': np.mean(train_times) if train_times else 0\n",
    "                    })\n",
    "                    \n",
    "                    # Unicode-Fix: Verwende -> statt →\n",
    "                    logger.info(f\"    Final: {len(labeled_indices):,} labeled -> \"\n",
    "                              f\"Accuracy: {final_acc:.4f}, F1: {final_f1:.4f}\")\n",
    "                \n",
    "                # Speicher freigeben\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Unerwarteter Fehler in Run {run+1}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ## 9. Visualisierungsfunktionen mit F1-Score und deutschen Beschriftungen\n",
    "\n",
    "def plot_per_classifier_with_significance(all_results, stat_results):\n",
    "    \"\"\"\n",
    "    Erstellt eine Visualisierung pro Klassifikator mit Signifikanzmarkierungen.\n",
    "    Verwendet F1-Score als Hauptmetrik mit deutschen Beschriftungen und adaptiver Skalierung.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen mit Fallback\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        # Deutsche Schriftart\n",
    "        plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "        \n",
    "        # Farben für Strategien\n",
    "        strategy_colors = {\n",
    "            'Random Sampling': '#808080',\n",
    "            'Entropy Sampling': '#1f77b4',\n",
    "            'Margin Sampling': '#ff7f0e',\n",
    "            'Least Confidence': '#2ca02c'\n",
    "        }\n",
    "        \n",
    "        # Deutsche Strategienamen\n",
    "        strategy_names_de = {\n",
    "            'Random Sampling': 'Zufällige Auswahl',\n",
    "            'Entropy Sampling': 'Entropie-basiert',\n",
    "            'Margin Sampling': 'Margin-basiert',\n",
    "            'Least Confidence': 'Geringste Konfidenz'\n",
    "        }\n",
    "        \n",
    "        # Klassifikatoren extrahieren\n",
    "        classifiers = sorted(list(set(r['classifier'] for r in all_results)))\n",
    "        \n",
    "        # Eine Figure pro Klassifikator\n",
    "        for classifier in classifiers:\n",
    "            fig, axes = plt.subplots(1, len(BUDGET_PERCENTAGES), figsize=(20, 4))\n",
    "            \n",
    "            # Handle für einzelne Subplot\n",
    "            if len(BUDGET_PERCENTAGES) == 1:\n",
    "                axes = [axes]\n",
    "                \n",
    "            fig.suptitle(f'{classifier} - Active Learning Leistung mit statistischer Signifikanz (F1-Score)', \n",
    "                         fontsize=16, y=1.02)\n",
    "            \n",
    "            # Gesamtanzahl Samples\n",
    "            n_total_samples = max(r['n_labeled'] for r in all_results if r['budget_pct'] == 1.0)\n",
    "            \n",
    "            # Sammle alle F1-Scores für adaptive Skalierung\n",
    "            all_f1_scores = []\n",
    "            \n",
    "            for budget_idx, budget_pct in enumerate(BUDGET_PERCENTAGES):\n",
    "                ax = axes[budget_idx]\n",
    "                \n",
    "                # Daten für diesen Klassifikator und Budget\n",
    "                plot_data = []\n",
    "                for strategy, color in strategy_colors.items():\n",
    "                    strategy_results = [r for r in all_results \n",
    "                                      if r['classifier'] == classifier \n",
    "                                      and r['strategy'] == strategy \n",
    "                                      and r['budget_pct'] == budget_pct]\n",
    "                    \n",
    "                    if strategy_results:\n",
    "                        # Lernkurven aggregieren - verwende f1_scores\n",
    "                        max_samples = int(budget_pct * n_total_samples)\n",
    "                        x_common = np.linspace(100, max_samples, 100)\n",
    "                        y_interpolated = []\n",
    "                        \n",
    "                        for r in strategy_results:\n",
    "                            if len(r['n_labeled_list']) > 1 and 'f1_scores' in r:\n",
    "                                try:\n",
    "                                    y_interp = np.interp(x_common, r['n_labeled_list'], r['f1_scores'])\n",
    "                                    y_interpolated.append(y_interp)\n",
    "                                    all_f1_scores.extend(y_interp)\n",
    "                                except:\n",
    "                                    logger.warning(f\"Interpolation fehlgeschlagen für {classifier}-{strategy}\")\n",
    "                        \n",
    "                        if y_interpolated:\n",
    "                            y_mean = np.mean(y_interpolated, axis=0)\n",
    "                            y_std = np.std(y_interpolated, axis=0)\n",
    "                            \n",
    "                            # Überprüfe Signifikanz\n",
    "                            is_significant = False\n",
    "                            effect_size = \"\"\n",
    "                            if strategy != 'Random Sampling' and not stat_results.empty:\n",
    "                                sig_data = stat_results[\n",
    "                                    (stat_results['classifier'] == classifier) & \n",
    "                                    (stat_results['strategy'] == strategy) & \n",
    "                                    (stat_results['budget_pct'] == budget_pct)\n",
    "                                ]\n",
    "                                if not sig_data.empty:\n",
    "                                    is_significant = sig_data.iloc[0]['significant']\n",
    "                                    effect_size = sig_data.iloc[0]['effect_size']\n",
    "                            \n",
    "                            # Label mit Signifikanz (deutsch)\n",
    "                            label = strategy_names_de.get(strategy, strategy)\n",
    "                            if is_significant:\n",
    "                                label += f\" *({effect_size})\"\n",
    "                            \n",
    "                            plot_data.append((x_common, y_mean, y_std, label, color, is_significant, strategy))\n",
    "                \n",
    "                # Plot mit adaptiver Skalierung\n",
    "                for x_common, y_mean, y_std, label, color, is_significant, strategy in plot_data:\n",
    "                    ax.plot(x_common, y_mean, \n",
    "                           label=label, \n",
    "                           color=color, \n",
    "                           linewidth=2.5,\n",
    "                           linestyle='-' if not is_significant or strategy == 'Random Sampling' else '--',\n",
    "                           marker='o' if strategy == 'Random Sampling' else None,\n",
    "                           markevery=10 if strategy == 'Random Sampling' else None,\n",
    "                           markersize=4)\n",
    "                    \n",
    "                    ax.fill_between(x_common, \n",
    "                                  y_mean - y_std, \n",
    "                                  y_mean + y_std, \n",
    "                                  color=color, \n",
    "                                  alpha=0.2)\n",
    "                \n",
    "                # Achsenbeschriftung (deutsch)\n",
    "                ax.set_xlabel('Anzahl markierter Beispiele', fontsize=11)\n",
    "                ax.set_ylabel('Test F1-Score (Makro)', fontsize=11)\n",
    "                ax.set_title(f'Budget: {int(budget_pct*100)}%', fontsize=12)\n",
    "                \n",
    "                # Adaptive Y-Achsen-Skalierung\n",
    "                if all_f1_scores:\n",
    "                    min_f1 = min(all_f1_scores)\n",
    "                    max_f1 = max(all_f1_scores)\n",
    "                    margin = (max_f1 - min_f1) * 0.1\n",
    "                    \n",
    "                    # Wenn Unterschiede klein sind, zoome rein\n",
    "                    if max_f1 - min_f1 < 0.2:\n",
    "                        ax.set_ylim([max(0, min_f1 - margin), min(1.0, max_f1 + margin)])\n",
    "                    else:\n",
    "                        ax.set_ylim([0.0, 1.0])\n",
    "                else:\n",
    "                    ax.set_ylim([0.0, 1.0])\n",
    "                \n",
    "                # Grid und Formatierung\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                \n",
    "                # X-Achse formatieren\n",
    "                ax.ticklabel_format(style='plain', axis='x')\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}k' if x >= 1000 else str(int(x))))\n",
    "                \n",
    "                # Legende nur beim ersten Plot\n",
    "                if budget_idx == 0:\n",
    "                    ax.legend(loc='lower right', fontsize=9, framealpha=0.9)\n",
    "            \n",
    "            # Signifikanz-Erklärung (deutsch)\n",
    "            fig.text(0.5, -0.05, \n",
    "                    '* = statistisch signifikant (p < 0.05 mit Bonferroni-Korrektur); ' +\n",
    "                    'Effektstärke in Klammern (vernachlässigbar/klein/mittel/groß)',\n",
    "                    ha='center', fontsize=10, style='italic')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Speichern mit Fehlerbehandlung\n",
    "            filename = f'plots/dachmaterial_{classifier.lower().replace(\" \", \"_\")}_f1_signifikanz_de.png'\n",
    "            try:\n",
    "                plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "                logger.info(f\"[ok] Deutsche Visualisierung mit F1-Score und Signifikanz für {classifier} erstellt: {filename}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Fehler beim Speichern der Visualisierung für {classifier}: {e}\")\n",
    "                \n",
    "            plt.close()\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_per_classifier_with_significance: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def plot_statistical_summary(stat_results):\n",
    "    \"\"\"\n",
    "    Erstellt eine Visualisierung der statistischen Ergebnisse für F1-Score mit deutschen Beschriftungen.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        # Deutsche Schriftart\n",
    "        plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "        \n",
    "        if stat_results.empty:\n",
    "            logger.warning(\"Keine statistischen Ergebnisse zum Visualisieren!\")\n",
    "            return\n",
    "            \n",
    "        # Filtere nur signifikante Ergebnisse\n",
    "        sig_results = stat_results[stat_results['significant']].copy() if 'significant' in stat_results.columns else pd.DataFrame()\n",
    "        \n",
    "        if sig_results.empty:\n",
    "            logger.warning(\"Keine signifikanten Ergebnisse gefunden!\")\n",
    "            # Erstelle trotzdem eine Visualisierung mit allen Ergebnissen\n",
    "            sig_results = stat_results.copy()\n",
    "        \n",
    "        # Figure mit Subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('Statistische Analyse - Dachmaterial Datensatz (F1-Score)', fontsize=16)\n",
    "        \n",
    "        # 1. Heatmap der p-Werte\n",
    "        try:\n",
    "            ax1 = axes[0, 0]\n",
    "            pivot_p = stat_results.pivot_table(\n",
    "                values='p_value_corrected',\n",
    "                index=['classifier', 'strategy'],\n",
    "                columns='budget_pct',\n",
    "                fill_value=1.0\n",
    "            )\n",
    "            \n",
    "            if sns is not None and not pivot_p.empty:\n",
    "                sns.heatmap(pivot_p, \n",
    "                            annot=True, \n",
    "                            fmt='.3f', \n",
    "                            cmap='RdYlGn_r',\n",
    "                            vmin=0, \n",
    "                            vmax=0.1,\n",
    "                            cbar_kws={'label': 'Korrigierter p-Wert'},\n",
    "                            ax=ax1)\n",
    "            else:\n",
    "                ax1.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "                \n",
    "            ax1.set_title('Korrigierte p-Werte (Wilcoxon Signed-Rank Test)')\n",
    "            ax1.set_xlabel('Budget (%)')\n",
    "            ax1.set_ylabel('Klassifikator / Strategie')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei p-Wert Heatmap: {e}\")\n",
    "            axes[0, 0].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        # 2. Heatmap der Effektstärken\n",
    "        try:\n",
    "            ax2 = axes[0, 1]\n",
    "            pivot_effect = stat_results.pivot_table(\n",
    "                values='cliffs_delta',\n",
    "                index=['classifier', 'strategy'],\n",
    "                columns='budget_pct',\n",
    "                fill_value=0.0\n",
    "            )\n",
    "            \n",
    "            if sns is not None and not pivot_effect.empty:\n",
    "                sns.heatmap(pivot_effect, \n",
    "                            annot=True, \n",
    "                            fmt='.3f', \n",
    "                            cmap='coolwarm',\n",
    "                            center=0,\n",
    "                            vmin=-1, \n",
    "                            vmax=1,\n",
    "                            cbar_kws={'label': \"Cliff's Delta\"},\n",
    "                            ax=ax2)\n",
    "            else:\n",
    "                ax2.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "                \n",
    "            ax2.set_title(\"Effektstärke (Cliff's Delta)\")\n",
    "            ax2.set_xlabel('Budget (%)')\n",
    "            ax2.set_ylabel('Klassifikator / Strategie')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei Effektstärken Heatmap: {e}\")\n",
    "            axes[0, 1].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        # 3. Anzahl signifikanter Verbesserungen pro Strategie\n",
    "        try:\n",
    "            ax3 = axes[1, 0]\n",
    "            if not sig_results.empty and 'strategy' in sig_results.columns:\n",
    "                sig_counts = sig_results.groupby('strategy').size().sort_values(ascending=False)\n",
    "                sig_counts.plot(kind='bar', ax=ax3, color='steelblue')\n",
    "                ax3.set_title('Anzahl signifikanter F1-Score Verbesserungen pro Strategie')\n",
    "                ax3.set_xlabel('Strategie')\n",
    "                ax3.set_ylabel('Anzahl')\n",
    "                ax3.grid(axis='y', alpha=0.3)\n",
    "                ax3.set_xticklabels(ax3.get_xticklabels(), rotation=45, ha='right')\n",
    "            else:\n",
    "                ax3.text(0.5, 0.5, 'Keine signifikanten Ergebnisse', ha='center', va='center')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei Signifikanz-Barplot: {e}\")\n",
    "            axes[1, 0].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        # 4. Durchschnittliche Effektstärke pro Klassifikator\n",
    "        try:\n",
    "            ax4 = axes[1, 1]\n",
    "            if 'classifier' in stat_results.columns and 'cliffs_delta' in stat_results.columns:\n",
    "                avg_effect = stat_results.groupby('classifier')['cliffs_delta'].agg(['mean', 'std'])\n",
    "                avg_effect['mean'].plot(kind='bar', ax=ax4, yerr=avg_effect['std'], \n",
    "                                       capsize=5, color='darkorange')\n",
    "                ax4.set_title(\"Durchschnittliche Effektstärke pro Klassifikator (F1-Score)\")\n",
    "                ax4.set_xlabel('Klassifikator')\n",
    "                ax4.set_ylabel(\"Mittleres Cliff's Delta\")\n",
    "                ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "                ax4.grid(axis='y', alpha=0.3)\n",
    "                ax4.set_xticklabels(ax4.get_xticklabels(), rotation=45, ha='right')\n",
    "            else:\n",
    "                ax4.text(0.5, 0.5, 'Daten nicht verfügbar', ha='center', va='center')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei Effektstärken-Barplot: {e}\")\n",
    "            axes[1, 1].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Speichern\n",
    "        filename = 'plots/dachmaterial_f1_statistische_zusammenfassung_de.png'\n",
    "        try:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"[ok] Statistische F1-Score Zusammenfassung (deutsch) erstellt: {filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern der statistischen Zusammenfassung: {e}\")\n",
    "            \n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_statistical_summary: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def create_statistical_report(stat_results):\n",
    "    \"\"\"\n",
    "    Erstellt einen detaillierten statistischen Bericht für F1-Score Ergebnisse.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Sortiere nach Effektstärke\n",
    "        if not stat_results.empty and 'cliffs_delta' in stat_results.columns:\n",
    "            stat_results_sorted = stat_results.sort_values('cliffs_delta', ascending=False)\n",
    "        else:\n",
    "            stat_results_sorted = stat_results\n",
    "        \n",
    "        # Erstelle formatierten Bericht\n",
    "        report = []\n",
    "        report.append(\"\\n\" + \"=\"*100)\n",
    "        report.append(\"DETAILLIERTER STATISTISCHER BERICHT - DACHMATERIAL (F1-SCORE)\")\n",
    "        report.append(\"=\"*100)\n",
    "        report.append(f\"Primäre Metrik: F1-Score (Macro Average)\")\n",
    "        report.append(f\"Signifikanzniveau: {SIGNIFICANCE_LEVEL} (mit Bonferroni-Korrektur)\")\n",
    "        report.append(f\"Anzahl Runs pro Experiment: {N_RUNS}\")\n",
    "        report.append(f\"Statistischer Test: Wilcoxon Signed-Rank Test\")\n",
    "        report.append(f\"Effektstärkemaß: Cliff's Delta\")\n",
    "        report.append(\"\\n\")\n",
    "        \n",
    "        # Signifikante Ergebnisse\n",
    "        if 'significant' in stat_results_sorted.columns:\n",
    "            sig_results = stat_results_sorted[stat_results_sorted['significant']]\n",
    "        else:\n",
    "            sig_results = pd.DataFrame()\n",
    "        \n",
    "        if not sig_results.empty:\n",
    "            report.append(\"SIGNIFIKANTE F1-SCORE VERBESSERUNGEN GEGENÜBER ZUFÄLLIGER AUSWAHL:\")\n",
    "            report.append(\"-\"*100)\n",
    "            report.append(f\"{'Klassifikator':<20} {'Strategie':<20} {'Budget':<10} {'Verbesserung':<15} \"\n",
    "                         f\"{'p-Wert':<12} {'Effekt':<15} {'Interpretation':<15}\")\n",
    "            report.append(\"-\"*100)\n",
    "            \n",
    "            for _, row in sig_results.iterrows():\n",
    "                report.append(f\"{row['classifier']:<20} {row['strategy']:<20} \"\n",
    "                             f\"{int(row['budget_pct']*100):>8}% \"\n",
    "                             f\"{row['improvement_pct']:>13.2f}% \"\n",
    "                             f\"{row['p_value_corrected']:>11.4f} \"\n",
    "                             f\"{row['cliffs_delta']:>14.3f} \"\n",
    "                             f\"{row['effect_size']:<15}\")\n",
    "        else:\n",
    "            report.append(\"Keine signifikanten F1-Score Verbesserungen gefunden!\")\n",
    "        \n",
    "        # Zusammenfassung nach Strategie\n",
    "        report.append(\"\\n\\nZUSAMMENFASSUNG NACH STRATEGIE (F1-SCORE):\")\n",
    "        report.append(\"-\"*100)\n",
    "        \n",
    "        for strategy in ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "            if 'strategy' in stat_results.columns:\n",
    "                strategy_data = stat_results[stat_results['strategy'] == strategy]\n",
    "                if not strategy_data.empty:\n",
    "                    sig_count = strategy_data['significant'].sum() if 'significant' in strategy_data.columns else 0\n",
    "                    avg_improvement = strategy_data['improvement_pct'].mean() if 'improvement_pct' in strategy_data.columns else 0\n",
    "                    avg_effect = strategy_data['cliffs_delta'].mean() if 'cliffs_delta' in strategy_data.columns else 0\n",
    "                    \n",
    "                    report.append(f\"\\n{strategy}:\")\n",
    "                    report.append(f\"  - Signifikante F1-Score Verbesserungen: {sig_count}/{len(strategy_data)} \"\n",
    "                                 f\"({sig_count/len(strategy_data)*100:.1f}%)\")\n",
    "                    report.append(f\"  - Durchschnittliche F1-Score Verbesserung: {avg_improvement:.2f}%\")\n",
    "                    report.append(f\"  - Durchschnittliche Effektstärke: {avg_effect:.3f}\")\n",
    "        \n",
    "        # Zusammenfassung nach Klassifikator\n",
    "        report.append(\"\\n\\nZUSAMMENFASSUNG NACH KLASSIFIKATOR (F1-SCORE):\")\n",
    "        report.append(\"-\"*100)\n",
    "        \n",
    "        if 'classifier' in stat_results.columns:\n",
    "            for classifier in stat_results['classifier'].unique():\n",
    "                classifier_data = stat_results[stat_results['classifier'] == classifier]\n",
    "                sig_count = classifier_data['significant'].sum() if 'significant' in classifier_data.columns else 0\n",
    "                \n",
    "                report.append(f\"\\n{classifier}:\")\n",
    "                report.append(f\"  - Signifikante F1-Score Verbesserungen: {sig_count}/{len(classifier_data)} \"\n",
    "                             f\"({sig_count/len(classifier_data)*100:.1f}%)\")\n",
    "                \n",
    "                if sig_count > 0 and 'cliffs_delta' in classifier_data.columns:\n",
    "                    best_strategy = classifier_data.loc[classifier_data['cliffs_delta'].idxmax()]\n",
    "                    report.append(f\"  - Beste Strategie: {best_strategy['strategy']} \"\n",
    "                                 f\"bei {int(best_strategy['budget_pct']*100)}% Budget \"\n",
    "                                 f\"(Effekt: {best_strategy['cliffs_delta']:.3f})\")\n",
    "        \n",
    "        report.append(\"\\n\" + \"=\"*100)\n",
    "        \n",
    "        # Ausgabe\n",
    "        report_text = \"\\n\".join(report)\n",
    "        print(report_text)\n",
    "        \n",
    "        # Speichern\n",
    "        report_filename = 'reports/dachmaterial_f1_statistischer_bericht.txt'\n",
    "        try:\n",
    "            with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(report_text)\n",
    "            logger.info(f\"[ok] Statistischer F1-Score Bericht gespeichert: {report_filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern des Berichts: {e}\")\n",
    "        \n",
    "        return report_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei create_statistical_report: {e}\")\n",
    "        return \"Fehler bei der Berichterstellung\"\n",
    "\n",
    "def plot_final_comparison(all_results):\n",
    "    \"\"\"\n",
    "    Erstellt eine Visualisierung, die zeigt, welche Kombination aus Klassifikator\n",
    "    und Query-Strategie bei 100% Budget am besten abgeschnitten hat (F1-Score).\n",
    "    Deutsche Beschriftungen.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        # Deutsche Schriftart\n",
    "        plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "        \n",
    "        # Nur Ergebnisse mit 100% Budget\n",
    "        final_results = [r for r in all_results if r['budget_pct'] == 1.0]\n",
    "        \n",
    "        if not final_results:\n",
    "            logger.warning(\"Keine Ergebnisse mit 100% Budget gefunden!\")\n",
    "            return\n",
    "        \n",
    "        # Aggregiere Ergebnisse\n",
    "        summary_data = []\n",
    "        classifiers = sorted(list(set(r['classifier'] for r in final_results)))\n",
    "        strategies = ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']\n",
    "        \n",
    "        # Deutsche Strategienamen\n",
    "        strategy_names_de = {\n",
    "            'Random Sampling': 'Zufällige Auswahl',\n",
    "            'Entropy Sampling': 'Entropie-basiert',\n",
    "            'Margin Sampling': 'Margin-basiert',\n",
    "            'Least Confidence': 'Geringste Konfidenz'\n",
    "        }\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            for strategy in strategies:\n",
    "                results = [r for r in final_results \n",
    "                          if r['classifier'] == classifier and r['strategy'] == strategy]\n",
    "                \n",
    "                if results:\n",
    "                    mean_acc = np.mean([r['accuracy'] for r in results])\n",
    "                    std_acc = np.std([r['accuracy'] for r in results])\n",
    "                    mean_f1 = np.mean([r['f1_score'] for r in results])\n",
    "                    std_f1 = np.std([r['f1_score'] for r in results])\n",
    "                    \n",
    "                    summary_data.append({\n",
    "                        'Klassifikator': classifier,\n",
    "                        'Strategie': strategy_names_de.get(strategy, strategy),\n",
    "                        'Strategie_orig': strategy,\n",
    "                        'Genauigkeit': mean_acc,\n",
    "                        'Genauigkeit_std': std_acc,\n",
    "                        'F1-Score': mean_f1,\n",
    "                        'F1-Score_std': std_f1\n",
    "                    })\n",
    "        \n",
    "        if not summary_data:\n",
    "            logger.warning(\"Keine Daten für finale Vergleichsmatrix!\")\n",
    "            return\n",
    "            \n",
    "        # DataFrame erstellen\n",
    "        df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # Pivot für Heatmap - fokussiere auf F1-Score\n",
    "        pivot_f1 = df.pivot(index='Klassifikator', columns='Strategie', values='F1-Score')\n",
    "        pivot_acc = df.pivot(index='Klassifikator', columns='Strategie', values='Genauigkeit')\n",
    "        \n",
    "        # Figure mit zwei Subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Heatmap für F1-Score (Hauptfokus) mit adaptiver Skalierung\n",
    "        if sns is not None and not pivot_f1.empty:\n",
    "            # Adaptive Farbskala\n",
    "            vmin = pivot_f1.min().min()\n",
    "            vmax = pivot_f1.max().max()\n",
    "            margin = (vmax - vmin) * 0.1\n",
    "            \n",
    "            sns.heatmap(pivot_f1, \n",
    "                        annot=True, \n",
    "                        fmt='.4f', \n",
    "                        cmap='RdYlGn', \n",
    "                        vmin=max(0, vmin - margin), \n",
    "                        vmax=min(1.0, vmax + margin),\n",
    "                        cbar_kws={'label': 'Test F1-Score (Makro)'},\n",
    "                        ax=ax1)\n",
    "        else:\n",
    "            ax1.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "            \n",
    "        ax1.set_title('Test F1-Score bei 100% Budget', fontsize=14)\n",
    "        ax1.set_xlabel('Query-Strategie', fontsize=12)\n",
    "        ax1.set_ylabel('Klassifikator', fontsize=12)\n",
    "        \n",
    "        # Heatmap für Accuracy (zum Vergleich) mit adaptiver Skalierung\n",
    "        if sns is not None and not pivot_acc.empty:\n",
    "            # Adaptive Farbskala\n",
    "            vmin = pivot_acc.min().min()\n",
    "            vmax = pivot_acc.max().max()\n",
    "            margin = (vmax - vmin) * 0.1\n",
    "            \n",
    "            sns.heatmap(pivot_acc, \n",
    "                        annot=True, \n",
    "                        fmt='.4f', \n",
    "                        cmap='RdYlGn', \n",
    "                        vmin=max(0, vmin - margin), \n",
    "                        vmax=min(1.0, vmax + margin),\n",
    "                        cbar_kws={'label': 'Test Genauigkeit'},\n",
    "                        ax=ax2)\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "            \n",
    "        ax2.set_title('Test Genauigkeit bei 100% Budget', fontsize=14)\n",
    "        ax2.set_xlabel('Query-Strategie', fontsize=12)\n",
    "        ax2.set_ylabel('Klassifikator', fontsize=12)\n",
    "        \n",
    "        plt.suptitle('Finaler Leistungsvergleich - Vollständiger Dachmaterial Datensatz (100% Budget)', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Speichern\n",
    "        filename = 'plots/dachmaterial_f1_finaler_vergleich_de.png'\n",
    "        try:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"[ok] Finale deutsche F1-Score Vergleichsvisualisierung erstellt: {filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern der finalen Vergleichsmatrix: {e}\")\n",
    "            \n",
    "        plt.close()\n",
    "        \n",
    "        # Beste Kombination finden basierend auf F1-Score\n",
    "        if not df.empty:\n",
    "            best_idx = df['F1-Score'].idxmax()\n",
    "            best_result = df.iloc[best_idx]\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"BESTE KOMBINATION BEI 100% BUDGET (F1-SCORE):\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"Klassifikator: {best_result['Klassifikator']}\")\n",
    "            print(f\"Query-Strategie: {best_result['Strategie']}\")\n",
    "            print(f\"Test F1-Score: {best_result['F1-Score']:.4f} (±{best_result['F1-Score_std']:.4f})\")\n",
    "            print(f\"Test Genauigkeit: {best_result['Genauigkeit']:.4f} (±{best_result['Genauigkeit_std']:.4f})\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            # Top 5 Kombinationen basierend auf F1-Score\n",
    "            print(\"\\nTOP 5 KOMBINATIONEN (F1-SCORE):\")\n",
    "            print(\"-\"*60)\n",
    "            top5 = df.nlargest(5, 'F1-Score')[['Klassifikator', 'Strategie', 'F1-Score', 'Genauigkeit']]\n",
    "            for idx, (_, row) in enumerate(top5.iterrows()):\n",
    "                print(f\"{idx+1}. {row['Klassifikator']} + {row['Strategie']}: \"\n",
    "                      f\"F1={row['F1-Score']:.4f}, Genauigkeit={row['Genauigkeit']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_final_comparison: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def plot_improvement_analysis(all_results):\n",
    "    \"\"\"\n",
    "    Zeigt die Verbesserung der Active Learning Strategien gegenüber Random Sampling (F1-Score).\n",
    "    Deutsche Beschriftungen mit adaptiver Skalierung.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        # Deutsche Schriftart\n",
    "        plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "        \n",
    "        # Berechne Verbesserungen basierend auf F1-Score\n",
    "        improvements = []\n",
    "        classifiers = sorted(list(set(r['classifier'] for r in all_results)))\n",
    "        strategies = ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            for strategy in strategies:\n",
    "                for budget_pct in BUDGET_PERCENTAGES:\n",
    "                    # Random Sampling Baseline\n",
    "                    random_results = [r for r in all_results \n",
    "                                    if r['classifier'] == classifier \n",
    "                                    and r['strategy'] == 'Random Sampling' \n",
    "                                    and r['budget_pct'] == budget_pct]\n",
    "                    \n",
    "                    # Active Learning Strategy\n",
    "                    strategy_results = [r for r in all_results \n",
    "                                      if r['classifier'] == classifier \n",
    "                                      and r['strategy'] == strategy \n",
    "                                      and r['budget_pct'] == budget_pct]\n",
    "                    \n",
    "                    if random_results and strategy_results:\n",
    "                        random_f1 = np.mean([r['f1_score'] for r in random_results])\n",
    "                        strategy_f1 = np.mean([r['f1_score'] for r in strategy_results])\n",
    "                        \n",
    "                        # Prozentuale Verbesserung\n",
    "                        improvement = ((strategy_f1 - random_f1) / random_f1) * 100 if random_f1 > 0 else 0\n",
    "                        \n",
    "                        improvements.append({\n",
    "                            'Klassifikator': classifier,\n",
    "                            'Strategie': strategy,\n",
    "                            'Budget': int(budget_pct * 100),\n",
    "                            'F1-Score Verbesserung (%)': improvement\n",
    "                        })\n",
    "        \n",
    "        if not improvements:\n",
    "            logger.warning(\"Keine Verbesserungsdaten gefunden!\")\n",
    "            return\n",
    "            \n",
    "        # DataFrame erstellen\n",
    "        imp_df = pd.DataFrame(improvements)\n",
    "        \n",
    "        # Figure\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        # Gruppierter Barplot\n",
    "        x = np.arange(len(BUDGET_PERCENTAGES))\n",
    "        width = 0.15\n",
    "        \n",
    "        # Erstelle eine eindeutige Farbe für jede Klassifikator-Strategie-Kombination\n",
    "        colors = plt.cm.tab20(np.linspace(0, 1, len(classifiers) * len(strategies)))\n",
    "        color_idx = 0\n",
    "        \n",
    "        # Sammle alle Verbesserungswerte für adaptive Skalierung\n",
    "        all_improvements = imp_df['F1-Score Verbesserung (%)'].values\n",
    "        \n",
    "        for i, classifier in enumerate(classifiers):\n",
    "            for j, strategy in enumerate(strategies):\n",
    "                data = imp_df[(imp_df['Klassifikator'] == classifier) & \n",
    "                             (imp_df['Strategie'] == strategy)]\n",
    "                \n",
    "                if not data.empty:\n",
    "                    values = []\n",
    "                    for b in BUDGET_PERCENTAGES:\n",
    "                        budget_data = data[data['Budget'] == int(b*100)]\n",
    "                        if not budget_data.empty:\n",
    "                            values.append(budget_data['F1-Score Verbesserung (%)'].values[0])\n",
    "                        else:\n",
    "                            values.append(0)\n",
    "                    \n",
    "                    offset = (i * len(strategies) + j - len(classifiers) * len(strategies) / 2) * width\n",
    "                    bars = ax.bar(x + offset, values, width, \n",
    "                                 label=f'{classifier} - {strategy}',\n",
    "                                 color=colors[color_idx])\n",
    "                    color_idx += 1\n",
    "        \n",
    "        # Achsenbeschriftung\n",
    "        ax.set_xlabel('Budget (%)', fontsize=12)\n",
    "        ax.set_ylabel('F1-Score Verbesserung gegenüber zufälliger Auswahl (%)', fontsize=12)\n",
    "        ax.set_title('Active Learning F1-Score Verbesserungsanalyse - Dachmaterial Datensatz', fontsize=14)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f'{int(b*100)}%' for b in BUDGET_PERCENTAGES])\n",
    "        \n",
    "        # Adaptive Y-Achsen-Skalierung\n",
    "        if len(all_improvements) > 0:\n",
    "            min_imp = min(all_improvements)\n",
    "            max_imp = max(all_improvements)\n",
    "            margin = (max_imp - min_imp) * 0.1\n",
    "            ax.set_ylim([min_imp - margin, max_imp + margin])\n",
    "        \n",
    "        # Nulllinie\n",
    "        ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Legende\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "        \n",
    "        # Grid\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Speichern\n",
    "        filename = 'plots/dachmaterial_f1_verbesserungsanalyse_de.png'\n",
    "        try:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"[ok] Deutsche F1-Score Verbesserungsanalyse erstellt: {filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern der F1-Score Verbesserungsanalyse: {e}\")\n",
    "            \n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_improvement_analysis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ## 10. Label-Einsparungs-Analyse mit F1-Score\n",
    "\n",
    "def calculate_label_savings(all_results, target_performance_percentages=[0.90, 0.95, 0.98]):\n",
    "    \"\"\"\n",
    "    Berechnet die Label-Einsparung für Active Learning Strategien basierend auf F1-Score.\n",
    "    \n",
    "    Args:\n",
    "        all_results: Liste aller Experiment-Ergebnisse\n",
    "        target_performance_percentages: Prozentsätze der Random Sampling 100% F1-Score Performance\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame mit Label-Einsparungen\n",
    "    \"\"\"\n",
    "    savings_results = []\n",
    "    \n",
    "    # Gruppiere nach Klassifikator\n",
    "    classifiers = sorted(list(set(r['classifier'] for r in all_results)))\n",
    "    \n",
    "    # Gesamtanzahl Samples\n",
    "    n_total_samples = max(r['n_labeled'] for r in all_results if r['budget_pct'] == 1.0)\n",
    "    \n",
    "    for classifier in classifiers:\n",
    "        # Hole Random Sampling F1-Score Performance bei 100% Budget als Referenz\n",
    "        random_100_results = [r for r in all_results \n",
    "                            if r['classifier'] == classifier \n",
    "                            and r['strategy'] == 'Random Sampling' \n",
    "                            and r['budget_pct'] == 1.0]\n",
    "        \n",
    "        if not random_100_results:\n",
    "            continue\n",
    "            \n",
    "        # Durchschnittliche F1-Score Performance bei 100% Budget\n",
    "        random_100_f1 = np.mean([r['f1_score'] for r in random_100_results])\n",
    "        \n",
    "        # Für verschiedene Ziel-Performance-Level\n",
    "        for target_pct in target_performance_percentages:\n",
    "            target_f1_score = random_100_f1 * target_pct\n",
    "            \n",
    "            # Für jede Strategie\n",
    "            for strategy in ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "                strategy_results = [r for r in all_results \n",
    "                                  if r['classifier'] == classifier \n",
    "                                  and r['strategy'] == strategy]\n",
    "                \n",
    "                if not strategy_results:\n",
    "                    continue\n",
    "                \n",
    "                # Aggregiere Lernkurven über alle Runs\n",
    "                all_curves = []\n",
    "                for r in strategy_results:\n",
    "                    if 'n_labeled_list' in r and 'f1_scores' in r:\n",
    "                        all_curves.append((r['n_labeled_list'], r['f1_scores']))\n",
    "                \n",
    "                if not all_curves:\n",
    "                    continue\n",
    "                \n",
    "                # Finde minimale Label-Anzahl um Ziel-F1-Score zu erreichen\n",
    "                labels_needed = []\n",
    "                \n",
    "                for n_labeled_list, f1_scores in all_curves:\n",
    "                    # Interpoliere um den Punkt zu finden, wo target_f1_score erreicht wird\n",
    "                    if len(f1_scores) > 0 and max(f1_scores) >= target_f1_score:\n",
    "                        # Finde ersten Punkt, der target_f1_score überschreitet\n",
    "                        for i, f1 in enumerate(f1_scores):\n",
    "                            if f1 >= target_f1_score:\n",
    "                                labels_needed.append(n_labeled_list[i])\n",
    "                                break\n",
    "                    else:\n",
    "                        # Ziel nicht erreicht - verwende Maximum\n",
    "                        labels_needed.append(n_total_samples)\n",
    "                \n",
    "                if labels_needed:\n",
    "                    avg_labels_needed = np.mean(labels_needed)\n",
    "                    std_labels_needed = np.std(labels_needed)\n",
    "                    \n",
    "                    # Berechne Einsparung gegenüber 100%\n",
    "                    savings_pct = ((n_total_samples - avg_labels_needed) / n_total_samples) * 100\n",
    "                    \n",
    "                    # Berechne Einsparung gegenüber Random Sampling\n",
    "                    if strategy != 'Random Sampling':\n",
    "                        random_labels = next((s['avg_labels_needed'] for s in savings_results \n",
    "                                            if s['classifier'] == classifier \n",
    "                                            and s['strategy'] == 'Random Sampling' \n",
    "                                            and s['target_performance'] == int(target_pct*100)), n_total_samples)\n",
    "                        relative_savings_pct = ((random_labels - avg_labels_needed) / random_labels) * 100 if random_labels > 0 else 0\n",
    "                    else:\n",
    "                        relative_savings_pct = 0\n",
    "                    \n",
    "                    savings_results.append({\n",
    "                        'classifier': classifier,\n",
    "                        'strategy': strategy,\n",
    "                        'target_performance': int(target_pct * 100),\n",
    "                        'target_f1_score': target_f1_score,\n",
    "                        'avg_labels_needed': avg_labels_needed,\n",
    "                        'std_labels_needed': std_labels_needed,\n",
    "                        'savings_pct': savings_pct,\n",
    "                        'relative_savings_pct': relative_savings_pct,\n",
    "                        'random_100_f1': random_100_f1\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(savings_results)\n",
    "\n",
    "def plot_label_savings(savings_df, dataset_name=\"Dachmaterial\"):\n",
    "    \"\"\"\n",
    "    Visualisiert die Label-Einsparungen basierend auf F1-Score mit deutschen Beschriftungen.\n",
    "    \"\"\"\n",
    "    # Style setzen\n",
    "    try:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    except:\n",
    "        plt.style.use('ggplot')\n",
    "    \n",
    "    # Deutsche Schriftart\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    \n",
    "    # Figure mit Subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'{dataset_name} - Label-Einsparungsanalyse (F1-Score basiert)', fontsize=16)\n",
    "    \n",
    "    # Deutsche Strategienamen\n",
    "    strategy_names_de = {\n",
    "        'Random Sampling': 'Zufällige Auswahl',\n",
    "        'Entropy Sampling': 'Entropie-basiert',\n",
    "        'Margin Sampling': 'Margin-basiert',\n",
    "        'Least Confidence': 'Geringste Konfidenz'\n",
    "    }\n",
    "    \n",
    "    # 1. Labels benötigt für verschiedene Performance-Level\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    # Gruppiere nach Klassifikator und Target Performance\n",
    "    for classifier in savings_df['classifier'].unique():\n",
    "        for target in savings_df['target_performance'].unique():\n",
    "            data = savings_df[(savings_df['classifier'] == classifier) & \n",
    "                            (savings_df['target_performance'] == target)]\n",
    "            \n",
    "            if not data.empty:\n",
    "                strategies = [strategy_names_de.get(s, s) for s in data['strategy'].values]\n",
    "                labels_needed = data['avg_labels_needed'].values\n",
    "                errors = data['std_labels_needed'].values\n",
    "                \n",
    "                x = np.arange(len(strategies))\n",
    "                width = 0.2\n",
    "                offset = (target - 95) * width / 5  # Offset basierend auf target\n",
    "                \n",
    "                ax1.bar(x + offset, labels_needed, width, \n",
    "                       yerr=errors, capsize=5,\n",
    "                       label=f'{classifier} - {target}% der Baseline F1',\n",
    "                       alpha=0.7)\n",
    "    \n",
    "    ax1.set_xlabel('Strategie')\n",
    "    ax1.set_ylabel('Benötigte Labels')\n",
    "    ax1.set_title('Benötigte Labels zum Erreichen der Ziel-F1-Score-Leistung')\n",
    "    ax1.set_xticks(np.arange(len(strategies)))\n",
    "    ax1.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 2. Relative Einsparung gegenüber Random Sampling\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    # Pivot für Heatmap\n",
    "    pivot_savings = savings_df[savings_df['strategy'] != 'Random Sampling'].pivot_table(\n",
    "        values='relative_savings_pct',\n",
    "        index=['classifier', 'strategy'],\n",
    "        columns='target_performance',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    if not pivot_savings.empty and sns is not None:\n",
    "        sns.heatmap(pivot_savings, \n",
    "                    annot=True, \n",
    "                    fmt='.1f', \n",
    "                    cmap='RdYlGn',\n",
    "                    center=0,\n",
    "                    cbar_kws={'label': 'Label-Einsparung (%)'},\n",
    "                    ax=ax2)\n",
    "        ax2.set_title('Label-Einsparung vs. Zufällige Auswahl (%) - F1-Score basiert')\n",
    "        ax2.set_xlabel('Ziel F1-Score Leistung (% der Baseline)')\n",
    "    \n",
    "    # 3. Absolute Label-Anzahl pro Klassifikator bei 95% Performance\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    data_95 = savings_df[savings_df['target_performance'] == 95]\n",
    "    \n",
    "    classifiers = data_95['classifier'].unique()\n",
    "    strategies_orig = ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']\n",
    "    strategies_de = [strategy_names_de.get(s, s) for s in strategies_orig]\n",
    "    \n",
    "    x = np.arange(len(classifiers))\n",
    "    width = 0.2\n",
    "    \n",
    "    for i, (strategy_orig, strategy_de) in enumerate(zip(strategies_orig, strategies_de)):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for classifier in classifiers:\n",
    "            row = data_95[(data_95['classifier'] == classifier) & \n",
    "                         (data_95['strategy'] == strategy_orig)]\n",
    "            if not row.empty:\n",
    "                values.append(row['avg_labels_needed'].values[0])\n",
    "                errors.append(row['std_labels_needed'].values[0])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        ax3.bar(x + i*width - 1.5*width, values, width, \n",
    "               yerr=errors, capsize=5,\n",
    "               label=strategy_de, alpha=0.8)\n",
    "    \n",
    "    ax3.set_xlabel('Klassifikator')\n",
    "    ax3.set_ylabel('Benötigte Labels')\n",
    "    ax3.set_title('Benötigte Labels zum Erreichen von 95% der Baseline F1-Score-Leistung')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels(classifiers, rotation=45, ha='right')\n",
    "    ax3.legend()\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Referenzlinie bei 100% der Daten\n",
    "    n_total_samples = savings_df['avg_labels_needed'].max() * 1.1  # Schätzung\n",
    "    ax3.axhline(y=n_total_samples, color='red', linestyle='--', alpha=0.5, label='Vollständiger Datensatz')\n",
    "    \n",
    "    # 4. Zusammenfassungstabelle\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('tight')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Erstelle Zusammenfassungstabelle für 95% Performance\n",
    "    summary_data = []\n",
    "    for classifier in classifiers:\n",
    "        row_data = [classifier]\n",
    "        for strategy_orig in strategies_orig:\n",
    "            data = data_95[(data_95['classifier'] == classifier) & \n",
    "                          (data_95['strategy'] == strategy_orig)]\n",
    "            if not data.empty:\n",
    "                labels = data['avg_labels_needed'].values[0]\n",
    "                savings = data['savings_pct'].values[0]\n",
    "                row_data.append(f'{int(labels):,}\\n({savings:.1f}% gespart)')\n",
    "            else:\n",
    "                row_data.append('N/V')\n",
    "        summary_data.append(row_data)\n",
    "    \n",
    "    table = ax4.table(cellText=summary_data,\n",
    "                     colLabels=['Klassifikator'] + strategies_de,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1.2, 2)\n",
    "    \n",
    "    # Style the header row\n",
    "    for i in range(len(strategies_de) + 1):\n",
    "        table[(0, i)].set_facecolor('#40466e')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    ax4.set_title('Zusammenfassung: Benötigte Labels für 95% F1-Score-Leistung', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Speichern\n",
    "    filename = f'plots/{dataset_name.lower()}_f1_label_einsparungen_de.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"[ok] Deutsche F1-Score basierte Label-Einsparungsanalyse erstellt: {filename}\")\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return savings_df\n",
    "\n",
    "def create_label_savings_report(savings_df, dataset_name=\"Dachmaterial\"):\n",
    "    \"\"\"\n",
    "    Erstellt einen detaillierten Bericht über Label-Einsparungen basierend auf F1-Score.\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(f\"LABEL-EINSPARUNGS-BERICHT - {dataset_name} (F1-SCORE BASIERT)\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    # Für jedes Performance-Level\n",
    "    for target_perf in sorted(savings_df['target_performance'].unique()):\n",
    "        report.append(f\"\\nZIEL: {target_perf}% der Baseline F1-Score Performance\")\n",
    "        report.append(\"-\"*60)\n",
    "        \n",
    "        target_data = savings_df[savings_df['target_performance'] == target_perf]\n",
    "        \n",
    "        # Nach Klassifikator gruppieren\n",
    "        for classifier in sorted(target_data['classifier'].unique()):\n",
    "            classifier_data = target_data[target_data['classifier'] == classifier]\n",
    "            baseline_f1 = classifier_data['random_100_f1'].iloc[0]\n",
    "            target_f1 = classifier_data['target_f1_score'].iloc[0]\n",
    "            \n",
    "            report.append(f\"\\n{classifier}:\")\n",
    "            report.append(f\"  Baseline F1-Score (Random 100%): {baseline_f1:.4f}\")\n",
    "            report.append(f\"  Ziel F1-Score: {target_f1:.4f}\")\n",
    "            report.append(f\"  Labels benötigt:\")\n",
    "            \n",
    "            # Sortiere nach Labels benötigt\n",
    "            sorted_data = classifier_data.sort_values('avg_labels_needed')\n",
    "            \n",
    "            for _, row in sorted_data.iterrows():\n",
    "                strategy = row['strategy']\n",
    "                labels = row['avg_labels_needed']\n",
    "                std = row['std_labels_needed']\n",
    "                savings = row['savings_pct']\n",
    "                rel_savings = row['relative_savings_pct']\n",
    "                \n",
    "                report.append(f\"    - {strategy:<20}: {int(labels):>6,} ± {int(std):>4} \"\n",
    "                            f\"({savings:>5.1f}% gespart)\")\n",
    "                \n",
    "                if strategy != 'Random Sampling' and rel_savings > 0:\n",
    "                    report.append(f\"      -> {rel_savings:.1f}% weniger Labels als Random Sampling\")\n",
    "    \n",
    "    # Beste Strategien\n",
    "    report.append(\"\\n\\nBESTE STRATEGIEN (bei 95% F1-Score Performance):\")\n",
    "    report.append(\"-\"*60)\n",
    "    \n",
    "    data_95 = savings_df[savings_df['target_performance'] == 95]\n",
    "    \n",
    "    for classifier in sorted(data_95['classifier'].unique()):\n",
    "        classifier_data = data_95[data_95['classifier'] == classifier]\n",
    "        best_row = classifier_data.loc[classifier_data['avg_labels_needed'].idxmin()]\n",
    "        \n",
    "        report.append(f\"{classifier}: {best_row['strategy']} \"\n",
    "                     f\"(nur {int(best_row['avg_labels_needed']):,} Labels = \"\n",
    "                     f\"{best_row['savings_pct']:.1f}% Einsparung)\")\n",
    "    \n",
    "    # Durchschnittliche Einsparungen\n",
    "    report.append(\"\\n\\nDURCHSCHNITTLICHE EINSPARUNGEN ÜBER ALLE KLASSIFIKATOREN:\")\n",
    "    report.append(\"-\"*60)\n",
    "    \n",
    "    avg_savings = data_95.groupby('strategy')['relative_savings_pct'].mean()\n",
    "    for strategy, savings in avg_savings.items():\n",
    "        if strategy != 'Random Sampling':\n",
    "            report.append(f\"{strategy}: {savings:.1f}% weniger Labels als Random Sampling\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Ausgabe und Speichern\n",
    "    report_text = \"\\n\".join(report)\n",
    "    print(report_text)\n",
    "    \n",
    "    filename = f'reports/{dataset_name.lower()}_f1_label_einsparungsbericht.txt'\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    logger.info(f\"[ok] F1-Score basierter Label-Einsparungsbericht gespeichert: {filename}\")\n",
    "    \n",
    "    return report_text\n",
    "\n",
    "# ## 11. Hauptprogramm\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Haupteinstiegspunkt für das erweiterte Active Learning Experiment für Dachmaterial mit F1-Score.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ACTIVE LEARNING AUF DACHMATERIAL - F1-SCORE VERSION MIT DEUTSCHEN PLOTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # System Info\n",
    "    print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"NumPy Version: {np.__version__}\")\n",
    "    print(f\"Pandas Version: {pd.__version__}\")\n",
    "    print(f\"Scikit-learn Version: {sklearn.__version__}\")\n",
    "    print(f\"SciPy Version: {scipy.__version__}\")\n",
    "    \n",
    "    # Device Info\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"Verwende GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    else:\n",
    "        print(\"Verwende CPU (keine GPU gefunden)\")\n",
    "    \n",
    "    print(f\"\\nExperiment-Konfiguration:\")\n",
    "    print(f\"- Hauptmetrik: F1-Score (Macro Average)\")\n",
    "    print(f\"- Anzahl Runs: {N_RUNS}\")\n",
    "    print(f\"- Budget-Stufen: {[f'{int(b*100)}%' for b in BUDGET_PERCENTAGES]}\")\n",
    "    print(f\"- Batch-Größe: {BATCH_SIZE}\")\n",
    "    print(f\"- Signifikanzniveau: {SIGNIFICANCE_LEVEL}\")\n",
    "    print(f\"- Mindest-Samples pro Klasse: {MIN_SAMPLES_PER_CLASS}\")\n",
    "    print(f\"- Visualisierungen: Deutsch mit adaptiver Skalierung\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Daten laden\n",
    "    try:\n",
    "        X_train, y_train, X_test, y_test, label_encoder, preprocessor = load_dachmaterial_data()\n",
    "        \n",
    "        # Speichere wichtige Variablen für spätere Verwendung\n",
    "        input_dim = X_train.shape[1]\n",
    "        n_classes = len(np.unique(y_train))\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Kritischer Fehler beim Laden der Daten: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    # Klassifikatoren und Strategien definieren\n",
    "    classifiers = ['Neural Network', 'Naive Bayes', 'Random Forest', 'Logistic Regression', 'SVM']\n",
    "    strategies = [\n",
    "        ('Random Sampling', random_sampling),\n",
    "        ('Entropy Sampling', entropy_sampling),\n",
    "        ('Margin Sampling', margin_sampling),\n",
    "        ('Least Confidence', least_confidence_sampling)\n",
    "    ]\n",
    "    \n",
    "    # Experimente durchführen\n",
    "    all_results = []\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    total_experiments = len(classifiers) * len(strategies)\n",
    "    current_experiment = 0\n",
    "    \n",
    "    for classifier_name in classifiers:\n",
    "        for strategy_name, strategy_func in strategies:\n",
    "            current_experiment += 1\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Experiment {current_experiment}/{total_experiments}: {classifier_name} + {strategy_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            experiment_start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                results = run_active_learning_experiment(\n",
    "                    X_train, y_train, X_test, y_test,\n",
    "                    classifier_name, strategy_name, strategy_func,\n",
    "                    BUDGET_PERCENTAGES, BATCH_SIZE,\n",
    "                    input_dim=input_dim, n_classes=n_classes\n",
    "                )\n",
    "                all_results.extend(results)\n",
    "                \n",
    "                experiment_time = time.time() - experiment_start_time\n",
    "                print(f\"\\n[ok] {classifier_name} + {strategy_name} abgeschlossen in {experiment_time/60:.1f} Minuten\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Kritischer Fehler bei {classifier_name} + {strategy_name}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    # Gesamtzeit\n",
    "    total_time = time.time() - total_start_time\n",
    "    print(f\"\\n[ok] Alle Experimente abgeschlossen in {total_time/60:.1f} Minuten\")\n",
    "    \n",
    "    # Überprüfe ob Ergebnisse vorhanden sind\n",
    "    if not all_results:\n",
    "        logger.error(\"Keine Experimenteergebnisse vorhanden!\")\n",
    "        return 1\n",
    "    \n",
    "    # Ergebnisse in DataFrame konvertieren für statistische Analyse\n",
    "    try:\n",
    "        results_df = pd.DataFrame([{\n",
    "            'classifier': r['classifier'],\n",
    "            'strategy': r['strategy'],\n",
    "            'budget_pct': r['budget_pct'],\n",
    "            'run': r['run'],\n",
    "            'n_labeled': r['n_labeled'],\n",
    "            'accuracy': r['accuracy'],\n",
    "            'f1_score': r['f1_score'],\n",
    "            'avg_query_time': r.get('avg_query_time', 0),\n",
    "            'avg_train_time': r.get('avg_train_time', 0)\n",
    "        } for r in all_results])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Erstellen des Results DataFrame: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    # Statistische Analyse durchführen mit F1-Score\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Führe statistische Analyse durch (F1-Score)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        stat_results = perform_statistical_analysis(results_df, metric='f1_score')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der statistischen Analyse: {e}\")\n",
    "        stat_results = pd.DataFrame()\n",
    "    \n",
    "    # Statistischen Bericht erstellen\n",
    "    try:\n",
    "        statistical_report = create_statistical_report(stat_results)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Erstellen des statistischen Berichts: {e}\")\n",
    "    \n",
    "    # Label-Einsparungs-Analyse mit F1-Score\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Berechne Label-Einsparungen (F1-Score basiert)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Berechne Label-Einsparungen für verschiedene Performance-Level\n",
    "        savings_df = calculate_label_savings(all_results, target_performance_percentages=[0.90, 0.95, 0.98])\n",
    "        \n",
    "        # Visualisiere Label-Einsparungen\n",
    "        plot_label_savings(savings_df, dataset_name=\"Dachmaterial\")\n",
    "        \n",
    "        # Erstelle detaillierten Bericht\n",
    "        label_savings_report = create_label_savings_report(savings_df, dataset_name=\"Dachmaterial\")\n",
    "        \n",
    "        # Speichere als CSV\n",
    "        savings_csv = 'results/dachmaterial_f1_label_einsparungen.csv'\n",
    "        savings_df.to_csv(savings_csv, index=False)\n",
    "        print(f\"[ok] F1-Score basierte Label-Einsparungen gespeichert: {savings_csv}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der Label-Einsparungs-Analyse: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # Ergebnisse visualisieren (deutsche Beschriftungen)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Erstelle Visualisierungen (F1-Score basiert, deutsche Beschriftungen)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Pro Klassifikator mit Signifikanz\n",
    "        plot_per_classifier_with_significance(all_results, stat_results)\n",
    "        \n",
    "        # Statistische Zusammenfassung\n",
    "        plot_statistical_summary(stat_results)\n",
    "        \n",
    "        # Finale Vergleichsmatrix\n",
    "        plot_final_comparison(all_results)\n",
    "        \n",
    "        # Improvement Analyse\n",
    "        plot_improvement_analysis(all_results)\n",
    "        \n",
    "        print(\"[ok] Alle deutschen F1-Score basierten Visualisierungen mit adaptiver Skalierung erstellt\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der Visualisierung: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # Ergebnisse speichern\n",
    "    try:\n",
    "        # Detaillierte Ergebnisse\n",
    "        csv_filename = 'results/dachmaterial_f1_active_learning_ergebnisse.csv'\n",
    "        results_df.to_csv(csv_filename, index=False)\n",
    "        print(f\"\\n[ok] F1-Score Ergebnisse gespeichert in: {csv_filename}\")\n",
    "        \n",
    "        # Statistische Ergebnisse\n",
    "        if not stat_results.empty:\n",
    "            stat_csv_filename = 'results/dachmaterial_f1_statistische_analyse.csv'\n",
    "            stat_results.to_csv(stat_csv_filename, index=False)\n",
    "            print(f\"[ok] Statistische F1-Score Analyse gespeichert in: {stat_csv_filename}\")\n",
    "        \n",
    "        # Zusammenfassung als Excel (wenn verfügbar)\n",
    "        if EXCEL_AVAILABLE:\n",
    "            excel_filename = 'results/dachmaterial_f1_active_learning_zusammenfassung.xlsx'\n",
    "            try:\n",
    "                with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "                    # Raw results\n",
    "                    results_df.to_excel(writer, sheet_name='Rohdaten', index=False)\n",
    "                    \n",
    "                    # Statistical analysis\n",
    "                    if not stat_results.empty:\n",
    "                        stat_results.to_excel(writer, sheet_name='Statistische Analyse', index=False)\n",
    "                    \n",
    "                    # Summary by classifier and strategy\n",
    "                    summary = results_df.groupby(['classifier', 'strategy', 'budget_pct'])[['accuracy', 'f1_score']].agg(['mean', 'std'])\n",
    "                    summary.to_excel(writer, sheet_name='Zusammenfassung Statistik')\n",
    "                    \n",
    "                    # Best combinations at 100% budget\n",
    "                    final_results = results_df[results_df['budget_pct'] == 1.0]\n",
    "                    if not final_results.empty:\n",
    "                        best_combinations = final_results.groupby(['classifier', 'strategy'])[['accuracy', 'f1_score']].mean()\n",
    "                        best_combinations = best_combinations.sort_values('f1_score', ascending=False)\n",
    "                        best_combinations.to_excel(writer, sheet_name='Beste Kombinationen')\n",
    "                    \n",
    "                    # Significant improvements\n",
    "                    if not stat_results.empty and 'significant' in stat_results.columns:\n",
    "                        sig_improvements = stat_results[stat_results['significant']].sort_values('cliffs_delta', ascending=False)\n",
    "                        if not sig_improvements.empty:\n",
    "                            sig_improvements.to_excel(writer, sheet_name='Signifikante Verbesserungen', index=False)\n",
    "                    \n",
    "                    # Label savings\n",
    "                    if 'savings_df' in locals() and not savings_df.empty:\n",
    "                        savings_df.to_excel(writer, sheet_name='Label-Einsparungen', index=False)\n",
    "                \n",
    "                print(f\"[ok] F1-Score Zusammenfassung gespeichert in: {excel_filename}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Fehler beim Excel-Export: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Speichern der Ergebnisse: {e}\")\n",
    "    \n",
    "    # Abschlusszusammenfassung\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPERIMENT ERFOLGREICH ABGESCHLOSSEN (F1-SCORE VERSION MIT DEUTSCHEN PLOTS)\")\n",
    "    print(f\"Hauptmetrik: F1-Score (Macro Average)\")\n",
    "    print(f\"Gesamtanzahl Experimente: {len(all_results)}\")\n",
    "    print(f\"Datensatzgröße: {len(y_train):,} Trainingssamples\")\n",
    "    print(f\"Klassifikatoren: {len(classifiers)}\")\n",
    "    print(f\"Query-Strategien: {len(strategies)}\")\n",
    "    print(f\"Budget-Stufen: {len(BUDGET_PERCENTAGES)}\")\n",
    "    print(f\"Wiederholungen pro Experiment: {N_RUNS}\")\n",
    "    \n",
    "    # Statistische Zusammenfassung\n",
    "    if not stat_results.empty:\n",
    "        total_comparisons = len(stat_results)\n",
    "        significant_count = stat_results['significant'].sum() if 'significant' in stat_results.columns else 0\n",
    "        print(f\"\\nStatistische Analyse (F1-Score):\")\n",
    "        print(f\"- Anzahl Vergleiche: {total_comparisons}\")\n",
    "        print(f\"- Signifikante F1-Score Verbesserungen: {significant_count} ({significant_count/total_comparisons*100:.1f}%)\")\n",
    "        print(f\"- Verwendeter Test: Wilcoxon Signed-Rank Test\")\n",
    "        print(f\"- Effektstärkemaß: Cliff's Delta\")\n",
    "        print(f\"- Multiple Vergleiche: Bonferroni-Korrektur\")\n",
    "    \n",
    "    print(\"\\nF1-Score basierte Label-Einsparungsanalyse durchgeführt!\")\n",
    "    print(\"- Visualisierung: plots/dachmaterial_f1_label_einsparungen_de.png\")\n",
    "    print(\"- Bericht: reports/dachmaterial_f1_label_einsparungsbericht.txt\")\n",
    "    print(\"\\nAlle Visualisierungen verwenden deutsche Beschriftungen und adaptive Skalierung!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# ## 12. Ausführung\n",
    "\n",
    "# Führe das Hauptprogramm aus\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        exit_code = main()\n",
    "        print(f\"\\nProgramm beendet mit Exit-Code: {exit_code}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unerwarteter Fehler im Hauptprogramm: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        exit_code = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
