{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70075094-8b7b-47b7-ab66-31bde6593fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:39:05 [INFO] Jupyter/IPython Umgebung erkannt - UTF-8 Handling bereits aktiv\n",
      "================================================================================\n",
      "ACTIVE LEARNING AUF DACHMATERIAL - F1-SCORE VERSION\n",
      "================================================================================\n",
      "Python Version: 3.13.4\n",
      "PyTorch Version: 2.7.0+cpu\n",
      "NumPy Version: 2.2.6\n",
      "Pandas Version: 2.2.3\n",
      "Scikit-learn Version: 1.6.1\n",
      "SciPy Version: 1.15.3\n",
      "Verwende CPU (keine GPU gefunden)\n",
      "\n",
      "Experiment-Konfiguration:\n",
      "- Hauptmetrik: F1-Score (Macro Average)\n",
      "- Anzahl Runs: 5\n",
      "- Budget-Stufen: ['20%', '40%', '60%', '80%', '100%']\n",
      "- Batch-Größe: 500\n",
      "- Signifikanzniveau: 0.05\n",
      "- Mindest-Samples pro Klasse: 20\n",
      "================================================================================\n",
      "14:39:05 [INFO] Lade vollständigen Dachmaterial-Datensatz...\n",
      "14:39:05 [INFO] [ok] Datensatz geladen: 8,213 Zeilen, 10 Spalten\n",
      "14:39:05 [INFO] Ursprüngliche Klassen-Verteilung:\n",
      "mat_qgis\n",
      "Ziegel                4112\n",
      "Metallbahn            1212\n",
      "Asbest|Faserzement     892\n",
      "Beton                  838\n",
      "Bitumen                734\n",
      "PVC|Polycarbonat       140\n",
      "Schiefer               128\n",
      "Glas                   119\n",
      "Dachbegrünung           24\n",
      "Kunststoffbahn          12\n",
      "Kupfer                   2\n",
      "Name: count, dtype: int64\n",
      "14:39:05 [WARNING] Entferne Klassen mit weniger als 20 Samples:\n",
      "14:39:05 [WARNING]   - Kunststoffbahn: 12 Samples\n",
      "14:39:05 [WARNING]   - Kupfer: 2 Samples\n",
      "14:39:05 [INFO] Gefilterte Klassen-Verteilung:\n",
      "mat_qgis\n",
      "Ziegel                4112\n",
      "Metallbahn            1212\n",
      "Asbest|Faserzement     892\n",
      "Beton                  838\n",
      "Bitumen                734\n",
      "PVC|Polycarbonat       140\n",
      "Schiefer               128\n",
      "Glas                   119\n",
      "Dachbegrünung           24\n",
      "Name: count, dtype: int64\n",
      "14:39:05 [INFO] [ok] Dachmaterial-Datensatz vorbereitet: 8,199 Samples\n",
      "14:39:05 [INFO]   Klassen: 9 - Asbest|Faserzement, Beton, Bitumen, Dachbegrünung, Glas, Metallbahn, PVC|Polycarbonat, Schiefer, Ziegel\n",
      "14:39:05 [INFO] Klassen im Trainingsset: 9\n",
      "14:39:05 [INFO] Klassen im Testset: 9\n",
      "14:39:05 [INFO] [ok] Daten vorbereitet: 6,559 Trainingssamples, 1,640 Testsamples\n",
      "14:39:05 [INFO]   Feature-Dimension nach Preprocessing: 28\n",
      "14:39:05 [INFO]   Klassen: 9 im Training, 9 im Test\n",
      "14:39:05 [INFO]   Speicherbedarf: 0.9 MB\n",
      "\n",
      "============================================================\n",
      "Experiment 1/20: Neural Network + Random Sampling\n",
      "============================================================\n",
      "14:39:05 [INFO] \n",
      "Neural Network + Random Sampling - Budget: 20% (1,311 Samples)\n",
      "14:39:05 [INFO]   Run 1/5\n",
      "14:39:12 [INFO]     1,311 labeled -> F1-Score: 0.1927 (Train: 0.6s, Query: 0.00s)\n",
      "14:39:13 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5287, F1: 0.1820\n",
      "14:39:13 [INFO]   Run 2/5\n",
      "14:39:16 [INFO]     1,311 labeled -> F1-Score: 0.1618 (Train: 0.6s, Query: 0.00s)\n",
      "14:39:17 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5439, F1: 0.1862\n",
      "14:39:17 [INFO]   Run 3/5\n",
      "14:39:19 [INFO]     1,311 labeled -> F1-Score: 0.2028 (Train: 0.6s, Query: 0.00s)\n",
      "14:39:20 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5323, F1: 0.1711\n",
      "14:39:20 [INFO]   Run 4/5\n",
      "14:39:23 [INFO]     1,311 labeled -> F1-Score: 0.1615 (Train: 0.7s, Query: 0.00s)\n",
      "14:39:24 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5311, F1: 0.1652\n",
      "14:39:24 [INFO]   Run 5/5\n",
      "14:39:27 [INFO]     1,311 labeled -> F1-Score: 0.1801 (Train: 0.6s, Query: 0.00s)\n",
      "14:39:28 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5238, F1: 0.1757\n",
      "14:39:28 [INFO] \n",
      "Neural Network + Random Sampling - Budget: 40% (2,623 Samples)\n",
      "14:39:28 [INFO]   Run 1/5\n",
      "14:39:34 [INFO]     2,623 labeled -> F1-Score: 0.1754 (Train: 1.7s, Query: 0.00s)\n",
      "14:39:37 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5329, F1: 0.1812\n",
      "14:39:37 [INFO]   Run 2/5\n",
      "14:39:46 [INFO]     2,623 labeled -> F1-Score: 0.1915 (Train: 1.4s, Query: 0.00s)\n",
      "14:39:49 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5396, F1: 0.1781\n",
      "14:39:49 [INFO]   Run 3/5\n",
      "14:39:55 [INFO]     2,623 labeled -> F1-Score: 0.1685 (Train: 1.4s, Query: 0.00s)\n",
      "14:39:58 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5402, F1: 0.1892\n",
      "14:39:58 [INFO]   Run 4/5\n",
      "14:40:04 [INFO]     2,623 labeled -> F1-Score: 0.1816 (Train: 1.4s, Query: 0.00s)\n",
      "14:40:07 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5378, F1: 0.1786\n",
      "14:40:07 [INFO]   Run 5/5\n",
      "14:40:12 [INFO]     2,623 labeled -> F1-Score: 0.1749 (Train: 1.4s, Query: 0.00s)\n",
      "14:40:15 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5341, F1: 0.1665\n",
      "14:40:15 [INFO] \n",
      "Neural Network + Random Sampling - Budget: 60% (3,935 Samples)\n",
      "14:40:15 [INFO]   Run 1/5\n",
      "14:40:25 [INFO]     3,935 labeled -> F1-Score: 0.1843 (Train: 1.9s, Query: 0.00s)\n",
      "14:40:29 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5390, F1: 0.1758\n",
      "14:40:29 [INFO]   Run 2/5\n",
      "14:40:38 [INFO]     3,935 labeled -> F1-Score: 0.1745 (Train: 1.9s, Query: 0.00s)\n",
      "14:40:42 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5378, F1: 0.1726\n",
      "14:40:42 [INFO]   Run 3/5\n",
      "14:40:51 [INFO]     3,935 labeled -> F1-Score: 0.1694 (Train: 2.0s, Query: 0.00s)\n",
      "14:40:55 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5384, F1: 0.1704\n",
      "14:40:55 [INFO]   Run 4/5\n",
      "14:41:04 [INFO]     3,935 labeled -> F1-Score: 0.1845 (Train: 1.8s, Query: 0.00s)\n",
      "14:41:08 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5402, F1: 0.1826\n",
      "14:41:08 [INFO]   Run 5/5\n",
      "14:41:17 [INFO]     3,935 labeled -> F1-Score: 0.1659 (Train: 1.8s, Query: 0.00s)\n",
      "14:41:21 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5427, F1: 0.1842\n",
      "14:41:21 [INFO] \n",
      "Neural Network + Random Sampling - Budget: 80% (5,247 Samples)\n",
      "14:41:21 [INFO]   Run 1/5\n",
      "14:41:36 [INFO]     5,247 labeled -> F1-Score: 0.1779 (Train: 2.5s, Query: 0.00s)\n",
      "14:41:42 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5512, F1: 0.1834\n",
      "14:41:42 [INFO]   Run 2/5\n",
      "14:41:57 [INFO]     5,247 labeled -> F1-Score: 0.1865 (Train: 2.6s, Query: 0.00s)\n",
      "14:42:03 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5482, F1: 0.1863\n",
      "14:42:03 [INFO]   Run 3/5\n",
      "14:42:18 [INFO]     5,247 labeled -> F1-Score: 0.1735 (Train: 2.4s, Query: 0.00s)\n",
      "14:42:23 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5366, F1: 0.1604\n",
      "14:42:23 [INFO]   Run 4/5\n",
      "14:42:39 [INFO]     5,247 labeled -> F1-Score: 0.1780 (Train: 2.7s, Query: 0.00s)\n",
      "14:42:44 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5451, F1: 0.1874\n",
      "14:42:44 [INFO]   Run 5/5\n",
      "14:42:59 [INFO]     5,247 labeled -> F1-Score: 0.1820 (Train: 2.2s, Query: 0.00s)\n",
      "14:43:03 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5348, F1: 0.1657\n",
      "14:43:03 [INFO] \n",
      "Neural Network + Random Sampling - Budget: 100% (6,559 Samples)\n",
      "14:43:03 [INFO]   Run 1/5\n",
      "14:43:22 [INFO]     6,559 labeled -> F1-Score: 0.1741 (Train: 2.8s, Query: 0.00s)\n",
      "14:43:29 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5390, F1: 0.1739\n",
      "14:43:29 [INFO]   Run 2/5\n",
      "14:43:49 [INFO]     6,559 labeled -> F1-Score: 0.1951 (Train: 2.8s, Query: 0.00s)\n",
      "14:43:55 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5494, F1: 0.1827\n",
      "14:43:55 [INFO]   Run 3/5\n",
      "14:44:16 [INFO]     6,559 labeled -> F1-Score: 0.1865 (Train: 3.1s, Query: 0.00s)\n",
      "14:44:23 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5445, F1: 0.1860\n",
      "14:44:23 [INFO]   Run 4/5\n",
      "14:44:45 [INFO]     6,559 labeled -> F1-Score: 0.1931 (Train: 3.0s, Query: 0.00s)\n",
      "14:44:51 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5463, F1: 0.1831\n",
      "14:44:51 [INFO]   Run 5/5\n",
      "14:45:13 [INFO]     6,559 labeled -> F1-Score: 0.1750 (Train: 3.0s, Query: 0.00s)\n",
      "14:45:19 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5476, F1: 0.1815\n",
      "\n",
      "[ok] Neural Network + Random Sampling abgeschlossen in 6.2 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 2/20: Neural Network + Entropy Sampling\n",
      "============================================================\n",
      "14:45:19 [INFO] \n",
      "Neural Network + Entropy Sampling - Budget: 20% (1,311 Samples)\n",
      "14:45:19 [INFO]   Run 1/5\n",
      "14:45:21 [INFO]     1,311 labeled -> F1-Score: 0.1429 (Train: 0.6s, Query: 0.02s)\n",
      "14:45:23 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4860, F1: 0.1844\n",
      "14:45:23 [INFO]   Run 2/5\n",
      "14:45:25 [INFO]     1,311 labeled -> F1-Score: 0.1582 (Train: 0.6s, Query: 0.02s)\n",
      "14:45:26 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5043, F1: 0.1736\n",
      "14:45:26 [INFO]   Run 3/5\n",
      "14:45:28 [INFO]     1,311 labeled -> F1-Score: 0.1624 (Train: 0.6s, Query: 0.02s)\n",
      "14:45:30 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5152, F1: 0.1643\n",
      "14:45:30 [INFO]   Run 4/5\n",
      "14:45:32 [INFO]     1,311 labeled -> F1-Score: 0.1417 (Train: 0.6s, Query: 0.02s)\n",
      "14:45:33 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4524, F1: 0.1651\n",
      "14:45:33 [INFO]   Run 5/5\n",
      "14:45:35 [INFO]     1,311 labeled -> F1-Score: 0.1591 (Train: 0.6s, Query: 0.01s)\n",
      "14:45:37 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4902, F1: 0.1810\n",
      "14:45:37 [INFO] \n",
      "Neural Network + Entropy Sampling - Budget: 40% (2,623 Samples)\n",
      "14:45:37 [INFO]   Run 1/5\n",
      "14:45:42 [INFO]     2,623 labeled -> F1-Score: 0.1693 (Train: 1.3s, Query: 0.01s)\n",
      "14:45:45 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5335, F1: 0.1701\n",
      "14:45:45 [INFO]   Run 2/5\n",
      "14:45:50 [INFO]     2,623 labeled -> F1-Score: 0.1665 (Train: 1.3s, Query: 0.01s)\n",
      "14:45:53 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5159, F1: 0.1710\n",
      "14:45:53 [INFO]   Run 3/5\n",
      "14:45:58 [INFO]     2,623 labeled -> F1-Score: 0.1808 (Train: 1.3s, Query: 0.01s)\n",
      "14:46:01 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5488, F1: 0.1921\n",
      "14:46:01 [INFO]   Run 4/5\n",
      "14:46:06 [INFO]     2,623 labeled -> F1-Score: 0.1463 (Train: 1.3s, Query: 0.01s)\n",
      "14:46:09 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5134, F1: 0.1475\n",
      "14:46:09 [INFO]   Run 5/5\n",
      "14:46:14 [INFO]     2,623 labeled -> F1-Score: 0.1697 (Train: 1.4s, Query: 0.01s)\n",
      "14:46:17 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5366, F1: 0.1925\n",
      "14:46:17 [INFO] \n",
      "Neural Network + Entropy Sampling - Budget: 60% (3,935 Samples)\n",
      "14:46:17 [INFO]   Run 1/5\n",
      "14:46:26 [INFO]     3,935 labeled -> F1-Score: 0.1807 (Train: 1.8s, Query: 0.01s)\n",
      "14:46:30 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5433, F1: 0.1920\n",
      "14:46:30 [INFO]   Run 2/5\n",
      "14:46:39 [INFO]     3,935 labeled -> F1-Score: 0.1909 (Train: 1.9s, Query: 0.01s)\n",
      "14:46:43 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5427, F1: 0.1865\n",
      "14:46:43 [INFO]   Run 3/5\n",
      "14:46:52 [INFO]     3,935 labeled -> F1-Score: 0.1829 (Train: 1.9s, Query: 0.01s)\n",
      "14:46:56 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5463, F1: 0.1963\n",
      "14:46:56 [INFO]   Run 4/5\n",
      "14:47:05 [INFO]     3,935 labeled -> F1-Score: 0.1770 (Train: 1.7s, Query: 0.01s)\n",
      "14:47:08 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5549, F1: 0.1981\n",
      "14:47:08 [INFO]   Run 5/5\n",
      "14:47:17 [INFO]     3,935 labeled -> F1-Score: 0.1626 (Train: 1.7s, Query: 0.01s)\n",
      "14:47:20 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5451, F1: 0.1807\n",
      "14:47:20 [INFO] \n",
      "Neural Network + Entropy Sampling - Budget: 80% (5,247 Samples)\n",
      "14:47:20 [INFO]   Run 1/5\n",
      "14:47:35 [INFO]     5,247 labeled -> F1-Score: 0.1847 (Train: 2.3s, Query: 0.01s)\n",
      "14:47:40 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1840\n",
      "14:47:40 [INFO]   Run 2/5\n",
      "14:47:55 [INFO]     5,247 labeled -> F1-Score: 0.1950 (Train: 2.4s, Query: 0.01s)\n",
      "14:48:00 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5445, F1: 0.1884\n",
      "14:48:00 [INFO]   Run 3/5\n",
      "14:48:15 [INFO]     5,247 labeled -> F1-Score: 0.1829 (Train: 2.4s, Query: 0.01s)\n",
      "14:48:19 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5524, F1: 0.1884\n",
      "14:48:19 [INFO]   Run 4/5\n",
      "14:48:33 [INFO]     5,247 labeled -> F1-Score: 0.1921 (Train: 2.3s, Query: 0.00s)\n",
      "14:48:38 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5476, F1: 0.1902\n",
      "14:48:38 [INFO]   Run 5/5\n",
      "14:48:54 [INFO]     5,247 labeled -> F1-Score: 0.1899 (Train: 2.4s, Query: 0.01s)\n",
      "14:48:58 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5409, F1: 0.1862\n",
      "14:48:58 [INFO] \n",
      "Neural Network + Entropy Sampling - Budget: 100% (6,559 Samples)\n",
      "14:48:58 [INFO]   Run 1/5\n",
      "14:49:19 [INFO]     6,559 labeled -> F1-Score: 0.1942 (Train: 2.8s, Query: 0.00s)\n",
      "14:49:25 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5439, F1: 0.1815\n",
      "14:49:25 [INFO]   Run 2/5\n",
      "14:49:45 [INFO]     6,559 labeled -> F1-Score: 0.1992 (Train: 2.8s, Query: 0.00s)\n",
      "14:49:51 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5384, F1: 0.1788\n",
      "14:49:51 [INFO]   Run 3/5\n",
      "14:50:11 [INFO]     6,559 labeled -> F1-Score: 0.2025 (Train: 2.9s, Query: 0.00s)\n",
      "14:50:18 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5427, F1: 0.1896\n",
      "14:50:18 [INFO]   Run 4/5\n",
      "14:50:38 [INFO]     6,559 labeled -> F1-Score: 0.1953 (Train: 2.8s, Query: 0.00s)\n",
      "14:50:45 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5494, F1: 0.1841\n",
      "14:50:45 [INFO]   Run 5/5\n",
      "14:51:05 [INFO]     6,559 labeled -> F1-Score: 0.1951 (Train: 2.9s, Query: 0.00s)\n",
      "14:51:12 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5524, F1: 0.1859\n",
      "\n",
      "[ok] Neural Network + Entropy Sampling abgeschlossen in 5.9 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 3/20: Neural Network + Margin Sampling\n",
      "============================================================\n",
      "14:51:12 [INFO] \n",
      "Neural Network + Margin Sampling - Budget: 20% (1,311 Samples)\n",
      "14:51:12 [INFO]   Run 1/5\n",
      "14:51:14 [INFO]     1,311 labeled -> F1-Score: 0.1733 (Train: 0.6s, Query: 0.01s)\n",
      "14:51:15 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5207, F1: 0.1740\n",
      "14:51:15 [INFO]   Run 2/5\n",
      "14:51:17 [INFO]     1,311 labeled -> F1-Score: 0.1493 (Train: 0.5s, Query: 0.02s)\n",
      "14:51:19 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5165, F1: 0.1838\n",
      "14:51:19 [INFO]   Run 3/5\n",
      "14:51:21 [INFO]     1,311 labeled -> F1-Score: 0.1585 (Train: 0.5s, Query: 0.01s)\n",
      "14:51:22 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4890, F1: 0.1607\n",
      "14:51:22 [INFO]   Run 4/5\n",
      "14:51:24 [INFO]     1,311 labeled -> F1-Score: 0.1690 (Train: 0.5s, Query: 0.01s)\n",
      "14:51:25 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4811, F1: 0.1680\n",
      "14:51:25 [INFO]   Run 5/5\n",
      "14:51:27 [INFO]     1,311 labeled -> F1-Score: 0.1670 (Train: 0.6s, Query: 0.01s)\n",
      "14:51:29 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5104, F1: 0.1698\n",
      "14:51:29 [INFO] \n",
      "Neural Network + Margin Sampling - Budget: 40% (2,623 Samples)\n",
      "14:51:29 [INFO]   Run 1/5\n",
      "14:51:34 [INFO]     2,623 labeled -> F1-Score: 0.1842 (Train: 1.2s, Query: 0.01s)\n",
      "14:51:36 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5402, F1: 0.1936\n",
      "14:51:36 [INFO]   Run 2/5\n",
      "14:51:42 [INFO]     2,623 labeled -> F1-Score: 0.1728 (Train: 1.3s, Query: 0.01s)\n",
      "14:51:44 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5390, F1: 0.1825\n",
      "14:51:44 [INFO]   Run 3/5\n",
      "14:51:49 [INFO]     2,623 labeled -> F1-Score: 0.1874 (Train: 1.3s, Query: 0.01s)\n",
      "14:51:52 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5445, F1: 0.1846\n",
      "14:51:52 [INFO]   Run 4/5\n",
      "14:51:57 [INFO]     2,623 labeled -> F1-Score: 0.1666 (Train: 1.2s, Query: 0.01s)\n",
      "14:51:59 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5439, F1: 0.1867\n",
      "14:51:59 [INFO]   Run 5/5\n",
      "14:52:04 [INFO]     2,623 labeled -> F1-Score: 0.1842 (Train: 1.3s, Query: 0.01s)\n",
      "14:52:07 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5482, F1: 0.1853\n",
      "14:52:07 [INFO] \n",
      "Neural Network + Margin Sampling - Budget: 60% (3,935 Samples)\n",
      "14:52:07 [INFO]   Run 1/5\n",
      "14:52:15 [INFO]     3,935 labeled -> F1-Score: 0.1863 (Train: 1.6s, Query: 0.01s)\n",
      "14:52:19 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5427, F1: 0.1800\n",
      "14:52:19 [INFO]   Run 2/5\n",
      "14:52:27 [INFO]     3,935 labeled -> F1-Score: 0.1790 (Train: 1.7s, Query: 0.01s)\n",
      "14:52:30 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5439, F1: 0.1860\n",
      "14:52:30 [INFO]   Run 3/5\n",
      "14:52:39 [INFO]     3,935 labeled -> F1-Score: 0.1997 (Train: 1.6s, Query: 0.01s)\n",
      "14:52:42 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5488, F1: 0.1911\n",
      "14:52:42 [INFO]   Run 4/5\n",
      "14:52:50 [INFO]     3,935 labeled -> F1-Score: 0.1813 (Train: 1.6s, Query: 0.01s)\n",
      "14:52:54 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5433, F1: 0.1874\n",
      "14:52:54 [INFO]   Run 5/5\n",
      "14:53:01 [INFO]     3,935 labeled -> F1-Score: 0.1963 (Train: 1.6s, Query: 0.01s)\n",
      "14:53:05 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5421, F1: 0.1847\n",
      "14:53:05 [INFO] \n",
      "Neural Network + Margin Sampling - Budget: 80% (5,247 Samples)\n",
      "14:53:05 [INFO]   Run 1/5\n",
      "14:53:20 [INFO]     5,247 labeled -> F1-Score: 0.1909 (Train: 2.5s, Query: 0.00s)\n",
      "14:53:25 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5518, F1: 0.1878\n",
      "14:53:25 [INFO]   Run 2/5\n",
      "14:53:40 [INFO]     5,247 labeled -> F1-Score: 0.1925 (Train: 2.5s, Query: 0.01s)\n",
      "14:53:45 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5537, F1: 0.1906\n",
      "14:53:45 [INFO]   Run 3/5\n",
      "14:54:00 [INFO]     5,247 labeled -> F1-Score: 0.1762 (Train: 2.4s, Query: 0.01s)\n",
      "14:54:05 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5494, F1: 0.1845\n",
      "14:54:05 [INFO]   Run 4/5\n",
      "14:54:21 [INFO]     5,247 labeled -> F1-Score: 0.1818 (Train: 2.4s, Query: 0.00s)\n",
      "14:54:26 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5488, F1: 0.1931\n",
      "14:54:26 [INFO]   Run 5/5\n",
      "14:54:41 [INFO]     5,247 labeled -> F1-Score: 0.2000 (Train: 2.4s, Query: 0.01s)\n",
      "14:54:46 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5457, F1: 0.1856\n",
      "14:54:46 [INFO] \n",
      "Neural Network + Margin Sampling - Budget: 100% (6,559 Samples)\n",
      "14:54:46 [INFO]   Run 1/5\n",
      "14:55:07 [INFO]     6,559 labeled -> F1-Score: 0.1725 (Train: 3.0s, Query: 0.00s)\n",
      "14:55:14 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5354, F1: 0.1733\n",
      "14:55:14 [INFO]   Run 2/5\n",
      "14:55:36 [INFO]     6,559 labeled -> F1-Score: 0.1958 (Train: 2.9s, Query: 0.00s)\n",
      "14:55:42 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5433, F1: 0.1928\n",
      "14:55:42 [INFO]   Run 3/5\n",
      "14:56:03 [INFO]     6,559 labeled -> F1-Score: 0.1944 (Train: 3.0s, Query: 0.00s)\n",
      "14:56:09 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5476, F1: 0.1971\n",
      "14:56:09 [INFO]   Run 4/5\n",
      "14:56:31 [INFO]     6,559 labeled -> F1-Score: 0.1934 (Train: 2.9s, Query: 0.00s)\n",
      "14:56:37 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5421, F1: 0.1697\n",
      "14:56:37 [INFO]   Run 5/5\n",
      "14:56:58 [INFO]     6,559 labeled -> F1-Score: 0.1927 (Train: 3.1s, Query: 0.00s)\n",
      "14:57:05 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5482, F1: 0.1859\n",
      "\n",
      "[ok] Neural Network + Margin Sampling abgeschlossen in 5.9 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 4/20: Neural Network + Least Confidence\n",
      "============================================================\n",
      "14:57:05 [INFO] \n",
      "Neural Network + Least Confidence - Budget: 20% (1,311 Samples)\n",
      "14:57:05 [INFO]   Run 1/5\n",
      "14:57:07 [INFO]     1,311 labeled -> F1-Score: 0.1388 (Train: 0.6s, Query: 0.01s)\n",
      "14:57:08 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4951, F1: 0.1836\n",
      "14:57:08 [INFO]   Run 2/5\n",
      "14:57:10 [INFO]     1,311 labeled -> F1-Score: 0.1573 (Train: 0.6s, Query: 0.02s)\n",
      "14:57:12 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5134, F1: 0.1931\n",
      "14:57:12 [INFO]   Run 3/5\n",
      "14:57:14 [INFO]     1,311 labeled -> F1-Score: 0.1414 (Train: 0.6s, Query: 0.01s)\n",
      "14:57:15 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4939, F1: 0.1601\n",
      "14:57:15 [INFO]   Run 4/5\n",
      "14:57:17 [INFO]     1,311 labeled -> F1-Score: 0.1597 (Train: 0.6s, Query: 0.02s)\n",
      "14:57:19 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5213, F1: 0.1814\n",
      "14:57:19 [INFO]   Run 5/5\n",
      "14:57:21 [INFO]     1,311 labeled -> F1-Score: 0.1529 (Train: 0.6s, Query: 0.02s)\n",
      "14:57:22 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5220, F1: 0.1765\n",
      "14:57:22 [INFO] \n",
      "Neural Network + Least Confidence - Budget: 40% (2,623 Samples)\n",
      "14:57:22 [INFO]   Run 1/5\n",
      "14:57:27 [INFO]     2,623 labeled -> F1-Score: 0.1925 (Train: 1.3s, Query: 0.01s)\n",
      "14:57:30 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5415, F1: 0.1898\n",
      "14:57:30 [INFO]   Run 2/5\n",
      "14:57:35 [INFO]     2,623 labeled -> F1-Score: 0.1826 (Train: 1.2s, Query: 0.01s)\n",
      "14:57:38 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5488, F1: 0.1856\n",
      "14:57:38 [INFO]   Run 3/5\n",
      "14:57:43 [INFO]     2,623 labeled -> F1-Score: 0.1577 (Train: 1.3s, Query: 0.01s)\n",
      "14:57:45 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5177, F1: 0.1479\n",
      "14:57:45 [INFO]   Run 4/5\n",
      "14:57:51 [INFO]     2,623 labeled -> F1-Score: 0.1630 (Train: 1.3s, Query: 0.01s)\n",
      "14:57:53 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5335, F1: 0.1781\n",
      "14:57:53 [INFO]   Run 5/5\n",
      "14:57:59 [INFO]     2,623 labeled -> F1-Score: 0.1911 (Train: 1.3s, Query: 0.01s)\n",
      "14:58:01 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5378, F1: 0.1937\n",
      "14:58:01 [INFO] \n",
      "Neural Network + Least Confidence - Budget: 60% (3,935 Samples)\n",
      "14:58:01 [INFO]   Run 1/5\n",
      "14:58:10 [INFO]     3,935 labeled -> F1-Score: 0.1885 (Train: 1.8s, Query: 0.01s)\n",
      "14:58:14 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5470, F1: 0.1968\n",
      "14:58:14 [INFO]   Run 2/5\n",
      "14:58:23 [INFO]     3,935 labeled -> F1-Score: 0.1803 (Train: 1.8s, Query: 0.01s)\n",
      "14:58:27 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1805\n",
      "14:58:27 [INFO]   Run 3/5\n",
      "14:58:36 [INFO]     3,935 labeled -> F1-Score: 0.1949 (Train: 1.8s, Query: 0.01s)\n",
      "14:58:40 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5451, F1: 0.1892\n",
      "14:58:40 [INFO]   Run 4/5\n",
      "14:58:48 [INFO]     3,935 labeled -> F1-Score: 0.1752 (Train: 1.8s, Query: 0.01s)\n",
      "14:58:52 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5537, F1: 0.1991\n",
      "14:58:52 [INFO]   Run 5/5\n",
      "14:59:01 [INFO]     3,935 labeled -> F1-Score: 0.1840 (Train: 1.8s, Query: 0.01s)\n",
      "14:59:04 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1934\n",
      "14:59:04 [INFO] \n",
      "Neural Network + Least Confidence - Budget: 80% (5,247 Samples)\n",
      "14:59:04 [INFO]   Run 1/5\n",
      "14:59:20 [INFO]     5,247 labeled -> F1-Score: 0.2001 (Train: 2.4s, Query: 0.01s)\n",
      "14:59:25 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5512, F1: 0.1940\n",
      "14:59:25 [INFO]   Run 2/5\n",
      "14:59:40 [INFO]     5,247 labeled -> F1-Score: 0.1965 (Train: 2.4s, Query: 0.01s)\n",
      "14:59:45 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5494, F1: 0.1915\n",
      "14:59:45 [INFO]   Run 3/5\n",
      "15:00:00 [INFO]     5,247 labeled -> F1-Score: 0.1836 (Train: 2.5s, Query: 0.00s)\n",
      "15:00:06 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5482, F1: 0.1910\n",
      "15:00:06 [INFO]   Run 4/5\n",
      "15:00:21 [INFO]     5,247 labeled -> F1-Score: 0.1882 (Train: 2.4s, Query: 0.00s)\n",
      "15:00:26 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5561, F1: 0.1999\n",
      "15:00:26 [INFO]   Run 5/5\n",
      "15:00:42 [INFO]     5,247 labeled -> F1-Score: 0.1987 (Train: 2.5s, Query: 0.00s)\n",
      "15:00:47 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5488, F1: 0.1952\n",
      "15:00:47 [INFO] \n",
      "Neural Network + Least Confidence - Budget: 100% (6,559 Samples)\n",
      "15:00:47 [INFO]   Run 1/5\n",
      "15:01:09 [INFO]     6,559 labeled -> F1-Score: 0.1931 (Train: 3.1s, Query: 0.00s)\n",
      "15:01:15 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1815\n",
      "15:01:15 [INFO]   Run 2/5\n",
      "15:01:36 [INFO]     6,559 labeled -> F1-Score: 0.1936 (Train: 2.8s, Query: 0.00s)\n",
      "15:01:42 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5463, F1: 0.1974\n",
      "15:01:42 [INFO]   Run 3/5\n",
      "15:02:03 [INFO]     6,559 labeled -> F1-Score: 0.1998 (Train: 2.8s, Query: 0.00s)\n",
      "15:02:08 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5488, F1: 0.2000\n",
      "15:02:08 [INFO]   Run 4/5\n",
      "15:02:29 [INFO]     6,559 labeled -> F1-Score: 0.2005 (Train: 2.8s, Query: 0.00s)\n",
      "15:02:35 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5384, F1: 0.1631\n",
      "15:02:35 [INFO]   Run 5/5\n",
      "15:02:55 [INFO]     6,559 labeled -> F1-Score: 0.1850 (Train: 2.9s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5537, F1: 0.1920\n",
      "\n",
      "[ok] Neural Network + Least Confidence abgeschlossen in 6.0 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 5/20: Naive Bayes + Random Sampling\n",
      "============================================================\n",
      "15:03:02 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 20% (1,311 Samples)\n",
      "15:03:02 [INFO]   Run 1/5\n",
      "15:03:02 [INFO]     1,311 labeled -> F1-Score: 0.0576 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0640, F1: 0.0640\n",
      "15:03:02 [INFO]   Run 2/5\n",
      "15:03:02 [INFO]     1,311 labeled -> F1-Score: 0.0682 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0659, F1: 0.0626\n",
      "15:03:02 [INFO]   Run 3/5\n",
      "15:03:02 [INFO]     1,311 labeled -> F1-Score: 0.0502 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0567, F1: 0.0539\n",
      "15:03:02 [INFO]   Run 4/5\n",
      "15:03:02 [INFO]     1,311 labeled -> F1-Score: 0.0498 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0488, F1: 0.0581\n",
      "15:03:02 [INFO]   Run 5/5\n",
      "15:03:02 [INFO]     1,311 labeled -> F1-Score: 0.0689 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0506, F1: 0.0500\n",
      "15:03:02 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 40% (2,623 Samples)\n",
      "15:03:02 [INFO]   Run 1/5\n",
      "15:03:02 [INFO]     2,623 labeled -> F1-Score: 0.0347 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0396, F1: 0.0347\n",
      "15:03:02 [INFO]   Run 2/5\n",
      "15:03:02 [INFO]     2,623 labeled -> F1-Score: 0.0407 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0378, F1: 0.0408\n",
      "15:03:02 [INFO]   Run 3/5\n",
      "15:03:02 [INFO]     2,623 labeled -> F1-Score: 0.0324 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0378, F1: 0.0327\n",
      "15:03:02 [INFO]   Run 4/5\n",
      "15:03:02 [INFO]     2,623 labeled -> F1-Score: 0.0385 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0348, F1: 0.0385\n",
      "15:03:02 [INFO]   Run 5/5\n",
      "15:03:02 [INFO]     2,623 labeled -> F1-Score: 0.0252 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0287, F1: 0.0252\n",
      "15:03:02 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 60% (3,935 Samples)\n",
      "15:03:02 [INFO]   Run 1/5\n",
      "15:03:02 [INFO]     3,935 labeled -> F1-Score: 0.0262 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:02 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0268, F1: 0.0318\n",
      "15:03:02 [INFO]   Run 2/5\n",
      "15:03:03 [INFO]     3,935 labeled -> F1-Score: 0.0308 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:03 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0280, F1: 0.0292\n",
      "15:03:03 [INFO]   Run 3/5\n",
      "15:03:03 [INFO]     3,935 labeled -> F1-Score: 0.0247 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:03 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0244, F1: 0.0227\n",
      "15:03:03 [INFO]   Run 4/5\n",
      "15:03:03 [INFO]     3,935 labeled -> F1-Score: 0.0230 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:03 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0244, F1: 0.0239\n",
      "15:03:03 [INFO]   Run 5/5\n",
      "15:03:03 [INFO]     3,935 labeled -> F1-Score: 0.0273 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:03 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0299, F1: 0.0279\n",
      "15:03:03 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 80% (5,247 Samples)\n",
      "15:03:03 [INFO]   Run 1/5\n",
      "15:03:03 [INFO]     5,247 labeled -> F1-Score: 0.0192 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:03 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0250, F1: 0.0243\n",
      "15:03:03 [INFO]   Run 2/5\n",
      "15:03:03 [INFO]     5,247 labeled -> F1-Score: 0.0299 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:03 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0262, F1: 0.0310\n",
      "15:03:03 [INFO]   Run 3/5\n",
      "15:03:03 [INFO]     5,247 labeled -> F1-Score: 0.0178 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:03 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0268, F1: 0.0252\n",
      "15:03:03 [INFO]   Run 4/5\n",
      "15:03:03 [INFO]     5,247 labeled -> F1-Score: 0.0283 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:03 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0250, F1: 0.0258\n",
      "15:03:03 [INFO]   Run 5/5\n",
      "15:03:03 [INFO]     5,247 labeled -> F1-Score: 0.0269 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:03 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0287, F1: 0.0282\n",
      "15:03:03 [INFO] \n",
      "Naive Bayes + Random Sampling - Budget: 100% (6,559 Samples)\n",
      "15:03:03 [INFO]   Run 1/5\n",
      "15:03:04 [INFO]     6,559 labeled -> F1-Score: 0.0289 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:04 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:04 [INFO]   Run 2/5\n",
      "15:03:04 [INFO]     6,559 labeled -> F1-Score: 0.0291 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:04 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:04 [INFO]   Run 3/5\n",
      "15:03:04 [INFO]     6,559 labeled -> F1-Score: 0.0327 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:04 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:04 [INFO]   Run 4/5\n",
      "15:03:04 [INFO]     6,559 labeled -> F1-Score: 0.0288 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:04 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:04 [INFO]   Run 5/5\n",
      "15:03:04 [INFO]     6,559 labeled -> F1-Score: 0.0277 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:04 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "\n",
      "[ok] Naive Bayes + Random Sampling abgeschlossen in 0.0 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 6/20: Naive Bayes + Entropy Sampling\n",
      "============================================================\n",
      "15:03:04 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 20% (1,311 Samples)\n",
      "15:03:04 [INFO]   Run 1/5\n",
      "15:03:04 [INFO]     1,311 labeled -> F1-Score: 0.0761 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:04 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0701, F1: 0.0718\n",
      "15:03:04 [INFO]   Run 2/5\n",
      "15:03:04 [INFO]     1,311 labeled -> F1-Score: 0.0937 (Train: 0.0s, Query: 0.04s)\n",
      "15:03:04 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0848, F1: 0.0704\n",
      "15:03:04 [INFO]   Run 3/5\n",
      "15:03:05 [INFO]     1,311 labeled -> F1-Score: 0.0854 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:05 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1024, F1: 0.0630\n",
      "15:03:05 [INFO]   Run 4/5\n",
      "15:03:05 [INFO]     1,311 labeled -> F1-Score: 0.1060 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:05 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1701, F1: 0.1154\n",
      "15:03:05 [INFO]   Run 5/5\n",
      "15:03:05 [INFO]     1,311 labeled -> F1-Score: 0.0556 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:05 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0524, F1: 0.0473\n",
      "15:03:05 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 40% (2,623 Samples)\n",
      "15:03:05 [INFO]   Run 1/5\n",
      "15:03:05 [INFO]     2,623 labeled -> F1-Score: 0.0534 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:05 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0573, F1: 0.0663\n",
      "15:03:05 [INFO]   Run 2/5\n",
      "15:03:05 [INFO]     2,623 labeled -> F1-Score: 0.0386 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:05 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0567, F1: 0.0386\n",
      "15:03:05 [INFO]   Run 3/5\n",
      "15:03:05 [INFO]     2,623 labeled -> F1-Score: 0.0590 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:05 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1012, F1: 0.0599\n",
      "15:03:05 [INFO]   Run 4/5\n",
      "15:03:05 [INFO]     2,623 labeled -> F1-Score: 0.0792 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:05 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1268, F1: 0.0792\n",
      "15:03:05 [INFO]   Run 5/5\n",
      "15:03:06 [INFO]     2,623 labeled -> F1-Score: 0.0448 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:06 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0494, F1: 0.0458\n",
      "15:03:06 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 60% (3,935 Samples)\n",
      "15:03:06 [INFO]   Run 1/5\n",
      "15:03:06 [INFO]     3,935 labeled -> F1-Score: 0.0567 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:06 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0500, F1: 0.0538\n",
      "15:03:06 [INFO]   Run 2/5\n",
      "15:03:06 [INFO]     3,935 labeled -> F1-Score: 0.0408 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:06 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0610, F1: 0.0515\n",
      "15:03:06 [INFO]   Run 3/5\n",
      "15:03:06 [INFO]     3,935 labeled -> F1-Score: 0.0613 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:06 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0927, F1: 0.0606\n",
      "15:03:06 [INFO]   Run 4/5\n",
      "15:03:06 [INFO]     3,935 labeled -> F1-Score: 0.0745 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:06 [INFO]     Final: 3,935 labeled -> Accuracy: 0.1152, F1: 0.0790\n",
      "15:03:06 [INFO]   Run 5/5\n",
      "15:03:07 [INFO]     3,935 labeled -> F1-Score: 0.0421 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:07 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0470, F1: 0.0446\n",
      "15:03:07 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 80% (5,247 Samples)\n",
      "15:03:07 [INFO]   Run 1/5\n",
      "15:03:07 [INFO]     5,247 labeled -> F1-Score: 0.0562 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:07 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0500, F1: 0.0519\n",
      "15:03:07 [INFO]   Run 2/5\n",
      "15:03:07 [INFO]     5,247 labeled -> F1-Score: 0.0531 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:07 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0427, F1: 0.0328\n",
      "15:03:07 [INFO]   Run 3/5\n",
      "15:03:07 [INFO]     5,247 labeled -> F1-Score: 0.0584 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:07 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0902, F1: 0.0592\n",
      "15:03:07 [INFO]   Run 4/5\n",
      "15:03:08 [INFO]     5,247 labeled -> F1-Score: 0.0722 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:08 [INFO]     Final: 5,247 labeled -> Accuracy: 0.1104, F1: 0.0742\n",
      "15:03:08 [INFO]   Run 5/5\n",
      "15:03:08 [INFO]     5,247 labeled -> F1-Score: 0.0493 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:08 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0604, F1: 0.0567\n",
      "15:03:08 [INFO] \n",
      "Naive Bayes + Entropy Sampling - Budget: 100% (6,559 Samples)\n",
      "15:03:08 [INFO]   Run 1/5\n",
      "15:03:08 [INFO]     6,559 labeled -> F1-Score: 0.0413 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:08 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:08 [INFO]   Run 2/5\n",
      "15:03:09 [INFO]     6,559 labeled -> F1-Score: 0.0418 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:09 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:09 [INFO]   Run 3/5\n",
      "15:03:09 [INFO]     6,559 labeled -> F1-Score: 0.0468 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:09 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:09 [INFO]   Run 4/5\n",
      "15:03:09 [INFO]     6,559 labeled -> F1-Score: 0.0370 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:09 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:09 [INFO]   Run 5/5\n",
      "15:03:09 [INFO]     6,559 labeled -> F1-Score: 0.0241 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:10 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "\n",
      "[ok] Naive Bayes + Entropy Sampling abgeschlossen in 0.1 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 7/20: Naive Bayes + Margin Sampling\n",
      "============================================================\n",
      "15:03:10 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 20% (1,311 Samples)\n",
      "15:03:10 [INFO]   Run 1/5\n",
      "15:03:10 [INFO]     1,311 labeled -> F1-Score: 0.0761 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:10 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0695, F1: 0.0727\n",
      "15:03:10 [INFO]   Run 2/5\n",
      "15:03:10 [INFO]     1,311 labeled -> F1-Score: 0.0937 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:10 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0902, F1: 0.0842\n",
      "15:03:10 [INFO]   Run 3/5\n",
      "15:03:10 [INFO]     1,311 labeled -> F1-Score: 0.0854 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:10 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1024, F1: 0.0619\n",
      "15:03:10 [INFO]   Run 4/5\n",
      "15:03:10 [INFO]     1,311 labeled -> F1-Score: 0.1166 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:10 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1488, F1: 0.1033\n",
      "15:03:10 [INFO]   Run 5/5\n",
      "15:03:10 [INFO]     1,311 labeled -> F1-Score: 0.0556 (Train: 0.0s, Query: 0.03s)\n",
      "15:03:10 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0524, F1: 0.0473\n",
      "15:03:10 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 40% (2,623 Samples)\n",
      "15:03:10 [INFO]   Run 1/5\n",
      "15:03:10 [INFO]     2,623 labeled -> F1-Score: 0.0593 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:10 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0585, F1: 0.0593\n",
      "15:03:10 [INFO]   Run 2/5\n",
      "15:03:10 [INFO]     2,623 labeled -> F1-Score: 0.0518 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:10 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0646, F1: 0.0518\n",
      "15:03:10 [INFO]   Run 3/5\n",
      "15:03:11 [INFO]     2,623 labeled -> F1-Score: 0.0590 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:11 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1012, F1: 0.0599\n",
      "15:03:11 [INFO]   Run 4/5\n",
      "15:03:11 [INFO]     2,623 labeled -> F1-Score: 0.0740 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:11 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1226, F1: 0.0740\n",
      "15:03:11 [INFO]   Run 5/5\n",
      "15:03:11 [INFO]     2,623 labeled -> F1-Score: 0.0448 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:11 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0494, F1: 0.0458\n",
      "15:03:11 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 60% (3,935 Samples)\n",
      "15:03:11 [INFO]   Run 1/5\n",
      "15:03:11 [INFO]     3,935 labeled -> F1-Score: 0.0558 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:11 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0543, F1: 0.0558\n",
      "15:03:11 [INFO]   Run 2/5\n",
      "15:03:11 [INFO]     3,935 labeled -> F1-Score: 0.0670 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:11 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0738, F1: 0.0666\n",
      "15:03:11 [INFO]   Run 3/5\n",
      "15:03:12 [INFO]     3,935 labeled -> F1-Score: 0.0613 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:12 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0927, F1: 0.0606\n",
      "15:03:12 [INFO]   Run 4/5\n",
      "15:03:12 [INFO]     3,935 labeled -> F1-Score: 0.0444 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:12 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0463, F1: 0.0452\n",
      "15:03:12 [INFO]   Run 5/5\n",
      "15:03:12 [INFO]     3,935 labeled -> F1-Score: 0.0421 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:12 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0470, F1: 0.0446\n",
      "15:03:12 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 80% (5,247 Samples)\n",
      "15:03:12 [INFO]   Run 1/5\n",
      "15:03:12 [INFO]     5,247 labeled -> F1-Score: 0.0594 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:12 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0530, F1: 0.0565\n",
      "15:03:12 [INFO]   Run 2/5\n",
      "15:03:13 [INFO]     5,247 labeled -> F1-Score: 0.0529 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:13 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0622, F1: 0.0585\n",
      "15:03:13 [INFO]   Run 3/5\n",
      "15:03:13 [INFO]     5,247 labeled -> F1-Score: 0.0394 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:13 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0329, F1: 0.0369\n",
      "15:03:13 [INFO]   Run 4/5\n",
      "15:03:13 [INFO]     5,247 labeled -> F1-Score: 0.0525 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:13 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0482, F1: 0.0511\n",
      "15:03:13 [INFO]   Run 5/5\n",
      "15:03:13 [INFO]     5,247 labeled -> F1-Score: 0.0607 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:13 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0671, F1: 0.0706\n",
      "15:03:13 [INFO] \n",
      "Naive Bayes + Margin Sampling - Budget: 100% (6,559 Samples)\n",
      "15:03:13 [INFO]   Run 1/5\n",
      "15:03:14 [INFO]     6,559 labeled -> F1-Score: 0.0338 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:14 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:14 [INFO]   Run 2/5\n",
      "15:03:14 [INFO]     6,559 labeled -> F1-Score: 0.0304 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:14 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:14 [INFO]   Run 3/5\n",
      "15:03:14 [INFO]     6,559 labeled -> F1-Score: 0.0252 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:14 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:14 [INFO]   Run 4/5\n",
      "15:03:15 [INFO]     6,559 labeled -> F1-Score: 0.0245 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:15 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:15 [INFO]   Run 5/5\n",
      "15:03:15 [INFO]     6,559 labeled -> F1-Score: 0.0366 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:15 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "\n",
      "[ok] Naive Bayes + Margin Sampling abgeschlossen in 0.1 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 8/20: Naive Bayes + Least Confidence\n",
      "============================================================\n",
      "15:03:15 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 20% (1,311 Samples)\n",
      "15:03:15 [INFO]   Run 1/5\n",
      "15:03:15 [INFO]     1,311 labeled -> F1-Score: 0.0761 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:15 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0695, F1: 0.0727\n",
      "15:03:15 [INFO]   Run 2/5\n",
      "15:03:15 [INFO]     1,311 labeled -> F1-Score: 0.0937 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:15 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0854, F1: 0.0724\n",
      "15:03:15 [INFO]   Run 3/5\n",
      "15:03:15 [INFO]     1,311 labeled -> F1-Score: 0.0854 (Train: 0.0s, Query: 0.03s)\n",
      "15:03:15 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1024, F1: 0.0619\n",
      "15:03:15 [INFO]   Run 4/5\n",
      "15:03:15 [INFO]     1,311 labeled -> F1-Score: 0.1168 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:15 [INFO]     Final: 1,311 labeled -> Accuracy: 0.1488, F1: 0.1032\n",
      "15:03:15 [INFO]   Run 5/5\n",
      "15:03:16 [INFO]     1,311 labeled -> F1-Score: 0.0556 (Train: 0.0s, Query: 0.02s)\n",
      "15:03:16 [INFO]     Final: 1,311 labeled -> Accuracy: 0.0524, F1: 0.0473\n",
      "15:03:16 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 40% (2,623 Samples)\n",
      "15:03:16 [INFO]   Run 1/5\n",
      "15:03:16 [INFO]     2,623 labeled -> F1-Score: 0.0593 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:16 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0585, F1: 0.0593\n",
      "15:03:16 [INFO]   Run 2/5\n",
      "15:03:16 [INFO]     2,623 labeled -> F1-Score: 0.0386 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:16 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0567, F1: 0.0386\n",
      "15:03:16 [INFO]   Run 3/5\n",
      "15:03:16 [INFO]     2,623 labeled -> F1-Score: 0.0590 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:16 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1012, F1: 0.0599\n",
      "15:03:16 [INFO]   Run 4/5\n",
      "15:03:16 [INFO]     2,623 labeled -> F1-Score: 0.0600 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:16 [INFO]     Final: 2,623 labeled -> Accuracy: 0.1159, F1: 0.0603\n",
      "15:03:16 [INFO]   Run 5/5\n",
      "15:03:16 [INFO]     2,623 labeled -> F1-Score: 0.0448 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:16 [INFO]     Final: 2,623 labeled -> Accuracy: 0.0494, F1: 0.0458\n",
      "15:03:16 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 60% (3,935 Samples)\n",
      "15:03:16 [INFO]   Run 1/5\n",
      "15:03:17 [INFO]     3,935 labeled -> F1-Score: 0.0558 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:17 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0543, F1: 0.0558\n",
      "15:03:17 [INFO]   Run 2/5\n",
      "15:03:17 [INFO]     3,935 labeled -> F1-Score: 0.0408 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:17 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0610, F1: 0.0518\n",
      "15:03:17 [INFO]   Run 3/5\n",
      "15:03:17 [INFO]     3,935 labeled -> F1-Score: 0.0613 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:17 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0927, F1: 0.0606\n",
      "15:03:17 [INFO]   Run 4/5\n",
      "15:03:17 [INFO]     3,935 labeled -> F1-Score: 0.0657 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:17 [INFO]     Final: 3,935 labeled -> Accuracy: 0.1165, F1: 0.0640\n",
      "15:03:17 [INFO]   Run 5/5\n",
      "15:03:17 [INFO]     3,935 labeled -> F1-Score: 0.0421 (Train: 0.0s, Query: 0.01s)\n",
      "15:03:17 [INFO]     Final: 3,935 labeled -> Accuracy: 0.0470, F1: 0.0446\n",
      "15:03:17 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 80% (5,247 Samples)\n",
      "15:03:17 [INFO]   Run 1/5\n",
      "15:03:18 [INFO]     5,247 labeled -> F1-Score: 0.0594 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:18 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0366, F1: 0.0391\n",
      "15:03:18 [INFO]   Run 2/5\n",
      "15:03:18 [INFO]     5,247 labeled -> F1-Score: 0.0570 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:18 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0500, F1: 0.0480\n",
      "15:03:18 [INFO]   Run 3/5\n",
      "15:03:18 [INFO]     5,247 labeled -> F1-Score: 0.0394 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:18 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0335, F1: 0.0362\n",
      "15:03:18 [INFO]   Run 4/5\n",
      "15:03:18 [INFO]     5,247 labeled -> F1-Score: 0.0592 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:18 [INFO]     Final: 5,247 labeled -> Accuracy: 0.1061, F1: 0.0616\n",
      "15:03:18 [INFO]   Run 5/5\n",
      "15:03:19 [INFO]     5,247 labeled -> F1-Score: 0.0665 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:19 [INFO]     Final: 5,247 labeled -> Accuracy: 0.0604, F1: 0.0648\n",
      "15:03:19 [INFO] \n",
      "Naive Bayes + Least Confidence - Budget: 100% (6,559 Samples)\n",
      "15:03:19 [INFO]   Run 1/5\n",
      "15:03:19 [INFO]     6,559 labeled -> F1-Score: 0.0330 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:19 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:19 [INFO]   Run 2/5\n",
      "15:03:19 [INFO]     6,559 labeled -> F1-Score: 0.0243 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:19 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:19 [INFO]   Run 3/5\n",
      "15:03:19 [INFO]     6,559 labeled -> F1-Score: 0.0244 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:19 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:19 [INFO]   Run 4/5\n",
      "15:03:20 [INFO]     6,559 labeled -> F1-Score: 0.0219 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:20 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "15:03:20 [INFO]   Run 5/5\n",
      "15:03:20 [INFO]     6,559 labeled -> F1-Score: 0.0362 (Train: 0.0s, Query: 0.00s)\n",
      "15:03:20 [INFO]     Final: 6,559 labeled -> Accuracy: 0.0262, F1: 0.0289\n",
      "\n",
      "[ok] Naive Bayes + Least Confidence abgeschlossen in 0.1 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 9/20: Random Forest + Random Sampling\n",
      "============================================================\n",
      "15:03:20 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 20% (1,311 Samples)\n",
      "15:03:20 [INFO]   Run 1/5\n",
      "15:03:21 [INFO]     1,311 labeled -> F1-Score: 0.2103 (Train: 0.3s, Query: 0.00s)\n",
      "15:03:21 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4811, F1: 0.2031\n",
      "15:03:21 [INFO]   Run 2/5\n",
      "15:03:22 [INFO]     1,311 labeled -> F1-Score: 0.2108 (Train: 0.3s, Query: 0.00s)\n",
      "15:03:23 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4659, F1: 0.2231\n",
      "15:03:23 [INFO]   Run 3/5\n",
      "15:03:24 [INFO]     1,311 labeled -> F1-Score: 0.2338 (Train: 0.3s, Query: 0.00s)\n",
      "15:03:24 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4823, F1: 0.2358\n",
      "15:03:24 [INFO]   Run 4/5\n",
      "15:03:25 [INFO]     1,311 labeled -> F1-Score: 0.2318 (Train: 0.3s, Query: 0.00s)\n",
      "15:03:26 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4677, F1: 0.2366\n",
      "15:03:26 [INFO]   Run 5/5\n",
      "15:03:27 [INFO]     1,311 labeled -> F1-Score: 0.2360 (Train: 0.3s, Query: 0.00s)\n",
      "15:03:27 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4610, F1: 0.2208\n",
      "15:03:27 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 40% (2,623 Samples)\n",
      "15:03:27 [INFO]   Run 1/5\n",
      "15:03:29 [INFO]     2,623 labeled -> F1-Score: 0.2179 (Train: 0.4s, Query: 0.00s)\n",
      "15:03:30 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4799, F1: 0.2166\n",
      "15:03:30 [INFO]   Run 2/5\n",
      "15:03:37 [INFO]     2,623 labeled -> F1-Score: 0.2026 (Train: 1.6s, Query: 0.00s)\n",
      "15:03:38 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4537, F1: 0.2016\n",
      "15:03:38 [INFO]   Run 3/5\n",
      "15:03:41 [INFO]     2,623 labeled -> F1-Score: 0.2383 (Train: 0.4s, Query: 0.00s)\n",
      "15:03:41 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4659, F1: 0.2373\n",
      "15:03:41 [INFO]   Run 4/5\n",
      "15:03:43 [INFO]     2,623 labeled -> F1-Score: 0.2396 (Train: 0.4s, Query: 0.00s)\n",
      "15:03:44 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4793, F1: 0.2383\n",
      "15:03:44 [INFO]   Run 5/5\n",
      "15:03:46 [INFO]     2,623 labeled -> F1-Score: 0.2231 (Train: 0.4s, Query: 0.00s)\n",
      "15:03:47 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4604, F1: 0.2214\n",
      "15:03:47 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 60% (3,935 Samples)\n",
      "15:03:47 [INFO]   Run 1/5\n",
      "15:03:50 [INFO]     3,935 labeled -> F1-Score: 0.2127 (Train: 0.5s, Query: 0.00s)\n",
      "15:03:50 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4689, F1: 0.2164\n",
      "15:03:50 [INFO]   Run 2/5\n",
      "15:03:54 [INFO]     3,935 labeled -> F1-Score: 0.2070 (Train: 0.5s, Query: 0.00s)\n",
      "15:03:55 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4591, F1: 0.2065\n",
      "15:03:55 [INFO]   Run 3/5\n",
      "15:03:58 [INFO]     3,935 labeled -> F1-Score: 0.2279 (Train: 0.5s, Query: 0.00s)\n",
      "15:03:58 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4750, F1: 0.2299\n",
      "15:03:58 [INFO]   Run 4/5\n",
      "15:04:02 [INFO]     3,935 labeled -> F1-Score: 0.2333 (Train: 0.4s, Query: 0.00s)\n",
      "15:04:02 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4732, F1: 0.2243\n",
      "15:04:02 [INFO]   Run 5/5\n",
      "15:04:06 [INFO]     3,935 labeled -> F1-Score: 0.2360 (Train: 0.5s, Query: 0.00s)\n",
      "15:04:06 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4793, F1: 0.2328\n",
      "15:04:06 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 80% (5,247 Samples)\n",
      "15:04:06 [INFO]   Run 1/5\n",
      "15:04:11 [INFO]     5,247 labeled -> F1-Score: 0.2253 (Train: 0.5s, Query: 0.00s)\n",
      "15:04:13 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4701, F1: 0.2246\n",
      "15:04:13 [INFO]   Run 2/5\n",
      "15:04:18 [INFO]     5,247 labeled -> F1-Score: 0.2254 (Train: 0.5s, Query: 0.00s)\n",
      "15:04:19 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4561, F1: 0.2270\n",
      "15:04:19 [INFO]   Run 3/5\n",
      "15:04:24 [INFO]     5,247 labeled -> F1-Score: 0.2279 (Train: 0.5s, Query: 0.00s)\n",
      "15:04:24 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4732, F1: 0.2255\n",
      "15:04:24 [INFO]   Run 4/5\n",
      "15:04:29 [INFO]     5,247 labeled -> F1-Score: 0.2185 (Train: 0.4s, Query: 0.00s)\n",
      "15:04:29 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4604, F1: 0.2162\n",
      "15:04:29 [INFO]   Run 5/5\n",
      "15:04:34 [INFO]     5,247 labeled -> F1-Score: 0.2227 (Train: 0.4s, Query: 0.00s)\n",
      "15:04:34 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4713, F1: 0.2244\n",
      "15:04:34 [INFO] \n",
      "Random Forest + Random Sampling - Budget: 100% (6,559 Samples)\n",
      "15:04:34 [INFO]   Run 1/5\n",
      "15:04:40 [INFO]     6,559 labeled -> F1-Score: 0.2365 (Train: 0.5s, Query: 0.00s)\n",
      "15:04:40 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4726, F1: 0.2328\n",
      "15:04:40 [INFO]   Run 2/5\n",
      "15:04:46 [INFO]     6,559 labeled -> F1-Score: 0.2328 (Train: 0.4s, Query: 0.00s)\n",
      "15:04:47 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4707, F1: 0.2304\n",
      "15:04:47 [INFO]   Run 3/5\n",
      "15:04:53 [INFO]     6,559 labeled -> F1-Score: 0.2238 (Train: 0.6s, Query: 0.00s)\n",
      "15:04:53 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4713, F1: 0.2342\n",
      "15:04:53 [INFO]   Run 4/5\n",
      "15:04:59 [INFO]     6,559 labeled -> F1-Score: 0.2237 (Train: 0.6s, Query: 0.00s)\n",
      "15:04:59 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4713, F1: 0.2305\n",
      "15:04:59 [INFO]   Run 5/5\n",
      "15:05:06 [INFO]     6,559 labeled -> F1-Score: 0.2305 (Train: 0.6s, Query: 0.00s)\n",
      "15:05:07 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4707, F1: 0.2297\n",
      "\n",
      "[ok] Random Forest + Random Sampling abgeschlossen in 1.8 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 10/20: Random Forest + Entropy Sampling\n",
      "============================================================\n",
      "15:05:07 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 20% (1,311 Samples)\n",
      "15:05:07 [INFO]   Run 1/5\n",
      "15:05:08 [INFO]     1,311 labeled -> F1-Score: 0.2404 (Train: 0.3s, Query: 0.05s)\n",
      "15:05:09 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4793, F1: 0.2353\n",
      "15:05:09 [INFO]   Run 2/5\n",
      "15:05:10 [INFO]     1,311 labeled -> F1-Score: 0.2098 (Train: 0.4s, Query: 0.06s)\n",
      "15:05:10 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4585, F1: 0.2179\n",
      "15:05:10 [INFO]   Run 3/5\n",
      "15:05:12 [INFO]     1,311 labeled -> F1-Score: 0.2577 (Train: 0.4s, Query: 0.06s)\n",
      "15:05:12 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4933, F1: 0.2554\n",
      "15:05:12 [INFO]   Run 4/5\n",
      "15:05:14 [INFO]     1,311 labeled -> F1-Score: 0.2097 (Train: 0.3s, Query: 0.05s)\n",
      "15:05:14 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4945, F1: 0.2121\n",
      "15:05:14 [INFO]   Run 5/5\n",
      "15:05:15 [INFO]     1,311 labeled -> F1-Score: 0.1874 (Train: 0.3s, Query: 0.05s)\n",
      "15:05:15 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4634, F1: 0.2126\n",
      "15:05:15 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 40% (2,623 Samples)\n",
      "15:05:15 [INFO]   Run 1/5\n",
      "15:05:18 [INFO]     2,623 labeled -> F1-Score: 0.2344 (Train: 0.4s, Query: 0.04s)\n",
      "15:05:18 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5061, F1: 0.2338\n",
      "15:05:18 [INFO]   Run 2/5\n",
      "15:05:21 [INFO]     2,623 labeled -> F1-Score: 0.2227 (Train: 0.4s, Query: 0.08s)\n",
      "15:05:21 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5104, F1: 0.2244\n",
      "15:05:21 [INFO]   Run 3/5\n",
      "15:05:24 [INFO]     2,623 labeled -> F1-Score: 0.2391 (Train: 0.4s, Query: 0.05s)\n",
      "15:05:24 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5000, F1: 0.2381\n",
      "15:05:24 [INFO]   Run 4/5\n",
      "15:05:27 [INFO]     2,623 labeled -> F1-Score: 0.2178 (Train: 0.3s, Query: 0.05s)\n",
      "15:05:27 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4841, F1: 0.2185\n",
      "15:05:27 [INFO]   Run 5/5\n",
      "15:05:30 [INFO]     2,623 labeled -> F1-Score: 0.2099 (Train: 0.4s, Query: 0.06s)\n",
      "15:05:30 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4604, F1: 0.2112\n",
      "15:05:30 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 60% (3,935 Samples)\n",
      "15:05:30 [INFO]   Run 1/5\n",
      "15:05:34 [INFO]     3,935 labeled -> F1-Score: 0.2196 (Train: 0.4s, Query: 0.05s)\n",
      "15:05:34 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5079, F1: 0.2219\n",
      "15:05:34 [INFO]   Run 2/5\n",
      "15:05:38 [INFO]     3,935 labeled -> F1-Score: 0.2145 (Train: 0.4s, Query: 0.05s)\n",
      "15:05:38 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5128, F1: 0.2221\n",
      "15:05:38 [INFO]   Run 3/5\n",
      "15:05:42 [INFO]     3,935 labeled -> F1-Score: 0.2344 (Train: 0.4s, Query: 0.04s)\n",
      "15:05:42 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5134, F1: 0.2305\n",
      "15:05:42 [INFO]   Run 4/5\n",
      "15:05:46 [INFO]     3,935 labeled -> F1-Score: 0.2296 (Train: 0.4s, Query: 0.07s)\n",
      "15:05:46 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5098, F1: 0.2441\n",
      "15:05:46 [INFO]   Run 5/5\n",
      "15:05:50 [INFO]     3,935 labeled -> F1-Score: 0.2050 (Train: 0.4s, Query: 0.06s)\n",
      "15:05:50 [INFO]     Final: 3,935 labeled -> Accuracy: 0.4896, F1: 0.2270\n",
      "15:05:50 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 80% (5,247 Samples)\n",
      "15:05:50 [INFO]   Run 1/5\n",
      "15:05:55 [INFO]     5,247 labeled -> F1-Score: 0.2341 (Train: 0.5s, Query: 0.07s)\n",
      "15:05:56 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5037, F1: 0.2345\n",
      "15:05:56 [INFO]   Run 2/5\n",
      "15:06:01 [INFO]     5,247 labeled -> F1-Score: 0.2254 (Train: 0.5s, Query: 0.04s)\n",
      "15:06:02 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5030, F1: 0.2249\n",
      "15:06:02 [INFO]   Run 3/5\n",
      "15:06:07 [INFO]     5,247 labeled -> F1-Score: 0.2164 (Train: 0.5s, Query: 0.04s)\n",
      "15:06:08 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4933, F1: 0.2155\n",
      "15:06:08 [INFO]   Run 4/5\n",
      "15:06:13 [INFO]     5,247 labeled -> F1-Score: 0.2393 (Train: 0.5s, Query: 0.05s)\n",
      "15:06:14 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5049, F1: 0.2363\n",
      "15:06:14 [INFO]   Run 5/5\n",
      "15:06:19 [INFO]     5,247 labeled -> F1-Score: 0.2390 (Train: 0.5s, Query: 0.04s)\n",
      "15:06:20 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4921, F1: 0.2305\n",
      "15:06:20 [INFO] \n",
      "Random Forest + Entropy Sampling - Budget: 100% (6,559 Samples)\n",
      "15:06:20 [INFO]   Run 1/5\n",
      "15:06:26 [INFO]     6,559 labeled -> F1-Score: 0.2314 (Train: 0.6s, Query: 0.04s)\n",
      "15:06:27 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4701, F1: 0.2297\n",
      "15:06:27 [INFO]   Run 2/5\n",
      "15:06:34 [INFO]     6,559 labeled -> F1-Score: 0.2371 (Train: 0.6s, Query: 0.04s)\n",
      "15:06:34 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4732, F1: 0.2363\n",
      "15:06:34 [INFO]   Run 3/5\n",
      "15:06:41 [INFO]     6,559 labeled -> F1-Score: 0.2266 (Train: 0.5s, Query: 0.06s)\n",
      "15:06:42 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4720, F1: 0.2305\n",
      "15:06:42 [INFO]   Run 4/5\n",
      "15:06:49 [INFO]     6,559 labeled -> F1-Score: 0.2422 (Train: 0.5s, Query: 0.04s)\n",
      "15:06:49 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4720, F1: 0.2348\n",
      "15:06:49 [INFO]   Run 5/5\n",
      "15:06:56 [INFO]     6,559 labeled -> F1-Score: 0.2262 (Train: 0.6s, Query: 0.04s)\n",
      "15:06:57 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4713, F1: 0.2260\n",
      "\n",
      "[ok] Random Forest + Entropy Sampling abgeschlossen in 1.8 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 11/20: Random Forest + Margin Sampling\n",
      "============================================================\n",
      "15:06:57 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 20% (1,311 Samples)\n",
      "15:06:57 [INFO]   Run 1/5\n",
      "15:06:58 [INFO]     1,311 labeled -> F1-Score: 0.2236 (Train: 0.3s, Query: 0.05s)\n",
      "15:06:58 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4683, F1: 0.2241\n",
      "15:06:58 [INFO]   Run 2/5\n",
      "15:07:00 [INFO]     1,311 labeled -> F1-Score: 0.2139 (Train: 0.3s, Query: 0.11s)\n",
      "15:07:00 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4988, F1: 0.2162\n",
      "15:07:00 [INFO]   Run 3/5\n",
      "15:07:02 [INFO]     1,311 labeled -> F1-Score: 0.2248 (Train: 0.4s, Query: 0.08s)\n",
      "15:07:02 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5012, F1: 0.2246\n",
      "15:07:02 [INFO]   Run 4/5\n",
      "15:07:04 [INFO]     1,311 labeled -> F1-Score: 0.2433 (Train: 0.4s, Query: 0.08s)\n",
      "15:07:04 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5213, F1: 0.2449\n",
      "15:07:04 [INFO]   Run 5/5\n",
      "15:07:05 [INFO]     1,311 labeled -> F1-Score: 0.1987 (Train: 0.3s, Query: 0.05s)\n",
      "15:07:05 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4848, F1: 0.2053\n",
      "15:07:05 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 40% (2,623 Samples)\n",
      "15:07:05 [INFO]   Run 1/5\n",
      "15:07:08 [INFO]     2,623 labeled -> F1-Score: 0.2297 (Train: 0.3s, Query: 0.04s)\n",
      "15:07:08 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5024, F1: 0.2278\n",
      "15:07:08 [INFO]   Run 2/5\n",
      "15:07:11 [INFO]     2,623 labeled -> F1-Score: 0.2238 (Train: 0.4s, Query: 0.04s)\n",
      "15:07:11 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5195, F1: 0.2240\n",
      "15:07:11 [INFO]   Run 3/5\n",
      "15:07:13 [INFO]     2,623 labeled -> F1-Score: 0.2350 (Train: 0.3s, Query: 0.05s)\n",
      "15:07:14 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5201, F1: 0.2352\n",
      "15:07:14 [INFO]   Run 4/5\n",
      "15:07:16 [INFO]     2,623 labeled -> F1-Score: 0.2292 (Train: 0.4s, Query: 0.05s)\n",
      "15:07:17 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5262, F1: 0.2279\n",
      "15:07:17 [INFO]   Run 5/5\n",
      "15:07:19 [INFO]     2,623 labeled -> F1-Score: 0.2172 (Train: 0.3s, Query: 0.05s)\n",
      "15:07:19 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5165, F1: 0.2189\n",
      "15:07:19 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 60% (3,935 Samples)\n",
      "15:07:19 [INFO]   Run 1/5\n",
      "15:07:23 [INFO]     3,935 labeled -> F1-Score: 0.2234 (Train: 0.4s, Query: 0.05s)\n",
      "15:07:23 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5061, F1: 0.2174\n",
      "15:07:23 [INFO]   Run 2/5\n",
      "15:07:27 [INFO]     3,935 labeled -> F1-Score: 0.2209 (Train: 0.4s, Query: 0.04s)\n",
      "15:07:27 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5116, F1: 0.2323\n",
      "15:07:27 [INFO]   Run 3/5\n",
      "15:07:31 [INFO]     3,935 labeled -> F1-Score: 0.2331 (Train: 0.4s, Query: 0.05s)\n",
      "15:07:31 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5055, F1: 0.2240\n",
      "15:07:31 [INFO]   Run 4/5\n",
      "15:07:34 [INFO]     3,935 labeled -> F1-Score: 0.2370 (Train: 0.4s, Query: 0.04s)\n",
      "15:07:35 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5268, F1: 0.2405\n",
      "15:07:35 [INFO]   Run 5/5\n",
      "15:07:38 [INFO]     3,935 labeled -> F1-Score: 0.2162 (Train: 0.5s, Query: 0.04s)\n",
      "15:07:39 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5104, F1: 0.2202\n",
      "15:07:39 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 80% (5,247 Samples)\n",
      "15:07:39 [INFO]   Run 1/5\n",
      "15:07:44 [INFO]     5,247 labeled -> F1-Score: 0.2386 (Train: 0.5s, Query: 0.06s)\n",
      "15:07:45 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4848, F1: 0.2379\n",
      "15:07:45 [INFO]   Run 2/5\n",
      "15:07:50 [INFO]     5,247 labeled -> F1-Score: 0.2184 (Train: 0.5s, Query: 0.05s)\n",
      "15:07:50 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4970, F1: 0.2149\n",
      "15:07:50 [INFO]   Run 3/5\n",
      "15:07:55 [INFO]     5,247 labeled -> F1-Score: 0.2216 (Train: 0.5s, Query: 0.05s)\n",
      "15:07:56 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4890, F1: 0.2157\n",
      "15:07:56 [INFO]   Run 4/5\n",
      "15:08:01 [INFO]     5,247 labeled -> F1-Score: 0.2353 (Train: 0.5s, Query: 0.08s)\n",
      "15:08:02 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5024, F1: 0.2338\n",
      "15:08:02 [INFO]   Run 5/5\n",
      "15:08:07 [INFO]     5,247 labeled -> F1-Score: 0.2251 (Train: 0.5s, Query: 0.05s)\n",
      "15:08:08 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4988, F1: 0.2240\n",
      "15:08:08 [INFO] \n",
      "Random Forest + Margin Sampling - Budget: 100% (6,559 Samples)\n",
      "15:08:08 [INFO]   Run 1/5\n",
      "15:08:14 [INFO]     6,559 labeled -> F1-Score: 0.2394 (Train: 0.5s, Query: 0.04s)\n",
      "15:08:14 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4732, F1: 0.2363\n",
      "15:08:14 [INFO]   Run 2/5\n",
      "15:08:21 [INFO]     6,559 labeled -> F1-Score: 0.2284 (Train: 0.5s, Query: 0.06s)\n",
      "15:08:22 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4707, F1: 0.2304\n",
      "15:08:22 [INFO]   Run 3/5\n",
      "15:08:28 [INFO]     6,559 labeled -> F1-Score: 0.2292 (Train: 0.6s, Query: 0.05s)\n",
      "15:08:28 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4726, F1: 0.2309\n",
      "15:08:28 [INFO]   Run 4/5\n",
      "15:08:35 [INFO]     6,559 labeled -> F1-Score: 0.2308 (Train: 0.6s, Query: 0.05s)\n",
      "15:08:36 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4701, F1: 0.2271\n",
      "15:08:36 [INFO]   Run 5/5\n",
      "15:08:42 [INFO]     6,559 labeled -> F1-Score: 0.2261 (Train: 0.5s, Query: 0.04s)\n",
      "15:08:43 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4695, F1: 0.2262\n",
      "\n",
      "[ok] Random Forest + Margin Sampling abgeschlossen in 1.8 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 12/20: Random Forest + Least Confidence\n",
      "============================================================\n",
      "15:08:43 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 20% (1,311 Samples)\n",
      "15:08:43 [INFO]   Run 1/5\n",
      "15:08:44 [INFO]     1,311 labeled -> F1-Score: 0.2354 (Train: 0.3s, Query: 0.04s)\n",
      "15:08:44 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4927, F1: 0.2380\n",
      "15:08:44 [INFO]   Run 2/5\n",
      "15:08:45 [INFO]     1,311 labeled -> F1-Score: 0.2129 (Train: 0.2s, Query: 0.04s)\n",
      "15:08:45 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5000, F1: 0.2266\n",
      "15:08:45 [INFO]   Run 3/5\n",
      "15:08:46 [INFO]     1,311 labeled -> F1-Score: 0.2300 (Train: 0.3s, Query: 0.05s)\n",
      "15:08:47 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4787, F1: 0.2212\n",
      "15:08:47 [INFO]   Run 4/5\n",
      "15:08:48 [INFO]     1,311 labeled -> F1-Score: 0.1980 (Train: 0.2s, Query: 0.04s)\n",
      "15:08:48 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5024, F1: 0.2015\n",
      "15:08:48 [INFO]   Run 5/5\n",
      "15:08:49 [INFO]     1,311 labeled -> F1-Score: 0.2082 (Train: 0.3s, Query: 0.04s)\n",
      "15:08:49 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4811, F1: 0.2200\n",
      "15:08:49 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 40% (2,623 Samples)\n",
      "15:08:49 [INFO]   Run 1/5\n",
      "15:08:51 [INFO]     2,623 labeled -> F1-Score: 0.2568 (Train: 0.3s, Query: 0.05s)\n",
      "15:08:52 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5183, F1: 0.2582\n",
      "15:08:52 [INFO]   Run 2/5\n",
      "15:08:54 [INFO]     2,623 labeled -> F1-Score: 0.2204 (Train: 0.4s, Query: 0.05s)\n",
      "15:08:55 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5110, F1: 0.2108\n",
      "15:08:55 [INFO]   Run 3/5\n",
      "15:08:57 [INFO]     2,623 labeled -> F1-Score: 0.2382 (Train: 0.3s, Query: 0.04s)\n",
      "15:08:57 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5018, F1: 0.2402\n",
      "15:08:57 [INFO]   Run 4/5\n",
      "15:09:00 [INFO]     2,623 labeled -> F1-Score: 0.2176 (Train: 0.4s, Query: 0.06s)\n",
      "15:09:00 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5110, F1: 0.2183\n",
      "15:09:00 [INFO]   Run 5/5\n",
      "15:09:03 [INFO]     2,623 labeled -> F1-Score: 0.2250 (Train: 0.4s, Query: 0.05s)\n",
      "15:09:04 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4994, F1: 0.2267\n",
      "15:09:04 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 60% (3,935 Samples)\n",
      "15:09:04 [INFO]   Run 1/5\n",
      "15:09:07 [INFO]     3,935 labeled -> F1-Score: 0.2359 (Train: 0.4s, Query: 0.04s)\n",
      "15:09:07 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5128, F1: 0.2309\n",
      "15:09:07 [INFO]   Run 2/5\n",
      "15:09:11 [INFO]     3,935 labeled -> F1-Score: 0.2201 (Train: 0.4s, Query: 0.06s)\n",
      "15:09:11 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5226, F1: 0.2278\n",
      "15:09:11 [INFO]   Run 3/5\n",
      "15:09:15 [INFO]     3,935 labeled -> F1-Score: 0.2376 (Train: 0.4s, Query: 0.05s)\n",
      "15:09:15 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5091, F1: 0.2265\n",
      "15:09:15 [INFO]   Run 4/5\n",
      "15:09:19 [INFO]     3,935 labeled -> F1-Score: 0.2216 (Train: 0.4s, Query: 0.05s)\n",
      "15:09:19 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5165, F1: 0.2203\n",
      "15:09:19 [INFO]   Run 5/5\n",
      "15:09:22 [INFO]     3,935 labeled -> F1-Score: 0.2331 (Train: 0.4s, Query: 0.05s)\n",
      "15:09:23 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5079, F1: 0.2329\n",
      "15:09:23 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 80% (5,247 Samples)\n",
      "15:09:23 [INFO]   Run 1/5\n",
      "15:09:28 [INFO]     5,247 labeled -> F1-Score: 0.2414 (Train: 0.5s, Query: 0.04s)\n",
      "15:09:29 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4982, F1: 0.2417\n",
      "15:09:29 [INFO]   Run 2/5\n",
      "15:09:34 [INFO]     5,247 labeled -> F1-Score: 0.2223 (Train: 0.5s, Query: 0.07s)\n",
      "15:09:35 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5030, F1: 0.2213\n",
      "15:09:35 [INFO]   Run 3/5\n",
      "15:09:40 [INFO]     5,247 labeled -> F1-Score: 0.2088 (Train: 0.5s, Query: 0.04s)\n",
      "15:09:41 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4945, F1: 0.2093\n",
      "15:09:41 [INFO]   Run 4/5\n",
      "15:09:46 [INFO]     5,247 labeled -> F1-Score: 0.2282 (Train: 0.5s, Query: 0.05s)\n",
      "15:09:47 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5043, F1: 0.2284\n",
      "15:09:47 [INFO]   Run 5/5\n",
      "15:09:52 [INFO]     5,247 labeled -> F1-Score: 0.2308 (Train: 0.5s, Query: 0.08s)\n",
      "15:09:53 [INFO]     Final: 5,247 labeled -> Accuracy: 0.4939, F1: 0.2362\n",
      "15:09:53 [INFO] \n",
      "Random Forest + Least Confidence - Budget: 100% (6,559 Samples)\n",
      "15:09:53 [INFO]   Run 1/5\n",
      "15:09:59 [INFO]     6,559 labeled -> F1-Score: 0.2321 (Train: 0.6s, Query: 0.04s)\n",
      "15:10:00 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4713, F1: 0.2300\n",
      "15:10:00 [INFO]   Run 2/5\n",
      "15:10:08 [INFO]     6,559 labeled -> F1-Score: 0.2311 (Train: 0.6s, Query: 0.04s)\n",
      "15:10:09 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4720, F1: 0.2319\n",
      "15:10:09 [INFO]   Run 3/5\n",
      "15:10:15 [INFO]     6,559 labeled -> F1-Score: 0.2295 (Train: 0.5s, Query: 0.05s)\n",
      "15:10:16 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4720, F1: 0.2306\n",
      "15:10:16 [INFO]   Run 4/5\n",
      "15:10:23 [INFO]     6,559 labeled -> F1-Score: 0.2223 (Train: 0.6s, Query: 0.04s)\n",
      "15:10:23 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4726, F1: 0.2281\n",
      "15:10:23 [INFO]   Run 5/5\n",
      "15:10:30 [INFO]     6,559 labeled -> F1-Score: 0.2313 (Train: 0.6s, Query: 0.04s)\n",
      "15:10:31 [INFO]     Final: 6,559 labeled -> Accuracy: 0.4738, F1: 0.2316\n",
      "\n",
      "[ok] Random Forest + Least Confidence abgeschlossen in 1.8 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 13/20: Logistic Regression + Random Sampling\n",
      "============================================================\n",
      "15:10:31 [INFO] \n",
      "Logistic Regression + Random Sampling - Budget: 20% (1,311 Samples)\n",
      "15:10:31 [INFO]   Run 1/5\n",
      "15:10:34 [INFO]     1,311 labeled -> F1-Score: 0.1700 (Train: 1.8s, Query: 0.00s)\n",
      "15:10:36 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5354, F1: 0.1839\n",
      "15:10:36 [INFO]   Run 2/5\n",
      "15:10:38 [INFO]     1,311 labeled -> F1-Score: 0.1783 (Train: 1.5s, Query: 0.00s)\n",
      "15:10:41 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5439, F1: 0.1784\n",
      "15:10:41 [INFO]   Run 3/5\n",
      "15:10:43 [INFO]     1,311 labeled -> F1-Score: 0.1857 (Train: 1.9s, Query: 0.00s)\n",
      "15:10:45 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5488, F1: 0.1879\n",
      "15:10:45 [INFO]   Run 4/5\n",
      "15:10:48 [INFO]     1,311 labeled -> F1-Score: 0.1789 (Train: 1.9s, Query: 0.00s)\n",
      "15:10:51 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5543, F1: 0.1845\n",
      "15:10:51 [INFO]   Run 5/5\n",
      "15:10:53 [INFO]     1,311 labeled -> F1-Score: 0.1724 (Train: 1.8s, Query: 0.00s)\n",
      "15:10:56 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5354, F1: 0.1736\n",
      "15:10:56 [INFO] \n",
      "Logistic Regression + Random Sampling - Budget: 40% (2,623 Samples)\n",
      "15:10:56 [INFO]   Run 1/5\n",
      "15:11:09 [INFO]     2,623 labeled -> F1-Score: 0.1797 (Train: 4.4s, Query: 0.00s)\n",
      "15:11:13 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5311, F1: 0.1789\n",
      "15:11:13 [INFO]   Run 2/5\n",
      "15:11:26 [INFO]     2,623 labeled -> F1-Score: 0.1943 (Train: 4.4s, Query: 0.00s)\n",
      "15:11:31 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5530, F1: 0.1956\n",
      "15:11:31 [INFO]   Run 3/5\n",
      "15:11:44 [INFO]     2,623 labeled -> F1-Score: 0.1847 (Train: 4.6s, Query: 0.00s)\n",
      "15:11:49 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5518, F1: 0.1848\n",
      "15:11:49 [INFO]   Run 4/5\n",
      "15:12:03 [INFO]     2,623 labeled -> F1-Score: 0.1859 (Train: 4.7s, Query: 0.00s)\n",
      "15:12:07 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5518, F1: 0.1856\n",
      "15:12:07 [INFO]   Run 5/5\n",
      "15:12:22 [INFO]     2,623 labeled -> F1-Score: 0.1853 (Train: 4.5s, Query: 0.00s)\n",
      "15:12:26 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5445, F1: 0.1848\n",
      "15:12:26 [INFO] \n",
      "Logistic Regression + Random Sampling - Budget: 60% (3,935 Samples)\n",
      "15:12:26 [INFO]   Run 1/5\n",
      "15:12:52 [INFO]     3,935 labeled -> F1-Score: 0.1860 (Train: 6.3s, Query: 0.00s)\n",
      "15:12:58 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5372, F1: 0.1835\n",
      "15:12:58 [INFO]   Run 2/5\n",
      "15:13:23 [INFO]     3,935 labeled -> F1-Score: 0.1946 (Train: 6.3s, Query: 0.00s)\n",
      "15:13:30 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5402, F1: 0.1930\n",
      "15:13:30 [INFO]   Run 3/5\n",
      "15:13:55 [INFO]     3,935 labeled -> F1-Score: 0.1830 (Train: 6.1s, Query: 0.00s)\n",
      "15:14:01 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5445, F1: 0.1831\n",
      "15:14:01 [INFO]   Run 4/5\n",
      "15:14:26 [INFO]     3,935 labeled -> F1-Score: 0.1891 (Train: 6.0s, Query: 0.00s)\n",
      "15:14:33 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5591, F1: 0.1925\n",
      "15:14:33 [INFO]   Run 5/5\n",
      "15:14:58 [INFO]     3,935 labeled -> F1-Score: 0.1886 (Train: 6.5s, Query: 0.00s)\n",
      "15:15:05 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1882\n",
      "15:15:05 [INFO] \n",
      "Logistic Regression + Random Sampling - Budget: 80% (5,247 Samples)\n",
      "15:15:05 [INFO]   Run 1/5\n",
      "15:15:55 [INFO]     5,247 labeled -> F1-Score: 0.1836 (Train: 9.0s, Query: 0.00s)\n",
      "15:16:05 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5348, F1: 0.1839\n",
      "15:16:05 [INFO]   Run 2/5\n",
      "15:16:55 [INFO]     5,247 labeled -> F1-Score: 0.1856 (Train: 9.3s, Query: 0.00s)\n",
      "15:17:04 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5372, F1: 0.1890\n",
      "15:17:04 [INFO]   Run 3/5\n",
      "15:17:54 [INFO]     5,247 labeled -> F1-Score: 0.1850 (Train: 9.2s, Query: 0.00s)\n",
      "15:18:04 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1858\n",
      "15:18:04 [INFO]   Run 4/5\n",
      "15:18:55 [INFO]     5,247 labeled -> F1-Score: 0.1905 (Train: 9.3s, Query: 0.00s)\n",
      "15:19:04 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5500, F1: 0.1931\n",
      "15:19:04 [INFO]   Run 5/5\n",
      "15:19:55 [INFO]     5,247 labeled -> F1-Score: 0.1867 (Train: 9.7s, Query: 0.00s)\n",
      "15:20:06 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5384, F1: 0.1862\n",
      "15:20:06 [INFO] \n",
      "Logistic Regression + Random Sampling - Budget: 100% (6,559 Samples)\n",
      "15:20:06 [INFO]   Run 1/5\n",
      "15:21:19 [INFO]     6,559 labeled -> F1-Score: 0.1858 (Train: 11.7s, Query: 0.00s)\n",
      "15:21:31 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:21:31 [INFO]   Run 2/5\n",
      "15:22:43 [INFO]     6,559 labeled -> F1-Score: 0.1848 (Train: 10.6s, Query: 0.00s)\n",
      "15:22:55 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:22:55 [INFO]   Run 3/5\n",
      "15:24:07 [INFO]     6,559 labeled -> F1-Score: 0.1866 (Train: 11.3s, Query: 0.00s)\n",
      "15:24:19 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:24:19 [INFO]   Run 4/5\n",
      "15:25:32 [INFO]     6,559 labeled -> F1-Score: 0.1849 (Train: 11.4s, Query: 0.00s)\n",
      "15:25:44 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:25:44 [INFO]   Run 5/5\n",
      "15:26:55 [INFO]     6,559 labeled -> F1-Score: 0.1869 (Train: 10.8s, Query: 0.00s)\n",
      "15:27:08 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "\n",
      "[ok] Logistic Regression + Random Sampling abgeschlossen in 16.6 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 14/20: Logistic Regression + Entropy Sampling\n",
      "============================================================\n",
      "15:27:08 [INFO] \n",
      "Logistic Regression + Entropy Sampling - Budget: 20% (1,311 Samples)\n",
      "15:27:08 [INFO]   Run 1/5\n",
      "15:27:11 [INFO]     1,311 labeled -> F1-Score: 0.2048 (Train: 1.9s, Query: 0.01s)\n",
      "15:27:13 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4817, F1: 0.2015\n",
      "15:27:13 [INFO]   Run 2/5\n",
      "15:27:16 [INFO]     1,311 labeled -> F1-Score: 0.1552 (Train: 1.8s, Query: 0.00s)\n",
      "15:27:18 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4689, F1: 0.1633\n",
      "15:27:18 [INFO]   Run 3/5\n",
      "15:27:21 [INFO]     1,311 labeled -> F1-Score: 0.1641 (Train: 1.9s, Query: 0.00s)\n",
      "15:27:23 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5030, F1: 0.1607\n",
      "15:27:23 [INFO]   Run 4/5\n",
      "15:27:26 [INFO]     1,311 labeled -> F1-Score: 0.1938 (Train: 1.8s, Query: 0.00s)\n",
      "15:27:28 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5000, F1: 0.1931\n",
      "15:27:28 [INFO]   Run 5/5\n",
      "15:27:31 [INFO]     1,311 labeled -> F1-Score: 0.1755 (Train: 1.8s, Query: 0.00s)\n",
      "15:27:33 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5220, F1: 0.1773\n",
      "15:27:33 [INFO] \n",
      "Logistic Regression + Entropy Sampling - Budget: 40% (2,623 Samples)\n",
      "15:27:33 [INFO]   Run 1/5\n",
      "15:27:46 [INFO]     2,623 labeled -> F1-Score: 0.1857 (Train: 4.3s, Query: 0.01s)\n",
      "15:27:51 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4927, F1: 0.1967\n",
      "15:27:51 [INFO]   Run 2/5\n",
      "15:28:05 [INFO]     2,623 labeled -> F1-Score: 0.1757 (Train: 4.6s, Query: 0.01s)\n",
      "15:28:10 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5165, F1: 0.1758\n",
      "15:28:10 [INFO]   Run 3/5\n",
      "15:28:24 [INFO]     2,623 labeled -> F1-Score: 0.1835 (Train: 4.4s, Query: 0.00s)\n",
      "15:28:28 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5463, F1: 0.1836\n",
      "15:28:28 [INFO]   Run 4/5\n",
      "15:28:42 [INFO]     2,623 labeled -> F1-Score: 0.1740 (Train: 4.4s, Query: 0.00s)\n",
      "15:28:46 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5439, F1: 0.1746\n",
      "15:28:46 [INFO]   Run 5/5\n",
      "15:28:59 [INFO]     2,623 labeled -> F1-Score: 0.1931 (Train: 4.1s, Query: 0.00s)\n",
      "15:29:03 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5305, F1: 0.1904\n",
      "15:29:03 [INFO] \n",
      "Logistic Regression + Entropy Sampling - Budget: 60% (3,935 Samples)\n",
      "15:29:03 [INFO]   Run 1/5\n",
      "15:29:29 [INFO]     3,935 labeled -> F1-Score: 0.1948 (Train: 6.3s, Query: 0.00s)\n",
      "15:29:35 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5341, F1: 0.1781\n",
      "15:29:35 [INFO]   Run 2/5\n",
      "15:30:00 [INFO]     3,935 labeled -> F1-Score: 0.1782 (Train: 6.5s, Query: 0.00s)\n",
      "15:30:08 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5329, F1: 0.1757\n",
      "15:30:08 [INFO]   Run 3/5\n",
      "15:30:32 [INFO]     3,935 labeled -> F1-Score: 0.1805 (Train: 6.1s, Query: 0.00s)\n",
      "15:30:39 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5433, F1: 0.1871\n",
      "15:30:39 [INFO]   Run 4/5\n",
      "15:31:06 [INFO]     3,935 labeled -> F1-Score: 0.1756 (Train: 6.5s, Query: 0.00s)\n",
      "15:31:13 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5421, F1: 0.1739\n",
      "15:31:13 [INFO]   Run 5/5\n",
      "15:31:38 [INFO]     3,935 labeled -> F1-Score: 0.1928 (Train: 6.0s, Query: 0.00s)\n",
      "15:31:44 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5427, F1: 0.1912\n",
      "15:31:44 [INFO] \n",
      "Logistic Regression + Entropy Sampling - Budget: 80% (5,247 Samples)\n",
      "15:31:44 [INFO]   Run 1/5\n",
      "15:32:34 [INFO]     5,247 labeled -> F1-Score: 0.1951 (Train: 9.1s, Query: 0.00s)\n",
      "15:32:43 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5317, F1: 0.1983\n",
      "15:32:43 [INFO]   Run 2/5\n",
      "15:33:33 [INFO]     5,247 labeled -> F1-Score: 0.1933 (Train: 8.6s, Query: 0.00s)\n",
      "15:33:43 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5463, F1: 0.1971\n",
      "15:33:43 [INFO]   Run 3/5\n",
      "15:34:33 [INFO]     5,247 labeled -> F1-Score: 0.1870 (Train: 9.0s, Query: 0.00s)\n",
      "15:34:42 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5482, F1: 0.1866\n",
      "15:34:42 [INFO]   Run 4/5\n",
      "15:35:32 [INFO]     5,247 labeled -> F1-Score: 0.1877 (Train: 9.0s, Query: 0.00s)\n",
      "15:35:41 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5433, F1: 0.1878\n",
      "15:35:41 [INFO]   Run 5/5\n",
      "15:36:30 [INFO]     5,247 labeled -> F1-Score: 0.2047 (Train: 8.9s, Query: 0.00s)\n",
      "15:36:40 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5506, F1: 0.2025\n",
      "15:36:40 [INFO] \n",
      "Logistic Regression + Entropy Sampling - Budget: 100% (6,559 Samples)\n",
      "15:36:40 [INFO]   Run 1/5\n",
      "15:37:51 [INFO]     6,559 labeled -> F1-Score: 0.1860 (Train: 10.6s, Query: 0.00s)\n",
      "15:38:03 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:38:03 [INFO]   Run 2/5\n",
      "15:39:13 [INFO]     6,559 labeled -> F1-Score: 0.1878 (Train: 11.2s, Query: 0.00s)\n",
      "15:39:25 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:39:25 [INFO]   Run 3/5\n",
      "15:40:35 [INFO]     6,559 labeled -> F1-Score: 0.1878 (Train: 11.1s, Query: 0.00s)\n",
      "15:40:46 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:40:46 [INFO]   Run 4/5\n",
      "15:41:58 [INFO]     6,559 labeled -> F1-Score: 0.1870 (Train: 11.0s, Query: 0.00s)\n",
      "15:42:10 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:42:10 [INFO]   Run 5/5\n",
      "15:43:22 [INFO]     6,559 labeled -> F1-Score: 0.1940 (Train: 11.0s, Query: 0.00s)\n",
      "15:43:34 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "\n",
      "[ok] Logistic Regression + Entropy Sampling abgeschlossen in 16.4 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 15/20: Logistic Regression + Margin Sampling\n",
      "============================================================\n",
      "15:43:34 [INFO] \n",
      "Logistic Regression + Margin Sampling - Budget: 20% (1,311 Samples)\n",
      "15:43:34 [INFO]   Run 1/5\n",
      "15:43:37 [INFO]     1,311 labeled -> F1-Score: 0.1718 (Train: 1.8s, Query: 0.01s)\n",
      "15:43:39 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5030, F1: 0.1518\n",
      "15:43:39 [INFO]   Run 2/5\n",
      "15:43:42 [INFO]     1,311 labeled -> F1-Score: 0.1588 (Train: 1.9s, Query: 0.00s)\n",
      "15:43:44 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5280, F1: 0.1724\n",
      "15:43:44 [INFO]   Run 3/5\n",
      "15:43:47 [INFO]     1,311 labeled -> F1-Score: 0.1722 (Train: 1.9s, Query: 0.00s)\n",
      "15:43:49 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5250, F1: 0.1791\n",
      "15:43:49 [INFO]   Run 4/5\n",
      "15:43:52 [INFO]     1,311 labeled -> F1-Score: 0.2064 (Train: 1.9s, Query: 0.01s)\n",
      "15:43:54 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5335, F1: 0.1926\n",
      "15:43:54 [INFO]   Run 5/5\n",
      "15:43:57 [INFO]     1,311 labeled -> F1-Score: 0.1817 (Train: 1.8s, Query: 0.00s)\n",
      "15:43:59 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5329, F1: 0.1813\n",
      "15:43:59 [INFO] \n",
      "Logistic Regression + Margin Sampling - Budget: 40% (2,623 Samples)\n",
      "15:43:59 [INFO]   Run 1/5\n",
      "15:44:13 [INFO]     2,623 labeled -> F1-Score: 0.1864 (Train: 4.7s, Query: 0.01s)\n",
      "15:44:18 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5323, F1: 0.1870\n",
      "15:44:18 [INFO]   Run 2/5\n",
      "15:44:32 [INFO]     2,623 labeled -> F1-Score: 0.1766 (Train: 4.7s, Query: 0.00s)\n",
      "15:44:36 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5354, F1: 0.1790\n",
      "15:44:36 [INFO]   Run 3/5\n",
      "15:44:50 [INFO]     2,623 labeled -> F1-Score: 0.1907 (Train: 4.4s, Query: 0.00s)\n",
      "15:44:54 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5463, F1: 0.1912\n",
      "15:44:54 [INFO]   Run 4/5\n",
      "15:45:08 [INFO]     2,623 labeled -> F1-Score: 0.1908 (Train: 4.4s, Query: 0.00s)\n",
      "15:45:13 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5555, F1: 0.1929\n",
      "15:45:13 [INFO]   Run 5/5\n",
      "15:45:26 [INFO]     2,623 labeled -> F1-Score: 0.1898 (Train: 4.5s, Query: 0.00s)\n",
      "15:45:31 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5409, F1: 0.1900\n",
      "15:45:31 [INFO] \n",
      "Logistic Regression + Margin Sampling - Budget: 60% (3,935 Samples)\n",
      "15:45:31 [INFO]   Run 1/5\n",
      "15:45:56 [INFO]     3,935 labeled -> F1-Score: 0.1885 (Train: 6.4s, Query: 0.00s)\n",
      "15:46:04 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5232, F1: 0.1871\n",
      "15:46:04 [INFO]   Run 2/5\n",
      "15:46:29 [INFO]     3,935 labeled -> F1-Score: 0.1771 (Train: 6.4s, Query: 0.00s)\n",
      "15:46:36 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5250, F1: 0.1782\n",
      "15:46:36 [INFO]   Run 3/5\n",
      "15:47:01 [INFO]     3,935 labeled -> F1-Score: 0.1905 (Train: 6.6s, Query: 0.00s)\n",
      "15:47:08 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5396, F1: 0.1844\n",
      "15:47:08 [INFO]   Run 4/5\n",
      "15:47:35 [INFO]     3,935 labeled -> F1-Score: 0.1952 (Train: 6.9s, Query: 0.00s)\n",
      "15:47:42 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5427, F1: 0.1848\n",
      "15:47:42 [INFO]   Run 5/5\n",
      "15:48:09 [INFO]     3,935 labeled -> F1-Score: 0.1851 (Train: 6.8s, Query: 0.01s)\n",
      "15:48:16 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5348, F1: 0.1835\n",
      "15:48:16 [INFO] \n",
      "Logistic Regression + Margin Sampling - Budget: 80% (5,247 Samples)\n",
      "15:48:16 [INFO]   Run 1/5\n",
      "15:49:07 [INFO]     5,247 labeled -> F1-Score: 0.1883 (Train: 9.4s, Query: 0.00s)\n",
      "15:49:17 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5287, F1: 0.1894\n",
      "15:49:17 [INFO]   Run 2/5\n",
      "15:50:06 [INFO]     5,247 labeled -> F1-Score: 0.1884 (Train: 9.7s, Query: 0.00s)\n",
      "15:50:16 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5378, F1: 0.1879\n",
      "15:50:16 [INFO]   Run 3/5\n",
      "15:51:07 [INFO]     5,247 labeled -> F1-Score: 0.1961 (Train: 9.4s, Query: 0.00s)\n",
      "15:51:16 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5518, F1: 0.1959\n",
      "15:51:16 [INFO]   Run 4/5\n",
      "15:52:07 [INFO]     5,247 labeled -> F1-Score: 0.1823 (Train: 9.5s, Query: 0.00s)\n",
      "15:52:17 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5451, F1: 0.1824\n",
      "15:52:17 [INFO]   Run 5/5\n",
      "15:53:07 [INFO]     5,247 labeled -> F1-Score: 0.1923 (Train: 9.2s, Query: 0.00s)\n",
      "15:53:17 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5402, F1: 0.1867\n",
      "15:53:17 [INFO] \n",
      "Logistic Regression + Margin Sampling - Budget: 100% (6,559 Samples)\n",
      "15:53:17 [INFO]   Run 1/5\n",
      "15:54:29 [INFO]     6,559 labeled -> F1-Score: 0.1888 (Train: 11.6s, Query: 0.00s)\n",
      "15:54:41 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:54:41 [INFO]   Run 2/5\n",
      "15:55:54 [INFO]     6,559 labeled -> F1-Score: 0.1821 (Train: 11.0s, Query: 0.00s)\n",
      "15:56:06 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:56:06 [INFO]   Run 3/5\n",
      "15:57:21 [INFO]     6,559 labeled -> F1-Score: 0.1883 (Train: 11.4s, Query: 0.00s)\n",
      "15:57:33 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:57:33 [INFO]   Run 4/5\n",
      "15:58:45 [INFO]     6,559 labeled -> F1-Score: 0.1880 (Train: 11.9s, Query: 0.00s)\n",
      "15:58:58 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "15:58:58 [INFO]   Run 5/5\n",
      "16:00:11 [INFO]     6,559 labeled -> F1-Score: 0.1873 (Train: 12.1s, Query: 0.00s)\n",
      "16:00:23 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "\n",
      "[ok] Logistic Regression + Margin Sampling abgeschlossen in 16.8 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 16/20: Logistic Regression + Least Confidence\n",
      "============================================================\n",
      "16:00:23 [INFO] \n",
      "Logistic Regression + Least Confidence - Budget: 20% (1,311 Samples)\n",
      "16:00:23 [INFO]   Run 1/5\n",
      "16:00:26 [INFO]     1,311 labeled -> F1-Score: 0.1954 (Train: 1.7s, Query: 0.01s)\n",
      "16:00:29 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4902, F1: 0.2067\n",
      "16:00:29 [INFO]   Run 2/5\n",
      "16:00:31 [INFO]     1,311 labeled -> F1-Score: 0.1738 (Train: 1.8s, Query: 0.00s)\n",
      "16:00:34 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5341, F1: 0.1787\n",
      "16:00:34 [INFO]   Run 3/5\n",
      "16:00:37 [INFO]     1,311 labeled -> F1-Score: 0.1628 (Train: 1.8s, Query: 0.01s)\n",
      "16:00:39 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5293, F1: 0.1695\n",
      "16:00:39 [INFO]   Run 4/5\n",
      "16:00:42 [INFO]     1,311 labeled -> F1-Score: 0.1796 (Train: 1.8s, Query: 0.00s)\n",
      "16:00:44 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5177, F1: 0.1799\n",
      "16:00:44 [INFO]   Run 5/5\n",
      "16:00:46 [INFO]     1,311 labeled -> F1-Score: 0.1881 (Train: 1.8s, Query: 0.00s)\n",
      "16:00:48 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5366, F1: 0.1878\n",
      "16:00:48 [INFO] \n",
      "Logistic Regression + Least Confidence - Budget: 40% (2,623 Samples)\n",
      "16:00:48 [INFO]   Run 1/5\n",
      "16:01:02 [INFO]     2,623 labeled -> F1-Score: 0.1801 (Train: 4.8s, Query: 0.00s)\n",
      "16:01:07 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5128, F1: 0.1829\n",
      "16:01:07 [INFO]   Run 2/5\n",
      "16:01:21 [INFO]     2,623 labeled -> F1-Score: 0.1861 (Train: 4.4s, Query: 0.00s)\n",
      "16:01:26 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5378, F1: 0.1871\n",
      "16:01:26 [INFO]   Run 3/5\n",
      "16:01:39 [INFO]     2,623 labeled -> F1-Score: 0.1878 (Train: 4.4s, Query: 0.00s)\n",
      "16:01:43 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5470, F1: 0.1888\n",
      "16:01:43 [INFO]   Run 4/5\n",
      "16:01:57 [INFO]     2,623 labeled -> F1-Score: 0.1777 (Train: 4.5s, Query: 0.00s)\n",
      "16:02:01 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5305, F1: 0.1776\n",
      "16:02:01 [INFO]   Run 5/5\n",
      "16:02:15 [INFO]     2,623 labeled -> F1-Score: 0.1949 (Train: 4.5s, Query: 0.00s)\n",
      "16:02:19 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5439, F1: 0.1935\n",
      "16:02:19 [INFO] \n",
      "Logistic Regression + Least Confidence - Budget: 60% (3,935 Samples)\n",
      "16:02:19 [INFO]   Run 1/5\n",
      "16:02:44 [INFO]     3,935 labeled -> F1-Score: 0.2018 (Train: 6.3s, Query: 0.01s)\n",
      "16:02:51 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5317, F1: 0.1985\n",
      "16:02:51 [INFO]   Run 2/5\n",
      "16:03:18 [INFO]     3,935 labeled -> F1-Score: 0.1933 (Train: 6.5s, Query: 0.00s)\n",
      "16:03:25 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5488, F1: 0.1930\n",
      "16:03:25 [INFO]   Run 3/5\n",
      "16:03:50 [INFO]     3,935 labeled -> F1-Score: 0.1892 (Train: 6.3s, Query: 0.00s)\n",
      "16:03:57 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5439, F1: 0.1823\n",
      "16:03:57 [INFO]   Run 4/5\n",
      "16:04:22 [INFO]     3,935 labeled -> F1-Score: 0.1831 (Train: 6.6s, Query: 0.00s)\n",
      "16:04:29 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5451, F1: 0.1866\n",
      "16:04:29 [INFO]   Run 5/5\n",
      "16:04:54 [INFO]     3,935 labeled -> F1-Score: 0.1935 (Train: 6.3s, Query: 0.00s)\n",
      "16:05:00 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5402, F1: 0.1887\n",
      "16:05:00 [INFO] \n",
      "Logistic Regression + Least Confidence - Budget: 80% (5,247 Samples)\n",
      "16:05:00 [INFO]   Run 1/5\n",
      "16:05:51 [INFO]     5,247 labeled -> F1-Score: 0.2033 (Train: 9.1s, Query: 0.00s)\n",
      "16:06:00 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5372, F1: 0.2060\n",
      "16:06:00 [INFO]   Run 2/5\n",
      "16:06:51 [INFO]     5,247 labeled -> F1-Score: 0.1887 (Train: 9.4s, Query: 0.00s)\n",
      "16:07:00 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5427, F1: 0.1880\n",
      "16:07:00 [INFO]   Run 3/5\n",
      "16:07:49 [INFO]     5,247 labeled -> F1-Score: 0.1881 (Train: 8.8s, Query: 0.00s)\n",
      "16:07:58 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5457, F1: 0.1874\n",
      "16:07:58 [INFO]   Run 4/5\n",
      "16:08:48 [INFO]     5,247 labeled -> F1-Score: 0.1991 (Train: 9.0s, Query: 0.00s)\n",
      "16:08:57 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5476, F1: 0.1969\n",
      "16:08:57 [INFO]   Run 5/5\n",
      "16:09:44 [INFO]     5,247 labeled -> F1-Score: 0.1839 (Train: 9.0s, Query: 0.00s)\n",
      "16:09:54 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5366, F1: 0.1846\n",
      "16:09:54 [INFO] \n",
      "Logistic Regression + Least Confidence - Budget: 100% (6,559 Samples)\n",
      "16:09:54 [INFO]   Run 1/5\n",
      "16:11:05 [INFO]     6,559 labeled -> F1-Score: 0.1895 (Train: 11.2s, Query: 0.00s)\n",
      "16:11:17 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "16:11:17 [INFO]   Run 2/5\n",
      "16:12:27 [INFO]     6,559 labeled -> F1-Score: 0.1921 (Train: 11.2s, Query: 0.00s)\n",
      "16:12:39 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "16:12:39 [INFO]   Run 3/5\n",
      "16:13:49 [INFO]     6,559 labeled -> F1-Score: 0.1882 (Train: 11.4s, Query: 0.00s)\n",
      "16:14:01 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "16:14:01 [INFO]   Run 4/5\n",
      "16:15:11 [INFO]     6,559 labeled -> F1-Score: 0.1917 (Train: 11.9s, Query: 0.00s)\n",
      "16:15:23 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "16:15:23 [INFO]   Run 5/5\n",
      "16:16:34 [INFO]     6,559 labeled -> F1-Score: 0.1899 (Train: 11.2s, Query: 0.00s)\n",
      "16:16:46 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5396, F1: 0.1883\n",
      "\n",
      "[ok] Logistic Regression + Least Confidence abgeschlossen in 16.4 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 17/20: SVM + Random Sampling\n",
      "============================================================\n",
      "16:16:46 [INFO] \n",
      "SVM + Random Sampling - Budget: 20% (1,311 Samples)\n",
      "16:16:46 [INFO]   Run 1/5\n",
      "16:16:47 [INFO]     1,311 labeled -> F1-Score: 0.1729 (Train: 0.5s, Query: 0.00s)\n",
      "16:16:48 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5390, F1: 0.1683\n",
      "16:16:48 [INFO]   Run 2/5\n",
      "16:16:49 [INFO]     1,311 labeled -> F1-Score: 0.1608 (Train: 0.5s, Query: 0.00s)\n",
      "16:16:50 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5335, F1: 0.1599\n",
      "16:16:50 [INFO]   Run 3/5\n",
      "16:16:51 [INFO]     1,311 labeled -> F1-Score: 0.1675 (Train: 0.5s, Query: 0.00s)\n",
      "16:16:52 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5390, F1: 0.1648\n",
      "16:16:52 [INFO]   Run 4/5\n",
      "16:16:53 [INFO]     1,311 labeled -> F1-Score: 0.1431 (Train: 0.5s, Query: 0.00s)\n",
      "16:16:54 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5226, F1: 0.1449\n",
      "16:16:54 [INFO]   Run 5/5\n",
      "16:16:55 [INFO]     1,311 labeled -> F1-Score: 0.1427 (Train: 0.5s, Query: 0.00s)\n",
      "16:16:56 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5421, F1: 0.1767\n",
      "16:16:56 [INFO] \n",
      "SVM + Random Sampling - Budget: 40% (2,623 Samples)\n",
      "16:16:56 [INFO]   Run 1/5\n",
      "16:17:04 [INFO]     2,623 labeled -> F1-Score: 0.1838 (Train: 2.8s, Query: 0.00s)\n",
      "16:17:07 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5476, F1: 0.1832\n",
      "16:17:07 [INFO]   Run 2/5\n",
      "16:17:15 [INFO]     2,623 labeled -> F1-Score: 0.1814 (Train: 2.9s, Query: 0.00s)\n",
      "16:17:18 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5482, F1: 0.1814\n",
      "16:17:18 [INFO]   Run 3/5\n",
      "16:17:26 [INFO]     2,623 labeled -> F1-Score: 0.1823 (Train: 2.6s, Query: 0.00s)\n",
      "16:17:29 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5488, F1: 0.1823\n",
      "16:17:29 [INFO]   Run 4/5\n",
      "16:17:37 [INFO]     2,623 labeled -> F1-Score: 0.1696 (Train: 2.8s, Query: 0.00s)\n",
      "16:17:40 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5451, F1: 0.1796\n",
      "16:17:40 [INFO]   Run 5/5\n",
      "16:17:48 [INFO]     2,623 labeled -> F1-Score: 0.1730 (Train: 2.7s, Query: 0.00s)\n",
      "16:17:51 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5451, F1: 0.1730\n",
      "16:17:51 [INFO] \n",
      "SVM + Random Sampling - Budget: 60% (3,935 Samples)\n",
      "16:17:51 [INFO]   Run 1/5\n",
      "16:18:09 [INFO]     3,935 labeled -> F1-Score: 0.1854 (Train: 5.2s, Query: 0.00s)\n",
      "16:18:15 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5494, F1: 0.1852\n",
      "16:18:15 [INFO]   Run 2/5\n",
      "16:18:33 [INFO]     3,935 labeled -> F1-Score: 0.1789 (Train: 5.1s, Query: 0.00s)\n",
      "16:18:39 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5518, F1: 0.1869\n",
      "16:18:39 [INFO]   Run 3/5\n",
      "16:18:56 [INFO]     3,935 labeled -> F1-Score: 0.1754 (Train: 4.8s, Query: 0.00s)\n",
      "16:19:03 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5445, F1: 0.1754\n",
      "16:19:03 [INFO]   Run 4/5\n",
      "16:19:21 [INFO]     3,935 labeled -> F1-Score: 0.1853 (Train: 5.2s, Query: 0.00s)\n",
      "16:19:27 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5488, F1: 0.1881\n",
      "16:19:27 [INFO]   Run 5/5\n",
      "16:19:45 [INFO]     3,935 labeled -> F1-Score: 0.1779 (Train: 5.1s, Query: 0.00s)\n",
      "16:19:51 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "16:19:51 [INFO] \n",
      "SVM + Random Sampling - Budget: 80% (5,247 Samples)\n",
      "16:19:51 [INFO]   Run 1/5\n",
      "16:20:36 [INFO]     5,247 labeled -> F1-Score: 0.1782 (Train: 10.0s, Query: 0.00s)\n",
      "16:20:48 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5463, F1: 0.1768\n",
      "16:20:48 [INFO]   Run 2/5\n",
      "16:21:32 [INFO]     5,247 labeled -> F1-Score: 0.1858 (Train: 9.6s, Query: 0.00s)\n",
      "16:21:43 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5506, F1: 0.1855\n",
      "16:21:43 [INFO]   Run 3/5\n",
      "16:22:27 [INFO]     5,247 labeled -> F1-Score: 0.1838 (Train: 9.7s, Query: 0.00s)\n",
      "16:22:39 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5488, F1: 0.1838\n",
      "16:22:39 [INFO]   Run 4/5\n",
      "16:23:23 [INFO]     5,247 labeled -> F1-Score: 0.1789 (Train: 10.5s, Query: 0.00s)\n",
      "16:23:35 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5488, F1: 0.1889\n",
      "16:23:35 [INFO]   Run 5/5\n",
      "16:24:21 [INFO]     5,247 labeled -> F1-Score: 0.1773 (Train: 10.6s, Query: 0.00s)\n",
      "16:24:32 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5476, F1: 0.1781\n",
      "16:24:32 [INFO] \n",
      "SVM + Random Sampling - Budget: 100% (6,559 Samples)\n",
      "16:24:32 [INFO]   Run 1/5\n",
      "16:25:47 [INFO]     6,559 labeled -> F1-Score: 0.1768 (Train: 15.1s, Query: 0.00s)\n",
      "16:26:05 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "16:26:05 [INFO]   Run 2/5\n",
      "16:27:18 [INFO]     6,559 labeled -> F1-Score: 0.1786 (Train: 14.3s, Query: 0.00s)\n",
      "16:27:36 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "16:27:36 [INFO]   Run 3/5\n",
      "16:28:50 [INFO]     6,559 labeled -> F1-Score: 0.1761 (Train: 14.7s, Query: 0.00s)\n",
      "16:29:08 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "16:29:08 [INFO]   Run 4/5\n",
      "16:30:23 [INFO]     6,559 labeled -> F1-Score: 0.1767 (Train: 14.6s, Query: 0.00s)\n",
      "16:30:41 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "16:30:41 [INFO]   Run 5/5\n",
      "16:31:55 [INFO]     6,559 labeled -> F1-Score: 0.1775 (Train: 14.5s, Query: 0.00s)\n",
      "16:32:12 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "\n",
      "[ok] SVM + Random Sampling abgeschlossen in 15.4 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 18/20: SVM + Entropy Sampling\n",
      "============================================================\n",
      "16:32:12 [INFO] \n",
      "SVM + Entropy Sampling - Budget: 20% (1,311 Samples)\n",
      "16:32:12 [INFO]   Run 1/5\n",
      "16:32:15 [INFO]     1,311 labeled -> F1-Score: 0.1897 (Train: 0.5s, Query: 0.71s)\n",
      "16:32:16 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5433, F1: 0.1809\n",
      "16:32:16 [INFO]   Run 2/5\n",
      "16:32:18 [INFO]     1,311 labeled -> F1-Score: 0.1386 (Train: 0.5s, Query: 0.70s)\n",
      "16:32:19 [INFO]     Final: 1,311 labeled -> Accuracy: 0.4659, F1: 0.1477\n",
      "16:32:19 [INFO]   Run 3/5\n",
      "16:32:22 [INFO]     1,311 labeled -> F1-Score: 0.1578 (Train: 0.6s, Query: 0.85s)\n",
      "16:32:23 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5305, F1: 0.1719\n",
      "16:32:23 [INFO]   Run 4/5\n",
      "16:32:25 [INFO]     1,311 labeled -> F1-Score: 0.1622 (Train: 0.6s, Query: 0.73s)\n",
      "16:32:26 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5348, F1: 0.1604\n",
      "16:32:26 [INFO]   Run 5/5\n",
      "16:32:29 [INFO]     1,311 labeled -> F1-Score: 0.1401 (Train: 0.6s, Query: 0.72s)\n",
      "16:32:30 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5177, F1: 0.1414\n",
      "16:32:30 [INFO] \n",
      "SVM + Entropy Sampling - Budget: 40% (2,623 Samples)\n",
      "16:32:30 [INFO]   Run 1/5\n",
      "16:32:42 [INFO]     2,623 labeled -> F1-Score: 0.1781 (Train: 2.7s, Query: 1.20s)\n",
      "16:32:45 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5476, F1: 0.1781\n",
      "16:32:45 [INFO]   Run 2/5\n",
      "16:32:57 [INFO]     2,623 labeled -> F1-Score: 0.1617 (Train: 2.6s, Query: 1.13s)\n",
      "16:33:01 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5396, F1: 0.1617\n",
      "16:33:01 [INFO]   Run 3/5\n",
      "16:33:14 [INFO]     2,623 labeled -> F1-Score: 0.1738 (Train: 2.9s, Query: 1.24s)\n",
      "16:33:17 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5317, F1: 0.1671\n",
      "16:33:17 [INFO]   Run 4/5\n",
      "16:33:30 [INFO]     2,623 labeled -> F1-Score: 0.1732 (Train: 2.6s, Query: 1.19s)\n",
      "16:33:33 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5378, F1: 0.1769\n",
      "16:33:33 [INFO]   Run 5/5\n",
      "16:33:46 [INFO]     2,623 labeled -> F1-Score: 0.1645 (Train: 3.2s, Query: 1.26s)\n",
      "16:33:50 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4787, F1: 0.1870\n",
      "16:33:50 [INFO] \n",
      "SVM + Entropy Sampling - Budget: 60% (3,935 Samples)\n",
      "16:33:50 [INFO]   Run 1/5\n",
      "16:34:14 [INFO]     3,935 labeled -> F1-Score: 0.1796 (Train: 5.1s, Query: 1.13s)\n",
      "16:34:21 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5470, F1: 0.1772\n",
      "16:34:21 [INFO]   Run 2/5\n",
      "16:34:45 [INFO]     3,935 labeled -> F1-Score: 0.1781 (Train: 5.0s, Query: 1.16s)\n",
      "16:34:51 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5476, F1: 0.1782\n",
      "16:34:51 [INFO]   Run 3/5\n",
      "16:35:19 [INFO]     3,935 labeled -> F1-Score: 0.1788 (Train: 5.7s, Query: 1.22s)\n",
      "16:35:26 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5506, F1: 0.1943\n",
      "16:35:26 [INFO]   Run 4/5\n",
      "16:35:51 [INFO]     3,935 labeled -> F1-Score: 0.1759 (Train: 5.3s, Query: 1.23s)\n",
      "16:35:58 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1787\n",
      "16:35:58 [INFO]   Run 5/5\n",
      "16:36:26 [INFO]     3,935 labeled -> F1-Score: 0.1780 (Train: 5.3s, Query: 1.22s)\n",
      "16:36:33 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5488, F1: 0.1776\n",
      "16:36:33 [INFO] \n",
      "SVM + Entropy Sampling - Budget: 80% (5,247 Samples)\n",
      "16:36:33 [INFO]   Run 1/5\n",
      "16:37:26 [INFO]     5,247 labeled -> F1-Score: 0.1773 (Train: 10.3s, Query: 0.78s)\n",
      "16:37:38 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "16:37:38 [INFO]   Run 2/5\n",
      "16:38:33 [INFO]     5,247 labeled -> F1-Score: 0.1861 (Train: 10.0s, Query: 0.89s)\n",
      "16:38:45 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5512, F1: 0.1861\n",
      "16:38:45 [INFO]   Run 3/5\n",
      "16:39:44 [INFO]     5,247 labeled -> F1-Score: 0.1773 (Train: 10.9s, Query: 0.81s)\n",
      "16:39:57 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "16:39:57 [INFO]   Run 4/5\n",
      "16:40:57 [INFO]     5,247 labeled -> F1-Score: 0.1782 (Train: 10.6s, Query: 0.86s)\n",
      "16:41:10 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "16:41:10 [INFO]   Run 5/5\n",
      "16:42:10 [INFO]     5,247 labeled -> F1-Score: 0.1861 (Train: 10.7s, Query: 0.80s)\n",
      "16:42:23 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5512, F1: 0.1861\n",
      "16:42:23 [INFO] \n",
      "SVM + Entropy Sampling - Budget: 100% (6,559 Samples)\n",
      "16:42:23 [INFO]   Run 1/5\n",
      "16:43:48 [INFO]     6,559 labeled -> F1-Score: 0.1861 (Train: 15.4s, Query: 0.33s)\n",
      "16:44:08 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "16:44:08 [INFO]   Run 2/5\n",
      "16:45:33 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 14.1s, Query: 0.31s)\n",
      "16:45:52 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "16:45:52 [INFO]   Run 3/5\n",
      "16:47:23 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 14.7s, Query: 0.29s)\n",
      "16:47:40 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "16:47:40 [INFO]   Run 4/5\n",
      "16:49:04 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 14.0s, Query: 0.30s)\n",
      "16:49:21 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "16:49:21 [INFO]   Run 5/5\n",
      "16:50:50 [INFO]     6,559 labeled -> F1-Score: 0.1861 (Train: 13.8s, Query: 0.29s)\n",
      "16:51:07 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "\n",
      "[ok] SVM + Entropy Sampling abgeschlossen in 18.9 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 19/20: SVM + Margin Sampling\n",
      "============================================================\n",
      "16:51:07 [INFO] \n",
      "SVM + Margin Sampling - Budget: 20% (1,311 Samples)\n",
      "16:51:07 [INFO]   Run 1/5\n",
      "16:51:09 [INFO]     1,311 labeled -> F1-Score: 0.1893 (Train: 0.5s, Query: 0.76s)\n",
      "16:51:10 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5409, F1: 0.1862\n",
      "16:51:10 [INFO]   Run 2/5\n",
      "16:51:13 [INFO]     1,311 labeled -> F1-Score: 0.1397 (Train: 0.6s, Query: 0.70s)\n",
      "16:51:14 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5360, F1: 0.1521\n",
      "16:51:14 [INFO]   Run 3/5\n",
      "16:51:16 [INFO]     1,311 labeled -> F1-Score: 0.1598 (Train: 0.6s, Query: 0.81s)\n",
      "16:51:17 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5354, F1: 0.1680\n",
      "16:51:17 [INFO]   Run 4/5\n",
      "16:51:20 [INFO]     1,311 labeled -> F1-Score: 0.1609 (Train: 0.6s, Query: 0.73s)\n",
      "16:51:21 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5390, F1: 0.1628\n",
      "16:51:21 [INFO]   Run 5/5\n",
      "16:51:23 [INFO]     1,311 labeled -> F1-Score: 0.1302 (Train: 0.6s, Query: 0.75s)\n",
      "16:51:25 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5085, F1: 0.1283\n",
      "16:51:25 [INFO] \n",
      "SVM + Margin Sampling - Budget: 40% (2,623 Samples)\n",
      "16:51:25 [INFO]   Run 1/5\n",
      "16:51:37 [INFO]     2,623 labeled -> F1-Score: 0.1665 (Train: 2.7s, Query: 1.14s)\n",
      "16:51:40 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5305, F1: 0.1664\n",
      "16:51:40 [INFO]   Run 2/5\n",
      "16:51:52 [INFO]     2,623 labeled -> F1-Score: 0.1780 (Train: 2.7s, Query: 1.11s)\n",
      "16:51:55 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5476, F1: 0.1780\n",
      "16:51:55 [INFO]   Run 3/5\n",
      "16:52:09 [INFO]     2,623 labeled -> F1-Score: 0.1749 (Train: 3.1s, Query: 1.25s)\n",
      "16:52:13 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5433, F1: 0.1756\n",
      "16:52:13 [INFO]   Run 4/5\n",
      "16:52:27 [INFO]     2,623 labeled -> F1-Score: 0.1742 (Train: 3.2s, Query: 1.23s)\n",
      "16:52:31 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5482, F1: 0.1768\n",
      "16:52:31 [INFO]   Run 5/5\n",
      "16:52:45 [INFO]     2,623 labeled -> F1-Score: 0.1717 (Train: 3.3s, Query: 1.31s)\n",
      "16:52:49 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4866, F1: 0.1560\n",
      "16:52:49 [INFO] \n",
      "SVM + Margin Sampling - Budget: 60% (3,935 Samples)\n",
      "16:52:49 [INFO]   Run 1/5\n",
      "16:53:14 [INFO]     3,935 labeled -> F1-Score: 0.1753 (Train: 5.3s, Query: 1.12s)\n",
      "16:53:21 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5445, F1: 0.1659\n",
      "16:53:21 [INFO]   Run 2/5\n",
      "16:53:46 [INFO]     3,935 labeled -> F1-Score: 0.1791 (Train: 5.4s, Query: 1.15s)\n",
      "16:53:53 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5524, F1: 0.1877\n",
      "16:53:53 [INFO]   Run 3/5\n",
      "16:54:21 [INFO]     3,935 labeled -> F1-Score: 0.1849 (Train: 5.7s, Query: 1.22s)\n",
      "16:54:29 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5500, F1: 0.1834\n",
      "16:54:29 [INFO]   Run 4/5\n",
      "16:54:55 [INFO]     3,935 labeled -> F1-Score: 0.1796 (Train: 5.9s, Query: 1.26s)\n",
      "16:55:03 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5470, F1: 0.1772\n",
      "16:55:03 [INFO]   Run 5/5\n",
      "16:55:32 [INFO]     3,935 labeled -> F1-Score: 0.1590 (Train: 5.8s, Query: 1.34s)\n",
      "16:55:40 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5415, F1: 0.1644\n",
      "16:55:40 [INFO] \n",
      "SVM + Margin Sampling - Budget: 80% (5,247 Samples)\n",
      "16:55:40 [INFO]   Run 1/5\n",
      "16:56:33 [INFO]     5,247 labeled -> F1-Score: 0.1642 (Train: 9.6s, Query: 0.70s)\n",
      "16:56:44 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5427, F1: 0.1642\n",
      "16:56:44 [INFO]   Run 2/5\n",
      "16:57:37 [INFO]     5,247 labeled -> F1-Score: 0.1782 (Train: 10.0s, Query: 0.78s)\n",
      "16:57:48 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "16:57:48 [INFO]   Run 3/5\n",
      "16:58:46 [INFO]     5,247 labeled -> F1-Score: 0.1835 (Train: 10.1s, Query: 0.76s)\n",
      "16:58:57 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5451, F1: 0.1851\n",
      "16:58:57 [INFO]   Run 4/5\n",
      "16:59:54 [INFO]     5,247 labeled -> F1-Score: 0.1861 (Train: 10.1s, Query: 0.83s)\n",
      "17:00:06 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "17:00:06 [INFO]   Run 5/5\n",
      "17:01:05 [INFO]     5,247 labeled -> F1-Score: 0.1774 (Train: 10.4s, Query: 0.78s)\n",
      "17:01:17 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "17:01:17 [INFO] \n",
      "SVM + Margin Sampling - Budget: 100% (6,559 Samples)\n",
      "17:01:17 [INFO]   Run 1/5\n",
      "17:02:39 [INFO]     6,559 labeled -> F1-Score: 0.1642 (Train: 13.7s, Query: 0.27s)\n",
      "17:02:55 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "17:02:55 [INFO]   Run 2/5\n",
      "17:04:18 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 13.7s, Query: 0.28s)\n",
      "17:04:35 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "17:04:35 [INFO]   Run 3/5\n",
      "17:06:03 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 14.1s, Query: 0.30s)\n",
      "17:06:20 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "17:06:20 [INFO]   Run 4/5\n",
      "17:07:44 [INFO]     6,559 labeled -> F1-Score: 0.1774 (Train: 14.0s, Query: 0.30s)\n",
      "17:08:02 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "17:08:02 [INFO]   Run 5/5\n",
      "17:09:29 [INFO]     6,559 labeled -> F1-Score: 0.1768 (Train: 14.4s, Query: 0.31s)\n",
      "17:09:46 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "\n",
      "[ok] SVM + Margin Sampling abgeschlossen in 18.6 Minuten\n",
      "\n",
      "============================================================\n",
      "Experiment 20/20: SVM + Least Confidence\n",
      "============================================================\n",
      "17:09:46 [INFO] \n",
      "SVM + Least Confidence - Budget: 20% (1,311 Samples)\n",
      "17:09:46 [INFO]   Run 1/5\n",
      "17:09:48 [INFO]     1,311 labeled -> F1-Score: 0.1831 (Train: 0.5s, Query: 0.69s)\n",
      "17:09:49 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5384, F1: 0.1843\n",
      "17:09:49 [INFO]   Run 2/5\n",
      "17:09:51 [INFO]     1,311 labeled -> F1-Score: 0.1387 (Train: 0.5s, Query: 0.69s)\n",
      "17:09:52 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5421, F1: 0.1598\n",
      "17:09:52 [INFO]   Run 3/5\n",
      "17:09:55 [INFO]     1,311 labeled -> F1-Score: 0.1851 (Train: 0.6s, Query: 0.83s)\n",
      "17:09:56 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5317, F1: 0.1766\n",
      "17:09:56 [INFO]   Run 4/5\n",
      "17:09:59 [INFO]     1,311 labeled -> F1-Score: 0.1681 (Train: 0.5s, Query: 0.72s)\n",
      "17:10:00 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5293, F1: 0.1575\n",
      "17:10:00 [INFO]   Run 5/5\n",
      "17:10:03 [INFO]     1,311 labeled -> F1-Score: 0.1552 (Train: 0.7s, Query: 0.82s)\n",
      "17:10:04 [INFO]     Final: 1,311 labeled -> Accuracy: 0.5152, F1: 0.1373\n",
      "17:10:04 [INFO] \n",
      "SVM + Least Confidence - Budget: 40% (2,623 Samples)\n",
      "17:10:04 [INFO]   Run 1/5\n",
      "17:10:16 [INFO]     2,623 labeled -> F1-Score: 0.1774 (Train: 2.7s, Query: 1.14s)\n",
      "17:10:19 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5445, F1: 0.1773\n",
      "17:10:19 [INFO]   Run 2/5\n",
      "17:10:31 [INFO]     2,623 labeled -> F1-Score: 0.1498 (Train: 2.6s, Query: 1.05s)\n",
      "17:10:34 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5341, F1: 0.1531\n",
      "17:10:34 [INFO]   Run 3/5\n",
      "17:10:47 [INFO]     2,623 labeled -> F1-Score: 0.1863 (Train: 2.9s, Query: 1.14s)\n",
      "17:10:50 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5427, F1: 0.1738\n",
      "17:10:50 [INFO]   Run 4/5\n",
      "17:11:02 [INFO]     2,623 labeled -> F1-Score: 0.1624 (Train: 2.7s, Query: 1.16s)\n",
      "17:11:06 [INFO]     Final: 2,623 labeled -> Accuracy: 0.5390, F1: 0.1669\n",
      "17:11:06 [INFO]   Run 5/5\n",
      "17:11:19 [INFO]     2,623 labeled -> F1-Score: 0.1701 (Train: 3.1s, Query: 1.25s)\n",
      "17:11:23 [INFO]     Final: 2,623 labeled -> Accuracy: 0.4963, F1: 0.1677\n",
      "17:11:23 [INFO] \n",
      "SVM + Least Confidence - Budget: 60% (3,935 Samples)\n",
      "17:11:23 [INFO]   Run 1/5\n",
      "17:11:46 [INFO]     3,935 labeled -> F1-Score: 0.1777 (Train: 4.5s, Query: 1.11s)\n",
      "17:11:52 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5470, F1: 0.1863\n",
      "17:11:52 [INFO]   Run 2/5\n",
      "17:12:16 [INFO]     3,935 labeled -> F1-Score: 0.1790 (Train: 4.9s, Query: 1.10s)\n",
      "17:12:22 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5482, F1: 0.1790\n",
      "17:12:22 [INFO]   Run 3/5\n",
      "17:12:48 [INFO]     3,935 labeled -> F1-Score: 0.1852 (Train: 5.5s, Query: 1.15s)\n",
      "17:12:55 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5463, F1: 0.1746\n",
      "17:12:55 [INFO]   Run 4/5\n",
      "17:13:20 [INFO]     3,935 labeled -> F1-Score: 0.1804 (Train: 4.7s, Query: 1.13s)\n",
      "17:13:26 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5488, F1: 0.1796\n",
      "17:13:26 [INFO]   Run 5/5\n",
      "17:13:53 [INFO]     3,935 labeled -> F1-Score: 0.1749 (Train: 5.4s, Query: 1.18s)\n",
      "17:14:00 [INFO]     Final: 3,935 labeled -> Accuracy: 0.5463, F1: 0.1777\n",
      "17:14:00 [INFO] \n",
      "SVM + Least Confidence - Budget: 80% (5,247 Samples)\n",
      "17:14:00 [INFO]   Run 1/5\n",
      "17:14:53 [INFO]     5,247 labeled -> F1-Score: 0.1861 (Train: 9.7s, Query: 0.77s)\n",
      "17:15:04 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5512, F1: 0.1861\n",
      "17:15:04 [INFO]   Run 2/5\n",
      "17:15:57 [INFO]     5,247 labeled -> F1-Score: 0.1782 (Train: 9.6s, Query: 0.72s)\n",
      "17:16:08 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "17:16:08 [INFO]   Run 3/5\n",
      "17:17:07 [INFO]     5,247 labeled -> F1-Score: 0.1773 (Train: 10.6s, Query: 0.80s)\n",
      "17:17:19 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "17:17:19 [INFO]   Run 4/5\n",
      "17:18:16 [INFO]     5,247 labeled -> F1-Score: 0.1780 (Train: 10.8s, Query: 0.83s)\n",
      "17:18:29 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "17:18:29 [INFO]   Run 5/5\n",
      "17:19:30 [INFO]     5,247 labeled -> F1-Score: 0.1782 (Train: 11.1s, Query: 0.85s)\n",
      "17:19:42 [INFO]     Final: 5,247 labeled -> Accuracy: 0.5470, F1: 0.1773\n",
      "17:19:42 [INFO] \n",
      "SVM + Least Confidence - Budget: 100% (6,559 Samples)\n",
      "17:19:42 [INFO]   Run 1/5\n",
      "17:21:06 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 14.8s, Query: 0.31s)\n",
      "17:21:23 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "17:21:23 [INFO]   Run 2/5\n",
      "17:22:45 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 14.7s, Query: 0.31s)\n",
      "17:23:03 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "17:23:03 [INFO]   Run 3/5\n",
      "17:24:33 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 14.2s, Query: 0.27s)\n",
      "17:24:50 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "17:24:50 [INFO]   Run 4/5\n",
      "17:26:13 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 13.9s, Query: 0.28s)\n",
      "17:26:30 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "17:26:30 [INFO]   Run 5/5\n",
      "17:27:55 [INFO]     6,559 labeled -> F1-Score: 0.1773 (Train: 13.7s, Query: 0.28s)\n",
      "17:28:12 [INFO]     Final: 6,559 labeled -> Accuracy: 0.5470, F1: 0.1774\n",
      "\n",
      "[ok] SVM + Least Confidence abgeschlossen in 18.4 Minuten\n",
      "\n",
      "[ok] Alle Experimente abgeschlossen in 169.1 Minuten\n",
      "\n",
      "============================================================\n",
      "Führe statistische Analyse durch (F1-Score)...\n",
      "============================================================\n",
      "\n",
      "====================================================================================================\n",
      "DETAILLIERTER STATISTISCHER BERICHT - DACHMATERIAL (F1-SCORE)\n",
      "====================================================================================================\n",
      "Primäre Metrik: F1-Score (Macro Average)\n",
      "Signifikanzniveau: 0.05 (mit Bonferroni-Korrektur)\n",
      "Anzahl Runs pro Experiment: 5\n",
      "Statistischer Test: Wilcoxon Signed-Rank Test\n",
      "Effektstärkemaß: Cliff's Delta\n",
      "\n",
      "\n",
      "Keine signifikanten F1-Score Verbesserungen gefunden!\n",
      "\n",
      "\n",
      "ZUSAMMENFASSUNG NACH STRATEGIE (F1-SCORE):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Entropy Sampling:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/25 (0.0%)\n",
      "  - Durchschnittliche F1-Score Verbesserung: 12.97%\n",
      "  - Durchschnittliche Effektstärke: 0.189\n",
      "\n",
      "Margin Sampling:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/25 (0.0%)\n",
      "  - Durchschnittliche F1-Score Verbesserung: 12.05%\n",
      "  - Durchschnittliche Effektstärke: 0.138\n",
      "\n",
      "Least Confidence:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/25 (0.0%)\n",
      "  - Durchschnittliche F1-Score Verbesserung: 11.66%\n",
      "  - Durchschnittliche Effektstärke: 0.218\n",
      "\n",
      "\n",
      "ZUSAMMENFASSUNG NACH KLASSIFIKATOR (F1-SCORE):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "Naive Bayes:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "Random Forest:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "Logistic Regression:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "SVM:\n",
      "  - Signifikante F1-Score Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "====================================================================================================\n",
      "17:28:13 [INFO] [ok] Statistischer F1-Score Bericht gespeichert: reports/dachmaterial_f1_statistical_report.txt\n",
      "\n",
      "============================================================\n",
      "Berechne Label-Einsparungen (F1-Score basiert)...\n",
      "============================================================\n",
      "17:28:16 [INFO] [ok] F1-Score basierte Label-Einsparungs-Analyse erstellt: plots/dachmaterial_f1_label_savings_analysis.png\n",
      "\n",
      "================================================================================\n",
      "LABEL-EINSPARUNGS-BERICHT - Dachmaterial (F1-SCORE BASIERT)\n",
      "================================================================================\n",
      "\n",
      "ZIEL: 90% der Baseline F1-Score Performance\n",
      "------------------------------------------------------------\n",
      "\n",
      "Logistic Regression:\n",
      "  Baseline F1-Score (Random 100%): 0.1883\n",
      "  Ziel F1-Score: 0.1694\n",
      "  Labels benötigt:\n",
      "    - Least Confidence    :    400 ±  244 ( 93.9% gespart)\n",
      "      -> 20.0% weniger Labels als Random Sampling\n",
      "    - Margin Sampling     :    400 ±  244 ( 93.9% gespart)\n",
      "      -> 20.0% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :    500 ±  374 ( 92.4% gespart)\n",
      "    - Entropy Sampling    :    958 ± 1425 ( 85.4% gespart)\n",
      "\n",
      "Naive Bayes:\n",
      "  Baseline F1-Score (Random 100%): 0.0289\n",
      "  Ziel F1-Score: 0.0260\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Entropy Sampling    :    100 ±    0 ( 98.5% gespart)\n",
      "    - Margin Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Least Confidence    :    100 ±    0 ( 98.5% gespart)\n",
      "\n",
      "Neural Network:\n",
      "  Baseline F1-Score (Random 100%): 0.1814\n",
      "  Ziel F1-Score: 0.1633\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  1,696 ± 1451 ( 74.1% gespart)\n",
      "    - Margin Sampling     :  1,696 ± 1451 ( 74.1% gespart)\n",
      "    - Least Confidence    :  2,671 ± 1951 ( 59.3% gespart)\n",
      "    - Entropy Sampling    :  2,831 ± 1897 ( 56.8% gespart)\n",
      "\n",
      "Random Forest:\n",
      "  Baseline F1-Score (Random 100%): 0.2315\n",
      "  Ziel F1-Score: 0.2084\n",
      "  Labels benötigt:\n",
      "    - Margin Sampling     :    700 ±  200 ( 89.3% gespart)\n",
      "      -> 22.2% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :    900 ±  244 ( 86.3% gespart)\n",
      "    - Entropy Sampling    :  1,198 ± 1149 ( 81.7% gespart)\n",
      "    - Least Confidence    :  1,576 ± 1567 ( 76.0% gespart)\n",
      "\n",
      "SVM:\n",
      "  Baseline F1-Score (Random 100%): 0.1774\n",
      "  Ziel F1-Score: 0.1597\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  1,676 ± 1517 ( 74.4% gespart)\n",
      "    - Least Confidence    :  1,696 ± 1451 ( 74.1% gespart)\n",
      "    - Entropy Sampling    :  1,756 ± 1524 ( 73.2% gespart)\n",
      "    - Margin Sampling     :  1,756 ± 1550 ( 73.2% gespart)\n",
      "\n",
      "ZIEL: 95% der Baseline F1-Score Performance\n",
      "------------------------------------------------------------\n",
      "\n",
      "Logistic Regression:\n",
      "  Baseline F1-Score (Random 100%): 0.1883\n",
      "  Ziel F1-Score: 0.1788\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    998 ± 1233 ( 84.8% gespart)\n",
      "    - Margin Sampling     :  1,456 ± 1719 ( 77.8% gespart)\n",
      "    - Least Confidence    :  1,456 ± 1696 ( 77.8% gespart)\n",
      "    - Entropy Sampling    :  1,535 ± 2171 ( 76.6% gespart)\n",
      "\n",
      "Naive Bayes:\n",
      "  Baseline F1-Score (Random 100%): 0.0289\n",
      "  Ziel F1-Score: 0.0275\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Entropy Sampling    :    100 ±    0 ( 98.5% gespart)\n",
      "    - Margin Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Least Confidence    :    100 ±    0 ( 98.5% gespart)\n",
      "\n",
      "Neural Network:\n",
      "  Baseline F1-Score (Random 100%): 0.1814\n",
      "  Ziel F1-Score: 0.1724\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  1,696 ± 1451 ( 74.1% gespart)\n",
      "    - Margin Sampling     :  2,373 ± 1851 ( 63.8% gespart)\n",
      "    - Least Confidence    :  2,751 ± 1916 ( 58.0% gespart)\n",
      "    - Entropy Sampling    :  3,130 ± 1997 ( 52.3% gespart)\n",
      "\n",
      "Random Forest:\n",
      "  Baseline F1-Score (Random 100%): 0.2315\n",
      "  Ziel F1-Score: 0.2199\n",
      "  Labels benötigt:\n",
      "    - Margin Sampling     :  1,656 ± 1579 ( 74.7% gespart)\n",
      "      -> 42.3% weniger Labels als Random Sampling\n",
      "    - Least Confidence    :  2,573 ± 1979 ( 60.8% gespart)\n",
      "      -> 10.3% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :  2,870 ± 2463 ( 56.2% gespart)\n",
      "    - Entropy Sampling    :  3,030 ± 2244 ( 53.8% gespart)\n",
      "\n",
      "SVM:\n",
      "  Baseline F1-Score (Random 100%): 0.1774\n",
      "  Ziel F1-Score: 0.1686\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  2,453 ± 1826 ( 62.6% gespart)\n",
      "    - Least Confidence    :  2,453 ± 1901 ( 62.6% gespart)\n",
      "    - Margin Sampling     :  2,613 ± 1810 ( 60.2% gespart)\n",
      "    - Entropy Sampling    :  2,871 ± 2112 ( 56.2% gespart)\n",
      "\n",
      "ZIEL: 98% der Baseline F1-Score Performance\n",
      "------------------------------------------------------------\n",
      "\n",
      "Logistic Regression:\n",
      "  Baseline F1-Score (Random 100%): 0.1883\n",
      "  Ziel F1-Score: 0.1845\n",
      "  Labels benötigt:\n",
      "    - Least Confidence    :  1,636 ± 1663 ( 75.0% gespart)\n",
      "      -> 46.4% weniger Labels als Random Sampling\n",
      "    - Margin Sampling     :  2,135 ± 1764 ( 67.4% gespart)\n",
      "      -> 30.0% weniger Labels als Random Sampling\n",
      "    - Entropy Sampling    :  2,670 ± 2614 ( 59.3% gespart)\n",
      "      -> 12.5% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :  3,051 ± 1892 ( 53.5% gespart)\n",
      "\n",
      "Naive Bayes:\n",
      "  Baseline F1-Score (Random 100%): 0.0289\n",
      "  Ziel F1-Score: 0.0283\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Entropy Sampling    :    100 ±    0 ( 98.5% gespart)\n",
      "    - Margin Sampling     :    100 ±    0 ( 98.5% gespart)\n",
      "    - Least Confidence    :    100 ±    0 ( 98.5% gespart)\n",
      "\n",
      "Neural Network:\n",
      "  Baseline F1-Score (Random 100%): 0.1814\n",
      "  Ziel F1-Score: 0.1778\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  1,696 ± 1451 ( 74.1% gespart)\n",
      "    - Margin Sampling     :  2,671 ± 1951 ( 59.3% gespart)\n",
      "    - Least Confidence    :  3,130 ± 1977 ( 52.3% gespart)\n",
      "    - Entropy Sampling    :  3,348 ± 2118 ( 48.9% gespart)\n",
      "\n",
      "Random Forest:\n",
      "  Baseline F1-Score (Random 100%): 0.2315\n",
      "  Ziel F1-Score: 0.2269\n",
      "  Labels benötigt:\n",
      "    - Random Sampling     :  2,988 ± 2572 ( 54.4% gespart)\n",
      "    - Margin Sampling     :  3,268 ± 2276 ( 50.2% gespart)\n",
      "    - Entropy Sampling    :  3,466 ± 2429 ( 47.1% gespart)\n",
      "    - Least Confidence    :  3,785 ± 2444 ( 42.3% gespart)\n",
      "\n",
      "SVM:\n",
      "  Baseline F1-Score (Random 100%): 0.1774\n",
      "  Ziel F1-Score: 0.1739\n",
      "  Labels benötigt:\n",
      "    - Margin Sampling     :  2,773 ± 1734 ( 57.7% gespart)\n",
      "      -> 15.2% weniger Labels als Random Sampling\n",
      "    - Least Confidence    :  2,831 ± 2020 ( 56.8% gespart)\n",
      "      -> 13.4% weniger Labels als Random Sampling\n",
      "    - Random Sampling     :  3,270 ± 1947 ( 50.1% gespart)\n",
      "    - Entropy Sampling    :  3,866 ± 2017 ( 41.0% gespart)\n",
      "\n",
      "\n",
      "BESTE STRATEGIEN (bei 95% F1-Score Performance):\n",
      "------------------------------------------------------------\n",
      "Logistic Regression: Random Sampling (nur 998 Labels = 84.8% Einsparung)\n",
      "Naive Bayes: Random Sampling (nur 100 Labels = 98.5% Einsparung)\n",
      "Neural Network: Random Sampling (nur 1,696 Labels = 74.1% Einsparung)\n",
      "Random Forest: Margin Sampling (nur 1,656 Labels = 74.7% Einsparung)\n",
      "SVM: Random Sampling (nur 2,453 Labels = 62.6% Einsparung)\n",
      "\n",
      "\n",
      "DURCHSCHNITTLICHE EINSPARUNGEN ÜBER ALLE KLASSIFIKATOREN:\n",
      "------------------------------------------------------------\n",
      "Entropy Sampling: -32.2% weniger Labels als Random Sampling\n",
      "Least Confidence: -19.6% weniger Labels als Random Sampling\n",
      "Margin Sampling: -10.0% weniger Labels als Random Sampling\n",
      "\n",
      "================================================================================\n",
      "17:28:16 [INFO] [ok] F1-Score basierter Label-Einsparungs-Bericht gespeichert: reports/dachmaterial_f1_label_savings_report.txt\n",
      "[ok] F1-Score basierte Label-Einsparungen gespeichert: results/dachmaterial_f1_label_savings.csv\n",
      "\n",
      "============================================================\n",
      "Erstelle Visualisierungen (F1-Score basiert)...\n",
      "============================================================\n",
      "17:28:18 [INFO] [ok] Visualisierung mit F1-Score und Signifikanz für Logistic Regression erstellt: plots/dachmaterial_logistic_regression_f1_with_significance.png\n",
      "17:28:20 [INFO] [ok] Visualisierung mit F1-Score und Signifikanz für Naive Bayes erstellt: plots/dachmaterial_naive_bayes_f1_with_significance.png\n",
      "17:28:21 [INFO] [ok] Visualisierung mit F1-Score und Signifikanz für Neural Network erstellt: plots/dachmaterial_neural_network_f1_with_significance.png\n",
      "17:28:23 [INFO] [ok] Visualisierung mit F1-Score und Signifikanz für Random Forest erstellt: plots/dachmaterial_random_forest_f1_with_significance.png\n",
      "17:28:24 [INFO] [ok] Visualisierung mit F1-Score und Signifikanz für SVM erstellt: plots/dachmaterial_svm_f1_with_significance.png\n",
      "17:28:24 [WARNING] Keine signifikanten Ergebnisse gefunden!\n",
      "17:28:27 [INFO] [ok] Statistische F1-Score Zusammenfassung erstellt: plots/dachmaterial_f1_statistical_summary.png\n",
      "17:28:28 [INFO] [ok] Finale F1-Score Vergleichsvisualisierung erstellt: plots/dachmaterial_f1_final_comparison.png\n",
      "\n",
      "============================================================\n",
      "BESTE KOMBINATION BEI 100% BUDGET (F1-SCORE):\n",
      "============================================================\n",
      "Klassifikator: Random Forest\n",
      "Query-Strategie: Random Sampling\n",
      "Test F1-Score: 0.2315 (±0.0017)\n",
      "Test Accuracy: 0.4713 (±0.0007)\n",
      "============================================================\n",
      "\n",
      "TOP 5 KOMBINATIONEN (F1-SCORE):\n",
      "------------------------------------------------------------\n",
      "1. Random Forest + Random Sampling: F1=0.2315, Acc=0.4713\n",
      "2. Random Forest + Entropy Sampling: F1=0.2315, Acc=0.4717\n",
      "3. Random Forest + Least Confidence: F1=0.2304, Acc=0.4723\n",
      "4. Random Forest + Margin Sampling: F1=0.2302, Acc=0.4712\n",
      "5. Logistic Regression + Random Sampling: F1=0.1883, Acc=0.5396\n",
      "17:28:29 [INFO] [ok] F1-Score Improvement-Analyse erstellt: plots/dachmaterial_f1_improvement_analysis.png\n",
      "[ok] Alle F1-Score basierten Visualisierungen erstellt\n",
      "\n",
      "[ok] F1-Score Ergebnisse gespeichert in: results/dachmaterial_f1_active_learning_results.csv\n",
      "[ok] Statistische F1-Score Analyse gespeichert in: results/dachmaterial_f1_statistical_analysis.csv\n",
      "[ok] F1-Score Zusammenfassung gespeichert in: results/dachmaterial_f1_active_learning_summary.xlsx\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT ERFOLGREICH ABGESCHLOSSEN (F1-SCORE VERSION)\n",
      "Hauptmetrik: F1-Score (Macro Average)\n",
      "Gesamtanzahl Experimente: 500\n",
      "Datensatzgröße: 6,559 Trainingssamples\n",
      "Klassifikatoren: 5\n",
      "Query-Strategien: 4\n",
      "Budget-Stufen: 5\n",
      "Wiederholungen pro Experiment: 5\n",
      "\n",
      "Statistische Analyse (F1-Score):\n",
      "- Anzahl Vergleiche: 75\n",
      "- Signifikante F1-Score Verbesserungen: 0 (0.0%)\n",
      "- Verwendeter Test: Wilcoxon Signed-Rank Test\n",
      "- Effektstärkemaß: Cliff's Delta\n",
      "- Multiple Vergleiche: Bonferroni-Korrektur\n",
      "\n",
      "F1-Score basierte Label-Einsparungs-Analyse durchgeführt!\n",
      "- Visualisierung: plots/dachmaterial_f1_label_savings_analysis.png\n",
      "- Bericht: reports/dachmaterial_f1_label_savings_report.txt\n",
      "================================================================================\n",
      "\n",
      "Programm beendet mit Exit-Code: 0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Active Learning für Dachmaterial-Klassifikation mit F1-Score\n",
    "# \n",
    "# ## Robuste Version mit statistischer Analyse für unausgewogene Datensätze\n",
    "# \n",
    "# Dieses Notebook implementiert Active Learning Experimente für die Klassifikation von Dachmaterialien. \n",
    "# Da der Datensatz sehr unausgewogen ist, verwenden wir den **F1-Score (Macro)** als Hauptmetrik anstatt der Accuracy.\n",
    "# \n",
    "# ### Features:\n",
    "# - Verwendet den kompletten Dachmaterial-Datensatz\n",
    "# - F1-Score als primäre Evaluationsmetrik\n",
    "# - Statistische Analyse mit Wilcoxon Signed-Rank Test\n",
    "# - Cliff's Delta für Effektstärken\n",
    "# - Label-Einsparungs-Analyse\n",
    "\n",
    "# ## 1. Import und Setup\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Matplotlib Backend setzen bevor pyplot importiert wird\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Für Server ohne GUI\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn mit Fehlerbehandlung\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    # Prüfe ob der Style verfügbar ist\n",
    "    try:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    except:\n",
    "        try:\n",
    "            plt.style.use('seaborn-whitegrid')\n",
    "        except:\n",
    "            plt.style.use('ggplot')\n",
    "except ImportError:\n",
    "    print(\"Warnung: Seaborn nicht installiert. Verwende Standard-Matplotlib.\")\n",
    "    sns = None\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import sklearn\n",
    "\n",
    "# Statistische Tests\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "import itertools\n",
    "\n",
    "# Excel-Export\n",
    "try:\n",
    "    import openpyxl\n",
    "    EXCEL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warnung: openpyxl nicht installiert. Excel-Export wird deaktiviert.\")\n",
    "    EXCEL_AVAILABLE = False\n",
    "\n",
    "# SSL-Fehler beim Download verhindern\n",
    "import ssl\n",
    "try:\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# ## 2. Konfiguration und Reproduzierbarkeit\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Reproduzierbarkeit\n",
    "# -------------------------------------------------------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Konfiguration\n",
    "# -------------------------------------------------------------------------------\n",
    "BUDGET_PERCENTAGES = [0.2, 0.4, 0.6, 0.8, 1.0]  # 20%, 40%, 60%, 80%, 100%\n",
    "BATCH_SIZE = 500  # Größere Batches für effizienteres Training\n",
    "N_RUNS = 5  # Erhöht von 3 auf 5 für bessere statistische Aussagekraft\n",
    "INITIAL_PERCENTAGE = 0.01  # 1% initial labeling\n",
    "SIGNIFICANCE_LEVEL = 0.05  # Für statistische Tests\n",
    "MIN_SAMPLES_PER_CLASS = 20  # Mindestanzahl Samples pro Klasse\n",
    "\n",
    "# Dachmaterial Klassen (wird dynamisch geladen)\n",
    "DACHMATERIAL_CLASSES = []\n",
    "\n",
    "# Erstelle Output-Verzeichnisse\n",
    "output_dirs = [\"plots\", \"results\", \"reports\"]\n",
    "for dir_name in output_dirs:\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Logging konfigurieren mit UTF-8 Encoding\n",
    "# -------------------------------------------------------------------------------\n",
    "# Erstelle Log-Verzeichnis\n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Logging Setup mit UTF-8 Encoding für Windows\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            os.path.join(log_dir, f\"dachmaterial_active_learning_{time.strftime('%Y%m%d_%H%M%S')}.log\"),\n",
    "            encoding='utf-8'\n",
    "        ),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set encoding for stdout to handle Unicode - nur wenn möglich\n",
    "if sys.platform == 'win32':\n",
    "    # Prüfe ob wir in einer Jupyter/IPython Umgebung sind\n",
    "    try:\n",
    "        get_ipython()\n",
    "        # In Jupyter/IPython - keine Änderung nötig\n",
    "        logger.info(\"Jupyter/IPython Umgebung erkannt - UTF-8 Handling bereits aktiv\")\n",
    "    except NameError:\n",
    "        # Normales Python - versuche UTF-8 zu setzen\n",
    "        try:\n",
    "            import io\n",
    "            if hasattr(sys.stdout, 'buffer'):\n",
    "                sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
    "                sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Konnte UTF-8 Encoding nicht setzen: {e}\")\n",
    "\n",
    "\n",
    "# ## 3. Daten laden und vorbereiten\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def load_dachmaterial_data(filepath='umrisse_with_all_data_and_shape_and_patch_and_normal.csv'):\n",
    "    \"\"\"\n",
    "    Lädt den VOLLSTÄNDIGEN Dachmaterial-Datensatz.\n",
    "    Filtert Klassen mit zu wenigen Samples aus.\n",
    "    Gibt auch den Preprocessor zurück für konsistente Transformation.\n",
    "    \"\"\"\n",
    "    logger.info(\"Lade vollständigen Dachmaterial-Datensatz...\")\n",
    "    \n",
    "    try:\n",
    "        # Daten laden\n",
    "        df = pd.read_csv(filepath)\n",
    "        logger.info(f\"[ok] Datensatz geladen: {len(df):,} Zeilen, {len(df.columns)} Spalten\")\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Datei '{filepath}' nicht gefunden!\")\n",
    "        logger.error(\"Bitte stellen Sie sicher, dass die CSV-Datei im aktuellen Verzeichnis liegt.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Laden der Daten: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Zielvariable und Features definieren\n",
    "    target_col = 'mat_qgis'\n",
    "    feature_cols = ['area', 'area_type', 'Shape', 'ezg']\n",
    "    \n",
    "    # Nur Zeilen mit gültiger Zielvariable behalten\n",
    "    df = df[df[target_col].notna()].copy()\n",
    "    \n",
    "    # Klassen-Verteilung anzeigen\n",
    "    class_dist = df[target_col].value_counts()\n",
    "    logger.info(f\"Ursprüngliche Klassen-Verteilung:\\n{class_dist}\")\n",
    "    \n",
    "    # Filtere Klassen mit zu wenigen Samples\n",
    "    valid_classes = class_dist[class_dist >= MIN_SAMPLES_PER_CLASS].index.tolist()\n",
    "    removed_classes = class_dist[class_dist < MIN_SAMPLES_PER_CLASS].index.tolist()\n",
    "    \n",
    "    if removed_classes:\n",
    "        logger.warning(f\"Entferne Klassen mit weniger als {MIN_SAMPLES_PER_CLASS} Samples:\")\n",
    "        for cls in removed_classes:\n",
    "            logger.warning(f\"  - {cls}: {class_dist[cls]} Samples\")\n",
    "    \n",
    "    # Behalte nur Samples der gültigen Klassen\n",
    "    df = df[df[target_col].isin(valid_classes)].copy()\n",
    "    \n",
    "    # Aktualisierte Klassen-Verteilung\n",
    "    class_dist_filtered = df[target_col].value_counts()\n",
    "    logger.info(f\"Gefilterte Klassen-Verteilung:\\n{class_dist_filtered}\")\n",
    "    \n",
    "    # Features und Target trennen\n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[target_col].copy()\n",
    "    \n",
    "    # Label Encoding für Target\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Dachmaterial-Klassen speichern\n",
    "    global DACHMATERIAL_CLASSES\n",
    "    DACHMATERIAL_CLASSES = list(label_encoder.classes_)\n",
    "    \n",
    "    logger.info(f\"[ok] Dachmaterial-Datensatz vorbereitet: {len(X):,} Samples\")\n",
    "    logger.info(f\"  Klassen: {len(DACHMATERIAL_CLASSES)} - {', '.join(DACHMATERIAL_CLASSES)}\")\n",
    "    \n",
    "    # Feature-Typen analysieren\n",
    "    numeric_features = ['area']\n",
    "    categorical_features = ['area_type', 'Shape', 'ezg']\n",
    "    \n",
    "    # Preprocessing Pipeline erstellen\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Robuster Train/Test Split\n",
    "    # Verwende StratifiedShuffleSplit für bessere Kontrolle\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "    train_idx, test_idx = next(splitter.split(X, y_encoded))\n",
    "    \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_test = X.iloc[test_idx]\n",
    "    y_train = y_encoded[train_idx]\n",
    "    y_test = y_encoded[test_idx]\n",
    "    \n",
    "    # Preprocessing\n",
    "    X_train_processed = preprocessor.fit_transform(X_train).astype(np.float32)\n",
    "    X_test_processed = preprocessor.transform(X_test).astype(np.float32)\n",
    "    \n",
    "    # Validierung der Daten - mit verbesserter Prüfung\n",
    "    train_classes = set(np.unique(y_train))\n",
    "    test_classes = set(np.unique(y_test))\n",
    "    all_classes = set(range(len(DACHMATERIAL_CLASSES)))\n",
    "    \n",
    "    logger.info(f\"Klassen im Trainingsset: {len(train_classes)}\")\n",
    "    logger.info(f\"Klassen im Testset: {len(test_classes)}\")\n",
    "    \n",
    "    # Warnung wenn nicht alle Klassen im Test-Set sind\n",
    "    missing_in_test = all_classes - test_classes\n",
    "    if missing_in_test:\n",
    "        logger.warning(f\"Folgende Klassen fehlen im Test-Set: {[DACHMATERIAL_CLASSES[i] for i in missing_in_test]}\")\n",
    "        logger.warning(\"Dies kann bei sehr unbalancierten Datensätzen vorkommen.\")\n",
    "    \n",
    "    # Sicherstellen dass mindestens die Mehrheit der Klassen vertreten ist\n",
    "    if len(test_classes) < len(all_classes) * 0.7:\n",
    "        logger.error(\"Zu wenige Klassen im Test-Set! Versuche anderen Random State.\")\n",
    "        # Versuche mit anderem Random State\n",
    "        for attempt in range(5):\n",
    "            new_seed = SEED + attempt + 1\n",
    "            splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=new_seed)\n",
    "            train_idx, test_idx = next(splitter.split(X, y_encoded))\n",
    "            \n",
    "            y_train_temp = y_encoded[train_idx]\n",
    "            y_test_temp = y_encoded[test_idx]\n",
    "            \n",
    "            test_classes_temp = set(np.unique(y_test_temp))\n",
    "            if len(test_classes_temp) >= len(all_classes) * 0.8:\n",
    "                logger.info(f\"Besserer Split gefunden mit Seed {new_seed}\")\n",
    "                X_train = X.iloc[train_idx]\n",
    "                X_test = X.iloc[test_idx]\n",
    "                y_train = y_train_temp\n",
    "                y_test = y_test_temp\n",
    "                \n",
    "                # Re-fit preprocessing\n",
    "                X_train_processed = preprocessor.fit_transform(X_train).astype(np.float32)\n",
    "                X_test_processed = preprocessor.transform(X_test).astype(np.float32)\n",
    "                break\n",
    "    \n",
    "    logger.info(f\"[ok] Daten vorbereitet: {len(X_train):,} Trainingssamples, {len(X_test):,} Testsamples\")\n",
    "    logger.info(f\"  Feature-Dimension nach Preprocessing: {X_train_processed.shape[1]}\")\n",
    "    logger.info(f\"  Klassen: {len(np.unique(y_train))} im Training, {len(np.unique(y_test))} im Test\")\n",
    "    logger.info(f\"  Speicherbedarf: {(X_train_processed.nbytes + X_test_processed.nbytes) / 1024**2:.1f} MB\")\n",
    "    \n",
    "    return X_train_processed, y_train, X_test_processed, y_test, label_encoder, preprocessor\n",
    "\n",
    "\n",
    "# ## 4. Neural Network Modell\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "class OptimizedTabularNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Optimierte NN-Architektur für tabellarische Dachmaterial-Daten.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, num_classes=11):\n",
    "        super(OptimizedTabularNN, self).__init__()\n",
    "        \n",
    "        # Architektur für tabellarische Daten\n",
    "        self.features = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(64, num_classes)\n",
    "        \n",
    "        # Device handling mit Fehlerbehandlung\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                self.device = torch.device('cuda')\n",
    "                # Test ob CUDA wirklich funktioniert\n",
    "                test_tensor = torch.zeros(1).cuda()\n",
    "                del test_tensor\n",
    "            except:\n",
    "                logger.warning(\"CUDA verfügbar aber nicht nutzbar. Verwende CPU.\")\n",
    "                self.device = torch.device('cpu')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self, X_np, y_np, epochs=10, lr=1e-3, batch_size=256, verbose=False):\n",
    "        \"\"\"\n",
    "        Trainiert das TabularNN mit optimierten Hyperparametern.\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "        \n",
    "        # Hyperparameter-Anpassung basierend auf Datensatzgröße\n",
    "        if len(X_np) < 1000:\n",
    "            batch_size = min(32, len(X_np))\n",
    "            lr = lr * 0.1\n",
    "        \n",
    "        optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Create dataset\n",
    "        try:\n",
    "            dataset = TensorDataset(\n",
    "                torch.from_numpy(X_np).float(),\n",
    "                torch.from_numpy(y_np).long()\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Erstellen des Datasets: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # DataLoader mit optimierten Settings\n",
    "        loader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=0,  # Immer 0 für Kompatibilität\n",
    "            pin_memory=(self.device.type == 'cuda'),\n",
    "            drop_last=False\n",
    "        )\n",
    "        \n",
    "        # Training loop mit Fehlerbehandlung\n",
    "        try:\n",
    "            for epoch in range(epochs):\n",
    "                total_loss = 0.0\n",
    "                batch_count = 0\n",
    "                \n",
    "                for xb, yb in loader:\n",
    "                    xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = self(xb)\n",
    "                    loss = loss_fn(outputs, yb)\n",
    "                    \n",
    "                    # Gradient clipping zur Stabilität\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    batch_count += 1\n",
    "                \n",
    "                scheduler.step()\n",
    "                \n",
    "                if verbose and (epoch + 1) % 2 == 0:\n",
    "                    avg_loss = total_loss / max(batch_count, 1)\n",
    "                    logger.info(f\"    Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler während des Trainings: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X_np, batch_size=1024):\n",
    "        \"\"\"\n",
    "        Gibt Wahrscheinlichkeiten für große Datenmengen zurück.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        probs = []\n",
    "        \n",
    "        # Anpassung der Batch-Größe bei wenig Speicher\n",
    "        if self.device.type == 'cuda':\n",
    "            try:\n",
    "                free_memory = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()\n",
    "                if free_memory < 1024**3:  # Weniger als 1GB frei\n",
    "                    batch_size = 256\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                for i in range(0, len(X_np), batch_size):\n",
    "                    batch = torch.from_numpy(X_np[i:i+batch_size]).float().to(self.device)\n",
    "                    logits = self(batch)\n",
    "                    batch_probs = F.softmax(logits, dim=1)\n",
    "                    probs.append(batch_probs.cpu().numpy())\n",
    "                    \n",
    "                    # Speicher freigeben\n",
    "                    del batch, logits, batch_probs\n",
    "                    if self.device.type == 'cuda':\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Fehler bei predict_proba: {e}\")\n",
    "                raise\n",
    "        \n",
    "        return np.vstack(probs) if probs else np.array([])\n",
    "\n",
    "    def predict(self, X_np, batch_size=1024):\n",
    "        \"\"\"\n",
    "        Gibt Vorhersagen zurück.\n",
    "        \"\"\"\n",
    "        probs = self.predict_proba(X_np, batch_size)\n",
    "        return np.argmax(probs, axis=1) if len(probs) > 0 else np.array([])\n",
    "\n",
    "\n",
    "# ## 5. Sklearn Wrapper und Klassifikator Factory\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "class SklearnWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper-Klasse für sklearn-Klassifikatoren mit NN-ähnlicher API.\n",
    "    \"\"\"\n",
    "    def __init__(self, classifier, scaler=None):\n",
    "        self.classifier = classifier\n",
    "        self.scaler = scaler\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X_np, y_np, **kwargs):\n",
    "        \"\"\"Trainiert den Klassifikator mit Fehlerbehandlung.\"\"\"\n",
    "        try:\n",
    "            if self.scaler is not None:\n",
    "                X_scaled = self.scaler.fit_transform(X_np)\n",
    "            else:\n",
    "                X_scaled = X_np\n",
    "            \n",
    "            self.classifier.fit(X_scaled, y_np)\n",
    "            self.is_fitted = True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Training des sklearn-Modells: {e}\")\n",
    "            raise\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X_np):\n",
    "        \"\"\"Gibt Wahrscheinlichkeiten zurueck mit Fehlerbehandlung.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Modell wurde noch nicht trainiert!\")\n",
    "        \n",
    "        try:\n",
    "            if self.scaler is not None:\n",
    "                X_scaled = self.scaler.transform(X_np)\n",
    "            else:\n",
    "                X_scaled = X_np\n",
    "                \n",
    "            if hasattr(self.classifier, 'predict_proba'):\n",
    "                return self.classifier.predict_proba(X_scaled)\n",
    "            else:\n",
    "                # Für SVM mit probability=False oder andere Klassifikatoren\n",
    "                if hasattr(self.classifier, 'decision_function'):\n",
    "                    decision = self.classifier.decision_function(X_scaled)\n",
    "                    \n",
    "                    # Multi-class Fall\n",
    "                    if len(decision.shape) == 2:\n",
    "                        # Softmax auf decision values\n",
    "                        exp_decision = np.exp(decision - np.max(decision, axis=1, keepdims=True))\n",
    "                        probs = exp_decision / np.sum(exp_decision, axis=1, keepdims=True)\n",
    "                    else:\n",
    "                        # Binary Fall - konvertiere zu 2-Klassen-Wahrscheinlichkeiten\n",
    "                        probs = np.zeros((len(decision), 2))\n",
    "                        probs[:, 1] = 1 / (1 + np.exp(-decision))\n",
    "                        probs[:, 0] = 1 - probs[:, 1]\n",
    "                    return probs\n",
    "                else:\n",
    "                    # Fallback: One-hot encoding der Vorhersagen\n",
    "                    predictions = self.classifier.predict(X_scaled)\n",
    "                    n_classes = len(np.unique(predictions))\n",
    "                    probs = np.zeros((len(predictions), n_classes))\n",
    "                    for i, pred in enumerate(predictions):\n",
    "                        probs[i, int(pred)] = 1.0\n",
    "                    return probs\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler bei predict_proba: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def predict(self, X_np):\n",
    "        \"\"\"Gibt Vorhersagen zurück mit Fehlerbehandlung.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Modell wurde noch nicht trainiert!\")\n",
    "            \n",
    "        try:\n",
    "            if self.scaler is not None:\n",
    "                X_scaled = self.scaler.transform(X_np)\n",
    "            else:\n",
    "                X_scaled = X_np\n",
    "            return self.classifier.predict(X_scaled)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler bei predict: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "def create_classifier(classifier_name, input_dim=None, n_classes=None):\n",
    "    \"\"\"\n",
    "    Erstellt einen Klassifikator basierend auf dem Namen.\n",
    "    \n",
    "    Args:\n",
    "        classifier_name: Name des Klassifikators\n",
    "        input_dim: Input-Dimension für Neural Network\n",
    "        n_classes: Anzahl der Klassen\n",
    "    \n",
    "    Returns:\n",
    "        Klassifikator-Objekt mit einheitlicher API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if classifier_name == 'Neural Network':\n",
    "            if input_dim is None or n_classes is None:\n",
    "                raise ValueError(\"input_dim und n_classes müssen für Neural Network angegeben werden\")\n",
    "            return OptimizedTabularNN(input_dim=input_dim, num_classes=n_classes)\n",
    "        \n",
    "        elif classifier_name == 'Naive Bayes':\n",
    "            return SklearnWrapper(GaussianNB())\n",
    "        \n",
    "        elif classifier_name == 'Random Forest':\n",
    "            # Angepasste Parameter für bessere Performance\n",
    "            n_jobs = min(os.cpu_count() - 1, -1) if os.cpu_count() else -1\n",
    "            return SklearnWrapper(\n",
    "                RandomForestClassifier(\n",
    "                    n_estimators=100,\n",
    "                    max_depth=None,\n",
    "                    min_samples_split=2,\n",
    "                    min_samples_leaf=1,\n",
    "                    n_jobs=n_jobs,\n",
    "                    random_state=SEED,\n",
    "                    verbose=0\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        elif classifier_name == 'Logistic Regression':\n",
    "            return SklearnWrapper(\n",
    "                LogisticRegression(\n",
    "                    max_iter=1000,\n",
    "                    solver='saga',\n",
    "                    multi_class='multinomial',\n",
    "                    n_jobs=-1,\n",
    "                    random_state=SEED,\n",
    "                    verbose=0\n",
    "                ),\n",
    "                scaler=StandardScaler()\n",
    "            )\n",
    "        \n",
    "        elif classifier_name == 'SVM':\n",
    "            return SklearnWrapper(\n",
    "                SVC(\n",
    "                    kernel='rbf',\n",
    "                    gamma='scale',\n",
    "                    decision_function_shape='ovr',\n",
    "                    probability=True,\n",
    "                    cache_size=500,  # Mehr Cache für bessere Performance\n",
    "                    random_state=SEED,\n",
    "                    verbose=False\n",
    "                ),\n",
    "                scaler=StandardScaler()\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unbekannter Klassifikator: {classifier_name}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Erstellen des Klassifikators {classifier_name}: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# ## 6. Query-Strategien\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def entropy_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Waehlt Samples mit hoechster Entropie aus.\n",
    "    H(x) = -Σ p(y|x) * log(p(y|x))\n",
    "    \"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        \n",
    "        # Kleine Konstante hinzufügen um log(0) zu vermeiden\n",
    "        epsilon = 1e-10\n",
    "        probs = np.clip(probs, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        # Entropie berechnen\n",
    "        entropies = -np.sum(probs * np.log(probs), axis=1)\n",
    "        \n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        # Indizes mit höchster Entropie\n",
    "        return np.argsort(entropies)[-n_instances:]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Entropy Sampling: {e}\")\n",
    "        # Fallback zu Random Sampling\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "\n",
    "def margin_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Wählt Samples mit kleinstem Margin zwischen Top-2 Klassen.\n",
    "    margin = P(y1|x) - P(y2|x)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        \n",
    "        # Sortiere Wahrscheinlichkeiten\n",
    "        sorted_probs = np.sort(probs, axis=1)\n",
    "        \n",
    "        # Berechne Margin\n",
    "        if sorted_probs.shape[1] >= 2:\n",
    "            margins = sorted_probs[:, -1] - sorted_probs[:, -2]\n",
    "        else:\n",
    "            # Falls nur eine Klasse, verwende 1 - max_prob als Margin\n",
    "            margins = 1.0 - sorted_probs[:, -1]\n",
    "        \n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        # Indizes mit kleinstem Margin\n",
    "        return np.argsort(margins)[:n_instances]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Margin Sampling: {e}\")\n",
    "        # Fallback zu Random Sampling\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "\n",
    "def least_confidence_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Wählt Samples mit geringster Konfidenz.\n",
    "    confidence = max P(y|x)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        \n",
    "        # Maximum-Wahrscheinlichkeit als Konfidenz\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        \n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        # Indizes mit geringster Konfidenz\n",
    "        return np.argsort(confidences)[:n_instances]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Least Confidence Sampling: {e}\")\n",
    "        # Fallback zu Random Sampling\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "\n",
    "def random_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"\n",
    "    Zufällige Auswahl (Baseline).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Sicherstellen, dass wir nicht mehr Samples anfordern als verfügbar\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        \n",
    "        if n_instances <= 0:\n",
    "            return np.array([], dtype=int)\n",
    "            \n",
    "        return np.random.choice(len(X_pool), size=n_instances, replace=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Random Sampling: {e}\")\n",
    "        # Notfall-Fallback\n",
    "        return np.arange(min(n_instances, len(X_pool)))\n",
    "\n",
    "\n",
    "# ## 7. Statistische Analyse Funktionen\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "def cliffs_delta(x, y):\n",
    "    \"\"\"\n",
    "    Berechnet Cliff's Delta als nicht-parametrisches Effektstaerkemaß.\n",
    "    \n",
    "    Interpretation:\n",
    "    |d| < 0.147 \"negligible\"\n",
    "    |d| < 0.33  \"small\" \n",
    "    |d| < 0.474 \"medium\"\n",
    "    |d| >= 0.474 \"large\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nx = len(x)\n",
    "        ny = len(y)\n",
    "        \n",
    "        if nx == 0 or ny == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Konvertiere zu numpy arrays falls nötig\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        # Berechne die Anzahl der Paare, wo x[i] > y[j]\n",
    "        greater = 0\n",
    "        less = 0\n",
    "        \n",
    "        # Vektorisierte Berechnung für bessere Performance\n",
    "        for xi in x:\n",
    "            greater += np.sum(xi > y)\n",
    "            less += np.sum(xi < y)\n",
    "        \n",
    "        # Cliff's Delta\n",
    "        d = (greater - less) / (nx * ny)\n",
    "        \n",
    "        # Sicherstellen, dass d im Bereich [-1, 1] liegt\n",
    "        d = np.clip(d, -1.0, 1.0)\n",
    "        \n",
    "        return d\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Cliff's Delta Berechnung: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def interpret_cliffs_delta(d):\n",
    "    \"\"\"\n",
    "    Interpretiert die Effektstärke nach Cliff's Delta.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        abs_d = abs(float(d))\n",
    "        if abs_d < 0.147:\n",
    "            return \"negligible\"\n",
    "        elif abs_d < 0.33:\n",
    "            return \"small\"\n",
    "        elif abs_d < 0.474:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"large\"\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "def perform_statistical_analysis(results_df, metric='f1_score'):\n",
    "    \"\"\"\n",
    "    Fuehrt statistische Analyse durch: Wilcoxon Signed-Rank Test mit Bonferroni-Korrektur.\n",
    "    \"\"\"\n",
    "    statistical_results = []\n",
    "    \n",
    "    try:\n",
    "        classifiers = results_df['classifier'].unique()\n",
    "        strategies = results_df['strategy'].unique()\n",
    "        budget_levels = results_df['budget_pct'].unique()\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            for budget_pct in budget_levels:\n",
    "                # Hole Random Sampling als Baseline\n",
    "                baseline_data = results_df[\n",
    "                    (results_df['classifier'] == classifier) & \n",
    "                    (results_df['strategy'] == 'Random Sampling') & \n",
    "                    (results_df['budget_pct'] == budget_pct)\n",
    "                ][metric].values\n",
    "                \n",
    "                # Vergleiche mit anderen Strategien\n",
    "                for strategy in strategies:\n",
    "                    if strategy == 'Random Sampling':\n",
    "                        continue\n",
    "                        \n",
    "                    strategy_data = results_df[\n",
    "                        (results_df['classifier'] == classifier) & \n",
    "                        (results_df['strategy'] == strategy) & \n",
    "                        (results_df['budget_pct'] == budget_pct)\n",
    "                    ][metric].values\n",
    "                    \n",
    "                    # Mindestens N_RUNS Datenpunkte für statistische Tests\n",
    "                    if len(baseline_data) >= N_RUNS and len(strategy_data) >= N_RUNS:\n",
    "                        # Wilcoxon Signed-Rank Test\n",
    "                        try:\n",
    "                            # Prüfe ob alle Werte gleich sind\n",
    "                            if np.allclose(strategy_data, baseline_data):\n",
    "                                statistic, p_value = 0.0, 1.0\n",
    "                            else:\n",
    "                                statistic, p_value = wilcoxon(\n",
    "                                    strategy_data, baseline_data, \n",
    "                                    alternative='greater',\n",
    "                                    zero_method='zsplit'\n",
    "                                )\n",
    "                        except Exception as e:\n",
    "                            logger.warning(f\"Wilcoxon Test fehlgeschlagen für {classifier}-{strategy}: {e}\")\n",
    "                            statistic, p_value = 0.0, 1.0\n",
    "                        \n",
    "                        # Effektstärke\n",
    "                        effect_size = cliffs_delta(strategy_data, baseline_data)\n",
    "                        effect_interpretation = interpret_cliffs_delta(effect_size)\n",
    "                        \n",
    "                        # Mittelwerte und Standardabweichungen\n",
    "                        baseline_mean = np.mean(baseline_data) if len(baseline_data) > 0 else 0\n",
    "                        baseline_std = np.std(baseline_data) if len(baseline_data) > 0 else 0\n",
    "                        strategy_mean = np.mean(strategy_data) if len(strategy_data) > 0 else 0\n",
    "                        strategy_std = np.std(strategy_data) if len(strategy_data) > 0 else 0\n",
    "                        \n",
    "                        # Verbesserung berechnen mit Division-by-Zero-Schutz\n",
    "                        improvement = strategy_mean - baseline_mean\n",
    "                        improvement_pct = ((improvement / baseline_mean) * 100) if baseline_mean > 0 else 0\n",
    "                        \n",
    "                        statistical_results.append({\n",
    "                            'classifier': classifier,\n",
    "                            'budget_pct': budget_pct,\n",
    "                            'strategy': strategy,\n",
    "                            'baseline_mean': baseline_mean,\n",
    "                            'baseline_std': baseline_std,\n",
    "                            'strategy_mean': strategy_mean,\n",
    "                            'strategy_std': strategy_std,\n",
    "                            'improvement': improvement,\n",
    "                            'improvement_pct': improvement_pct,\n",
    "                            'wilcoxon_statistic': float(statistic),\n",
    "                            'p_value': float(p_value),\n",
    "                            'cliffs_delta': float(effect_size),\n",
    "                            'effect_size': effect_interpretation,\n",
    "                            'n_samples': len(strategy_data)\n",
    "                        })\n",
    "        \n",
    "        # Konvertiere zu DataFrame\n",
    "        stat_df = pd.DataFrame(statistical_results)\n",
    "        \n",
    "        if len(stat_df) > 0:\n",
    "            # Bonferroni-Korrektur für multiple Vergleiche\n",
    "            n_comparisons = len(stat_df)\n",
    "            stat_df['p_value_corrected'] = np.minimum(stat_df['p_value'] * n_comparisons, 1.0)\n",
    "            stat_df['significant'] = stat_df['p_value_corrected'] < SIGNIFICANCE_LEVEL\n",
    "        else:\n",
    "            logger.warning(\"Keine statistischen Ergebnisse generiert!\")\n",
    "            \n",
    "        return stat_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der statistischen Analyse: {e}\")\n",
    "        return pd.DataFrame()  # Leerer DataFrame als Fallback\n",
    "\n",
    "\n",
    "# ## 8. Active Learning Hauptfunktion\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "def run_active_learning_experiment(X_train, y_train, X_test, y_test,\n",
    "                                 classifier_name, strategy_name, strategy_func,\n",
    "                                 budget_percentages, batch_size=500,\n",
    "                                 input_dim=None, n_classes=None):\n",
    "    \"\"\"\n",
    "    Führt ein Active Learning Experiment durch mit umfassender Fehlerbehandlung.\n",
    "    Verwendet F1-Score als Hauptmetrik.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    n_total = len(y_train)\n",
    "    \n",
    "    # Input-Dimension und Anzahl Klassen ermitteln\n",
    "    if input_dim is None:\n",
    "        input_dim = X_train.shape[1]\n",
    "    if n_classes is None:\n",
    "        n_classes = len(np.unique(y_train))\n",
    "    \n",
    "    for budget_pct in budget_percentages:\n",
    "        n_budget = int(budget_pct * n_total)\n",
    "        \n",
    "        logger.info(f\"\\n{classifier_name} + {strategy_name} - Budget: {budget_pct:.0%} ({n_budget:,} Samples)\")\n",
    "        \n",
    "        for run in range(N_RUNS):\n",
    "            logger.info(f\"  Run {run+1}/{N_RUNS}\")\n",
    "            \n",
    "            try:\n",
    "                # Set seed for reproducibility\n",
    "                np.random.seed(SEED + run)\n",
    "                torch.manual_seed(SEED + run)\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.manual_seed(SEED + run)\n",
    "                \n",
    "                # Initialisierung\n",
    "                pool_indices = np.arange(n_total)\n",
    "                labeled_indices = []\n",
    "                \n",
    "                # Initiale zufällige Auswahl\n",
    "                n_initial = max(100, int(INITIAL_PERCENTAGE * n_total))\n",
    "                n_initial = min(n_initial, len(pool_indices))  # Sicherstellen dass genug Samples da sind\n",
    "                \n",
    "                initial_indices = np.random.choice(pool_indices, size=n_initial, replace=False)\n",
    "                labeled_indices = list(initial_indices)\n",
    "                pool_indices = np.setdiff1d(pool_indices, labeled_indices)\n",
    "                \n",
    "                # Tracking - verwende F1-Scores statt Accuracies\n",
    "                f1_scores = []\n",
    "                n_labeled_list = []\n",
    "                query_times = []\n",
    "                train_times = []\n",
    "                \n",
    "                while len(labeled_indices) < n_budget and len(pool_indices) > 0:\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    # Modell erstellen und trainieren\n",
    "                    model = create_classifier(classifier_name, input_dim=input_dim, n_classes=n_classes)\n",
    "                    \n",
    "                    train_start = time.time()\n",
    "                    \n",
    "                    # Training mit Fehlerbehandlung\n",
    "                    try:\n",
    "                        model.fit(X_train[labeled_indices], y_train[labeled_indices])\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler beim Training in Run {run+1}: {e}\")\n",
    "                        # Skip diesen Durchlauf\n",
    "                        break\n",
    "                    \n",
    "                    train_time = time.time() - train_start\n",
    "                    train_times.append(train_time)\n",
    "                    \n",
    "                    # Evaluation mit F1-Score\n",
    "                    try:\n",
    "                        y_pred = model.predict(X_test)\n",
    "                        # Verwende macro average F1-Score für unausgewogene Datensätze\n",
    "                        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler bei der Evaluation in Run {run+1}: {e}\")\n",
    "                        f1 = 0.0\n",
    "                    \n",
    "                    f1_scores.append(f1)\n",
    "                    n_labeled_list.append(len(labeled_indices))\n",
    "                    \n",
    "                    # Nächste Batch auswählen\n",
    "                    n_query = min(batch_size, n_budget - len(labeled_indices), len(pool_indices))\n",
    "                    if n_query <= 0:\n",
    "                        break\n",
    "                    \n",
    "                    # Query mit Zeitmessung und Fehlerbehandlung\n",
    "                    query_start = time.time()\n",
    "                    try:\n",
    "                        query_indices = strategy_func(model, X_train[pool_indices], n_query)\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler bei Query-Strategie {strategy_name}: {e}\")\n",
    "                        # Fallback zu Random Sampling\n",
    "                        query_indices = random_sampling(model, X_train[pool_indices], n_query)\n",
    "                    \n",
    "                    query_time = time.time() - query_start\n",
    "                    query_times.append(query_time)\n",
    "                    \n",
    "                    # Validierung der Query-Indizes\n",
    "                    query_indices = np.asarray(query_indices)\n",
    "                    query_indices = query_indices[query_indices < len(pool_indices)]  # Entferne ungültige Indizes\n",
    "                    \n",
    "                    if len(query_indices) == 0:\n",
    "                        logger.warning(f\"Keine gueltigen Query-Indizes in Run {run+1}\")\n",
    "                        break\n",
    "                    \n",
    "                    selected_indices = pool_indices[query_indices]\n",
    "                    \n",
    "                    # Update\n",
    "                    labeled_indices.extend(selected_indices)\n",
    "                    pool_indices = np.setdiff1d(pool_indices, selected_indices)\n",
    "                    \n",
    "                    # Progress logging - Unicode-Fix: Verwende -> statt →\n",
    "                    if len(labeled_indices) % 2000 == 0 or len(labeled_indices) == n_budget:\n",
    "                        logger.info(f\"    {len(labeled_indices):,} labeled -> F1-Score: {f1:.4f} \"\n",
    "                                  f\"(Train: {train_time:.1f}s, Query: {query_time:.2f}s)\")\n",
    "                    \n",
    "                    # Speicher freigeben bei NN\n",
    "                    if classifier_name == 'Neural Network' and hasattr(model, 'device') and model.device.type == 'cuda':\n",
    "                        torch.cuda.empty_cache()\n",
    "                \n",
    "                # Finale Evaluation mit mehr Training\n",
    "                if len(labeled_indices) > 0:\n",
    "                    try:\n",
    "                        model = create_classifier(classifier_name, input_dim=input_dim, n_classes=n_classes)\n",
    "                        \n",
    "                        # Mehr Epochs für finale Evaluation\n",
    "                        if classifier_name == 'Neural Network':\n",
    "                            model.fit(X_train[labeled_indices], y_train[labeled_indices], \n",
    "                                     epochs=20, verbose=False)\n",
    "                        else:\n",
    "                            model.fit(X_train[labeled_indices], y_train[labeled_indices])\n",
    "                        \n",
    "                        y_pred = model.predict(X_test)\n",
    "                        final_acc = accuracy_score(y_test, y_pred)\n",
    "                        final_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Fehler bei finaler Evaluation in Run {run+1}: {e}\")\n",
    "                        final_acc = 0.0\n",
    "                        final_f1 = f1 if 'f1' in locals() else 0.0\n",
    "                    \n",
    "                    results.append({\n",
    "                        'classifier': classifier_name,\n",
    "                        'strategy': strategy_name,\n",
    "                        'budget_pct': budget_pct,\n",
    "                        'run': run,\n",
    "                        'n_labeled': len(labeled_indices),\n",
    "                        'accuracy': final_acc,\n",
    "                        'f1_score': final_f1,\n",
    "                        'f1_scores': f1_scores,  # Verwende f1_scores statt accuracies\n",
    "                        'n_labeled_list': n_labeled_list,\n",
    "                        'avg_query_time': np.mean(query_times) if query_times else 0,\n",
    "                        'avg_train_time': np.mean(train_times) if train_times else 0\n",
    "                    })\n",
    "                    \n",
    "                    # Unicode-Fix: Verwende -> statt →\n",
    "                    logger.info(f\"    Final: {len(labeled_indices):,} labeled -> \"\n",
    "                              f\"Accuracy: {final_acc:.4f}, F1: {final_f1:.4f}\")\n",
    "                \n",
    "                # Speicher freigeben\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Unerwarteter Fehler in Run {run+1}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ## 9. Visualisierungsfunktionen mit F1-Score\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def plot_per_classifier_with_significance(all_results, stat_results):\n",
    "    \"\"\"\n",
    "    Erstellt eine Visualisierung pro Klassifikator mit Signifikanzmarkierungen.\n",
    "    Verwendet F1-Score als Hauptmetrik.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen mit Fallback\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        # Farben für Strategien\n",
    "        strategy_colors = {\n",
    "            'Random Sampling': '#808080',\n",
    "            'Entropy Sampling': '#1f77b4',\n",
    "            'Margin Sampling': '#ff7f0e',\n",
    "            'Least Confidence': '#2ca02c'\n",
    "        }\n",
    "        \n",
    "        # Klassifikatoren extrahieren\n",
    "        classifiers = sorted(list(set(r['classifier'] for r in all_results)))\n",
    "        \n",
    "        # Eine Figure pro Klassifikator\n",
    "        for classifier in classifiers:\n",
    "            fig, axes = plt.subplots(1, len(BUDGET_PERCENTAGES), figsize=(20, 4))\n",
    "            \n",
    "            # Handle für einzelne Subplot\n",
    "            if len(BUDGET_PERCENTAGES) == 1:\n",
    "                axes = [axes]\n",
    "                \n",
    "            fig.suptitle(f'{classifier} - Active Learning Performance with Statistical Significance (F1-Score)', \n",
    "                         fontsize=16, y=1.02)\n",
    "            \n",
    "            # Gesamtanzahl Samples\n",
    "            n_total_samples = max(r['n_labeled'] for r in all_results if r['budget_pct'] == 1.0)\n",
    "            \n",
    "            for budget_idx, budget_pct in enumerate(BUDGET_PERCENTAGES):\n",
    "                ax = axes[budget_idx]\n",
    "                \n",
    "                # Daten für diesen Klassifikator und Budget\n",
    "                for strategy, color in strategy_colors.items():\n",
    "                    strategy_results = [r for r in all_results \n",
    "                                      if r['classifier'] == classifier \n",
    "                                      and r['strategy'] == strategy \n",
    "                                      and r['budget_pct'] == budget_pct]\n",
    "                    \n",
    "                    if strategy_results:\n",
    "                        # Lernkurven aggregieren - verwende f1_scores\n",
    "                        max_samples = int(budget_pct * n_total_samples)\n",
    "                        x_common = np.linspace(100, max_samples, 100)\n",
    "                        y_interpolated = []\n",
    "                        \n",
    "                        for r in strategy_results:\n",
    "                            if len(r['n_labeled_list']) > 1 and 'f1_scores' in r:\n",
    "                                try:\n",
    "                                    y_interp = np.interp(x_common, r['n_labeled_list'], r['f1_scores'])\n",
    "                                    y_interpolated.append(y_interp)\n",
    "                                except:\n",
    "                                    logger.warning(f\"Interpolation fehlgeschlagen für {classifier}-{strategy}\")\n",
    "                        \n",
    "                        if y_interpolated:\n",
    "                            y_mean = np.mean(y_interpolated, axis=0)\n",
    "                            y_std = np.std(y_interpolated, axis=0)\n",
    "                            \n",
    "                            # Überprüfe Signifikanz\n",
    "                            is_significant = False\n",
    "                            effect_size = \"\"\n",
    "                            if strategy != 'Random Sampling' and not stat_results.empty:\n",
    "                                sig_data = stat_results[\n",
    "                                    (stat_results['classifier'] == classifier) & \n",
    "                                    (stat_results['strategy'] == strategy) & \n",
    "                                    (stat_results['budget_pct'] == budget_pct)\n",
    "                                ]\n",
    "                                if not sig_data.empty:\n",
    "                                    is_significant = sig_data.iloc[0]['significant']\n",
    "                                    effect_size = sig_data.iloc[0]['effect_size']\n",
    "                            \n",
    "                            # Label mit Signifikanz\n",
    "                            label = strategy\n",
    "                            if is_significant:\n",
    "                                label += f\" *({effect_size})\"\n",
    "                            \n",
    "                            # Plot mit Konfidenzintervall\n",
    "                            ax.plot(x_common, y_mean, \n",
    "                                   label=label, \n",
    "                                   color=color, \n",
    "                                   linewidth=2.5,\n",
    "                                   linestyle='-' if not is_significant or strategy == 'Random Sampling' else '--',\n",
    "                                   marker='o' if strategy == 'Random Sampling' else None,\n",
    "                                   markevery=10 if strategy == 'Random Sampling' else None,\n",
    "                                   markersize=4)\n",
    "                            \n",
    "                            ax.fill_between(x_common, \n",
    "                                          y_mean - y_std, \n",
    "                                          y_mean + y_std, \n",
    "                                          color=color, \n",
    "                                          alpha=0.2)\n",
    "                \n",
    "                # Achsenbeschriftung\n",
    "                ax.set_xlabel('Number of Labeled Samples', fontsize=11)\n",
    "                ax.set_ylabel('Test F1-Score (Macro)', fontsize=11)\n",
    "                ax.set_title(f'Budget: {int(budget_pct*100)}%', fontsize=12)\n",
    "                \n",
    "                # Grid und Limits\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                ax.set_ylim([0.0, 1.0])\n",
    "                \n",
    "                # X-Achse formatieren\n",
    "                ax.ticklabel_format(style='plain', axis='x')\n",
    "                ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}k' if x >= 1000 else str(int(x))))\n",
    "                \n",
    "                # Legende nur beim ersten Plot\n",
    "                if budget_idx == 0:\n",
    "                    ax.legend(loc='lower right', fontsize=9, framealpha=0.9)\n",
    "            \n",
    "            # Signifikanz-Erklärung\n",
    "            fig.text(0.5, -0.05, \n",
    "                    '* = statistically significant (p < 0.05 with Bonferroni correction); ' +\n",
    "                    'Effect size in parentheses (negligible/small/medium/large)',\n",
    "                    ha='center', fontsize=10, style='italic')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Speichern mit Fehlerbehandlung\n",
    "            filename = f'plots/dachmaterial_{classifier.lower().replace(\" \", \"_\")}_f1_with_significance.png'\n",
    "            try:\n",
    "                plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "                logger.info(f\"[ok] Visualisierung mit F1-Score und Signifikanz für {classifier} erstellt: {filename}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Fehler beim Speichern der Visualisierung für {classifier}: {e}\")\n",
    "                \n",
    "            plt.close()\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_per_classifier_with_significance: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def plot_statistical_summary(stat_results):\n",
    "    \"\"\"\n",
    "    Erstellt eine Visualisierung der statistischen Ergebnisse für F1-Score.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        if stat_results.empty:\n",
    "            logger.warning(\"Keine statistischen Ergebnisse zum Visualisieren!\")\n",
    "            return\n",
    "            \n",
    "        # Filtere nur signifikante Ergebnisse\n",
    "        sig_results = stat_results[stat_results['significant']].copy() if 'significant' in stat_results.columns else pd.DataFrame()\n",
    "        \n",
    "        if sig_results.empty:\n",
    "            logger.warning(\"Keine signifikanten Ergebnisse gefunden!\")\n",
    "            # Erstelle trotzdem eine Visualisierung mit allen Ergebnissen\n",
    "            sig_results = stat_results.copy()\n",
    "        \n",
    "        # Figure mit Subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('Statistical Analysis Summary - Dachmaterial Dataset (F1-Score)', fontsize=16)\n",
    "        \n",
    "        # 1. Heatmap der p-Werte\n",
    "        try:\n",
    "            ax1 = axes[0, 0]\n",
    "            pivot_p = stat_results.pivot_table(\n",
    "                values='p_value_corrected',\n",
    "                index=['classifier', 'strategy'],\n",
    "                columns='budget_pct',\n",
    "                fill_value=1.0\n",
    "            )\n",
    "            \n",
    "            if sns is not None and not pivot_p.empty:\n",
    "                sns.heatmap(pivot_p, \n",
    "                            annot=True, \n",
    "                            fmt='.3f', \n",
    "                            cmap='RdYlGn_r',\n",
    "                            vmin=0, \n",
    "                            vmax=0.1,\n",
    "                            cbar_kws={'label': 'Corrected p-value'},\n",
    "                            ax=ax1)\n",
    "            else:\n",
    "                ax1.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "                \n",
    "            ax1.set_title('Corrected p-values (Wilcoxon Signed-Rank Test)')\n",
    "            ax1.set_xlabel('Budget (%)')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei p-Wert Heatmap: {e}\")\n",
    "            axes[0, 0].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        # 2. Heatmap der Effektstärken\n",
    "        try:\n",
    "            ax2 = axes[0, 1]\n",
    "            pivot_effect = stat_results.pivot_table(\n",
    "                values='cliffs_delta',\n",
    "                index=['classifier', 'strategy'],\n",
    "                columns='budget_pct',\n",
    "                fill_value=0.0\n",
    "            )\n",
    "            \n",
    "            if sns is not None and not pivot_effect.empty:\n",
    "                sns.heatmap(pivot_effect, \n",
    "                            annot=True, \n",
    "                            fmt='.3f', \n",
    "                            cmap='coolwarm',\n",
    "                            center=0,\n",
    "                            vmin=-1, \n",
    "                            vmax=1,\n",
    "                            cbar_kws={'label': \"Cliff's Delta\"},\n",
    "                            ax=ax2)\n",
    "            else:\n",
    "                ax2.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "                \n",
    "            ax2.set_title(\"Effect Size (Cliff's Delta)\")\n",
    "            ax2.set_xlabel('Budget (%)')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei Effektstärken Heatmap: {e}\")\n",
    "            axes[0, 1].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        # 3. Anzahl signifikanter Verbesserungen pro Strategie\n",
    "        try:\n",
    "            ax3 = axes[1, 0]\n",
    "            if not sig_results.empty and 'strategy' in sig_results.columns:\n",
    "                sig_counts = sig_results.groupby('strategy').size().sort_values(ascending=False)\n",
    "                sig_counts.plot(kind='bar', ax=ax3, color='steelblue')\n",
    "                ax3.set_title('Number of Significant F1-Score Improvements per Strategy')\n",
    "                ax3.set_xlabel('Strategy')\n",
    "                ax3.set_ylabel('Count')\n",
    "                ax3.grid(axis='y', alpha=0.3)\n",
    "            else:\n",
    "                ax3.text(0.5, 0.5, 'Keine signifikanten Ergebnisse', ha='center', va='center')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei Signifikanz-Barplot: {e}\")\n",
    "            axes[1, 0].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        # 4. Durchschnittliche Effektstärke pro Klassifikator\n",
    "        try:\n",
    "            ax4 = axes[1, 1]\n",
    "            if 'classifier' in stat_results.columns and 'cliffs_delta' in stat_results.columns:\n",
    "                avg_effect = stat_results.groupby('classifier')['cliffs_delta'].agg(['mean', 'std'])\n",
    "                avg_effect['mean'].plot(kind='bar', ax=ax4, yerr=avg_effect['std'], \n",
    "                                       capsize=5, color='darkorange')\n",
    "                ax4.set_title(\"Average Effect Size per Classifier (F1-Score)\")\n",
    "                ax4.set_xlabel('Classifier')\n",
    "                ax4.set_ylabel(\"Mean Cliff's Delta\")\n",
    "                ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "                ax4.grid(axis='y', alpha=0.3)\n",
    "            else:\n",
    "                ax4.text(0.5, 0.5, 'Daten nicht verfügbar', ha='center', va='center')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Fehler bei Effektstärken-Barplot: {e}\")\n",
    "            axes[1, 1].text(0.5, 0.5, 'Fehler bei der Erstellung', ha='center', va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Speichern\n",
    "        filename = 'plots/dachmaterial_f1_statistical_summary.png'\n",
    "        try:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"[ok] Statistische F1-Score Zusammenfassung erstellt: {filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern der statistischen Zusammenfassung: {e}\")\n",
    "            \n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_statistical_summary: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def create_statistical_report(stat_results):\n",
    "    \"\"\"\n",
    "    Erstellt einen detaillierten statistischen Bericht für F1-Score Ergebnisse.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Sortiere nach Effektstärke\n",
    "        if not stat_results.empty and 'cliffs_delta' in stat_results.columns:\n",
    "            stat_results_sorted = stat_results.sort_values('cliffs_delta', ascending=False)\n",
    "        else:\n",
    "            stat_results_sorted = stat_results\n",
    "        \n",
    "        # Erstelle formatierten Bericht\n",
    "        report = []\n",
    "        report.append(\"\\n\" + \"=\"*100)\n",
    "        report.append(\"DETAILLIERTER STATISTISCHER BERICHT - DACHMATERIAL (F1-SCORE)\")\n",
    "        report.append(\"=\"*100)\n",
    "        report.append(f\"Primäre Metrik: F1-Score (Macro Average)\")\n",
    "        report.append(f\"Signifikanzniveau: {SIGNIFICANCE_LEVEL} (mit Bonferroni-Korrektur)\")\n",
    "        report.append(f\"Anzahl Runs pro Experiment: {N_RUNS}\")\n",
    "        report.append(f\"Statistischer Test: Wilcoxon Signed-Rank Test\")\n",
    "        report.append(f\"Effektstärkemaß: Cliff's Delta\")\n",
    "        report.append(\"\\n\")\n",
    "        \n",
    "        # Signifikante Ergebnisse\n",
    "        if 'significant' in stat_results_sorted.columns:\n",
    "            sig_results = stat_results_sorted[stat_results_sorted['significant']]\n",
    "        else:\n",
    "            sig_results = pd.DataFrame()\n",
    "        \n",
    "        if not sig_results.empty:\n",
    "            report.append(\"SIGNIFIKANTE F1-SCORE VERBESSERUNGEN GEGENÜBER RANDOM SAMPLING:\")\n",
    "            report.append(\"-\"*100)\n",
    "            report.append(f\"{'Klassifikator':<20} {'Strategie':<20} {'Budget':<10} {'Verbesserung':<15} \"\n",
    "                         f\"{'p-Wert':<12} {'Effekt':<15} {'Interpretation':<15}\")\n",
    "            report.append(\"-\"*100)\n",
    "            \n",
    "            for _, row in sig_results.iterrows():\n",
    "                report.append(f\"{row['classifier']:<20} {row['strategy']:<20} \"\n",
    "                             f\"{int(row['budget_pct']*100):>8}% \"\n",
    "                             f\"{row['improvement_pct']:>13.2f}% \"\n",
    "                             f\"{row['p_value_corrected']:>11.4f} \"\n",
    "                             f\"{row['cliffs_delta']:>14.3f} \"\n",
    "                             f\"{row['effect_size']:<15}\")\n",
    "        else:\n",
    "            report.append(\"Keine signifikanten F1-Score Verbesserungen gefunden!\")\n",
    "        \n",
    "        # Zusammenfassung nach Strategie\n",
    "        report.append(\"\\n\\nZUSAMMENFASSUNG NACH STRATEGIE (F1-SCORE):\")\n",
    "        report.append(\"-\"*100)\n",
    "        \n",
    "        for strategy in ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "            if 'strategy' in stat_results.columns:\n",
    "                strategy_data = stat_results[stat_results['strategy'] == strategy]\n",
    "                if not strategy_data.empty:\n",
    "                    sig_count = strategy_data['significant'].sum() if 'significant' in strategy_data.columns else 0\n",
    "                    avg_improvement = strategy_data['improvement_pct'].mean() if 'improvement_pct' in strategy_data.columns else 0\n",
    "                    avg_effect = strategy_data['cliffs_delta'].mean() if 'cliffs_delta' in strategy_data.columns else 0\n",
    "                    \n",
    "                    report.append(f\"\\n{strategy}:\")\n",
    "                    report.append(f\"  - Signifikante F1-Score Verbesserungen: {sig_count}/{len(strategy_data)} \"\n",
    "                                 f\"({sig_count/len(strategy_data)*100:.1f}%)\")\n",
    "                    report.append(f\"  - Durchschnittliche F1-Score Verbesserung: {avg_improvement:.2f}%\")\n",
    "                    report.append(f\"  - Durchschnittliche Effektstärke: {avg_effect:.3f}\")\n",
    "        \n",
    "        # Zusammenfassung nach Klassifikator\n",
    "        report.append(\"\\n\\nZUSAMMENFASSUNG NACH KLASSIFIKATOR (F1-SCORE):\")\n",
    "        report.append(\"-\"*100)\n",
    "        \n",
    "        if 'classifier' in stat_results.columns:\n",
    "            for classifier in stat_results['classifier'].unique():\n",
    "                classifier_data = stat_results[stat_results['classifier'] == classifier]\n",
    "                sig_count = classifier_data['significant'].sum() if 'significant' in classifier_data.columns else 0\n",
    "                \n",
    "                report.append(f\"\\n{classifier}:\")\n",
    "                report.append(f\"  - Signifikante F1-Score Verbesserungen: {sig_count}/{len(classifier_data)} \"\n",
    "                             f\"({sig_count/len(classifier_data)*100:.1f}%)\")\n",
    "                \n",
    "                if sig_count > 0 and 'cliffs_delta' in classifier_data.columns:\n",
    "                    best_strategy = classifier_data.loc[classifier_data['cliffs_delta'].idxmax()]\n",
    "                    report.append(f\"  - Beste Strategie: {best_strategy['strategy']} \"\n",
    "                                 f\"bei {int(best_strategy['budget_pct']*100)}% Budget \"\n",
    "                                 f\"(Effekt: {best_strategy['cliffs_delta']:.3f})\")\n",
    "        \n",
    "        report.append(\"\\n\" + \"=\"*100)\n",
    "        \n",
    "        # Ausgabe\n",
    "        report_text = \"\\n\".join(report)\n",
    "        print(report_text)\n",
    "        \n",
    "        # Speichern\n",
    "        report_filename = 'reports/dachmaterial_f1_statistical_report.txt'\n",
    "        try:\n",
    "            with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(report_text)\n",
    "            logger.info(f\"[ok] Statistischer F1-Score Bericht gespeichert: {report_filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern des Berichts: {e}\")\n",
    "        \n",
    "        return report_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei create_statistical_report: {e}\")\n",
    "        return \"Fehler bei der Berichterstellung\"\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "def plot_final_comparison(all_results):\n",
    "    \"\"\"\n",
    "    Erstellt eine Visualisierung, die zeigt, welche Kombination aus Klassifikator\n",
    "    und Query-Strategie bei 100% Budget am besten abgeschnitten hat (F1-Score).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        # Nur Ergebnisse mit 100% Budget\n",
    "        final_results = [r for r in all_results if r['budget_pct'] == 1.0]\n",
    "        \n",
    "        if not final_results:\n",
    "            logger.warning(\"Keine Ergebnisse mit 100% Budget gefunden!\")\n",
    "            return\n",
    "        \n",
    "        # Aggregiere Ergebnisse\n",
    "        summary_data = []\n",
    "        classifiers = sorted(list(set(r['classifier'] for r in final_results)))\n",
    "        strategies = ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            for strategy in strategies:\n",
    "                results = [r for r in final_results \n",
    "                          if r['classifier'] == classifier and r['strategy'] == strategy]\n",
    "                \n",
    "                if results:\n",
    "                    mean_acc = np.mean([r['accuracy'] for r in results])\n",
    "                    std_acc = np.std([r['accuracy'] for r in results])\n",
    "                    mean_f1 = np.mean([r['f1_score'] for r in results])\n",
    "                    std_f1 = np.std([r['f1_score'] for r in results])\n",
    "                    \n",
    "                    summary_data.append({\n",
    "                        'Classifier': classifier,\n",
    "                        'Strategy': strategy,\n",
    "                        'Accuracy': mean_acc,\n",
    "                        'Accuracy_std': std_acc,\n",
    "                        'F1-Score': mean_f1,\n",
    "                        'F1-Score_std': std_f1\n",
    "                    })\n",
    "        \n",
    "        if not summary_data:\n",
    "            logger.warning(\"Keine Daten für finale Vergleichsmatrix!\")\n",
    "            return\n",
    "            \n",
    "        # DataFrame erstellen\n",
    "        df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # Pivot für Heatmap - fokussiere auf F1-Score\n",
    "        pivot_f1 = df.pivot(index='Classifier', columns='Strategy', values='F1-Score')\n",
    "        pivot_acc = df.pivot(index='Classifier', columns='Strategy', values='Accuracy')\n",
    "        \n",
    "        # Figure mit zwei Subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Heatmap für F1-Score (Hauptfokus)\n",
    "        if sns is not None and not pivot_f1.empty:\n",
    "            sns.heatmap(pivot_f1, \n",
    "                        annot=True, \n",
    "                        fmt='.4f', \n",
    "                        cmap='RdYlGn', \n",
    "                        vmin=0.0, \n",
    "                        vmax=1.0,\n",
    "                        cbar_kws={'label': 'Test F1-Score (Macro)'},\n",
    "                        ax=ax1)\n",
    "        else:\n",
    "            ax1.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "            \n",
    "        ax1.set_title('Test F1-Score at 100% Budget', fontsize=14)\n",
    "        ax1.set_xlabel('Query Strategy', fontsize=12)\n",
    "        ax1.set_ylabel('Classifier', fontsize=12)\n",
    "        \n",
    "        # Heatmap für Accuracy (zum Vergleich)\n",
    "        if sns is not None and not pivot_acc.empty:\n",
    "            sns.heatmap(pivot_acc, \n",
    "                        annot=True, \n",
    "                        fmt='.4f', \n",
    "                        cmap='RdYlGn', \n",
    "                        vmin=0.0, \n",
    "                        vmax=1.0,\n",
    "                        cbar_kws={'label': 'Test Accuracy'},\n",
    "                        ax=ax2)\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'Heatmap nicht verfügbar', ha='center', va='center')\n",
    "            \n",
    "        ax2.set_title('Test Accuracy at 100% Budget', fontsize=14)\n",
    "        ax2.set_xlabel('Query Strategy', fontsize=12)\n",
    "        ax2.set_ylabel('Classifier', fontsize=12)\n",
    "        \n",
    "        plt.suptitle('Final Performance Comparison - Full Dachmaterial Dataset (100% Budget)', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Speichern\n",
    "        filename = 'plots/dachmaterial_f1_final_comparison.png'\n",
    "        try:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"[ok] Finale F1-Score Vergleichsvisualisierung erstellt: {filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern der finalen Vergleichsmatrix: {e}\")\n",
    "            \n",
    "        plt.close()\n",
    "        \n",
    "        # Beste Kombination finden basierend auf F1-Score\n",
    "        if not df.empty:\n",
    "            best_idx = df['F1-Score'].idxmax()\n",
    "            best_result = df.iloc[best_idx]\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"BESTE KOMBINATION BEI 100% BUDGET (F1-SCORE):\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"Klassifikator: {best_result['Classifier']}\")\n",
    "            print(f\"Query-Strategie: {best_result['Strategy']}\")\n",
    "            print(f\"Test F1-Score: {best_result['F1-Score']:.4f} (±{best_result['F1-Score_std']:.4f})\")\n",
    "            print(f\"Test Accuracy: {best_result['Accuracy']:.4f} (±{best_result['Accuracy_std']:.4f})\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            # Top 5 Kombinationen basierend auf F1-Score\n",
    "            print(\"\\nTOP 5 KOMBINATIONEN (F1-SCORE):\")\n",
    "            print(\"-\"*60)\n",
    "            top5 = df.nlargest(5, 'F1-Score')[['Classifier', 'Strategy', 'F1-Score', 'Accuracy']]\n",
    "            for idx, (_, row) in enumerate(top5.iterrows()):\n",
    "                print(f\"{idx+1}. {row['Classifier']} + {row['Strategy']}: \"\n",
    "                      f\"F1={row['F1-Score']:.4f}, Acc={row['Accuracy']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_final_comparison: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "def plot_improvement_analysis(all_results):\n",
    "    \"\"\"\n",
    "    Zeigt die Verbesserung der Active Learning Strategien gegenüber Random Sampling (F1-Score).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Style setzen\n",
    "        try:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        except:\n",
    "            try:\n",
    "                plt.style.use('seaborn-whitegrid')\n",
    "            except:\n",
    "                plt.style.use('ggplot')\n",
    "        \n",
    "        # Berechne Verbesserungen basierend auf F1-Score\n",
    "        improvements = []\n",
    "        classifiers = sorted(list(set(r['classifier'] for r in all_results)))\n",
    "        strategies = ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            for strategy in strategies:\n",
    "                for budget_pct in BUDGET_PERCENTAGES:\n",
    "                    # Random Sampling Baseline\n",
    "                    random_results = [r for r in all_results \n",
    "                                    if r['classifier'] == classifier \n",
    "                                    and r['strategy'] == 'Random Sampling' \n",
    "                                    and r['budget_pct'] == budget_pct]\n",
    "                    \n",
    "                    # Active Learning Strategy\n",
    "                    strategy_results = [r for r in all_results \n",
    "                                      if r['classifier'] == classifier \n",
    "                                      and r['strategy'] == strategy \n",
    "                                      and r['budget_pct'] == budget_pct]\n",
    "                    \n",
    "                    if random_results and strategy_results:\n",
    "                        random_f1 = np.mean([r['f1_score'] for r in random_results])\n",
    "                        strategy_f1 = np.mean([r['f1_score'] for r in strategy_results])\n",
    "                        \n",
    "                        # Prozentuale Verbesserung\n",
    "                        improvement = ((strategy_f1 - random_f1) / random_f1) * 100 if random_f1 > 0 else 0\n",
    "                        \n",
    "                        improvements.append({\n",
    "                            'Classifier': classifier,\n",
    "                            'Strategy': strategy,\n",
    "                            'Budget': int(budget_pct * 100),\n",
    "                            'F1-Score Improvement (%)': improvement\n",
    "                        })\n",
    "        \n",
    "        if not improvements:\n",
    "            logger.warning(\"Keine Verbesserungsdaten gefunden!\")\n",
    "            return\n",
    "            \n",
    "        # DataFrame erstellen\n",
    "        imp_df = pd.DataFrame(improvements)\n",
    "        \n",
    "        # Figure\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Gruppierter Barplot\n",
    "        x = np.arange(len(BUDGET_PERCENTAGES))\n",
    "        width = 0.15\n",
    "        \n",
    "        # Erstelle eine eindeutige Farbe für jede Klassifikator-Strategie-Kombination\n",
    "        colors = plt.cm.tab20(np.linspace(0, 1, len(classifiers) * len(strategies)))\n",
    "        color_idx = 0\n",
    "        \n",
    "        for i, classifier in enumerate(classifiers):\n",
    "            for j, strategy in enumerate(strategies):\n",
    "                data = imp_df[(imp_df['Classifier'] == classifier) & \n",
    "                             (imp_df['Strategy'] == strategy)]\n",
    "                \n",
    "                if not data.empty:\n",
    "                    values = []\n",
    "                    for b in BUDGET_PERCENTAGES:\n",
    "                        budget_data = data[data['Budget'] == int(b*100)]\n",
    "                        if not budget_data.empty:\n",
    "                            values.append(budget_data['F1-Score Improvement (%)'].values[0])\n",
    "                        else:\n",
    "                            values.append(0)\n",
    "                    \n",
    "                    offset = (i * len(strategies) + j - len(classifiers) * len(strategies) / 2) * width\n",
    "                    bars = ax.bar(x + offset, values, width, \n",
    "                                 label=f'{classifier} - {strategy}',\n",
    "                                 color=colors[color_idx])\n",
    "                    color_idx += 1\n",
    "        \n",
    "        # Achsenbeschriftung\n",
    "        ax.set_xlabel('Budget (%)', fontsize=12)\n",
    "        ax.set_ylabel('F1-Score Improvement over Random Sampling (%)', fontsize=12)\n",
    "        ax.set_title('Active Learning F1-Score Improvement Analysis - Dachmaterial Dataset', fontsize=14)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f'{int(b*100)}%' for b in BUDGET_PERCENTAGES])\n",
    "        \n",
    "        # Nulllinie\n",
    "        ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Legende\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "        \n",
    "        # Grid\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Speichern\n",
    "        filename = 'plots/dachmaterial_f1_improvement_analysis.png'\n",
    "        try:\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"[ok] F1-Score Improvement-Analyse erstellt: {filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern der F1-Score Improvement-Analyse: {e}\")\n",
    "            \n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei plot_improvement_analysis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "# ## 10. Label-Einsparungs-Analyse mit F1-Score\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "def calculate_label_savings(all_results, target_performance_percentages=[0.90, 0.95, 0.98]):\n",
    "    \"\"\"\n",
    "    Berechnet die Label-Einsparung für Active Learning Strategien basierend auf F1-Score.\n",
    "    \n",
    "    Args:\n",
    "        all_results: Liste aller Experiment-Ergebnisse\n",
    "        target_performance_percentages: Prozentsätze der Random Sampling 100% F1-Score Performance\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame mit Label-Einsparungen\n",
    "    \"\"\"\n",
    "    savings_results = []\n",
    "    \n",
    "    # Gruppiere nach Klassifikator\n",
    "    classifiers = sorted(list(set(r['classifier'] for r in all_results)))\n",
    "    \n",
    "    # Gesamtanzahl Samples\n",
    "    n_total_samples = max(r['n_labeled'] for r in all_results if r['budget_pct'] == 1.0)\n",
    "    \n",
    "    for classifier in classifiers:\n",
    "        # Hole Random Sampling F1-Score Performance bei 100% Budget als Referenz\n",
    "        random_100_results = [r for r in all_results \n",
    "                            if r['classifier'] == classifier \n",
    "                            and r['strategy'] == 'Random Sampling' \n",
    "                            and r['budget_pct'] == 1.0]\n",
    "        \n",
    "        if not random_100_results:\n",
    "            continue\n",
    "            \n",
    "        # Durchschnittliche F1-Score Performance bei 100% Budget\n",
    "        random_100_f1 = np.mean([r['f1_score'] for r in random_100_results])\n",
    "        \n",
    "        # Für verschiedene Ziel-Performance-Level\n",
    "        for target_pct in target_performance_percentages:\n",
    "            target_f1_score = random_100_f1 * target_pct\n",
    "            \n",
    "            # Für jede Strategie\n",
    "            for strategy in ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "                strategy_results = [r for r in all_results \n",
    "                                  if r['classifier'] == classifier \n",
    "                                  and r['strategy'] == strategy]\n",
    "                \n",
    "                if not strategy_results:\n",
    "                    continue\n",
    "                \n",
    "                # Aggregiere Lernkurven über alle Runs\n",
    "                all_curves = []\n",
    "                for r in strategy_results:\n",
    "                    if 'n_labeled_list' in r and 'f1_scores' in r:\n",
    "                        all_curves.append((r['n_labeled_list'], r['f1_scores']))\n",
    "                \n",
    "                if not all_curves:\n",
    "                    continue\n",
    "                \n",
    "                # Finde minimale Label-Anzahl um Ziel-F1-Score zu erreichen\n",
    "                labels_needed = []\n",
    "                \n",
    "                for n_labeled_list, f1_scores in all_curves:\n",
    "                    # Interpoliere um den Punkt zu finden, wo target_f1_score erreicht wird\n",
    "                    if len(f1_scores) > 0 and max(f1_scores) >= target_f1_score:\n",
    "                        # Finde ersten Punkt, der target_f1_score überschreitet\n",
    "                        for i, f1 in enumerate(f1_scores):\n",
    "                            if f1 >= target_f1_score:\n",
    "                                labels_needed.append(n_labeled_list[i])\n",
    "                                break\n",
    "                    else:\n",
    "                        # Ziel nicht erreicht - verwende Maximum\n",
    "                        labels_needed.append(n_total_samples)\n",
    "                \n",
    "                if labels_needed:\n",
    "                    avg_labels_needed = np.mean(labels_needed)\n",
    "                    std_labels_needed = np.std(labels_needed)\n",
    "                    \n",
    "                    # Berechne Einsparung gegenüber 100%\n",
    "                    savings_pct = ((n_total_samples - avg_labels_needed) / n_total_samples) * 100\n",
    "                    \n",
    "                    # Berechne Einsparung gegenüber Random Sampling\n",
    "                    if strategy != 'Random Sampling':\n",
    "                        random_labels = next((s['avg_labels_needed'] for s in savings_results \n",
    "                                            if s['classifier'] == classifier \n",
    "                                            and s['strategy'] == 'Random Sampling' \n",
    "                                            and s['target_performance'] == int(target_pct*100)), n_total_samples)\n",
    "                        relative_savings_pct = ((random_labels - avg_labels_needed) / random_labels) * 100 if random_labels > 0 else 0\n",
    "                    else:\n",
    "                        relative_savings_pct = 0\n",
    "                    \n",
    "                    savings_results.append({\n",
    "                        'classifier': classifier,\n",
    "                        'strategy': strategy,\n",
    "                        'target_performance': int(target_pct * 100),\n",
    "                        'target_f1_score': target_f1_score,\n",
    "                        'avg_labels_needed': avg_labels_needed,\n",
    "                        'std_labels_needed': std_labels_needed,\n",
    "                        'savings_pct': savings_pct,\n",
    "                        'relative_savings_pct': relative_savings_pct,\n",
    "                        'random_100_f1': random_100_f1\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(savings_results)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "def plot_label_savings(savings_df, dataset_name=\"Dachmaterial\"):\n",
    "    \"\"\"\n",
    "    Visualisiert die Label-Einsparungen basierend auf F1-Score.\n",
    "    \"\"\"\n",
    "    # Style setzen\n",
    "    try:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    except:\n",
    "        plt.style.use('ggplot')\n",
    "    \n",
    "    # Figure mit Subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'{dataset_name} - Label Savings Analysis (F1-Score Based)', fontsize=16)\n",
    "    \n",
    "    # 1. Labels benötigt für verschiedene Performance-Level\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    # Gruppiere nach Klassifikator und Target Performance\n",
    "    for classifier in savings_df['classifier'].unique():\n",
    "        for target in savings_df['target_performance'].unique():\n",
    "            data = savings_df[(savings_df['classifier'] == classifier) & \n",
    "                            (savings_df['target_performance'] == target)]\n",
    "            \n",
    "            if not data.empty:\n",
    "                strategies = data['strategy'].values\n",
    "                labels_needed = data['avg_labels_needed'].values\n",
    "                errors = data['std_labels_needed'].values\n",
    "                \n",
    "                x = np.arange(len(strategies))\n",
    "                width = 0.2\n",
    "                offset = (target - 95) * width / 5  # Offset basierend auf target\n",
    "                \n",
    "                ax1.bar(x + offset, labels_needed, width, \n",
    "                       yerr=errors, capsize=5,\n",
    "                       label=f'{classifier} - {target}% of baseline F1',\n",
    "                       alpha=0.7)\n",
    "    \n",
    "    ax1.set_xlabel('Strategy')\n",
    "    ax1.set_ylabel('Labels Needed')\n",
    "    ax1.set_title('Labels Required to Reach Target F1-Score Performance')\n",
    "    ax1.set_xticks(np.arange(len(strategies)))\n",
    "    ax1.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 2. Relative Einsparung gegenüber Random Sampling\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    # Pivot für Heatmap\n",
    "    pivot_savings = savings_df[savings_df['strategy'] != 'Random Sampling'].pivot_table(\n",
    "        values='relative_savings_pct',\n",
    "        index=['classifier', 'strategy'],\n",
    "        columns='target_performance',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    if not pivot_savings.empty and sns is not None:\n",
    "        sns.heatmap(pivot_savings, \n",
    "                    annot=True, \n",
    "                    fmt='.1f', \n",
    "                    cmap='RdYlGn',\n",
    "                    center=0,\n",
    "                    cbar_kws={'label': 'Label Savings (%)'},\n",
    "                    ax=ax2)\n",
    "        ax2.set_title('Label Savings vs Random Sampling (%) - F1-Score Based')\n",
    "        ax2.set_xlabel('Target F1-Score Performance (% of baseline)')\n",
    "    \n",
    "    # 3. Absolute Label-Anzahl pro Klassifikator bei 95% Performance\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    data_95 = savings_df[savings_df['target_performance'] == 95]\n",
    "    \n",
    "    classifiers = data_95['classifier'].unique()\n",
    "    strategies = ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']\n",
    "    \n",
    "    x = np.arange(len(classifiers))\n",
    "    width = 0.2\n",
    "    \n",
    "    for i, strategy in enumerate(strategies):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for classifier in classifiers:\n",
    "            row = data_95[(data_95['classifier'] == classifier) & \n",
    "                         (data_95['strategy'] == strategy)]\n",
    "            if not row.empty:\n",
    "                values.append(row['avg_labels_needed'].values[0])\n",
    "                errors.append(row['std_labels_needed'].values[0])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        ax3.bar(x + i*width - 1.5*width, values, width, \n",
    "               yerr=errors, capsize=5,\n",
    "               label=strategy, alpha=0.8)\n",
    "    \n",
    "    ax3.set_xlabel('Classifier')\n",
    "    ax3.set_ylabel('Labels Needed')\n",
    "    ax3.set_title('Labels Needed to Reach 95% of Baseline F1-Score Performance')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels(classifiers, rotation=45, ha='right')\n",
    "    ax3.legend()\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Referenzlinie bei 100% der Daten\n",
    "    n_total_samples = savings_df['avg_labels_needed'].max() * 1.1  # Schätzung\n",
    "    ax3.axhline(y=n_total_samples, color='red', linestyle='--', alpha=0.5, label='Full Dataset')\n",
    "    \n",
    "    # 4. Zusammenfassungstabelle\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('tight')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Erstelle Zusammenfassungstabelle für 95% Performance\n",
    "    summary_data = []\n",
    "    for classifier in classifiers:\n",
    "        row_data = [classifier]\n",
    "        for strategy in strategies:\n",
    "            data = data_95[(data_95['classifier'] == classifier) & \n",
    "                          (data_95['strategy'] == strategy)]\n",
    "            if not data.empty:\n",
    "                labels = data['avg_labels_needed'].values[0]\n",
    "                savings = data['savings_pct'].values[0]\n",
    "                row_data.append(f'{int(labels):,}\\n({savings:.1f}% saved)')\n",
    "            else:\n",
    "                row_data.append('N/A')\n",
    "        summary_data.append(row_data)\n",
    "    \n",
    "    table = ax4.table(cellText=summary_data,\n",
    "                     colLabels=['Classifier'] + strategies,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1.2, 2)\n",
    "    \n",
    "    # Style the header row\n",
    "    for i in range(len(strategies) + 1):\n",
    "        table[(0, i)].set_facecolor('#40466e')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    ax4.set_title('Summary: Labels Needed for 95% F1-Score Performance', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Speichern\n",
    "    filename = f'plots/{dataset_name.lower()}_f1_label_savings_analysis.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"[ok] F1-Score basierte Label-Einsparungs-Analyse erstellt: {filename}\")\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return savings_df\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "def create_label_savings_report(savings_df, dataset_name=\"Dachmaterial\"):\n",
    "    \"\"\"\n",
    "    Erstellt einen detaillierten Bericht über Label-Einsparungen basierend auf F1-Score.\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(f\"LABEL-EINSPARUNGS-BERICHT - {dataset_name} (F1-SCORE BASIERT)\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    # Für jedes Performance-Level\n",
    "    for target_perf in sorted(savings_df['target_performance'].unique()):\n",
    "        report.append(f\"\\nZIEL: {target_perf}% der Baseline F1-Score Performance\")\n",
    "        report.append(\"-\"*60)\n",
    "        \n",
    "        target_data = savings_df[savings_df['target_performance'] == target_perf]\n",
    "        \n",
    "        # Nach Klassifikator gruppieren\n",
    "        for classifier in sorted(target_data['classifier'].unique()):\n",
    "            classifier_data = target_data[target_data['classifier'] == classifier]\n",
    "            baseline_f1 = classifier_data['random_100_f1'].iloc[0]\n",
    "            target_f1 = classifier_data['target_f1_score'].iloc[0]\n",
    "            \n",
    "            report.append(f\"\\n{classifier}:\")\n",
    "            report.append(f\"  Baseline F1-Score (Random 100%): {baseline_f1:.4f}\")\n",
    "            report.append(f\"  Ziel F1-Score: {target_f1:.4f}\")\n",
    "            report.append(f\"  Labels benötigt:\")\n",
    "            \n",
    "            # Sortiere nach Labels benötigt\n",
    "            sorted_data = classifier_data.sort_values('avg_labels_needed')\n",
    "            \n",
    "            for _, row in sorted_data.iterrows():\n",
    "                strategy = row['strategy']\n",
    "                labels = row['avg_labels_needed']\n",
    "                std = row['std_labels_needed']\n",
    "                savings = row['savings_pct']\n",
    "                rel_savings = row['relative_savings_pct']\n",
    "                \n",
    "                report.append(f\"    - {strategy:<20}: {int(labels):>6,} ± {int(std):>4} \"\n",
    "                            f\"({savings:>5.1f}% gespart)\")\n",
    "                \n",
    "                if strategy != 'Random Sampling' and rel_savings > 0:\n",
    "                    report.append(f\"      -> {rel_savings:.1f}% weniger Labels als Random Sampling\")\n",
    "    \n",
    "    # Beste Strategien\n",
    "    report.append(\"\\n\\nBESTE STRATEGIEN (bei 95% F1-Score Performance):\")\n",
    "    report.append(\"-\"*60)\n",
    "    \n",
    "    data_95 = savings_df[savings_df['target_performance'] == 95]\n",
    "    \n",
    "    for classifier in sorted(data_95['classifier'].unique()):\n",
    "        classifier_data = data_95[data_95['classifier'] == classifier]\n",
    "        best_row = classifier_data.loc[classifier_data['avg_labels_needed'].idxmin()]\n",
    "        \n",
    "        report.append(f\"{classifier}: {best_row['strategy']} \"\n",
    "                     f\"(nur {int(best_row['avg_labels_needed']):,} Labels = \"\n",
    "                     f\"{best_row['savings_pct']:.1f}% Einsparung)\")\n",
    "    \n",
    "    # Durchschnittliche Einsparungen\n",
    "    report.append(\"\\n\\nDURCHSCHNITTLICHE EINSPARUNGEN ÜBER ALLE KLASSIFIKATOREN:\")\n",
    "    report.append(\"-\"*60)\n",
    "    \n",
    "    avg_savings = data_95.groupby('strategy')['relative_savings_pct'].mean()\n",
    "    for strategy, savings in avg_savings.items():\n",
    "        if strategy != 'Random Sampling':\n",
    "            report.append(f\"{strategy}: {savings:.1f}% weniger Labels als Random Sampling\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Ausgabe und Speichern\n",
    "    report_text = \"\\n\".join(report)\n",
    "    print(report_text)\n",
    "    \n",
    "    filename = f'reports/{dataset_name.lower()}_f1_label_savings_report.txt'\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    logger.info(f\"[ok] F1-Score basierter Label-Einsparungs-Bericht gespeichert: {filename}\")\n",
    "    \n",
    "    return report_text\n",
    "\n",
    "\n",
    "# ## 11. Hauptprogramm\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Haupteinstiegspunkt für das erweiterte Active Learning Experiment für Dachmaterial mit F1-Score.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ACTIVE LEARNING AUF DACHMATERIAL - F1-SCORE VERSION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # System Info\n",
    "    print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"NumPy Version: {np.__version__}\")\n",
    "    print(f\"Pandas Version: {pd.__version__}\")\n",
    "    print(f\"Scikit-learn Version: {sklearn.__version__}\")\n",
    "    print(f\"SciPy Version: {scipy.__version__}\")\n",
    "    \n",
    "    # Device Info\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"Verwende GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    else:\n",
    "        print(\"Verwende CPU (keine GPU gefunden)\")\n",
    "    \n",
    "    print(f\"\\nExperiment-Konfiguration:\")\n",
    "    print(f\"- Hauptmetrik: F1-Score (Macro Average)\")\n",
    "    print(f\"- Anzahl Runs: {N_RUNS}\")\n",
    "    print(f\"- Budget-Stufen: {[f'{int(b*100)}%' for b in BUDGET_PERCENTAGES]}\")\n",
    "    print(f\"- Batch-Größe: {BATCH_SIZE}\")\n",
    "    print(f\"- Signifikanzniveau: {SIGNIFICANCE_LEVEL}\")\n",
    "    print(f\"- Mindest-Samples pro Klasse: {MIN_SAMPLES_PER_CLASS}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Daten laden\n",
    "    try:\n",
    "        X_train, y_train, X_test, y_test, label_encoder, preprocessor = load_dachmaterial_data()\n",
    "        \n",
    "        # Speichere wichtige Variablen für spätere Verwendung\n",
    "        input_dim = X_train.shape[1]\n",
    "        n_classes = len(np.unique(y_train))\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Kritischer Fehler beim Laden der Daten: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    # Klassifikatoren und Strategien definieren\n",
    "    classifiers = ['Neural Network', 'Naive Bayes', 'Random Forest', 'Logistic Regression', 'SVM']\n",
    "    strategies = [\n",
    "        ('Random Sampling', random_sampling),\n",
    "        ('Entropy Sampling', entropy_sampling),\n",
    "        ('Margin Sampling', margin_sampling),\n",
    "        ('Least Confidence', least_confidence_sampling)\n",
    "    ]\n",
    "    \n",
    "    # Experimente durchführen\n",
    "    all_results = []\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    total_experiments = len(classifiers) * len(strategies)\n",
    "    current_experiment = 0\n",
    "    \n",
    "    for classifier_name in classifiers:\n",
    "        for strategy_name, strategy_func in strategies:\n",
    "            current_experiment += 1\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Experiment {current_experiment}/{total_experiments}: {classifier_name} + {strategy_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            experiment_start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                results = run_active_learning_experiment(\n",
    "                    X_train, y_train, X_test, y_test,\n",
    "                    classifier_name, strategy_name, strategy_func,\n",
    "                    BUDGET_PERCENTAGES, BATCH_SIZE,\n",
    "                    input_dim=input_dim, n_classes=n_classes\n",
    "                )\n",
    "                all_results.extend(results)\n",
    "                \n",
    "                experiment_time = time.time() - experiment_start_time\n",
    "                print(f\"\\n[ok] {classifier_name} + {strategy_name} abgeschlossen in {experiment_time/60:.1f} Minuten\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Kritischer Fehler bei {classifier_name} + {strategy_name}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    # Gesamtzeit\n",
    "    total_time = time.time() - total_start_time\n",
    "    print(f\"\\n[ok] Alle Experimente abgeschlossen in {total_time/60:.1f} Minuten\")\n",
    "    \n",
    "    # Überprüfe ob Ergebnisse vorhanden sind\n",
    "    if not all_results:\n",
    "        logger.error(\"Keine Experimenteergebnisse vorhanden!\")\n",
    "        return 1\n",
    "    \n",
    "    # Ergebnisse in DataFrame konvertieren für statistische Analyse\n",
    "    try:\n",
    "        results_df = pd.DataFrame([{\n",
    "            'classifier': r['classifier'],\n",
    "            'strategy': r['strategy'],\n",
    "            'budget_pct': r['budget_pct'],\n",
    "            'run': r['run'],\n",
    "            'n_labeled': r['n_labeled'],\n",
    "            'accuracy': r['accuracy'],\n",
    "            'f1_score': r['f1_score'],\n",
    "            'avg_query_time': r.get('avg_query_time', 0),\n",
    "            'avg_train_time': r.get('avg_train_time', 0)\n",
    "        } for r in all_results])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Erstellen des Results DataFrame: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    # Statistische Analyse durchführen mit F1-Score\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Führe statistische Analyse durch (F1-Score)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        stat_results = perform_statistical_analysis(results_df, metric='f1_score')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der statistischen Analyse: {e}\")\n",
    "        stat_results = pd.DataFrame()\n",
    "    \n",
    "    # Statistischen Bericht erstellen\n",
    "    try:\n",
    "        statistical_report = create_statistical_report(stat_results)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Erstellen des statistischen Berichts: {e}\")\n",
    "    \n",
    "    # Label-Einsparungs-Analyse mit F1-Score\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Berechne Label-Einsparungen (F1-Score basiert)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Berechne Label-Einsparungen für verschiedene Performance-Level\n",
    "        savings_df = calculate_label_savings(all_results, target_performance_percentages=[0.90, 0.95, 0.98])\n",
    "        \n",
    "        # Visualisiere Label-Einsparungen\n",
    "        plot_label_savings(savings_df, dataset_name=\"Dachmaterial\")\n",
    "        \n",
    "        # Erstelle detaillierten Bericht\n",
    "        label_savings_report = create_label_savings_report(savings_df, dataset_name=\"Dachmaterial\")\n",
    "        \n",
    "        # Speichere als CSV\n",
    "        savings_csv = 'results/dachmaterial_f1_label_savings.csv'\n",
    "        savings_df.to_csv(savings_csv, index=False)\n",
    "        print(f\"[ok] F1-Score basierte Label-Einsparungen gespeichert: {savings_csv}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der Label-Einsparungs-Analyse: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # Ergebnisse visualisieren\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Erstelle Visualisierungen (F1-Score basiert)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Pro Klassifikator mit Signifikanz\n",
    "        plot_per_classifier_with_significance(all_results, stat_results)\n",
    "        \n",
    "        # Statistische Zusammenfassung\n",
    "        plot_statistical_summary(stat_results)\n",
    "        \n",
    "        # Finale Vergleichsmatrix\n",
    "        plot_final_comparison(all_results)\n",
    "        \n",
    "        # Improvement Analyse\n",
    "        plot_improvement_analysis(all_results)\n",
    "        \n",
    "        print(\"[ok] Alle F1-Score basierten Visualisierungen erstellt\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei der Visualisierung: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # Ergebnisse speichern\n",
    "    try:\n",
    "        # Detaillierte Ergebnisse\n",
    "        csv_filename = 'results/dachmaterial_f1_active_learning_results.csv'\n",
    "        results_df.to_csv(csv_filename, index=False)\n",
    "        print(f\"\\n[ok] F1-Score Ergebnisse gespeichert in: {csv_filename}\")\n",
    "        \n",
    "        # Statistische Ergebnisse\n",
    "        if not stat_results.empty:\n",
    "            stat_csv_filename = 'results/dachmaterial_f1_statistical_analysis.csv'\n",
    "            stat_results.to_csv(stat_csv_filename, index=False)\n",
    "            print(f\"[ok] Statistische F1-Score Analyse gespeichert in: {stat_csv_filename}\")\n",
    "        \n",
    "        # Zusammenfassung als Excel (wenn verfügbar)\n",
    "        if EXCEL_AVAILABLE:\n",
    "            excel_filename = 'results/dachmaterial_f1_active_learning_summary.xlsx'\n",
    "            try:\n",
    "                with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "                    # Raw results\n",
    "                    results_df.to_excel(writer, sheet_name='Raw Results', index=False)\n",
    "                    \n",
    "                    # Statistical analysis\n",
    "                    if not stat_results.empty:\n",
    "                        stat_results.to_excel(writer, sheet_name='Statistical Analysis', index=False)\n",
    "                    \n",
    "                    # Summary by classifier and strategy\n",
    "                    summary = results_df.groupby(['classifier', 'strategy', 'budget_pct'])[['accuracy', 'f1_score']].agg(['mean', 'std'])\n",
    "                    summary.to_excel(writer, sheet_name='Summary Statistics')\n",
    "                    \n",
    "                    # Best combinations at 100% budget\n",
    "                    final_results = results_df[results_df['budget_pct'] == 1.0]\n",
    "                    if not final_results.empty:\n",
    "                        best_combinations = final_results.groupby(['classifier', 'strategy'])[['accuracy', 'f1_score']].mean()\n",
    "                        best_combinations = best_combinations.sort_values('f1_score', ascending=False)\n",
    "                        best_combinations.to_excel(writer, sheet_name='Best Combinations')\n",
    "                    \n",
    "                    # Significant improvements\n",
    "                    if not stat_results.empty and 'significant' in stat_results.columns:\n",
    "                        sig_improvements = stat_results[stat_results['significant']].sort_values('cliffs_delta', ascending=False)\n",
    "                        if not sig_improvements.empty:\n",
    "                            sig_improvements.to_excel(writer, sheet_name='Significant Improvements', index=False)\n",
    "                    \n",
    "                    # Label savings\n",
    "                    if 'savings_df' in locals() and not savings_df.empty:\n",
    "                        savings_df.to_excel(writer, sheet_name='Label Savings', index=False)\n",
    "                \n",
    "                print(f\"[ok] F1-Score Zusammenfassung gespeichert in: {excel_filename}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Fehler beim Excel-Export: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Speichern der Ergebnisse: {e}\")\n",
    "    \n",
    "    # Abschlusszusammenfassung\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPERIMENT ERFOLGREICH ABGESCHLOSSEN (F1-SCORE VERSION)\")\n",
    "    print(f\"Hauptmetrik: F1-Score (Macro Average)\")\n",
    "    print(f\"Gesamtanzahl Experimente: {len(all_results)}\")\n",
    "    print(f\"Datensatzgröße: {len(y_train):,} Trainingssamples\")\n",
    "    print(f\"Klassifikatoren: {len(classifiers)}\")\n",
    "    print(f\"Query-Strategien: {len(strategies)}\")\n",
    "    print(f\"Budget-Stufen: {len(BUDGET_PERCENTAGES)}\")\n",
    "    print(f\"Wiederholungen pro Experiment: {N_RUNS}\")\n",
    "    \n",
    "    # Statistische Zusammenfassung\n",
    "    if not stat_results.empty:\n",
    "        total_comparisons = len(stat_results)\n",
    "        significant_count = stat_results['significant'].sum() if 'significant' in stat_results.columns else 0\n",
    "        print(f\"\\nStatistische Analyse (F1-Score):\")\n",
    "        print(f\"- Anzahl Vergleiche: {total_comparisons}\")\n",
    "        print(f\"- Signifikante F1-Score Verbesserungen: {significant_count} ({significant_count/total_comparisons*100:.1f}%)\")\n",
    "        print(f\"- Verwendeter Test: Wilcoxon Signed-Rank Test\")\n",
    "        print(f\"- Effektstärkemaß: Cliff's Delta\")\n",
    "        print(f\"- Multiple Vergleiche: Bonferroni-Korrektur\")\n",
    "    \n",
    "    print(\"\\nF1-Score basierte Label-Einsparungs-Analyse durchgeführt!\")\n",
    "    print(\"- Visualisierung: plots/dachmaterial_f1_label_savings_analysis.png\")\n",
    "    print(\"- Bericht: reports/dachmaterial_f1_label_savings_report.txt\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "# ## 12. Ausführung\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "# Führe das Hauptprogramm aus\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        exit_code = main()\n",
    "        print(f\"\\nProgramm beendet mit Exit-Code: {exit_code}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unerwarteter Fehler im Hauptprogramm: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        exit_code = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
