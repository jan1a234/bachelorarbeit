{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39bd83b0-c819-495c-90f3-2aa1ad154344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TensorFloat-32 (TF32) aktiviert für RTX 40xx Serie\n",
      "  → Bis zu 10x schnellere Matrix-Operationen mit Tensor Cores\n",
      "✓ RAPIDS cuML verfügbar - primäre GPU-Beschleunigung aktiviert\n",
      "✓ cuML Output-Type auf 'numpy' gesetzt - verhindert unnötige GPU→CPU Kopien\n",
      "⚠ ThunderSVM benötigt ältere CUDA-Version (9.x/10.x). Aktuelle CUDA-Version inkompatibel.\n",
      "  Tipp: Verwenden Sie RAPIDS cuML stattdessen für moderne GPUs.\n",
      "================================================================================\n",
      "GPU-OPTIMIERTES ACTIVE LEARNING FÜR SVM - FASHION-MNIST\n",
      "================================================================================\n",
      "Python Version: 3.13.5\n",
      "PyTorch Version: 2.7.1+cu126\n",
      "NumPy Version: 2.2.6\n",
      "Scikit-learn Version: 1.7.1\n",
      "\n",
      "GPU Setup:\n",
      "✓ CUDA verfügbar: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "  VRAM: 7.6 GB\n",
      "  TensorFloat-32: Aktiviert\n",
      "  Float32 MatMul Präzision: high\n",
      "\n",
      "GPU Memory Setup:\n",
      "✓ Verwende Standard GPU Memory Management (RMM Pool deaktiviert)\n",
      "  GPU: NVIDIA GeForce RTX 4060 Laptop GPU, 8188 MiB\n",
      "\n",
      "Hinweis: RMM Memory Pool ist deaktiviert (USE_MEMORY_POOL = False)\n",
      "Falls Sie Speicherprobleme haben, können Sie den Pool aktivieren:\n",
      "  Setzen Sie USE_MEMORY_POOL = True in der Konfiguration\n",
      "\n",
      "Für GPU Monitoring installieren Sie:\n",
      "  pip install nvidia-ml-py gpustat\n",
      "  Dann verwenden Sie: gpustat -i 1\n",
      "\n",
      "Experiment-Konfiguration:\n",
      "- Datensatz: Fashion-MNIST\n",
      "- Anzahl Runs: 5\n",
      "- Budget-Stufen: ['20%', '40%', '60%', '80%', '100%']\n",
      "- Batch-Größe: 500\n",
      "- GPU Backends: cuML=True, ThunderSVM=False\n",
      "================================================================================\n",
      "06:31:38 [INFO] Lade Fashion-MNIST-Datensatz...\n",
      "06:31:41 [INFO] ✓ Fashion-MNIST geladen: 60,000 Trainingsbilder, 10,000 Testbilder\n",
      "06:31:41 [INFO]   Feature-Dimensionen: 784\n",
      "06:31:41 [INFO]   Klassen: 10 - T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
      "06:31:41 [INFO]   Speicherbedarf: 209.4 MB\n",
      "\n",
      "============================================================\n",
      "Strategie: Random Sampling\n",
      "============================================================\n",
      "06:31:41 [INFO] \n",
      "GPU-SVM + Random Sampling - Budget: 20% (12,000 Samples)\n",
      "06:31:41 [INFO]   Run 1/5\n",
      "06:31:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 0.3/8.0 GB)\n",
      "06:31:46 [INFO]   Training abgeschlossen in 4.50s (Backend: cuml)\n",
      "06:31:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:31:53 [INFO]   Training abgeschlossen in 4.57s (Backend: cuml)\n",
      "06:31:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:32:00 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "06:32:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:32:08 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "06:32:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:32:15 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "06:32:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:32:23 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "06:32:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:32:30 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "06:32:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:32:38 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "06:32:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:32:46 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "06:32:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:32:54 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "06:32:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:33:03 [INFO]   Training abgeschlossen in 5.52s (Backend: cuml)\n",
      "06:33:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:33:11 [INFO]   Training abgeschlossen in 5.82s (Backend: cuml)\n",
      "06:33:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:33:20 [INFO]   Training abgeschlossen in 5.97s (Backend: cuml)\n",
      "06:33:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:33:29 [INFO]   Training abgeschlossen in 6.05s (Backend: cuml)\n",
      "06:33:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:33:39 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "06:33:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:33:48 [INFO]   Training abgeschlossen in 6.06s (Backend: cuml)\n",
      "06:33:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:33:57 [INFO]   Training abgeschlossen in 6.11s (Backend: cuml)\n",
      "06:34:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:34:06 [INFO]   Training abgeschlossen in 6.17s (Backend: cuml)\n",
      "06:34:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:34:15 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "06:34:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:34:24 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "06:34:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:34:34 [INFO]   Training abgeschlossen in 6.33s (Backend: cuml)\n",
      "06:34:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:34:44 [INFO]   Training abgeschlossen in 6.63s (Backend: cuml)\n",
      "06:34:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:34:53 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "06:34:56 [INFO]     12,000 labeled → Accuracy: 0.8568 (Train: 6.4s, Query: 0.02s) | GPU: 2.3/8.0 GB\n",
      "06:34:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:35:03 [INFO]   Training abgeschlossen in 6.49s (Backend: cuml)\n",
      "06:35:06 [INFO]     Final: 12,000 labeled → Accuracy: 0.8578, F1: 0.8560\n",
      "06:35:06 [INFO]   Run 2/5\n",
      "06:35:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:35:10 [INFO]   Training abgeschlossen in 4.56s (Backend: cuml)\n",
      "06:35:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:35:18 [INFO]   Training abgeschlossen in 4.64s (Backend: cuml)\n",
      "06:35:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:35:25 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "06:35:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:35:33 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "06:35:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:35:40 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "06:35:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:35:48 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "06:35:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:35:55 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "06:35:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:36:03 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "06:36:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:36:11 [INFO]   Training abgeschlossen in 5.34s (Backend: cuml)\n",
      "06:36:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:36:19 [INFO]   Training abgeschlossen in 5.38s (Backend: cuml)\n",
      "06:36:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:36:28 [INFO]   Training abgeschlossen in 5.72s (Backend: cuml)\n",
      "06:36:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:36:36 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "06:36:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:36:45 [INFO]   Training abgeschlossen in 5.87s (Backend: cuml)\n",
      "06:36:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:36:55 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "06:36:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:37:04 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "06:37:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:37:13 [INFO]   Training abgeschlossen in 6.07s (Backend: cuml)\n",
      "06:37:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:37:22 [INFO]   Training abgeschlossen in 6.63s (Backend: cuml)\n",
      "06:37:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:37:32 [INFO]   Training abgeschlossen in 6.42s (Backend: cuml)\n",
      "06:37:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:37:41 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "06:37:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:37:50 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "06:37:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:38:00 [INFO]   Training abgeschlossen in 6.65s (Backend: cuml)\n",
      "06:38:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:38:09 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "06:38:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:38:19 [INFO]   Training abgeschlossen in 6.49s (Backend: cuml)\n",
      "06:38:22 [INFO]     12,000 labeled → Accuracy: 0.8559 (Train: 6.5s, Query: 0.02s) | GPU: 2.3/8.0 GB\n",
      "06:38:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:38:29 [INFO]   Training abgeschlossen in 6.71s (Backend: cuml)\n",
      "06:38:32 [INFO]     Final: 12,000 labeled → Accuracy: 0.8565, F1: 0.8548\n",
      "06:38:32 [INFO]   Run 3/5\n",
      "06:38:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:38:37 [INFO]   Training abgeschlossen in 4.51s (Backend: cuml)\n",
      "06:38:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:38:44 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "06:38:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:38:51 [INFO]   Training abgeschlossen in 4.53s (Backend: cuml)\n",
      "06:38:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:38:58 [INFO]   Training abgeschlossen in 4.67s (Backend: cuml)\n",
      "06:39:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:39:06 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "06:39:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:39:13 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "06:39:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:39:21 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "06:39:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:39:29 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "06:39:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:39:37 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "06:39:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:39:45 [INFO]   Training abgeschlossen in 5.39s (Backend: cuml)\n",
      "06:39:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:39:54 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "06:39:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:40:02 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "06:40:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:40:11 [INFO]   Training abgeschlossen in 6.08s (Backend: cuml)\n",
      "06:40:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:40:20 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "06:40:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:40:29 [INFO]   Training abgeschlossen in 6.06s (Backend: cuml)\n",
      "06:40:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:40:38 [INFO]   Training abgeschlossen in 6.28s (Backend: cuml)\n",
      "06:40:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:40:48 [INFO]   Training abgeschlossen in 6.33s (Backend: cuml)\n",
      "06:40:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:40:57 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "06:41:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:41:07 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "06:41:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:41:17 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "06:41:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:41:26 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "06:41:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:41:36 [INFO]   Training abgeschlossen in 6.47s (Backend: cuml)\n",
      "06:41:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:41:46 [INFO]   Training abgeschlossen in 6.71s (Backend: cuml)\n",
      "06:41:49 [INFO]     12,000 labeled → Accuracy: 0.8556 (Train: 6.7s, Query: 0.02s) | GPU: 2.3/8.0 GB\n",
      "06:41:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:41:55 [INFO]   Training abgeschlossen in 6.47s (Backend: cuml)\n",
      "06:41:58 [INFO]     Final: 12,000 labeled → Accuracy: 0.8572, F1: 0.8562\n",
      "06:41:58 [INFO]   Run 4/5\n",
      "06:41:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:42:03 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "06:42:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:42:10 [INFO]   Training abgeschlossen in 4.65s (Backend: cuml)\n",
      "06:42:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:42:18 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "06:42:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:42:25 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "06:42:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:42:33 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "06:42:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:42:40 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "06:42:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:42:48 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "06:42:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:42:56 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "06:42:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:43:05 [INFO]   Training abgeschlossen in 5.45s (Backend: cuml)\n",
      "06:43:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:43:13 [INFO]   Training abgeschlossen in 5.57s (Backend: cuml)\n",
      "06:43:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:43:22 [INFO]   Training abgeschlossen in 5.61s (Backend: cuml)\n",
      "06:43:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:43:30 [INFO]   Training abgeschlossen in 5.72s (Backend: cuml)\n",
      "06:43:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:43:39 [INFO]   Training abgeschlossen in 6.02s (Backend: cuml)\n",
      "06:43:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:43:48 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "06:43:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:43:58 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "06:44:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:44:07 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "06:44:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:44:17 [INFO]   Training abgeschlossen in 6.65s (Backend: cuml)\n",
      "06:44:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:44:26 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "06:44:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:44:36 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "06:44:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:44:46 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "06:44:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:44:55 [INFO]   Training abgeschlossen in 6.42s (Backend: cuml)\n",
      "06:44:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:45:05 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "06:45:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:45:15 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "06:45:18 [INFO]     12,000 labeled → Accuracy: 0.8561 (Train: 6.8s, Query: 0.02s) | GPU: 2.3/8.0 GB\n",
      "06:45:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:45:24 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "06:45:27 [INFO]     Final: 12,000 labeled → Accuracy: 0.8566, F1: 0.8552\n",
      "06:45:27 [INFO]   Run 5/5\n",
      "06:45:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:45:32 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "06:45:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:45:40 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "06:45:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:45:47 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "06:45:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:45:54 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "06:45:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:46:02 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "06:46:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:46:10 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "06:46:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:46:17 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "06:46:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:46:25 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "06:46:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:46:34 [INFO]   Training abgeschlossen in 5.65s (Backend: cuml)\n",
      "06:46:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:46:42 [INFO]   Training abgeschlossen in 5.43s (Backend: cuml)\n",
      "06:46:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:46:51 [INFO]   Training abgeschlossen in 5.61s (Backend: cuml)\n",
      "06:46:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:46:59 [INFO]   Training abgeschlossen in 5.75s (Backend: cuml)\n",
      "06:47:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:47:09 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "06:47:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:47:18 [INFO]   Training abgeschlossen in 6.06s (Backend: cuml)\n",
      "06:47:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:47:27 [INFO]   Training abgeschlossen in 6.48s (Backend: cuml)\n",
      "06:47:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:47:37 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "06:47:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:47:46 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "06:47:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:47:55 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "06:47:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:48:05 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "06:48:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:48:14 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "06:48:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:48:24 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "06:48:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:48:33 [INFO]   Training abgeschlossen in 6.48s (Backend: cuml)\n",
      "06:48:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:48:43 [INFO]   Training abgeschlossen in 6.56s (Backend: cuml)\n",
      "06:48:46 [INFO]     12,000 labeled → Accuracy: 0.8569 (Train: 6.6s, Query: 0.01s) | GPU: 2.3/8.0 GB\n",
      "06:48:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:48:53 [INFO]   Training abgeschlossen in 6.72s (Backend: cuml)\n",
      "06:48:56 [INFO]     Final: 12,000 labeled → Accuracy: 0.8581, F1: 0.8567\n",
      "06:48:56 [INFO] \n",
      "GPU-SVM + Random Sampling - Budget: 40% (24,000 Samples)\n",
      "06:48:56 [INFO]   Run 1/5\n",
      "06:48:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:49:01 [INFO]   Training abgeschlossen in 4.53s (Backend: cuml)\n",
      "06:49:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:49:08 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "06:49:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:49:15 [INFO]   Training abgeschlossen in 4.67s (Backend: cuml)\n",
      "06:49:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:49:23 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "06:49:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:49:30 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "06:49:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:49:38 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "06:49:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:49:46 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "06:49:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:49:53 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "06:49:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:50:01 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "06:50:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:50:10 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "06:50:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:50:18 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "06:50:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:50:27 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "06:50:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:50:36 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "06:50:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:50:45 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "06:50:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:50:55 [INFO]   Training abgeschlossen in 6.40s (Backend: cuml)\n",
      "06:50:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:51:04 [INFO]   Training abgeschlossen in 6.12s (Backend: cuml)\n",
      "06:51:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:51:13 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "06:51:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:51:22 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "06:51:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:51:32 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "06:51:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:51:41 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "06:51:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:51:51 [INFO]   Training abgeschlossen in 6.42s (Backend: cuml)\n",
      "06:51:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:52:00 [INFO]   Training abgeschlossen in 6.47s (Backend: cuml)\n",
      "06:52:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:52:10 [INFO]   Training abgeschlossen in 6.74s (Backend: cuml)\n",
      "06:52:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:52:20 [INFO]   Training abgeschlossen in 6.61s (Backend: cuml)\n",
      "06:52:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:52:30 [INFO]   Training abgeschlossen in 6.81s (Backend: cuml)\n",
      "06:52:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:52:40 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "06:52:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:52:50 [INFO]   Training abgeschlossen in 7.00s (Backend: cuml)\n",
      "06:52:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:53:01 [INFO]   Training abgeschlossen in 7.02s (Backend: cuml)\n",
      "06:53:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:53:11 [INFO]   Training abgeschlossen in 7.00s (Backend: cuml)\n",
      "06:53:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:53:21 [INFO]   Training abgeschlossen in 7.13s (Backend: cuml)\n",
      "06:53:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:53:32 [INFO]   Training abgeschlossen in 7.16s (Backend: cuml)\n",
      "06:53:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:53:42 [INFO]   Training abgeschlossen in 7.31s (Backend: cuml)\n",
      "06:53:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:53:53 [INFO]   Training abgeschlossen in 7.38s (Backend: cuml)\n",
      "06:53:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:54:04 [INFO]   Training abgeschlossen in 7.67s (Backend: cuml)\n",
      "06:54:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:54:15 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "06:54:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:54:26 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "06:54:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:54:37 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "06:54:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:54:48 [INFO]   Training abgeschlossen in 8.10s (Backend: cuml)\n",
      "06:54:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:54:59 [INFO]   Training abgeschlossen in 8.06s (Backend: cuml)\n",
      "06:55:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:55:11 [INFO]   Training abgeschlossen in 8.06s (Backend: cuml)\n",
      "06:55:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:55:22 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "06:55:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:55:34 [INFO]   Training abgeschlossen in 8.22s (Backend: cuml)\n",
      "06:55:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:55:46 [INFO]   Training abgeschlossen in 8.36s (Backend: cuml)\n",
      "06:55:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:55:57 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "06:56:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:56:09 [INFO]   Training abgeschlossen in 8.28s (Backend: cuml)\n",
      "06:56:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:56:21 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "06:56:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:56:33 [INFO]   Training abgeschlossen in 8.47s (Backend: cuml)\n",
      "06:56:36 [INFO]     24,000 labeled → Accuracy: 0.8691 (Train: 8.5s, Query: 0.01s) | GPU: 2.5/8.0 GB\n",
      "06:56:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:56:45 [INFO]   Training abgeschlossen in 8.60s (Backend: cuml)\n",
      "06:56:48 [INFO]     Final: 24,000 labeled → Accuracy: 0.8688, F1: 0.8677\n",
      "06:56:49 [INFO]   Run 2/5\n",
      "06:56:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:56:53 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "06:56:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:57:01 [INFO]   Training abgeschlossen in 4.62s (Backend: cuml)\n",
      "06:57:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:57:08 [INFO]   Training abgeschlossen in 4.65s (Backend: cuml)\n",
      "06:57:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:57:15 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "06:57:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:57:23 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "06:57:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:57:30 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "06:57:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:57:38 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "06:57:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:57:46 [INFO]   Training abgeschlossen in 5.07s (Backend: cuml)\n",
      "06:57:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:57:54 [INFO]   Training abgeschlossen in 5.38s (Backend: cuml)\n",
      "06:57:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:58:03 [INFO]   Training abgeschlossen in 5.41s (Backend: cuml)\n",
      "06:58:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:58:11 [INFO]   Training abgeschlossen in 5.76s (Backend: cuml)\n",
      "06:58:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:58:20 [INFO]   Training abgeschlossen in 5.72s (Backend: cuml)\n",
      "06:58:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:58:29 [INFO]   Training abgeschlossen in 6.28s (Backend: cuml)\n",
      "06:58:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:58:38 [INFO]   Training abgeschlossen in 6.07s (Backend: cuml)\n",
      "06:58:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:58:48 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "06:58:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:58:57 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "06:59:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:59:06 [INFO]   Training abgeschlossen in 6.16s (Backend: cuml)\n",
      "06:59:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:59:15 [INFO]   Training abgeschlossen in 6.33s (Backend: cuml)\n",
      "06:59:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:59:25 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "06:59:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:59:34 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "06:59:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:59:43 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "06:59:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:59:53 [INFO]   Training abgeschlossen in 6.76s (Backend: cuml)\n",
      "06:59:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:00:03 [INFO]   Training abgeschlossen in 6.60s (Backend: cuml)\n",
      "07:00:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:00:12 [INFO]   Training abgeschlossen in 6.58s (Backend: cuml)\n",
      "07:00:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:00:22 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "07:00:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:00:32 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "07:00:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:00:42 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "07:00:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:00:53 [INFO]   Training abgeschlossen in 6.98s (Backend: cuml)\n",
      "07:00:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:01:03 [INFO]   Training abgeschlossen in 7.07s (Backend: cuml)\n",
      "07:01:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:01:13 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "07:01:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:01:24 [INFO]   Training abgeschlossen in 7.26s (Backend: cuml)\n",
      "07:01:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:01:35 [INFO]   Training abgeschlossen in 7.37s (Backend: cuml)\n",
      "07:01:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:01:45 [INFO]   Training abgeschlossen in 7.56s (Backend: cuml)\n",
      "07:01:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:01:56 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "07:02:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:02:07 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "07:02:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:02:18 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "07:02:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:02:30 [INFO]   Training abgeschlossen in 7.72s (Backend: cuml)\n",
      "07:02:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:02:41 [INFO]   Training abgeschlossen in 7.91s (Backend: cuml)\n",
      "07:02:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:02:52 [INFO]   Training abgeschlossen in 8.07s (Backend: cuml)\n",
      "07:02:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:03:04 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "07:03:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:03:15 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "07:03:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:03:27 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "07:03:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:03:39 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "07:03:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:03:51 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "07:03:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:04:02 [INFO]   Training abgeschlossen in 8.15s (Backend: cuml)\n",
      "07:04:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:04:14 [INFO]   Training abgeschlossen in 8.43s (Backend: cuml)\n",
      "07:04:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:04:26 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "07:04:29 [INFO]     24,000 labeled → Accuracy: 0.8700 (Train: 8.3s, Query: 0.01s) | GPU: 2.5/8.0 GB\n",
      "07:04:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:04:38 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "07:04:41 [INFO]     Final: 24,000 labeled → Accuracy: 0.8691, F1: 0.8680\n",
      "07:04:41 [INFO]   Run 3/5\n",
      "07:04:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:04:46 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "07:04:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:04:53 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "07:04:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:05:01 [INFO]   Training abgeschlossen in 4.67s (Backend: cuml)\n",
      "07:05:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:05:08 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "07:05:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:05:16 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "07:05:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:05:23 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "07:05:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:05:31 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "07:05:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:05:39 [INFO]   Training abgeschlossen in 5.08s (Backend: cuml)\n",
      "07:05:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:05:47 [INFO]   Training abgeschlossen in 5.53s (Backend: cuml)\n",
      "07:05:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:05:56 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "07:05:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:06:04 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "07:06:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:06:13 [INFO]   Training abgeschlossen in 5.70s (Backend: cuml)\n",
      "07:06:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:06:21 [INFO]   Training abgeschlossen in 5.82s (Backend: cuml)\n",
      "07:06:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:06:31 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "07:06:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:06:40 [INFO]   Training abgeschlossen in 6.13s (Backend: cuml)\n",
      "07:06:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:06:49 [INFO]   Training abgeschlossen in 6.20s (Backend: cuml)\n",
      "07:06:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:06:58 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "07:07:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:07:07 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "07:07:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:07:17 [INFO]   Training abgeschlossen in 6.61s (Backend: cuml)\n",
      "07:07:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:07:26 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "07:07:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:07:36 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "07:07:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:07:46 [INFO]   Training abgeschlossen in 6.65s (Backend: cuml)\n",
      "07:07:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:07:55 [INFO]   Training abgeschlossen in 6.46s (Backend: cuml)\n",
      "07:07:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:08:05 [INFO]   Training abgeschlossen in 6.65s (Backend: cuml)\n",
      "07:08:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:08:15 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "07:08:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:08:25 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "07:08:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:08:35 [INFO]   Training abgeschlossen in 6.95s (Backend: cuml)\n",
      "07:08:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:08:46 [INFO]   Training abgeschlossen in 7.17s (Backend: cuml)\n",
      "07:08:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:08:56 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "07:08:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:09:06 [INFO]   Training abgeschlossen in 7.12s (Backend: cuml)\n",
      "07:09:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:09:17 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "07:09:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:09:27 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "07:09:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:09:38 [INFO]   Training abgeschlossen in 7.42s (Backend: cuml)\n",
      "07:09:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:09:49 [INFO]   Training abgeschlossen in 7.58s (Backend: cuml)\n",
      "07:09:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:09:59 [INFO]   Training abgeschlossen in 7.52s (Backend: cuml)\n",
      "07:10:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:10:10 [INFO]   Training abgeschlossen in 7.59s (Backend: cuml)\n",
      "07:10:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:10:21 [INFO]   Training abgeschlossen in 7.77s (Backend: cuml)\n",
      "07:10:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:10:32 [INFO]   Training abgeschlossen in 7.78s (Backend: cuml)\n",
      "07:10:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:10:44 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "07:10:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:10:55 [INFO]   Training abgeschlossen in 8.13s (Backend: cuml)\n",
      "07:10:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:11:07 [INFO]   Training abgeschlossen in 8.10s (Backend: cuml)\n",
      "07:11:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:11:18 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "07:11:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:11:30 [INFO]   Training abgeschlossen in 8.31s (Backend: cuml)\n",
      "07:11:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:11:41 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "07:11:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:11:53 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "07:11:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:12:05 [INFO]   Training abgeschlossen in 8.20s (Backend: cuml)\n",
      "07:12:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:12:17 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "07:12:20 [INFO]     24,000 labeled → Accuracy: 0.8687 (Train: 8.3s, Query: 0.01s) | GPU: 2.5/8.0 GB\n",
      "07:12:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:12:29 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "07:12:32 [INFO]     Final: 24,000 labeled → Accuracy: 0.8690, F1: 0.8680\n",
      "07:12:32 [INFO]   Run 4/5\n",
      "07:12:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:12:37 [INFO]   Training abgeschlossen in 4.57s (Backend: cuml)\n",
      "07:12:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:12:44 [INFO]   Training abgeschlossen in 4.57s (Backend: cuml)\n",
      "07:12:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:12:51 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "07:12:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:12:59 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "07:13:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:13:06 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "07:13:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:13:14 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "07:13:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:13:21 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "07:13:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:13:29 [INFO]   Training abgeschlossen in 5.02s (Backend: cuml)\n",
      "07:13:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:13:37 [INFO]   Training abgeschlossen in 5.35s (Backend: cuml)\n",
      "07:13:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:13:46 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "07:13:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:13:54 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "07:13:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:14:03 [INFO]   Training abgeschlossen in 5.88s (Backend: cuml)\n",
      "07:14:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:14:12 [INFO]   Training abgeschlossen in 5.87s (Backend: cuml)\n",
      "07:14:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:14:21 [INFO]   Training abgeschlossen in 5.97s (Backend: cuml)\n",
      "07:14:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:14:30 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "07:14:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:14:40 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "07:14:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:14:49 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "07:14:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:14:59 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "07:15:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:15:08 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "07:15:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:15:18 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "07:15:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:15:28 [INFO]   Training abgeschlossen in 6.49s (Backend: cuml)\n",
      "07:15:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:15:38 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "07:15:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:15:48 [INFO]   Training abgeschlossen in 6.82s (Backend: cuml)\n",
      "07:15:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:15:58 [INFO]   Training abgeschlossen in 6.76s (Backend: cuml)\n",
      "07:16:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:16:08 [INFO]   Training abgeschlossen in 6.97s (Backend: cuml)\n",
      "07:16:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:16:18 [INFO]   Training abgeschlossen in 7.04s (Backend: cuml)\n",
      "07:16:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:16:28 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "07:16:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:16:39 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "07:16:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:16:49 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "07:16:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:17:00 [INFO]   Training abgeschlossen in 7.29s (Backend: cuml)\n",
      "07:17:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:17:10 [INFO]   Training abgeschlossen in 7.41s (Backend: cuml)\n",
      "07:17:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:17:21 [INFO]   Training abgeschlossen in 7.37s (Backend: cuml)\n",
      "07:17:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:17:32 [INFO]   Training abgeschlossen in 7.41s (Backend: cuml)\n",
      "07:17:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:17:43 [INFO]   Training abgeschlossen in 7.46s (Backend: cuml)\n",
      "07:17:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:17:53 [INFO]   Training abgeschlossen in 7.79s (Backend: cuml)\n",
      "07:17:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:18:05 [INFO]   Training abgeschlossen in 7.63s (Backend: cuml)\n",
      "07:18:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:18:16 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "07:18:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:18:27 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "07:18:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:18:38 [INFO]   Training abgeschlossen in 7.94s (Backend: cuml)\n",
      "07:18:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:18:49 [INFO]   Training abgeschlossen in 8.08s (Backend: cuml)\n",
      "07:18:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:19:01 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "07:19:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:19:13 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "07:19:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:19:25 [INFO]   Training abgeschlossen in 8.31s (Backend: cuml)\n",
      "07:19:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:19:36 [INFO]   Training abgeschlossen in 8.07s (Backend: cuml)\n",
      "07:19:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:19:48 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "07:19:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:19:59 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "07:20:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:20:12 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "07:20:15 [INFO]     24,000 labeled → Accuracy: 0.8675 (Train: 8.6s, Query: 0.01s) | GPU: 2.5/8.0 GB\n",
      "07:20:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:20:24 [INFO]   Training abgeschlossen in 8.47s (Backend: cuml)\n",
      "07:20:27 [INFO]     Final: 24,000 labeled → Accuracy: 0.8686, F1: 0.8679\n",
      "07:20:27 [INFO]   Run 5/5\n",
      "07:20:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:20:32 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "07:20:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:20:39 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "07:20:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:20:46 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "07:20:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:20:54 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "07:20:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:21:01 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "07:21:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:21:09 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "07:21:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:21:17 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "07:21:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:21:25 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "07:21:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:21:33 [INFO]   Training abgeschlossen in 5.34s (Backend: cuml)\n",
      "07:21:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:21:41 [INFO]   Training abgeschlossen in 5.52s (Backend: cuml)\n",
      "07:21:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:21:50 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "07:21:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:21:58 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "07:22:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:22:07 [INFO]   Training abgeschlossen in 5.89s (Backend: cuml)\n",
      "07:22:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:22:17 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "07:22:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:22:26 [INFO]   Training abgeschlossen in 6.04s (Backend: cuml)\n",
      "07:22:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:22:35 [INFO]   Training abgeschlossen in 6.48s (Backend: cuml)\n",
      "07:22:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:22:44 [INFO]   Training abgeschlossen in 6.16s (Backend: cuml)\n",
      "07:22:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:22:54 [INFO]   Training abgeschlossen in 6.21s (Backend: cuml)\n",
      "07:22:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:23:03 [INFO]   Training abgeschlossen in 6.54s (Backend: cuml)\n",
      "07:23:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:23:13 [INFO]   Training abgeschlossen in 6.90s (Backend: cuml)\n",
      "07:23:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:23:23 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "07:23:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:23:32 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "07:23:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:23:42 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "07:23:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:23:52 [INFO]   Training abgeschlossen in 6.82s (Backend: cuml)\n",
      "07:23:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:24:02 [INFO]   Training abgeschlossen in 6.71s (Backend: cuml)\n",
      "07:24:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:24:12 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "07:24:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:24:22 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "07:24:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:24:32 [INFO]   Training abgeschlossen in 6.99s (Backend: cuml)\n",
      "07:24:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:24:43 [INFO]   Training abgeschlossen in 7.07s (Backend: cuml)\n",
      "07:24:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:24:53 [INFO]   Training abgeschlossen in 7.11s (Backend: cuml)\n",
      "07:24:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:25:03 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "07:25:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:25:14 [INFO]   Training abgeschlossen in 7.41s (Backend: cuml)\n",
      "07:25:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:25:25 [INFO]   Training abgeschlossen in 7.47s (Backend: cuml)\n",
      "07:25:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:25:36 [INFO]   Training abgeschlossen in 7.42s (Backend: cuml)\n",
      "07:25:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:25:47 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "07:25:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:25:57 [INFO]   Training abgeschlossen in 7.59s (Backend: cuml)\n",
      "07:26:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:26:09 [INFO]   Training abgeschlossen in 7.74s (Backend: cuml)\n",
      "07:26:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:26:20 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "07:26:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:26:31 [INFO]   Training abgeschlossen in 7.96s (Backend: cuml)\n",
      "07:26:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:26:43 [INFO]   Training abgeschlossen in 8.07s (Backend: cuml)\n",
      "07:26:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:26:54 [INFO]   Training abgeschlossen in 8.10s (Backend: cuml)\n",
      "07:26:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:27:06 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "07:27:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:27:18 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "07:27:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:27:29 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "07:27:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:27:41 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "07:27:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:27:53 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "07:27:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:28:05 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "07:28:08 [INFO]     24,000 labeled → Accuracy: 0.8707 (Train: 8.4s, Query: 0.01s) | GPU: 2.5/8.0 GB\n",
      "07:28:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:28:17 [INFO]   Training abgeschlossen in 8.53s (Backend: cuml)\n",
      "07:28:20 [INFO]     Final: 24,000 labeled → Accuracy: 0.8708, F1: 0.8696\n",
      "07:28:20 [INFO] \n",
      "GPU-SVM + Random Sampling - Budget: 60% (36,000 Samples)\n",
      "07:28:20 [INFO]   Run 1/5\n",
      "07:28:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:28:25 [INFO]   Training abgeschlossen in 4.57s (Backend: cuml)\n",
      "07:28:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:28:32 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "07:28:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:28:40 [INFO]   Training abgeschlossen in 4.62s (Backend: cuml)\n",
      "07:28:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:28:47 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "07:28:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:28:55 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "07:28:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:29:02 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "07:29:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:29:10 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "07:29:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:29:18 [INFO]   Training abgeschlossen in 5.06s (Backend: cuml)\n",
      "07:29:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:29:26 [INFO]   Training abgeschlossen in 5.44s (Backend: cuml)\n",
      "07:29:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:29:34 [INFO]   Training abgeschlossen in 5.40s (Backend: cuml)\n",
      "07:29:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:29:43 [INFO]   Training abgeschlossen in 5.75s (Backend: cuml)\n",
      "07:29:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:29:51 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "07:29:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:30:00 [INFO]   Training abgeschlossen in 5.84s (Backend: cuml)\n",
      "07:30:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:30:09 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "07:30:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:30:18 [INFO]   Training abgeschlossen in 6.09s (Backend: cuml)\n",
      "07:30:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:30:28 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "07:30:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:30:37 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "07:30:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:30:47 [INFO]   Training abgeschlossen in 6.17s (Backend: cuml)\n",
      "07:30:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:30:56 [INFO]   Training abgeschlossen in 6.40s (Backend: cuml)\n",
      "07:30:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:31:05 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "07:31:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:31:15 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "07:31:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:31:25 [INFO]   Training abgeschlossen in 6.59s (Backend: cuml)\n",
      "07:31:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:31:34 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "07:31:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:31:44 [INFO]   Training abgeschlossen in 6.74s (Backend: cuml)\n",
      "07:31:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:31:54 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "07:31:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:32:04 [INFO]   Training abgeschlossen in 6.89s (Backend: cuml)\n",
      "07:32:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:32:14 [INFO]   Training abgeschlossen in 6.95s (Backend: cuml)\n",
      "07:32:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:32:25 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "07:32:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:32:35 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "07:32:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:32:46 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "07:32:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:32:56 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "07:32:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:33:07 [INFO]   Training abgeschlossen in 7.30s (Backend: cuml)\n",
      "07:33:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:33:17 [INFO]   Training abgeschlossen in 7.36s (Backend: cuml)\n",
      "07:33:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:33:28 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "07:33:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:33:39 [INFO]   Training abgeschlossen in 7.61s (Backend: cuml)\n",
      "07:33:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:33:50 [INFO]   Training abgeschlossen in 7.61s (Backend: cuml)\n",
      "07:33:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:34:01 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "07:34:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:34:12 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "07:34:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:34:23 [INFO]   Training abgeschlossen in 8.00s (Backend: cuml)\n",
      "07:34:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:34:35 [INFO]   Training abgeschlossen in 8.25s (Backend: cuml)\n",
      "07:34:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:34:47 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "07:34:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:34:58 [INFO]   Training abgeschlossen in 8.22s (Backend: cuml)\n",
      "07:35:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:35:10 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "07:35:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:35:21 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "07:35:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:35:33 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "07:35:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:35:45 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "07:35:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:35:57 [INFO]   Training abgeschlossen in 8.36s (Backend: cuml)\n",
      "07:36:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:36:09 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "07:36:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:36:21 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "07:36:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:36:33 [INFO]   Training abgeschlossen in 8.89s (Backend: cuml)\n",
      "07:36:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:36:46 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "07:36:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:36:58 [INFO]   Training abgeschlossen in 8.89s (Backend: cuml)\n",
      "07:37:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:37:11 [INFO]   Training abgeschlossen in 9.06s (Backend: cuml)\n",
      "07:37:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:37:24 [INFO]   Training abgeschlossen in 9.11s (Backend: cuml)\n",
      "07:37:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:37:37 [INFO]   Training abgeschlossen in 9.50s (Backend: cuml)\n",
      "07:37:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:37:50 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "07:37:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:38:02 [INFO]   Training abgeschlossen in 9.29s (Backend: cuml)\n",
      "07:38:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:38:16 [INFO]   Training abgeschlossen in 9.47s (Backend: cuml)\n",
      "07:38:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:38:29 [INFO]   Training abgeschlossen in 9.76s (Backend: cuml)\n",
      "07:38:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:38:43 [INFO]   Training abgeschlossen in 9.93s (Backend: cuml)\n",
      "07:38:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:38:56 [INFO]   Training abgeschlossen in 9.97s (Backend: cuml)\n",
      "07:39:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:39:10 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "07:39:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:39:24 [INFO]   Training abgeschlossen in 10.20s (Backend: cuml)\n",
      "07:39:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:39:38 [INFO]   Training abgeschlossen in 10.25s (Backend: cuml)\n",
      "07:39:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:39:52 [INFO]   Training abgeschlossen in 10.24s (Backend: cuml)\n",
      "07:39:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:40:06 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "07:40:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:40:20 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "07:40:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:40:35 [INFO]   Training abgeschlossen in 10.66s (Backend: cuml)\n",
      "07:40:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:40:49 [INFO]   Training abgeschlossen in 10.61s (Backend: cuml)\n",
      "07:40:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:41:04 [INFO]   Training abgeschlossen in 10.75s (Backend: cuml)\n",
      "07:41:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:41:18 [INFO]   Training abgeschlossen in 10.83s (Backend: cuml)\n",
      "07:41:22 [INFO]     36,000 labeled → Accuracy: 0.8779 (Train: 10.8s, Query: 0.01s) | GPU: 2.6/8.0 GB\n",
      "07:41:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:41:33 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "07:41:37 [INFO]     Final: 36,000 labeled → Accuracy: 0.8783, F1: 0.8775\n",
      "07:41:37 [INFO]   Run 2/5\n",
      "07:41:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:41:42 [INFO]   Training abgeschlossen in 4.57s (Backend: cuml)\n",
      "07:41:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:41:49 [INFO]   Training abgeschlossen in 4.64s (Backend: cuml)\n",
      "07:41:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:41:57 [INFO]   Training abgeschlossen in 4.64s (Backend: cuml)\n",
      "07:41:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:42:04 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "07:42:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:42:12 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "07:42:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:42:19 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "07:42:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:42:27 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "07:42:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:42:35 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "07:42:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:42:43 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "07:42:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:42:51 [INFO]   Training abgeschlossen in 5.43s (Backend: cuml)\n",
      "07:42:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:43:00 [INFO]   Training abgeschlossen in 5.52s (Backend: cuml)\n",
      "07:43:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:43:09 [INFO]   Training abgeschlossen in 5.82s (Backend: cuml)\n",
      "07:43:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:43:17 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "07:43:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:43:26 [INFO]   Training abgeschlossen in 5.96s (Backend: cuml)\n",
      "07:43:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:43:35 [INFO]   Training abgeschlossen in 6.07s (Backend: cuml)\n",
      "07:43:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:43:45 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "07:43:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:43:54 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "07:43:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:44:03 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "07:44:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:44:13 [INFO]   Training abgeschlossen in 6.28s (Backend: cuml)\n",
      "07:44:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:44:22 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "07:44:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:44:32 [INFO]   Training abgeschlossen in 6.62s (Backend: cuml)\n",
      "07:44:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:44:41 [INFO]   Training abgeschlossen in 6.46s (Backend: cuml)\n",
      "07:44:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:44:51 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "07:44:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:45:01 [INFO]   Training abgeschlossen in 6.76s (Backend: cuml)\n",
      "07:45:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:45:11 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "07:45:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:45:21 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "07:45:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:45:31 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "07:45:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:45:41 [INFO]   Training abgeschlossen in 7.05s (Backend: cuml)\n",
      "07:45:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:45:51 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "07:45:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:46:02 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "07:46:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:46:13 [INFO]   Training abgeschlossen in 7.50s (Backend: cuml)\n",
      "07:46:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:46:23 [INFO]   Training abgeschlossen in 7.34s (Backend: cuml)\n",
      "07:46:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:46:34 [INFO]   Training abgeschlossen in 7.43s (Backend: cuml)\n",
      "07:46:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:46:45 [INFO]   Training abgeschlossen in 7.48s (Backend: cuml)\n",
      "07:46:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:46:56 [INFO]   Training abgeschlossen in 7.79s (Backend: cuml)\n",
      "07:46:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:47:07 [INFO]   Training abgeschlossen in 7.70s (Backend: cuml)\n",
      "07:47:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:47:18 [INFO]   Training abgeschlossen in 7.83s (Backend: cuml)\n",
      "07:47:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:47:30 [INFO]   Training abgeschlossen in 7.95s (Backend: cuml)\n",
      "07:47:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:47:41 [INFO]   Training abgeschlossen in 8.11s (Backend: cuml)\n",
      "07:47:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:47:53 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "07:47:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:48:04 [INFO]   Training abgeschlossen in 8.29s (Backend: cuml)\n",
      "07:48:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:48:16 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "07:48:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:48:28 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "07:48:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:48:39 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "07:48:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:48:51 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "07:48:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:49:03 [INFO]   Training abgeschlossen in 8.40s (Backend: cuml)\n",
      "07:49:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:49:15 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "07:49:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:49:27 [INFO]   Training abgeschlossen in 8.45s (Backend: cuml)\n",
      "07:49:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:49:39 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "07:49:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:49:51 [INFO]   Training abgeschlossen in 8.67s (Backend: cuml)\n",
      "07:49:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:50:04 [INFO]   Training abgeschlossen in 9.09s (Backend: cuml)\n",
      "07:50:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:50:16 [INFO]   Training abgeschlossen in 8.88s (Backend: cuml)\n",
      "07:50:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:50:29 [INFO]   Training abgeschlossen in 9.03s (Backend: cuml)\n",
      "07:50:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:50:42 [INFO]   Training abgeschlossen in 9.19s (Backend: cuml)\n",
      "07:50:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:50:54 [INFO]   Training abgeschlossen in 9.29s (Backend: cuml)\n",
      "07:50:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:51:07 [INFO]   Training abgeschlossen in 9.37s (Backend: cuml)\n",
      "07:51:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:51:20 [INFO]   Training abgeschlossen in 9.34s (Backend: cuml)\n",
      "07:51:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:51:33 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "07:51:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:51:47 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "07:51:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:52:00 [INFO]   Training abgeschlossen in 9.98s (Backend: cuml)\n",
      "07:52:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:52:14 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "07:52:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:52:28 [INFO]   Training abgeschlossen in 10.02s (Backend: cuml)\n",
      "07:52:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:52:42 [INFO]   Training abgeschlossen in 10.12s (Backend: cuml)\n",
      "07:52:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:52:55 [INFO]   Training abgeschlossen in 10.26s (Backend: cuml)\n",
      "07:52:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:53:10 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "07:53:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:53:24 [INFO]   Training abgeschlossen in 10.37s (Backend: cuml)\n",
      "07:53:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:53:38 [INFO]   Training abgeschlossen in 10.47s (Backend: cuml)\n",
      "07:53:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:53:52 [INFO]   Training abgeschlossen in 10.70s (Backend: cuml)\n",
      "07:53:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:54:07 [INFO]   Training abgeschlossen in 10.85s (Backend: cuml)\n",
      "07:54:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:54:21 [INFO]   Training abgeschlossen in 10.62s (Backend: cuml)\n",
      "07:54:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:54:36 [INFO]   Training abgeschlossen in 10.73s (Backend: cuml)\n",
      "07:54:39 [INFO]     36,000 labeled → Accuracy: 0.8766 (Train: 10.8s, Query: 0.01s) | GPU: 2.6/8.0 GB\n",
      "07:54:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:54:51 [INFO]   Training abgeschlossen in 10.90s (Backend: cuml)\n",
      "07:54:54 [INFO]     Final: 36,000 labeled → Accuracy: 0.8760, F1: 0.8754\n",
      "07:54:54 [INFO]   Run 3/5\n",
      "07:54:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:54:59 [INFO]   Training abgeschlossen in 4.62s (Backend: cuml)\n",
      "07:55:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:55:06 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "07:55:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:55:14 [INFO]   Training abgeschlossen in 4.56s (Backend: cuml)\n",
      "07:55:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:55:21 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "07:55:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:55:29 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "07:55:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:55:36 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "07:55:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:55:44 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "07:55:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:55:52 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "07:55:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:56:00 [INFO]   Training abgeschlossen in 5.37s (Backend: cuml)\n",
      "07:56:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:56:09 [INFO]   Training abgeschlossen in 5.56s (Backend: cuml)\n",
      "07:56:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:56:17 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "07:56:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:56:26 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "07:56:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:56:34 [INFO]   Training abgeschlossen in 5.78s (Backend: cuml)\n",
      "07:56:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:56:44 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "07:56:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:56:53 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "07:56:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:57:02 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "07:57:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:57:11 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "07:57:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:57:21 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "07:57:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:57:30 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "07:57:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:57:40 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "07:57:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:57:49 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "07:57:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:57:59 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "07:58:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:58:08 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "07:58:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:58:18 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "07:58:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:58:28 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "07:58:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:58:38 [INFO]   Training abgeschlossen in 6.85s (Backend: cuml)\n",
      "07:58:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:58:48 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "07:58:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:58:59 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "07:59:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:59:09 [INFO]   Training abgeschlossen in 7.16s (Backend: cuml)\n",
      "07:59:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:59:20 [INFO]   Training abgeschlossen in 7.40s (Backend: cuml)\n",
      "07:59:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:59:30 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "07:59:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:59:41 [INFO]   Training abgeschlossen in 7.28s (Backend: cuml)\n",
      "07:59:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:59:51 [INFO]   Training abgeschlossen in 7.32s (Backend: cuml)\n",
      "07:59:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:00:02 [INFO]   Training abgeschlossen in 7.46s (Backend: cuml)\n",
      "08:00:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:00:13 [INFO]   Training abgeschlossen in 7.60s (Backend: cuml)\n",
      "08:00:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:00:24 [INFO]   Training abgeschlossen in 7.72s (Backend: cuml)\n",
      "08:00:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:00:35 [INFO]   Training abgeschlossen in 7.72s (Backend: cuml)\n",
      "08:00:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:00:46 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "08:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:00:57 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "08:01:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:01:09 [INFO]   Training abgeschlossen in 8.08s (Backend: cuml)\n",
      "08:01:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:01:20 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "08:01:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:01:32 [INFO]   Training abgeschlossen in 8.19s (Backend: cuml)\n",
      "08:01:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:01:44 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "08:01:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:01:55 [INFO]   Training abgeschlossen in 8.10s (Backend: cuml)\n",
      "08:01:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:02:07 [INFO]   Training abgeschlossen in 8.20s (Backend: cuml)\n",
      "08:02:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:02:19 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "08:02:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:02:31 [INFO]   Training abgeschlossen in 8.40s (Backend: cuml)\n",
      "08:02:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:02:43 [INFO]   Training abgeschlossen in 8.48s (Backend: cuml)\n",
      "08:02:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:02:55 [INFO]   Training abgeschlossen in 8.47s (Backend: cuml)\n",
      "08:02:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:03:07 [INFO]   Training abgeschlossen in 8.57s (Backend: cuml)\n",
      "08:03:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:03:19 [INFO]   Training abgeschlossen in 9.19s (Backend: cuml)\n",
      "08:03:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:03:32 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "08:03:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:03:45 [INFO]   Training abgeschlossen in 9.04s (Backend: cuml)\n",
      "08:03:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:03:57 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "08:04:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:04:10 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "08:04:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:04:23 [INFO]   Training abgeschlossen in 9.51s (Backend: cuml)\n",
      "08:04:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:04:36 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "08:04:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:04:50 [INFO]   Training abgeschlossen in 9.49s (Backend: cuml)\n",
      "08:04:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:05:03 [INFO]   Training abgeschlossen in 9.60s (Backend: cuml)\n",
      "08:05:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:05:16 [INFO]   Training abgeschlossen in 9.89s (Backend: cuml)\n",
      "08:05:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:05:30 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "08:05:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:05:44 [INFO]   Training abgeschlossen in 10.04s (Backend: cuml)\n",
      "08:05:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:05:57 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "08:06:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:06:11 [INFO]   Training abgeschlossen in 10.16s (Backend: cuml)\n",
      "08:06:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:06:25 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "08:06:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:06:39 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "08:06:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:06:54 [INFO]   Training abgeschlossen in 10.64s (Backend: cuml)\n",
      "08:06:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:07:08 [INFO]   Training abgeschlossen in 10.58s (Backend: cuml)\n",
      "08:07:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:07:23 [INFO]   Training abgeschlossen in 10.75s (Backend: cuml)\n",
      "08:07:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:07:37 [INFO]   Training abgeschlossen in 10.69s (Backend: cuml)\n",
      "08:07:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:07:52 [INFO]   Training abgeschlossen in 10.76s (Backend: cuml)\n",
      "08:07:55 [INFO]     36,000 labeled → Accuracy: 0.8750 (Train: 10.8s, Query: 0.01s) | GPU: 2.6/8.0 GB\n",
      "08:07:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:08:06 [INFO]   Training abgeschlossen in 10.85s (Backend: cuml)\n",
      "08:08:10 [INFO]     Final: 36,000 labeled → Accuracy: 0.8757, F1: 0.8750\n",
      "08:08:10 [INFO]   Run 4/5\n",
      "08:08:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:08:15 [INFO]   Training abgeschlossen in 4.55s (Backend: cuml)\n",
      "08:08:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:08:22 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "08:08:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:08:29 [INFO]   Training abgeschlossen in 4.62s (Backend: cuml)\n",
      "08:08:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:08:37 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "08:08:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:08:45 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "08:08:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:08:52 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "08:08:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:09:00 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "08:09:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:09:08 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "08:09:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:09:16 [INFO]   Training abgeschlossen in 5.34s (Backend: cuml)\n",
      "08:09:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:09:25 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "08:09:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:09:33 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "08:09:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:09:42 [INFO]   Training abgeschlossen in 5.84s (Backend: cuml)\n",
      "08:09:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:09:51 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "08:09:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:10:00 [INFO]   Training abgeschlossen in 5.98s (Backend: cuml)\n",
      "08:10:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:10:09 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "08:10:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:10:18 [INFO]   Training abgeschlossen in 6.10s (Backend: cuml)\n",
      "08:10:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:10:28 [INFO]   Training abgeschlossen in 6.60s (Backend: cuml)\n",
      "08:10:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:10:37 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "08:10:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:10:47 [INFO]   Training abgeschlossen in 6.21s (Backend: cuml)\n",
      "08:10:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:10:56 [INFO]   Training abgeschlossen in 6.58s (Backend: cuml)\n",
      "08:10:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:11:06 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "08:11:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:11:15 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "08:11:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:11:25 [INFO]   Training abgeschlossen in 6.62s (Backend: cuml)\n",
      "08:11:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:11:35 [INFO]   Training abgeschlossen in 6.65s (Backend: cuml)\n",
      "08:11:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:11:45 [INFO]   Training abgeschlossen in 6.71s (Backend: cuml)\n",
      "08:11:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:11:55 [INFO]   Training abgeschlossen in 6.89s (Backend: cuml)\n",
      "08:11:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:12:05 [INFO]   Training abgeschlossen in 6.94s (Backend: cuml)\n",
      "08:12:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:12:15 [INFO]   Training abgeschlossen in 6.99s (Backend: cuml)\n",
      "08:12:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:12:26 [INFO]   Training abgeschlossen in 7.45s (Backend: cuml)\n",
      "08:12:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:12:37 [INFO]   Training abgeschlossen in 7.28s (Backend: cuml)\n",
      "08:12:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:12:47 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "08:12:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:12:58 [INFO]   Training abgeschlossen in 7.28s (Backend: cuml)\n",
      "08:13:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:13:08 [INFO]   Training abgeschlossen in 7.38s (Backend: cuml)\n",
      "08:13:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:13:19 [INFO]   Training abgeschlossen in 7.46s (Backend: cuml)\n",
      "08:13:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:13:30 [INFO]   Training abgeschlossen in 7.77s (Backend: cuml)\n",
      "08:13:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:13:41 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "08:13:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:13:52 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "08:13:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:14:04 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "08:14:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:14:15 [INFO]   Training abgeschlossen in 8.00s (Backend: cuml)\n",
      "08:14:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:14:26 [INFO]   Training abgeschlossen in 8.19s (Backend: cuml)\n",
      "08:14:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:14:38 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "08:14:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:14:50 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "08:14:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:15:02 [INFO]   Training abgeschlossen in 8.36s (Backend: cuml)\n",
      "08:15:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:15:13 [INFO]   Training abgeschlossen in 8.15s (Backend: cuml)\n",
      "08:15:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:15:25 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "08:15:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:15:37 [INFO]   Training abgeschlossen in 8.37s (Backend: cuml)\n",
      "08:15:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:15:49 [INFO]   Training abgeschlossen in 8.34s (Backend: cuml)\n",
      "08:15:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:16:01 [INFO]   Training abgeschlossen in 8.40s (Backend: cuml)\n",
      "08:16:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:16:12 [INFO]   Training abgeschlossen in 8.47s (Backend: cuml)\n",
      "08:16:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:16:25 [INFO]   Training abgeschlossen in 8.65s (Backend: cuml)\n",
      "08:16:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:16:37 [INFO]   Training abgeschlossen in 9.14s (Backend: cuml)\n",
      "08:16:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:16:50 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "08:16:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:17:03 [INFO]   Training abgeschlossen in 9.04s (Backend: cuml)\n",
      "08:17:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:17:16 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "08:17:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:17:28 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "08:17:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:17:41 [INFO]   Training abgeschlossen in 9.39s (Backend: cuml)\n",
      "08:17:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:17:54 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "08:17:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:18:07 [INFO]   Training abgeschlossen in 9.49s (Backend: cuml)\n",
      "08:18:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:18:21 [INFO]   Training abgeschlossen in 9.63s (Backend: cuml)\n",
      "08:18:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:18:34 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "08:18:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:18:48 [INFO]   Training abgeschlossen in 10.00s (Backend: cuml)\n",
      "08:18:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:19:01 [INFO]   Training abgeschlossen in 9.94s (Backend: cuml)\n",
      "08:19:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:19:15 [INFO]   Training abgeschlossen in 10.06s (Backend: cuml)\n",
      "08:19:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:19:29 [INFO]   Training abgeschlossen in 10.30s (Backend: cuml)\n",
      "08:19:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:19:44 [INFO]   Training abgeschlossen in 10.61s (Backend: cuml)\n",
      "08:19:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:19:58 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "08:20:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:20:12 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "08:20:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:20:26 [INFO]   Training abgeschlossen in 10.65s (Backend: cuml)\n",
      "08:20:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:20:41 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "08:20:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:20:55 [INFO]   Training abgeschlossen in 10.71s (Backend: cuml)\n",
      "08:20:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:21:10 [INFO]   Training abgeschlossen in 10.80s (Backend: cuml)\n",
      "08:21:14 [INFO]     36,000 labeled → Accuracy: 0.8765 (Train: 10.8s, Query: 0.01s) | GPU: 2.6/8.0 GB\n",
      "08:21:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:21:25 [INFO]   Training abgeschlossen in 11.03s (Backend: cuml)\n",
      "08:21:29 [INFO]     Final: 36,000 labeled → Accuracy: 0.8760, F1: 0.8754\n",
      "08:21:29 [INFO]   Run 5/5\n",
      "08:21:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:21:34 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "08:21:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:21:41 [INFO]   Training abgeschlossen in 4.63s (Backend: cuml)\n",
      "08:21:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:21:48 [INFO]   Training abgeschlossen in 4.68s (Backend: cuml)\n",
      "08:21:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:21:56 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "08:21:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:22:03 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "08:22:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:22:11 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "08:22:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:22:18 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "08:22:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:22:26 [INFO]   Training abgeschlossen in 4.94s (Backend: cuml)\n",
      "08:22:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:22:35 [INFO]   Training abgeschlossen in 5.51s (Backend: cuml)\n",
      "08:22:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:22:43 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "08:22:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:22:52 [INFO]   Training abgeschlossen in 5.72s (Backend: cuml)\n",
      "08:22:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:23:00 [INFO]   Training abgeschlossen in 5.70s (Backend: cuml)\n",
      "08:23:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:23:09 [INFO]   Training abgeschlossen in 5.82s (Backend: cuml)\n",
      "08:23:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:23:18 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "08:23:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:23:27 [INFO]   Training abgeschlossen in 6.04s (Backend: cuml)\n",
      "08:23:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:23:37 [INFO]   Training abgeschlossen in 6.11s (Backend: cuml)\n",
      "08:23:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:23:46 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "08:23:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:23:55 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "08:23:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:24:05 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "08:24:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:24:14 [INFO]   Training abgeschlossen in 6.39s (Backend: cuml)\n",
      "08:24:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:24:23 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "08:24:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:24:33 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "08:24:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:24:43 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "08:24:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:24:53 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "08:24:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:25:03 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "08:25:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:25:13 [INFO]   Training abgeschlossen in 6.87s (Backend: cuml)\n",
      "08:25:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:25:23 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "08:25:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:25:33 [INFO]   Training abgeschlossen in 7.04s (Backend: cuml)\n",
      "08:25:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:25:44 [INFO]   Training abgeschlossen in 7.14s (Backend: cuml)\n",
      "08:25:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:25:55 [INFO]   Training abgeschlossen in 7.52s (Backend: cuml)\n",
      "08:25:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:26:05 [INFO]   Training abgeschlossen in 7.38s (Backend: cuml)\n",
      "08:26:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:26:16 [INFO]   Training abgeschlossen in 7.35s (Backend: cuml)\n",
      "08:26:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:26:27 [INFO]   Training abgeschlossen in 7.43s (Backend: cuml)\n",
      "08:26:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:26:37 [INFO]   Training abgeschlossen in 7.47s (Backend: cuml)\n",
      "08:26:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:26:49 [INFO]   Training abgeschlossen in 7.84s (Backend: cuml)\n",
      "08:26:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:27:00 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "08:27:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:27:11 [INFO]   Training abgeschlossen in 7.69s (Backend: cuml)\n",
      "08:27:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:27:22 [INFO]   Training abgeschlossen in 7.82s (Backend: cuml)\n",
      "08:27:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:27:33 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "08:27:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:27:45 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "08:27:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:27:57 [INFO]   Training abgeschlossen in 8.36s (Backend: cuml)\n",
      "08:28:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:28:08 [INFO]   Training abgeschlossen in 8.25s (Backend: cuml)\n",
      "08:28:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:28:20 [INFO]   Training abgeschlossen in 8.31s (Backend: cuml)\n",
      "08:28:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:28:32 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "08:28:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:28:43 [INFO]   Training abgeschlossen in 8.22s (Backend: cuml)\n",
      "08:28:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:28:55 [INFO]   Training abgeschlossen in 8.48s (Backend: cuml)\n",
      "08:28:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:29:07 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "08:29:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:29:19 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "08:29:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:29:31 [INFO]   Training abgeschlossen in 8.53s (Backend: cuml)\n",
      "08:29:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:29:43 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "08:29:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:29:56 [INFO]   Training abgeschlossen in 9.08s (Backend: cuml)\n",
      "08:29:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:30:08 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "08:30:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:30:21 [INFO]   Training abgeschlossen in 9.03s (Backend: cuml)\n",
      "08:30:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:30:34 [INFO]   Training abgeschlossen in 9.14s (Backend: cuml)\n",
      "08:30:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:30:46 [INFO]   Training abgeschlossen in 9.18s (Backend: cuml)\n",
      "08:30:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:30:59 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "08:31:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:31:13 [INFO]   Training abgeschlossen in 9.38s (Backend: cuml)\n",
      "08:31:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:31:26 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "08:31:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:31:39 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "08:31:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:31:53 [INFO]   Training abgeschlossen in 9.94s (Backend: cuml)\n",
      "08:31:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:32:06 [INFO]   Training abgeschlossen in 10.06s (Backend: cuml)\n",
      "08:32:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:32:20 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "08:32:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:32:34 [INFO]   Training abgeschlossen in 10.04s (Backend: cuml)\n",
      "08:32:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:32:48 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "08:32:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:33:02 [INFO]   Training abgeschlossen in 10.45s (Backend: cuml)\n",
      "08:33:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:33:16 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "08:33:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:33:30 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "08:33:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:33:45 [INFO]   Training abgeschlossen in 10.59s (Backend: cuml)\n",
      "08:33:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:33:59 [INFO]   Training abgeschlossen in 10.83s (Backend: cuml)\n",
      "08:34:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:34:14 [INFO]   Training abgeschlossen in 10.85s (Backend: cuml)\n",
      "08:34:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:34:29 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "08:34:32 [INFO]     36,000 labeled → Accuracy: 0.8760 (Train: 10.8s, Query: 0.01s) | GPU: 2.6/8.0 GB\n",
      "08:34:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:34:43 [INFO]   Training abgeschlossen in 10.91s (Backend: cuml)\n",
      "08:34:47 [INFO]     Final: 36,000 labeled → Accuracy: 0.8762, F1: 0.8752\n",
      "08:34:47 [INFO] \n",
      "GPU-SVM + Random Sampling - Budget: 80% (48,000 Samples)\n",
      "08:34:47 [INFO]   Run 1/5\n",
      "08:34:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:34:52 [INFO]   Training abgeschlossen in 4.56s (Backend: cuml)\n",
      "08:34:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:34:59 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "08:35:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:35:06 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "08:35:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:35:14 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "08:35:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:35:21 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "08:35:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:35:29 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "08:35:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:35:37 [INFO]   Training abgeschlossen in 4.94s (Backend: cuml)\n",
      "08:35:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:35:45 [INFO]   Training abgeschlossen in 5.06s (Backend: cuml)\n",
      "08:35:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:35:53 [INFO]   Training abgeschlossen in 5.36s (Backend: cuml)\n",
      "08:35:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:36:01 [INFO]   Training abgeschlossen in 5.76s (Backend: cuml)\n",
      "08:36:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:36:10 [INFO]   Training abgeschlossen in 5.54s (Backend: cuml)\n",
      "08:36:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:36:19 [INFO]   Training abgeschlossen in 5.80s (Backend: cuml)\n",
      "08:36:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:36:27 [INFO]   Training abgeschlossen in 5.87s (Backend: cuml)\n",
      "08:36:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:36:37 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "08:36:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:36:46 [INFO]   Training abgeschlossen in 6.07s (Backend: cuml)\n",
      "08:36:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:36:55 [INFO]   Training abgeschlossen in 6.15s (Backend: cuml)\n",
      "08:36:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:37:04 [INFO]   Training abgeschlossen in 6.28s (Backend: cuml)\n",
      "08:37:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:37:14 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "08:37:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:37:23 [INFO]   Training abgeschlossen in 6.20s (Backend: cuml)\n",
      "08:37:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:37:32 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "08:37:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:37:42 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "08:37:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:37:51 [INFO]   Training abgeschlossen in 6.49s (Backend: cuml)\n",
      "08:37:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:38:01 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "08:38:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:38:11 [INFO]   Training abgeschlossen in 6.90s (Backend: cuml)\n",
      "08:38:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:38:21 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "08:38:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:38:31 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "08:38:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:38:41 [INFO]   Training abgeschlossen in 6.98s (Backend: cuml)\n",
      "08:38:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:38:52 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "08:38:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:39:02 [INFO]   Training abgeschlossen in 7.12s (Backend: cuml)\n",
      "08:39:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:39:13 [INFO]   Training abgeschlossen in 7.40s (Backend: cuml)\n",
      "08:39:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:39:23 [INFO]   Training abgeschlossen in 7.16s (Backend: cuml)\n",
      "08:39:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:39:34 [INFO]   Training abgeschlossen in 7.32s (Backend: cuml)\n",
      "08:39:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:39:44 [INFO]   Training abgeschlossen in 7.38s (Backend: cuml)\n",
      "08:39:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:39:55 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "08:39:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:40:06 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "08:40:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:40:17 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "08:40:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:40:28 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "08:40:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:40:39 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "08:40:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:40:51 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "08:40:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:41:02 [INFO]   Training abgeschlossen in 8.07s (Backend: cuml)\n",
      "08:41:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:41:14 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "08:41:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:41:26 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "08:41:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:41:37 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "08:41:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:41:49 [INFO]   Training abgeschlossen in 8.15s (Backend: cuml)\n",
      "08:41:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:42:01 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "08:42:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:42:13 [INFO]   Training abgeschlossen in 8.66s (Backend: cuml)\n",
      "08:42:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:42:25 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "08:42:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:42:37 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "08:42:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:42:49 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "08:42:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:43:01 [INFO]   Training abgeschlossen in 8.60s (Backend: cuml)\n",
      "08:43:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:43:14 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "08:43:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:43:26 [INFO]   Training abgeschlossen in 8.87s (Backend: cuml)\n",
      "08:43:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:43:39 [INFO]   Training abgeschlossen in 9.18s (Backend: cuml)\n",
      "08:43:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:43:51 [INFO]   Training abgeschlossen in 9.12s (Backend: cuml)\n",
      "08:43:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:44:04 [INFO]   Training abgeschlossen in 9.14s (Backend: cuml)\n",
      "08:44:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:44:17 [INFO]   Training abgeschlossen in 9.31s (Backend: cuml)\n",
      "08:44:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:44:30 [INFO]   Training abgeschlossen in 9.31s (Backend: cuml)\n",
      "08:44:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:44:43 [INFO]   Training abgeschlossen in 9.57s (Backend: cuml)\n",
      "08:44:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:44:57 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "08:45:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:45:10 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "08:45:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:45:24 [INFO]   Training abgeschlossen in 9.95s (Backend: cuml)\n",
      "08:45:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:45:38 [INFO]   Training abgeschlossen in 10.02s (Backend: cuml)\n",
      "08:45:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:45:51 [INFO]   Training abgeschlossen in 10.01s (Backend: cuml)\n",
      "08:45:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:46:05 [INFO]   Training abgeschlossen in 10.15s (Backend: cuml)\n",
      "08:46:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:46:19 [INFO]   Training abgeschlossen in 10.47s (Backend: cuml)\n",
      "08:46:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:46:34 [INFO]   Training abgeschlossen in 10.40s (Backend: cuml)\n",
      "08:46:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:46:48 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "08:46:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:47:02 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "08:47:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:47:17 [INFO]   Training abgeschlossen in 10.69s (Backend: cuml)\n",
      "08:47:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:47:31 [INFO]   Training abgeschlossen in 10.68s (Backend: cuml)\n",
      "08:47:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:47:46 [INFO]   Training abgeschlossen in 10.78s (Backend: cuml)\n",
      "08:47:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:48:01 [INFO]   Training abgeschlossen in 10.86s (Backend: cuml)\n",
      "08:48:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:48:16 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "08:48:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:48:31 [INFO]   Training abgeschlossen in 11.14s (Backend: cuml)\n",
      "08:48:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:48:46 [INFO]   Training abgeschlossen in 11.25s (Backend: cuml)\n",
      "08:48:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:49:01 [INFO]   Training abgeschlossen in 11.25s (Backend: cuml)\n",
      "08:49:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:49:16 [INFO]   Training abgeschlossen in 11.62s (Backend: cuml)\n",
      "08:49:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:49:32 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "08:49:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:49:47 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "08:49:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:50:03 [INFO]   Training abgeschlossen in 11.76s (Backend: cuml)\n",
      "08:50:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:50:19 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "08:50:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:50:35 [INFO]   Training abgeschlossen in 11.83s (Backend: cuml)\n",
      "08:50:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:50:51 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "08:50:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:51:07 [INFO]   Training abgeschlossen in 12.01s (Backend: cuml)\n",
      "08:51:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:51:23 [INFO]   Training abgeschlossen in 12.10s (Backend: cuml)\n",
      "08:51:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:51:39 [INFO]   Training abgeschlossen in 12.17s (Backend: cuml)\n",
      "08:51:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:51:55 [INFO]   Training abgeschlossen in 12.33s (Backend: cuml)\n",
      "08:51:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:52:12 [INFO]   Training abgeschlossen in 12.71s (Backend: cuml)\n",
      "08:52:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:52:29 [INFO]   Training abgeschlossen in 12.65s (Backend: cuml)\n",
      "08:52:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:52:45 [INFO]   Training abgeschlossen in 12.60s (Backend: cuml)\n",
      "08:52:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:53:02 [INFO]   Training abgeschlossen in 12.79s (Backend: cuml)\n",
      "08:53:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:53:20 [INFO]   Training abgeschlossen in 13.21s (Backend: cuml)\n",
      "08:53:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:53:37 [INFO]   Training abgeschlossen in 13.05s (Backend: cuml)\n",
      "08:53:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:53:54 [INFO]   Training abgeschlossen in 13.24s (Backend: cuml)\n",
      "08:53:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:54:12 [INFO]   Training abgeschlossen in 13.61s (Backend: cuml)\n",
      "08:54:16 [INFO]     48,000 labeled → Accuracy: 0.8808 (Train: 13.6s, Query: 0.00s) | GPU: 2.7/8.0 GB\n",
      "08:54:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:54:30 [INFO]   Training abgeschlossen in 13.63s (Backend: cuml)\n",
      "08:54:33 [INFO]     Final: 48,000 labeled → Accuracy: 0.8802, F1: 0.8795\n",
      "08:54:33 [INFO]   Run 2/5\n",
      "08:54:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:54:38 [INFO]   Training abgeschlossen in 4.65s (Backend: cuml)\n",
      "08:54:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:54:46 [INFO]   Training abgeschlossen in 4.62s (Backend: cuml)\n",
      "08:54:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:54:53 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "08:54:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:55:00 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "08:55:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:55:08 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "08:55:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:55:15 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "08:55:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:55:23 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "08:55:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:55:31 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "08:55:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:55:39 [INFO]   Training abgeschlossen in 5.40s (Backend: cuml)\n",
      "08:55:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:55:47 [INFO]   Training abgeschlossen in 5.37s (Backend: cuml)\n",
      "08:55:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:55:56 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "08:55:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:56:04 [INFO]   Training abgeschlossen in 5.71s (Backend: cuml)\n",
      "08:56:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:56:14 [INFO]   Training abgeschlossen in 6.15s (Backend: cuml)\n",
      "08:56:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:56:23 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "08:56:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:56:32 [INFO]   Training abgeschlossen in 6.10s (Backend: cuml)\n",
      "08:56:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:56:41 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "08:56:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:56:50 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "08:56:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:57:00 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "08:57:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:57:09 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "08:57:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:57:19 [INFO]   Training abgeschlossen in 6.67s (Backend: cuml)\n",
      "08:57:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:57:28 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "08:57:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:57:38 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "08:57:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:57:48 [INFO]   Training abgeschlossen in 6.90s (Backend: cuml)\n",
      "08:57:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:57:58 [INFO]   Training abgeschlossen in 6.57s (Backend: cuml)\n",
      "08:58:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:58:07 [INFO]   Training abgeschlossen in 6.77s (Backend: cuml)\n",
      "08:58:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:58:18 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "08:58:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:58:28 [INFO]   Training abgeschlossen in 7.15s (Backend: cuml)\n",
      "08:58:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:58:38 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "08:58:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:58:49 [INFO]   Training abgeschlossen in 7.17s (Backend: cuml)\n",
      "08:58:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:58:59 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "08:59:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:59:10 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "08:59:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:59:20 [INFO]   Training abgeschlossen in 7.38s (Backend: cuml)\n",
      "08:59:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:59:31 [INFO]   Training abgeschlossen in 7.57s (Backend: cuml)\n",
      "08:59:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:59:42 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "08:59:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:59:53 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "08:59:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:00:04 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "09:00:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:00:15 [INFO]   Training abgeschlossen in 7.74s (Backend: cuml)\n",
      "09:00:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:00:26 [INFO]   Training abgeschlossen in 8.00s (Backend: cuml)\n",
      "09:00:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:00:38 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "09:00:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:00:50 [INFO]   Training abgeschlossen in 8.08s (Backend: cuml)\n",
      "09:00:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:01:01 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "09:01:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:01:13 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "09:01:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:01:25 [INFO]   Training abgeschlossen in 8.36s (Backend: cuml)\n",
      "09:01:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:01:36 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "09:01:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:01:48 [INFO]   Training abgeschlossen in 8.22s (Backend: cuml)\n",
      "09:01:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:02:00 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "09:02:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:02:11 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "09:02:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:02:23 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "09:02:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:02:36 [INFO]   Training abgeschlossen in 8.89s (Backend: cuml)\n",
      "09:02:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:02:48 [INFO]   Training abgeschlossen in 8.66s (Backend: cuml)\n",
      "09:02:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:03:00 [INFO]   Training abgeschlossen in 8.94s (Backend: cuml)\n",
      "09:03:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:03:13 [INFO]   Training abgeschlossen in 8.93s (Backend: cuml)\n",
      "09:03:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:03:25 [INFO]   Training abgeschlossen in 9.04s (Backend: cuml)\n",
      "09:03:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:03:38 [INFO]   Training abgeschlossen in 9.38s (Backend: cuml)\n",
      "09:03:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:03:51 [INFO]   Training abgeschlossen in 9.08s (Backend: cuml)\n",
      "09:03:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:04:04 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "09:04:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:04:17 [INFO]   Training abgeschlossen in 9.32s (Backend: cuml)\n",
      "09:04:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:04:30 [INFO]   Training abgeschlossen in 9.62s (Backend: cuml)\n",
      "09:04:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:04:43 [INFO]   Training abgeschlossen in 9.76s (Backend: cuml)\n",
      "09:04:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:04:57 [INFO]   Training abgeschlossen in 9.77s (Backend: cuml)\n",
      "09:05:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:05:11 [INFO]   Training abgeschlossen in 9.90s (Backend: cuml)\n",
      "09:05:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:05:24 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "09:05:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:05:38 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "09:05:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:05:53 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "09:05:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:06:06 [INFO]   Training abgeschlossen in 10.24s (Backend: cuml)\n",
      "09:06:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:06:21 [INFO]   Training abgeschlossen in 10.43s (Backend: cuml)\n",
      "09:06:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:06:35 [INFO]   Training abgeschlossen in 10.74s (Backend: cuml)\n",
      "09:06:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:06:50 [INFO]   Training abgeschlossen in 10.64s (Backend: cuml)\n",
      "09:06:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:07:04 [INFO]   Training abgeschlossen in 10.61s (Backend: cuml)\n",
      "09:07:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:07:18 [INFO]   Training abgeschlossen in 10.63s (Backend: cuml)\n",
      "09:07:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:07:33 [INFO]   Training abgeschlossen in 10.86s (Backend: cuml)\n",
      "09:07:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:07:48 [INFO]   Training abgeschlossen in 10.90s (Backend: cuml)\n",
      "09:07:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:08:03 [INFO]   Training abgeschlossen in 10.93s (Backend: cuml)\n",
      "09:08:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:08:18 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "09:08:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:08:33 [INFO]   Training abgeschlossen in 11.28s (Backend: cuml)\n",
      "09:08:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:08:48 [INFO]   Training abgeschlossen in 11.45s (Backend: cuml)\n",
      "09:08:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:09:03 [INFO]   Training abgeschlossen in 11.46s (Backend: cuml)\n",
      "09:09:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:09:19 [INFO]   Training abgeschlossen in 11.47s (Backend: cuml)\n",
      "09:09:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:09:35 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "09:09:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:09:50 [INFO]   Training abgeschlossen in 11.72s (Backend: cuml)\n",
      "09:09:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:10:06 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "09:10:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:10:22 [INFO]   Training abgeschlossen in 11.76s (Backend: cuml)\n",
      "09:10:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:10:38 [INFO]   Training abgeschlossen in 12.13s (Backend: cuml)\n",
      "09:10:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:10:54 [INFO]   Training abgeschlossen in 11.96s (Backend: cuml)\n",
      "09:10:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:11:10 [INFO]   Training abgeschlossen in 12.18s (Backend: cuml)\n",
      "09:11:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:11:26 [INFO]   Training abgeschlossen in 12.15s (Backend: cuml)\n",
      "09:11:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:11:42 [INFO]   Training abgeschlossen in 12.50s (Backend: cuml)\n",
      "09:11:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:11:59 [INFO]   Training abgeschlossen in 12.44s (Backend: cuml)\n",
      "09:12:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:12:15 [INFO]   Training abgeschlossen in 12.44s (Backend: cuml)\n",
      "09:12:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:12:32 [INFO]   Training abgeschlossen in 12.89s (Backend: cuml)\n",
      "09:12:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:12:49 [INFO]   Training abgeschlossen in 12.90s (Backend: cuml)\n",
      "09:12:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:13:06 [INFO]   Training abgeschlossen in 12.85s (Backend: cuml)\n",
      "09:13:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:13:23 [INFO]   Training abgeschlossen in 12.90s (Backend: cuml)\n",
      "09:13:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:13:40 [INFO]   Training abgeschlossen in 13.37s (Backend: cuml)\n",
      "09:13:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:13:57 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "09:14:01 [INFO]     48,000 labeled → Accuracy: 0.8816 (Train: 13.1s, Query: 0.00s) | GPU: 2.7/8.0 GB\n",
      "09:14:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:14:15 [INFO]   Training abgeschlossen in 13.34s (Backend: cuml)\n",
      "09:14:19 [INFO]     Final: 48,000 labeled → Accuracy: 0.8810, F1: 0.8803\n",
      "09:14:19 [INFO]   Run 3/5\n",
      "09:14:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:14:24 [INFO]   Training abgeschlossen in 4.54s (Backend: cuml)\n",
      "09:14:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:14:31 [INFO]   Training abgeschlossen in 4.68s (Backend: cuml)\n",
      "09:14:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:14:38 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "09:14:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:14:46 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "09:14:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:14:53 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "09:14:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:15:01 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "09:15:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:15:09 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "09:15:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:15:17 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "09:15:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:15:25 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "09:15:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:15:33 [INFO]   Training abgeschlossen in 5.51s (Backend: cuml)\n",
      "09:15:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:15:42 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "09:15:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:15:51 [INFO]   Training abgeschlossen in 5.81s (Backend: cuml)\n",
      "09:15:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:15:59 [INFO]   Training abgeschlossen in 5.76s (Backend: cuml)\n",
      "09:16:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:16:08 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "09:16:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:16:18 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "09:16:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:16:27 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "09:16:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:16:36 [INFO]   Training abgeschlossen in 6.40s (Backend: cuml)\n",
      "09:16:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:16:46 [INFO]   Training abgeschlossen in 6.46s (Backend: cuml)\n",
      "09:16:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:16:55 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "09:16:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:17:05 [INFO]   Training abgeschlossen in 6.62s (Backend: cuml)\n",
      "09:17:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:17:14 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "09:17:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:17:24 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "09:17:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:17:33 [INFO]   Training abgeschlossen in 6.57s (Backend: cuml)\n",
      "09:17:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:17:43 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "09:17:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:17:53 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "09:17:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:18:03 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "09:18:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:18:13 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "09:18:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:18:24 [INFO]   Training abgeschlossen in 7.02s (Backend: cuml)\n",
      "09:18:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:18:34 [INFO]   Training abgeschlossen in 7.13s (Backend: cuml)\n",
      "09:18:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:18:45 [INFO]   Training abgeschlossen in 7.28s (Backend: cuml)\n",
      "09:18:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:18:55 [INFO]   Training abgeschlossen in 7.28s (Backend: cuml)\n",
      "09:18:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:19:06 [INFO]   Training abgeschlossen in 7.32s (Backend: cuml)\n",
      "09:19:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:19:16 [INFO]   Training abgeschlossen in 7.38s (Backend: cuml)\n",
      "09:19:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:19:27 [INFO]   Training abgeschlossen in 7.45s (Backend: cuml)\n",
      "09:19:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:19:38 [INFO]   Training abgeschlossen in 7.57s (Backend: cuml)\n",
      "09:19:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:19:49 [INFO]   Training abgeschlossen in 7.74s (Backend: cuml)\n",
      "09:19:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:20:00 [INFO]   Training abgeschlossen in 7.66s (Backend: cuml)\n",
      "09:20:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:20:11 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "09:20:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:20:23 [INFO]   Training abgeschlossen in 7.96s (Backend: cuml)\n",
      "09:20:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:20:34 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "09:20:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:20:46 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "09:20:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:20:57 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "09:21:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:21:09 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "09:21:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:21:21 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "09:21:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:21:32 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "09:21:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:21:44 [INFO]   Training abgeschlossen in 8.28s (Backend: cuml)\n",
      "09:21:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:21:56 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "09:22:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:22:08 [INFO]   Training abgeschlossen in 8.37s (Backend: cuml)\n",
      "09:22:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:22:20 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "09:22:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:22:32 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "09:22:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:22:44 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "09:22:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:22:57 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "09:23:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:23:10 [INFO]   Training abgeschlossen in 9.03s (Backend: cuml)\n",
      "09:23:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:23:23 [INFO]   Training abgeschlossen in 9.22s (Backend: cuml)\n",
      "09:23:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:23:35 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "09:23:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:23:48 [INFO]   Training abgeschlossen in 9.26s (Backend: cuml)\n",
      "09:23:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:24:01 [INFO]   Training abgeschlossen in 9.55s (Backend: cuml)\n",
      "09:24:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:24:14 [INFO]   Training abgeschlossen in 9.38s (Backend: cuml)\n",
      "09:24:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:24:28 [INFO]   Training abgeschlossen in 9.55s (Backend: cuml)\n",
      "09:24:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:24:41 [INFO]   Training abgeschlossen in 9.66s (Backend: cuml)\n",
      "09:24:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:24:55 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "09:24:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:25:09 [INFO]   Training abgeschlossen in 10.12s (Backend: cuml)\n",
      "09:25:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:25:22 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "09:25:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:25:36 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "09:25:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:25:50 [INFO]   Training abgeschlossen in 10.25s (Backend: cuml)\n",
      "09:25:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:26:05 [INFO]   Training abgeschlossen in 10.56s (Backend: cuml)\n",
      "09:26:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:26:19 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "09:26:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:26:33 [INFO]   Training abgeschlossen in 10.54s (Backend: cuml)\n",
      "09:26:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:26:47 [INFO]   Training abgeschlossen in 10.61s (Backend: cuml)\n",
      "09:26:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:27:02 [INFO]   Training abgeschlossen in 10.98s (Backend: cuml)\n",
      "09:27:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:27:17 [INFO]   Training abgeschlossen in 10.71s (Backend: cuml)\n",
      "09:27:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:27:31 [INFO]   Training abgeschlossen in 10.91s (Backend: cuml)\n",
      "09:27:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:27:46 [INFO]   Training abgeschlossen in 10.92s (Backend: cuml)\n",
      "09:27:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:28:01 [INFO]   Training abgeschlossen in 11.35s (Backend: cuml)\n",
      "09:28:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:28:16 [INFO]   Training abgeschlossen in 11.15s (Backend: cuml)\n",
      "09:28:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:28:32 [INFO]   Training abgeschlossen in 11.22s (Backend: cuml)\n",
      "09:28:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:28:47 [INFO]   Training abgeschlossen in 11.44s (Backend: cuml)\n",
      "09:28:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:29:03 [INFO]   Training abgeschlossen in 11.87s (Backend: cuml)\n",
      "09:29:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:29:18 [INFO]   Training abgeschlossen in 11.73s (Backend: cuml)\n",
      "09:29:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:29:34 [INFO]   Training abgeschlossen in 11.69s (Backend: cuml)\n",
      "09:29:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:29:49 [INFO]   Training abgeschlossen in 11.76s (Backend: cuml)\n",
      "09:29:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:30:05 [INFO]   Training abgeschlossen in 12.03s (Backend: cuml)\n",
      "09:30:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:30:21 [INFO]   Training abgeschlossen in 11.95s (Backend: cuml)\n",
      "09:30:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:30:37 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "09:30:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:30:54 [INFO]   Training abgeschlossen in 12.29s (Backend: cuml)\n",
      "09:30:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:31:10 [INFO]   Training abgeschlossen in 12.33s (Backend: cuml)\n",
      "09:31:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:31:27 [INFO]   Training abgeschlossen in 12.41s (Backend: cuml)\n",
      "09:31:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:31:43 [INFO]   Training abgeschlossen in 12.46s (Backend: cuml)\n",
      "09:31:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:32:00 [INFO]   Training abgeschlossen in 12.70s (Backend: cuml)\n",
      "09:32:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:32:16 [INFO]   Training abgeschlossen in 12.74s (Backend: cuml)\n",
      "09:32:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:32:33 [INFO]   Training abgeschlossen in 12.86s (Backend: cuml)\n",
      "09:32:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:32:50 [INFO]   Training abgeschlossen in 12.84s (Backend: cuml)\n",
      "09:32:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:33:07 [INFO]   Training abgeschlossen in 13.01s (Backend: cuml)\n",
      "09:33:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:33:24 [INFO]   Training abgeschlossen in 12.99s (Backend: cuml)\n",
      "09:33:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:33:42 [INFO]   Training abgeschlossen in 13.13s (Backend: cuml)\n",
      "09:33:46 [INFO]     48,000 labeled → Accuracy: 0.8810 (Train: 13.1s, Query: 0.00s) | GPU: 2.7/8.0 GB\n",
      "09:33:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:34:00 [INFO]   Training abgeschlossen in 13.60s (Backend: cuml)\n",
      "09:34:03 [INFO]     Final: 48,000 labeled → Accuracy: 0.8809, F1: 0.8802\n",
      "09:34:04 [INFO]   Run 4/5\n",
      "09:34:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:34:08 [INFO]   Training abgeschlossen in 4.55s (Backend: cuml)\n",
      "09:34:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:34:16 [INFO]   Training abgeschlossen in 4.62s (Backend: cuml)\n",
      "09:34:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:34:23 [INFO]   Training abgeschlossen in 4.65s (Backend: cuml)\n",
      "09:34:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:34:30 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "09:34:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:34:38 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "09:34:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:34:45 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "09:34:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:34:53 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "09:34:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:35:01 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "09:35:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:35:09 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "09:35:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:35:18 [INFO]   Training abgeschlossen in 5.52s (Backend: cuml)\n",
      "09:35:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:35:26 [INFO]   Training abgeschlossen in 5.54s (Backend: cuml)\n",
      "09:35:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:35:35 [INFO]   Training abgeschlossen in 5.86s (Backend: cuml)\n",
      "09:35:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:35:44 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "09:35:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:35:53 [INFO]   Training abgeschlossen in 6.57s (Backend: cuml)\n",
      "09:35:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:36:03 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "09:36:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:36:12 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "09:36:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:36:21 [INFO]   Training abgeschlossen in 6.16s (Backend: cuml)\n",
      "09:36:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:36:30 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "09:36:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:36:40 [INFO]   Training abgeschlossen in 6.48s (Backend: cuml)\n",
      "09:36:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:36:49 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "09:36:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:36:59 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "09:37:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:37:09 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "09:37:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:37:18 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "09:37:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:37:28 [INFO]   Training abgeschlossen in 6.58s (Backend: cuml)\n",
      "09:37:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:37:38 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "09:37:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:37:48 [INFO]   Training abgeschlossen in 6.90s (Backend: cuml)\n",
      "09:37:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:37:58 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "09:38:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:38:09 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "09:38:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:38:19 [INFO]   Training abgeschlossen in 7.12s (Backend: cuml)\n",
      "09:38:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:38:30 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "09:38:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:38:40 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "09:38:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:38:51 [INFO]   Training abgeschlossen in 7.36s (Backend: cuml)\n",
      "09:38:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:39:02 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "09:39:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:39:13 [INFO]   Training abgeschlossen in 7.57s (Backend: cuml)\n",
      "09:39:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:39:24 [INFO]   Training abgeschlossen in 7.60s (Backend: cuml)\n",
      "09:39:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:39:35 [INFO]   Training abgeschlossen in 7.63s (Backend: cuml)\n",
      "09:39:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:39:46 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "09:39:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:39:57 [INFO]   Training abgeschlossen in 7.94s (Backend: cuml)\n",
      "09:40:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:40:09 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "09:40:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:40:20 [INFO]   Training abgeschlossen in 8.22s (Backend: cuml)\n",
      "09:40:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:40:32 [INFO]   Training abgeschlossen in 8.28s (Backend: cuml)\n",
      "09:40:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:40:44 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "09:40:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:40:56 [INFO]   Training abgeschlossen in 8.43s (Backend: cuml)\n",
      "09:40:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:41:07 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "09:41:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:41:20 [INFO]   Training abgeschlossen in 8.47s (Backend: cuml)\n",
      "09:41:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:41:31 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "09:41:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:41:43 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "09:41:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:41:55 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "09:41:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:42:07 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "09:42:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:42:20 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "09:42:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:42:32 [INFO]   Training abgeschlossen in 9.04s (Backend: cuml)\n",
      "09:42:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:42:45 [INFO]   Training abgeschlossen in 8.93s (Backend: cuml)\n",
      "09:42:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:42:58 [INFO]   Training abgeschlossen in 9.12s (Backend: cuml)\n",
      "09:43:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:43:11 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "09:43:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:43:24 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "09:43:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:43:36 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "09:43:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:43:49 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "09:43:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:44:03 [INFO]   Training abgeschlossen in 9.55s (Backend: cuml)\n",
      "09:44:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:44:16 [INFO]   Training abgeschlossen in 9.78s (Backend: cuml)\n",
      "09:44:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:44:30 [INFO]   Training abgeschlossen in 9.97s (Backend: cuml)\n",
      "09:44:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:44:43 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "09:44:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:44:57 [INFO]   Training abgeschlossen in 10.00s (Backend: cuml)\n",
      "09:45:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:45:11 [INFO]   Training abgeschlossen in 10.12s (Backend: cuml)\n",
      "09:45:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:45:25 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "09:45:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:45:39 [INFO]   Training abgeschlossen in 10.23s (Backend: cuml)\n",
      "09:45:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:45:53 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "09:45:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:46:07 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "09:46:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:46:22 [INFO]   Training abgeschlossen in 10.67s (Backend: cuml)\n",
      "09:46:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:46:36 [INFO]   Training abgeschlossen in 10.74s (Backend: cuml)\n",
      "09:46:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:46:51 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "09:46:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:47:06 [INFO]   Training abgeschlossen in 10.86s (Backend: cuml)\n",
      "09:47:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:47:20 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "09:47:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:47:35 [INFO]   Training abgeschlossen in 11.07s (Backend: cuml)\n",
      "09:47:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:47:50 [INFO]   Training abgeschlossen in 11.09s (Backend: cuml)\n",
      "09:47:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:48:05 [INFO]   Training abgeschlossen in 11.18s (Backend: cuml)\n",
      "09:48:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:48:21 [INFO]   Training abgeschlossen in 11.41s (Backend: cuml)\n",
      "09:48:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:48:36 [INFO]   Training abgeschlossen in 11.48s (Backend: cuml)\n",
      "09:48:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:48:51 [INFO]   Training abgeschlossen in 11.52s (Backend: cuml)\n",
      "09:48:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:49:07 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "09:49:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:49:23 [INFO]   Training abgeschlossen in 11.72s (Backend: cuml)\n",
      "09:49:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:49:39 [INFO]   Training abgeschlossen in 11.89s (Backend: cuml)\n",
      "09:49:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:49:55 [INFO]   Training abgeschlossen in 11.79s (Backend: cuml)\n",
      "09:49:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:50:10 [INFO]   Training abgeschlossen in 12.00s (Backend: cuml)\n",
      "09:50:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:50:27 [INFO]   Training abgeschlossen in 12.34s (Backend: cuml)\n",
      "09:50:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:50:43 [INFO]   Training abgeschlossen in 12.08s (Backend: cuml)\n",
      "09:50:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:50:59 [INFO]   Training abgeschlossen in 12.18s (Backend: cuml)\n",
      "09:51:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:51:15 [INFO]   Training abgeschlossen in 12.42s (Backend: cuml)\n",
      "09:51:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:51:32 [INFO]   Training abgeschlossen in 12.73s (Backend: cuml)\n",
      "09:51:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:51:49 [INFO]   Training abgeschlossen in 12.59s (Backend: cuml)\n",
      "09:51:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:52:06 [INFO]   Training abgeschlossen in 12.61s (Backend: cuml)\n",
      "09:52:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:52:23 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "09:52:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:52:40 [INFO]   Training abgeschlossen in 13.09s (Backend: cuml)\n",
      "09:52:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:52:57 [INFO]   Training abgeschlossen in 12.99s (Backend: cuml)\n",
      "09:53:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:53:14 [INFO]   Training abgeschlossen in 13.14s (Backend: cuml)\n",
      "09:53:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:53:32 [INFO]   Training abgeschlossen in 13.28s (Backend: cuml)\n",
      "09:53:35 [INFO]     48,000 labeled → Accuracy: 0.8824 (Train: 13.3s, Query: 0.00s) | GPU: 2.7/8.0 GB\n",
      "09:53:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:53:49 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "09:53:53 [INFO]     Final: 48,000 labeled → Accuracy: 0.8826, F1: 0.8819\n",
      "09:53:53 [INFO]   Run 5/5\n",
      "09:53:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:53:58 [INFO]   Training abgeschlossen in 4.55s (Backend: cuml)\n",
      "09:54:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:54:05 [INFO]   Training abgeschlossen in 4.51s (Backend: cuml)\n",
      "09:54:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:54:12 [INFO]   Training abgeschlossen in 4.68s (Backend: cuml)\n",
      "09:54:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:54:20 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "09:54:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:54:27 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "09:54:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "09:54:35 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "09:54:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:54:43 [INFO]   Training abgeschlossen in 5.02s (Backend: cuml)\n",
      "09:54:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:54:51 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "09:54:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:54:59 [INFO]   Training abgeschlossen in 5.41s (Backend: cuml)\n",
      "09:55:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:55:07 [INFO]   Training abgeschlossen in 5.39s (Backend: cuml)\n",
      "09:55:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:55:16 [INFO]   Training abgeschlossen in 5.51s (Backend: cuml)\n",
      "09:55:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:55:24 [INFO]   Training abgeschlossen in 5.98s (Backend: cuml)\n",
      "09:55:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:55:33 [INFO]   Training abgeschlossen in 5.91s (Backend: cuml)\n",
      "09:55:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:55:42 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "09:55:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:55:52 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "09:55:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:56:01 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "09:56:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "09:56:10 [INFO]   Training abgeschlossen in 6.15s (Backend: cuml)\n",
      "09:56:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:56:20 [INFO]   Training abgeschlossen in 6.19s (Backend: cuml)\n",
      "09:56:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:56:29 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "09:56:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:56:39 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "09:56:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:56:48 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "09:56:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:56:58 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "09:57:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:57:08 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "09:57:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:57:17 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "09:57:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:57:27 [INFO]   Training abgeschlossen in 6.77s (Backend: cuml)\n",
      "09:57:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:57:38 [INFO]   Training abgeschlossen in 7.07s (Backend: cuml)\n",
      "09:57:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:57:48 [INFO]   Training abgeschlossen in 7.05s (Backend: cuml)\n",
      "09:57:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:57:58 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "09:58:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:58:08 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "09:58:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:58:19 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "09:58:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:58:30 [INFO]   Training abgeschlossen in 7.32s (Backend: cuml)\n",
      "09:58:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:58:40 [INFO]   Training abgeschlossen in 7.39s (Backend: cuml)\n",
      "09:58:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:58:51 [INFO]   Training abgeschlossen in 7.36s (Backend: cuml)\n",
      "09:58:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:59:02 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "09:59:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:59:13 [INFO]   Training abgeschlossen in 7.58s (Backend: cuml)\n",
      "09:59:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:59:24 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "09:59:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:59:35 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "09:59:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:59:46 [INFO]   Training abgeschlossen in 7.86s (Backend: cuml)\n",
      "09:59:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:59:58 [INFO]   Training abgeschlossen in 7.96s (Backend: cuml)\n",
      "10:00:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:00:09 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "10:00:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:00:21 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "10:00:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:00:32 [INFO]   Training abgeschlossen in 8.29s (Backend: cuml)\n",
      "10:00:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:00:44 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "10:00:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:00:56 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "10:00:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:01:07 [INFO]   Training abgeschlossen in 8.15s (Backend: cuml)\n",
      "10:01:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:01:19 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "10:01:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:01:31 [INFO]   Training abgeschlossen in 8.44s (Backend: cuml)\n",
      "10:01:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:01:43 [INFO]   Training abgeschlossen in 8.60s (Backend: cuml)\n",
      "10:01:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:01:55 [INFO]   Training abgeschlossen in 8.44s (Backend: cuml)\n",
      "10:01:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:02:07 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "10:02:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:02:20 [INFO]   Training abgeschlossen in 8.96s (Backend: cuml)\n",
      "10:02:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:02:32 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "10:02:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:02:45 [INFO]   Training abgeschlossen in 9.29s (Backend: cuml)\n",
      "10:02:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:02:58 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "10:03:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:03:10 [INFO]   Training abgeschlossen in 9.09s (Backend: cuml)\n",
      "10:03:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:03:23 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "10:03:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:03:36 [INFO]   Training abgeschlossen in 9.35s (Backend: cuml)\n",
      "10:03:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:03:49 [INFO]   Training abgeschlossen in 9.51s (Backend: cuml)\n",
      "10:03:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:04:03 [INFO]   Training abgeschlossen in 9.60s (Backend: cuml)\n",
      "10:04:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:04:16 [INFO]   Training abgeschlossen in 9.77s (Backend: cuml)\n",
      "10:04:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:04:30 [INFO]   Training abgeschlossen in 9.76s (Backend: cuml)\n",
      "10:04:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:04:44 [INFO]   Training abgeschlossen in 10.15s (Backend: cuml)\n",
      "10:04:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:04:57 [INFO]   Training abgeschlossen in 10.06s (Backend: cuml)\n",
      "10:05:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:05:11 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "10:05:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:05:25 [INFO]   Training abgeschlossen in 10.24s (Backend: cuml)\n",
      "10:05:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:05:39 [INFO]   Training abgeschlossen in 10.43s (Backend: cuml)\n",
      "10:05:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:05:54 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "10:05:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:06:08 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "10:06:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:06:22 [INFO]   Training abgeschlossen in 10.58s (Backend: cuml)\n",
      "10:06:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:06:37 [INFO]   Training abgeschlossen in 10.80s (Backend: cuml)\n",
      "10:06:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:06:52 [INFO]   Training abgeschlossen in 10.78s (Backend: cuml)\n",
      "10:06:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:07:06 [INFO]   Training abgeschlossen in 10.86s (Backend: cuml)\n",
      "10:07:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:07:21 [INFO]   Training abgeschlossen in 11.05s (Backend: cuml)\n",
      "10:07:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:07:36 [INFO]   Training abgeschlossen in 11.03s (Backend: cuml)\n",
      "10:07:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:07:51 [INFO]   Training abgeschlossen in 11.14s (Backend: cuml)\n",
      "10:07:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:08:06 [INFO]   Training abgeschlossen in 11.25s (Backend: cuml)\n",
      "10:08:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:08:21 [INFO]   Training abgeschlossen in 11.35s (Backend: cuml)\n",
      "10:08:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:08:36 [INFO]   Training abgeschlossen in 11.40s (Backend: cuml)\n",
      "10:08:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:08:52 [INFO]   Training abgeschlossen in 11.52s (Backend: cuml)\n",
      "10:08:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:09:07 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "10:09:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:09:23 [INFO]   Training abgeschlossen in 11.68s (Backend: cuml)\n",
      "10:09:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:09:39 [INFO]   Training abgeschlossen in 11.83s (Backend: cuml)\n",
      "10:09:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:09:55 [INFO]   Training abgeschlossen in 11.95s (Backend: cuml)\n",
      "10:09:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:10:11 [INFO]   Training abgeschlossen in 12.21s (Backend: cuml)\n",
      "10:10:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:10:27 [INFO]   Training abgeschlossen in 12.28s (Backend: cuml)\n",
      "10:10:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:10:44 [INFO]   Training abgeschlossen in 12.52s (Backend: cuml)\n",
      "10:10:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:11:00 [INFO]   Training abgeschlossen in 12.60s (Backend: cuml)\n",
      "10:11:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:11:17 [INFO]   Training abgeschlossen in 12.58s (Backend: cuml)\n",
      "10:11:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:11:34 [INFO]   Training abgeschlossen in 13.13s (Backend: cuml)\n",
      "10:11:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:11:51 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "10:11:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:12:08 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "10:12:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:12:26 [INFO]   Training abgeschlossen in 13.16s (Backend: cuml)\n",
      "10:12:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:12:43 [INFO]   Training abgeschlossen in 13.08s (Backend: cuml)\n",
      "10:12:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:13:00 [INFO]   Training abgeschlossen in 13.14s (Backend: cuml)\n",
      "10:13:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:13:18 [INFO]   Training abgeschlossen in 13.14s (Backend: cuml)\n",
      "10:13:21 [INFO]     48,000 labeled → Accuracy: 0.8802 (Train: 13.2s, Query: 0.00s) | GPU: 2.7/8.0 GB\n",
      "10:13:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:13:35 [INFO]   Training abgeschlossen in 13.31s (Backend: cuml)\n",
      "10:13:39 [INFO]     Final: 48,000 labeled → Accuracy: 0.8801, F1: 0.8794\n",
      "10:13:39 [INFO] \n",
      "GPU-SVM + Random Sampling - Budget: 100% (60,000 Samples)\n",
      "10:13:39 [INFO]   Run 1/5\n",
      "10:13:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:13:44 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "10:13:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:13:51 [INFO]   Training abgeschlossen in 4.63s (Backend: cuml)\n",
      "10:13:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:13:58 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "10:14:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:14:06 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "10:14:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:14:13 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "10:14:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:14:21 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "10:14:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:14:28 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "10:14:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:14:36 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "10:14:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:14:44 [INFO]   Training abgeschlossen in 5.46s (Backend: cuml)\n",
      "10:14:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:14:53 [INFO]   Training abgeschlossen in 5.44s (Backend: cuml)\n",
      "10:14:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:15:02 [INFO]   Training abgeschlossen in 5.97s (Backend: cuml)\n",
      "10:15:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:15:11 [INFO]   Training abgeschlossen in 5.83s (Backend: cuml)\n",
      "10:15:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:15:19 [INFO]   Training abgeschlossen in 5.98s (Backend: cuml)\n",
      "10:15:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:15:29 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "10:15:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:15:38 [INFO]   Training abgeschlossen in 6.08s (Backend: cuml)\n",
      "10:15:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:15:47 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "10:15:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:15:56 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "10:15:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:16:05 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "10:16:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:16:15 [INFO]   Training abgeschlossen in 6.28s (Backend: cuml)\n",
      "10:16:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:16:24 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "10:16:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:16:34 [INFO]   Training abgeschlossen in 6.39s (Backend: cuml)\n",
      "10:16:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:16:43 [INFO]   Training abgeschlossen in 6.42s (Backend: cuml)\n",
      "10:16:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:16:53 [INFO]   Training abgeschlossen in 6.91s (Backend: cuml)\n",
      "10:16:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:17:03 [INFO]   Training abgeschlossen in 6.54s (Backend: cuml)\n",
      "10:17:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:17:13 [INFO]   Training abgeschlossen in 6.59s (Backend: cuml)\n",
      "10:17:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:17:23 [INFO]   Training abgeschlossen in 6.92s (Backend: cuml)\n",
      "10:17:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:17:33 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "10:17:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:17:44 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "10:17:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:17:54 [INFO]   Training abgeschlossen in 7.17s (Backend: cuml)\n",
      "10:17:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:18:05 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "10:18:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:18:15 [INFO]   Training abgeschlossen in 7.32s (Backend: cuml)\n",
      "10:18:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:18:26 [INFO]   Training abgeschlossen in 7.45s (Backend: cuml)\n",
      "10:18:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:18:37 [INFO]   Training abgeschlossen in 7.50s (Backend: cuml)\n",
      "10:18:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:18:48 [INFO]   Training abgeschlossen in 7.47s (Backend: cuml)\n",
      "10:18:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:18:59 [INFO]   Training abgeschlossen in 7.63s (Backend: cuml)\n",
      "10:19:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:19:10 [INFO]   Training abgeschlossen in 7.61s (Backend: cuml)\n",
      "10:19:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:19:21 [INFO]   Training abgeschlossen in 7.73s (Backend: cuml)\n",
      "10:19:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:19:32 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "10:19:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:19:43 [INFO]   Training abgeschlossen in 7.98s (Backend: cuml)\n",
      "10:19:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:19:55 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "10:19:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:20:07 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "10:20:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:20:18 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "10:20:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:20:30 [INFO]   Training abgeschlossen in 8.37s (Backend: cuml)\n",
      "10:20:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:20:41 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "10:20:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:20:53 [INFO]   Training abgeschlossen in 8.13s (Backend: cuml)\n",
      "10:20:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:21:05 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "10:21:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:21:17 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "10:21:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:21:28 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "10:21:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:21:40 [INFO]   Training abgeschlossen in 8.40s (Backend: cuml)\n",
      "10:21:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:21:52 [INFO]   Training abgeschlossen in 8.62s (Backend: cuml)\n",
      "10:21:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:22:05 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "10:22:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:22:17 [INFO]   Training abgeschlossen in 8.94s (Backend: cuml)\n",
      "10:22:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:22:30 [INFO]   Training abgeschlossen in 9.06s (Backend: cuml)\n",
      "10:22:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:22:42 [INFO]   Training abgeschlossen in 9.05s (Backend: cuml)\n",
      "10:22:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:22:55 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "10:22:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:23:08 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "10:23:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:23:21 [INFO]   Training abgeschlossen in 9.37s (Backend: cuml)\n",
      "10:23:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:23:34 [INFO]   Training abgeschlossen in 9.36s (Backend: cuml)\n",
      "10:23:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:23:47 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "10:23:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:24:00 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "10:24:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:24:14 [INFO]   Training abgeschlossen in 9.73s (Backend: cuml)\n",
      "10:24:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:24:28 [INFO]   Training abgeschlossen in 10.00s (Backend: cuml)\n",
      "10:24:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:24:41 [INFO]   Training abgeschlossen in 10.04s (Backend: cuml)\n",
      "10:24:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:24:55 [INFO]   Training abgeschlossen in 10.24s (Backend: cuml)\n",
      "10:24:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:25:09 [INFO]   Training abgeschlossen in 10.17s (Backend: cuml)\n",
      "10:25:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:25:23 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "10:25:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:25:37 [INFO]   Training abgeschlossen in 10.44s (Backend: cuml)\n",
      "10:25:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:25:52 [INFO]   Training abgeschlossen in 10.69s (Backend: cuml)\n",
      "10:25:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:26:06 [INFO]   Training abgeschlossen in 10.63s (Backend: cuml)\n",
      "10:26:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:26:21 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "10:26:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:26:35 [INFO]   Training abgeschlossen in 10.66s (Backend: cuml)\n",
      "10:26:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:26:50 [INFO]   Training abgeschlossen in 10.88s (Backend: cuml)\n",
      "10:26:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:27:05 [INFO]   Training abgeschlossen in 10.98s (Backend: cuml)\n",
      "10:27:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:27:19 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "10:27:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:27:34 [INFO]   Training abgeschlossen in 11.17s (Backend: cuml)\n",
      "10:27:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:27:49 [INFO]   Training abgeschlossen in 11.41s (Backend: cuml)\n",
      "10:27:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:28:05 [INFO]   Training abgeschlossen in 11.45s (Backend: cuml)\n",
      "10:28:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:28:20 [INFO]   Training abgeschlossen in 11.74s (Backend: cuml)\n",
      "10:28:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:28:36 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "10:28:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:28:52 [INFO]   Training abgeschlossen in 11.98s (Backend: cuml)\n",
      "10:28:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:29:08 [INFO]   Training abgeschlossen in 11.86s (Backend: cuml)\n",
      "10:29:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:29:24 [INFO]   Training abgeschlossen in 11.93s (Backend: cuml)\n",
      "10:29:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:29:40 [INFO]   Training abgeschlossen in 11.99s (Backend: cuml)\n",
      "10:29:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:29:56 [INFO]   Training abgeschlossen in 12.09s (Backend: cuml)\n",
      "10:30:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:30:12 [INFO]   Training abgeschlossen in 12.05s (Backend: cuml)\n",
      "10:30:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:30:28 [INFO]   Training abgeschlossen in 12.20s (Backend: cuml)\n",
      "10:30:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:30:45 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "10:30:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:31:01 [INFO]   Training abgeschlossen in 12.71s (Backend: cuml)\n",
      "10:31:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:31:18 [INFO]   Training abgeschlossen in 12.61s (Backend: cuml)\n",
      "10:31:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:31:35 [INFO]   Training abgeschlossen in 12.71s (Backend: cuml)\n",
      "10:31:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:31:52 [INFO]   Training abgeschlossen in 12.92s (Backend: cuml)\n",
      "10:31:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:32:09 [INFO]   Training abgeschlossen in 13.14s (Backend: cuml)\n",
      "10:32:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:32:26 [INFO]   Training abgeschlossen in 12.98s (Backend: cuml)\n",
      "10:32:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:32:43 [INFO]   Training abgeschlossen in 13.08s (Backend: cuml)\n",
      "10:32:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:33:01 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "10:33:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:33:19 [INFO]   Training abgeschlossen in 13.45s (Backend: cuml)\n",
      "10:33:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:33:36 [INFO]   Training abgeschlossen in 13.45s (Backend: cuml)\n",
      "10:33:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:33:54 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "10:33:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:34:13 [INFO]   Training abgeschlossen in 13.98s (Backend: cuml)\n",
      "10:34:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:34:42 [INFO]   Training abgeschlossen in 25.46s (Backend: cuml)\n",
      "10:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:35:14 [INFO]   Training abgeschlossen in 27.85s (Backend: cuml)\n",
      "10:35:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:35:47 [INFO]   Training abgeschlossen in 28.45s (Backend: cuml)\n",
      "10:35:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:36:17 [INFO]   Training abgeschlossen in 25.78s (Backend: cuml)\n",
      "10:36:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:36:49 [INFO]   Training abgeschlossen in 27.38s (Backend: cuml)\n",
      "10:36:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:37:22 [INFO]   Training abgeschlossen in 29.55s (Backend: cuml)\n",
      "10:37:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:37:54 [INFO]   Training abgeschlossen in 27.93s (Backend: cuml)\n",
      "10:37:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:38:26 [INFO]   Training abgeschlossen in 26.88s (Backend: cuml)\n",
      "10:38:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:38:57 [INFO]   Training abgeschlossen in 27.68s (Backend: cuml)\n",
      "10:39:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:39:31 [INFO]   Training abgeschlossen in 29.03s (Backend: cuml)\n",
      "10:39:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:40:04 [INFO]   Training abgeschlossen in 29.18s (Backend: cuml)\n",
      "10:40:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:40:35 [INFO]   Training abgeschlossen in 26.47s (Backend: cuml)\n",
      "10:40:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:41:07 [INFO]   Training abgeschlossen in 27.52s (Backend: cuml)\n",
      "10:41:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:41:41 [INFO]   Training abgeschlossen in 30.11s (Backend: cuml)\n",
      "10:41:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:42:14 [INFO]   Training abgeschlossen in 27.83s (Backend: cuml)\n",
      "10:42:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:42:45 [INFO]   Training abgeschlossen in 27.26s (Backend: cuml)\n",
      "10:42:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:43:16 [INFO]   Training abgeschlossen in 26.22s (Backend: cuml)\n",
      "10:43:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:43:50 [INFO]   Training abgeschlossen in 29.83s (Backend: cuml)\n",
      "10:43:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:44:23 [INFO]   Training abgeschlossen in 28.91s (Backend: cuml)\n",
      "10:44:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:44:56 [INFO]   Training abgeschlossen in 28.16s (Backend: cuml)\n",
      "10:45:00 [INFO]     60,000 labeled → Accuracy: 0.8829 (Train: 28.2s, Query: 0.00s) | GPU: 2.8/8.0 GB\n",
      "10:45:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:45:26 [INFO]   Training abgeschlossen in 25.71s (Backend: cuml)\n",
      "10:45:30 [INFO]     Final: 60,000 labeled → Accuracy: 0.8836, F1: 0.8829\n",
      "10:45:30 [INFO]   Run 2/5\n",
      "10:45:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:45:35 [INFO]   Training abgeschlossen in 4.57s (Backend: cuml)\n",
      "10:45:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:45:42 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "10:45:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:45:50 [INFO]   Training abgeschlossen in 4.67s (Backend: cuml)\n",
      "10:45:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:45:57 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "10:46:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:46:05 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "10:46:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:46:12 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "10:46:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:46:20 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "10:46:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:46:28 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "10:46:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:46:36 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "10:46:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:46:44 [INFO]   Training abgeschlossen in 5.37s (Backend: cuml)\n",
      "10:46:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:46:53 [INFO]   Training abgeschlossen in 5.77s (Backend: cuml)\n",
      "10:46:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:47:02 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "10:47:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:47:10 [INFO]   Training abgeschlossen in 5.88s (Backend: cuml)\n",
      "10:47:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:47:19 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "10:47:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:47:28 [INFO]   Training abgeschlossen in 6.01s (Backend: cuml)\n",
      "10:47:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:47:37 [INFO]   Training abgeschlossen in 6.11s (Backend: cuml)\n",
      "10:47:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:47:46 [INFO]   Training abgeschlossen in 6.10s (Backend: cuml)\n",
      "10:47:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:47:56 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "10:47:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:48:05 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "10:48:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:48:14 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "10:48:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:48:24 [INFO]   Training abgeschlossen in 6.39s (Backend: cuml)\n",
      "10:48:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:48:33 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "10:48:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:48:43 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "10:48:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:48:53 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "10:48:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:49:03 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "10:49:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:49:13 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "10:49:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:49:23 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "10:49:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:49:34 [INFO]   Training abgeschlossen in 7.12s (Backend: cuml)\n",
      "10:49:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:49:44 [INFO]   Training abgeschlossen in 7.16s (Backend: cuml)\n",
      "10:49:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:49:55 [INFO]   Training abgeschlossen in 7.37s (Backend: cuml)\n",
      "10:49:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:50:05 [INFO]   Training abgeschlossen in 7.33s (Backend: cuml)\n",
      "10:50:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:50:16 [INFO]   Training abgeschlossen in 7.43s (Backend: cuml)\n",
      "10:50:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:50:27 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "10:50:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:50:38 [INFO]   Training abgeschlossen in 7.48s (Backend: cuml)\n",
      "10:50:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:50:49 [INFO]   Training abgeschlossen in 7.61s (Backend: cuml)\n",
      "10:50:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:51:00 [INFO]   Training abgeschlossen in 7.65s (Backend: cuml)\n",
      "10:51:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:51:11 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "10:51:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:51:22 [INFO]   Training abgeschlossen in 7.98s (Backend: cuml)\n",
      "10:51:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:51:33 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "10:51:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:51:45 [INFO]   Training abgeschlossen in 8.00s (Backend: cuml)\n",
      "10:51:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:51:56 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "10:52:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:52:08 [INFO]   Training abgeschlossen in 8.13s (Backend: cuml)\n",
      "10:52:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:52:20 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "10:52:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:52:31 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "10:52:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:52:43 [INFO]   Training abgeschlossen in 8.06s (Backend: cuml)\n",
      "10:52:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:52:54 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "10:52:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:53:06 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "10:53:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:53:18 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "10:53:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:53:30 [INFO]   Training abgeschlossen in 8.55s (Backend: cuml)\n",
      "10:53:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:53:42 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "10:53:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:53:54 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "10:53:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:54:07 [INFO]   Training abgeschlossen in 8.85s (Backend: cuml)\n",
      "10:54:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:54:20 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "10:54:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:54:32 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "10:54:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:54:45 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "10:54:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:54:58 [INFO]   Training abgeschlossen in 9.33s (Backend: cuml)\n",
      "10:55:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:55:11 [INFO]   Training abgeschlossen in 9.29s (Backend: cuml)\n",
      "10:55:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:55:24 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "10:55:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:55:37 [INFO]   Training abgeschlossen in 9.47s (Backend: cuml)\n",
      "10:55:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:55:50 [INFO]   Training abgeschlossen in 9.70s (Backend: cuml)\n",
      "10:55:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:56:04 [INFO]   Training abgeschlossen in 9.74s (Backend: cuml)\n",
      "10:56:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:56:17 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "10:56:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:56:31 [INFO]   Training abgeschlossen in 10.19s (Backend: cuml)\n",
      "10:56:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:56:45 [INFO]   Training abgeschlossen in 10.26s (Backend: cuml)\n",
      "10:56:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:56:59 [INFO]   Training abgeschlossen in 10.19s (Backend: cuml)\n",
      "10:57:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:57:13 [INFO]   Training abgeschlossen in 10.46s (Backend: cuml)\n",
      "10:57:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:57:27 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "10:57:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:57:42 [INFO]   Training abgeschlossen in 10.48s (Backend: cuml)\n",
      "10:57:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:57:56 [INFO]   Training abgeschlossen in 10.57s (Backend: cuml)\n",
      "10:57:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:58:10 [INFO]   Training abgeschlossen in 10.57s (Backend: cuml)\n",
      "10:58:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:58:25 [INFO]   Training abgeschlossen in 10.82s (Backend: cuml)\n",
      "10:58:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:58:39 [INFO]   Training abgeschlossen in 10.74s (Backend: cuml)\n",
      "10:58:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:58:54 [INFO]   Training abgeschlossen in 10.83s (Backend: cuml)\n",
      "10:58:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:59:08 [INFO]   Training abgeschlossen in 10.91s (Backend: cuml)\n",
      "10:59:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:59:24 [INFO]   Training abgeschlossen in 11.28s (Backend: cuml)\n",
      "10:59:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:59:39 [INFO]   Training abgeschlossen in 11.18s (Backend: cuml)\n",
      "10:59:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "10:59:54 [INFO]   Training abgeschlossen in 11.32s (Backend: cuml)\n",
      "10:59:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:00:09 [INFO]   Training abgeschlossen in 11.75s (Backend: cuml)\n",
      "11:00:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:00:25 [INFO]   Training abgeschlossen in 11.65s (Backend: cuml)\n",
      "11:00:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:00:40 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "11:00:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:00:56 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "11:01:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:01:11 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "11:01:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:01:27 [INFO]   Training abgeschlossen in 12.00s (Backend: cuml)\n",
      "11:01:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:01:43 [INFO]   Training abgeschlossen in 12.03s (Backend: cuml)\n",
      "11:01:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:01:59 [INFO]   Training abgeschlossen in 12.16s (Backend: cuml)\n",
      "11:02:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:02:16 [INFO]   Training abgeschlossen in 12.30s (Backend: cuml)\n",
      "11:02:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:02:32 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "11:02:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:02:49 [INFO]   Training abgeschlossen in 12.83s (Backend: cuml)\n",
      "11:02:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:03:06 [INFO]   Training abgeschlossen in 12.70s (Backend: cuml)\n",
      "11:03:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:03:23 [INFO]   Training abgeschlossen in 12.83s (Backend: cuml)\n",
      "11:03:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:03:40 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "11:03:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:03:58 [INFO]   Training abgeschlossen in 13.14s (Backend: cuml)\n",
      "11:04:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:04:15 [INFO]   Training abgeschlossen in 13.04s (Backend: cuml)\n",
      "11:04:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:04:32 [INFO]   Training abgeschlossen in 13.40s (Backend: cuml)\n",
      "11:04:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:04:50 [INFO]   Training abgeschlossen in 13.53s (Backend: cuml)\n",
      "11:04:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:05:08 [INFO]   Training abgeschlossen in 13.63s (Backend: cuml)\n",
      "11:05:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:05:26 [INFO]   Training abgeschlossen in 13.62s (Backend: cuml)\n",
      "11:05:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:05:44 [INFO]   Training abgeschlossen in 14.07s (Backend: cuml)\n",
      "11:05:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:06:02 [INFO]   Training abgeschlossen in 13.74s (Backend: cuml)\n",
      "11:06:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:06:31 [INFO]   Training abgeschlossen in 24.51s (Backend: cuml)\n",
      "11:06:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:07:02 [INFO]   Training abgeschlossen in 26.79s (Backend: cuml)\n",
      "11:07:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:07:33 [INFO]   Training abgeschlossen in 27.56s (Backend: cuml)\n",
      "11:07:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:08:02 [INFO]   Training abgeschlossen in 24.94s (Backend: cuml)\n",
      "11:08:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:08:33 [INFO]   Training abgeschlossen in 26.07s (Backend: cuml)\n",
      "11:08:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:09:04 [INFO]   Training abgeschlossen in 26.65s (Backend: cuml)\n",
      "11:09:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:09:34 [INFO]   Training abgeschlossen in 26.50s (Backend: cuml)\n",
      "11:09:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:10:06 [INFO]   Training abgeschlossen in 27.03s (Backend: cuml)\n",
      "11:10:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:10:37 [INFO]   Training abgeschlossen in 26.78s (Backend: cuml)\n",
      "11:10:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:11:08 [INFO]   Training abgeschlossen in 26.92s (Backend: cuml)\n",
      "11:11:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:11:40 [INFO]   Training abgeschlossen in 27.96s (Backend: cuml)\n",
      "11:11:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:12:14 [INFO]   Training abgeschlossen in 29.49s (Backend: cuml)\n",
      "11:12:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:12:45 [INFO]   Training abgeschlossen in 26.97s (Backend: cuml)\n",
      "11:12:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:13:18 [INFO]   Training abgeschlossen in 28.37s (Backend: cuml)\n",
      "11:13:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:13:49 [INFO]   Training abgeschlossen in 27.40s (Backend: cuml)\n",
      "11:13:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:14:22 [INFO]   Training abgeschlossen in 28.38s (Backend: cuml)\n",
      "11:14:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:14:56 [INFO]   Training abgeschlossen in 29.13s (Backend: cuml)\n",
      "11:15:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:15:28 [INFO]   Training abgeschlossen in 27.81s (Backend: cuml)\n",
      "11:15:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:16:02 [INFO]   Training abgeschlossen in 29.17s (Backend: cuml)\n",
      "11:16:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:16:34 [INFO]   Training abgeschlossen in 27.79s (Backend: cuml)\n",
      "11:16:38 [INFO]     60,000 labeled → Accuracy: 0.8839 (Train: 27.8s, Query: 0.00s) | GPU: 2.8/8.0 GB\n",
      "11:16:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:17:07 [INFO]   Training abgeschlossen in 28.48s (Backend: cuml)\n",
      "11:17:11 [INFO]     Final: 60,000 labeled → Accuracy: 0.8841, F1: 0.8833\n",
      "11:17:11 [INFO]   Run 3/5\n",
      "11:17:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:17:16 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "11:17:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:17:23 [INFO]   Training abgeschlossen in 4.61s (Backend: cuml)\n",
      "11:17:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:17:31 [INFO]   Training abgeschlossen in 4.61s (Backend: cuml)\n",
      "11:17:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:17:38 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "11:17:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:17:46 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "11:17:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:17:54 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "11:17:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:18:01 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "11:18:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:18:09 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "11:18:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:18:17 [INFO]   Training abgeschlossen in 5.37s (Backend: cuml)\n",
      "11:18:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:18:26 [INFO]   Training abgeschlossen in 5.44s (Backend: cuml)\n",
      "11:18:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:18:34 [INFO]   Training abgeschlossen in 5.75s (Backend: cuml)\n",
      "11:18:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:18:43 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "11:18:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:18:51 [INFO]   Training abgeschlossen in 5.75s (Backend: cuml)\n",
      "11:18:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:19:00 [INFO]   Training abgeschlossen in 5.90s (Backend: cuml)\n",
      "11:19:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:19:09 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "11:19:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:19:18 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "11:19:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:19:28 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "11:19:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:19:37 [INFO]   Training abgeschlossen in 6.48s (Backend: cuml)\n",
      "11:19:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:19:46 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "11:19:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:19:56 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "11:19:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:20:05 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "11:20:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:20:14 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "11:20:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:20:24 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "11:20:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:20:34 [INFO]   Training abgeschlossen in 6.62s (Backend: cuml)\n",
      "11:20:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:20:44 [INFO]   Training abgeschlossen in 6.77s (Backend: cuml)\n",
      "11:20:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:20:54 [INFO]   Training abgeschlossen in 6.80s (Backend: cuml)\n",
      "11:20:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:21:04 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "11:21:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:21:14 [INFO]   Training abgeschlossen in 6.97s (Backend: cuml)\n",
      "11:21:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:21:24 [INFO]   Training abgeschlossen in 7.07s (Backend: cuml)\n",
      "11:21:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:21:34 [INFO]   Training abgeschlossen in 7.14s (Backend: cuml)\n",
      "11:21:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:21:45 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "11:21:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:21:55 [INFO]   Training abgeschlossen in 7.21s (Backend: cuml)\n",
      "11:21:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:22:06 [INFO]   Training abgeschlossen in 7.30s (Backend: cuml)\n",
      "11:22:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:22:16 [INFO]   Training abgeschlossen in 7.41s (Backend: cuml)\n",
      "11:22:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:22:27 [INFO]   Training abgeschlossen in 7.49s (Backend: cuml)\n",
      "11:22:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:22:38 [INFO]   Training abgeschlossen in 7.67s (Backend: cuml)\n",
      "11:22:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:22:49 [INFO]   Training abgeschlossen in 7.65s (Backend: cuml)\n",
      "11:22:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:23:00 [INFO]   Training abgeschlossen in 7.74s (Backend: cuml)\n",
      "11:23:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:23:11 [INFO]   Training abgeschlossen in 7.95s (Backend: cuml)\n",
      "11:23:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:23:23 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "11:23:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:23:34 [INFO]   Training abgeschlossen in 8.10s (Backend: cuml)\n",
      "11:23:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:23:46 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "11:23:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:23:57 [INFO]   Training abgeschlossen in 8.22s (Backend: cuml)\n",
      "11:24:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:24:09 [INFO]   Training abgeschlossen in 8.05s (Backend: cuml)\n",
      "11:24:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:24:20 [INFO]   Training abgeschlossen in 8.11s (Backend: cuml)\n",
      "11:24:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:24:32 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "11:24:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:24:43 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "11:24:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:24:55 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "11:24:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:25:07 [INFO]   Training abgeschlossen in 8.37s (Backend: cuml)\n",
      "11:25:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:25:19 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "11:25:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:25:32 [INFO]   Training abgeschlossen in 9.01s (Backend: cuml)\n",
      "11:25:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:25:44 [INFO]   Training abgeschlossen in 9.07s (Backend: cuml)\n",
      "11:25:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:25:57 [INFO]   Training abgeschlossen in 9.11s (Backend: cuml)\n",
      "11:26:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:26:10 [INFO]   Training abgeschlossen in 9.34s (Backend: cuml)\n",
      "11:26:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:26:23 [INFO]   Training abgeschlossen in 9.31s (Backend: cuml)\n",
      "11:26:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:26:36 [INFO]   Training abgeschlossen in 9.29s (Backend: cuml)\n",
      "11:26:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:26:49 [INFO]   Training abgeschlossen in 9.39s (Backend: cuml)\n",
      "11:26:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:27:02 [INFO]   Training abgeschlossen in 9.58s (Backend: cuml)\n",
      "11:27:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:27:16 [INFO]   Training abgeschlossen in 9.84s (Backend: cuml)\n",
      "11:27:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:27:29 [INFO]   Training abgeschlossen in 9.74s (Backend: cuml)\n",
      "11:27:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:27:43 [INFO]   Training abgeschlossen in 9.90s (Backend: cuml)\n",
      "11:27:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:27:57 [INFO]   Training abgeschlossen in 9.97s (Backend: cuml)\n",
      "11:28:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:28:10 [INFO]   Training abgeschlossen in 10.19s (Backend: cuml)\n",
      "11:28:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:28:24 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "11:28:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:28:38 [INFO]   Training abgeschlossen in 10.23s (Backend: cuml)\n",
      "11:28:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:28:52 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "11:28:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:29:06 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "11:29:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:29:21 [INFO]   Training abgeschlossen in 10.46s (Backend: cuml)\n",
      "11:29:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:29:35 [INFO]   Training abgeschlossen in 10.62s (Backend: cuml)\n",
      "11:29:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:29:50 [INFO]   Training abgeschlossen in 10.68s (Backend: cuml)\n",
      "11:29:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:30:04 [INFO]   Training abgeschlossen in 10.69s (Backend: cuml)\n",
      "11:30:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:30:19 [INFO]   Training abgeschlossen in 10.81s (Backend: cuml)\n",
      "11:30:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:30:33 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "11:30:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:30:48 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "11:30:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:31:03 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "11:31:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:31:18 [INFO]   Training abgeschlossen in 11.24s (Backend: cuml)\n",
      "11:31:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:31:34 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "11:31:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:31:49 [INFO]   Training abgeschlossen in 11.53s (Backend: cuml)\n",
      "11:31:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:32:05 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "11:32:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:32:20 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "11:32:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:32:36 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "11:32:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:32:52 [INFO]   Training abgeschlossen in 11.93s (Backend: cuml)\n",
      "11:32:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:33:08 [INFO]   Training abgeschlossen in 12.03s (Backend: cuml)\n",
      "11:33:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:33:24 [INFO]   Training abgeschlossen in 11.91s (Backend: cuml)\n",
      "11:33:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:33:40 [INFO]   Training abgeschlossen in 12.29s (Backend: cuml)\n",
      "11:33:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:33:56 [INFO]   Training abgeschlossen in 12.10s (Backend: cuml)\n",
      "11:34:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:34:12 [INFO]   Training abgeschlossen in 12.43s (Backend: cuml)\n",
      "11:34:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:34:29 [INFO]   Training abgeschlossen in 12.53s (Backend: cuml)\n",
      "11:34:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:34:46 [INFO]   Training abgeschlossen in 12.55s (Backend: cuml)\n",
      "11:34:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:35:02 [INFO]   Training abgeschlossen in 12.67s (Backend: cuml)\n",
      "11:35:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:35:19 [INFO]   Training abgeschlossen in 12.80s (Backend: cuml)\n",
      "11:35:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:35:36 [INFO]   Training abgeschlossen in 12.95s (Backend: cuml)\n",
      "11:35:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:35:53 [INFO]   Training abgeschlossen in 12.96s (Backend: cuml)\n",
      "11:35:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:36:10 [INFO]   Training abgeschlossen in 13.04s (Backend: cuml)\n",
      "11:36:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:36:27 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "11:36:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:36:45 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "11:36:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:37:02 [INFO]   Training abgeschlossen in 13.43s (Backend: cuml)\n",
      "11:37:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:37:20 [INFO]   Training abgeschlossen in 13.43s (Backend: cuml)\n",
      "11:37:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:37:38 [INFO]   Training abgeschlossen in 13.80s (Backend: cuml)\n",
      "11:37:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:38:08 [INFO]   Training abgeschlossen in 25.93s (Backend: cuml)\n",
      "11:38:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:38:39 [INFO]   Training abgeschlossen in 26.48s (Backend: cuml)\n",
      "11:38:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:39:08 [INFO]   Training abgeschlossen in 25.68s (Backend: cuml)\n",
      "11:39:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:39:40 [INFO]   Training abgeschlossen in 27.21s (Backend: cuml)\n",
      "11:39:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:40:11 [INFO]   Training abgeschlossen in 27.28s (Backend: cuml)\n",
      "11:40:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:40:41 [INFO]   Training abgeschlossen in 25.72s (Backend: cuml)\n",
      "11:40:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:41:15 [INFO]   Training abgeschlossen in 29.56s (Backend: cuml)\n",
      "11:41:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:41:46 [INFO]   Training abgeschlossen in 26.71s (Backend: cuml)\n",
      "11:41:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:42:18 [INFO]   Training abgeschlossen in 27.93s (Backend: cuml)\n",
      "11:42:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:42:50 [INFO]   Training abgeschlossen in 27.39s (Backend: cuml)\n",
      "11:42:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:43:21 [INFO]   Training abgeschlossen in 26.92s (Backend: cuml)\n",
      "11:43:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:43:53 [INFO]   Training abgeschlossen in 27.23s (Backend: cuml)\n",
      "11:43:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:44:26 [INFO]   Training abgeschlossen in 28.49s (Backend: cuml)\n",
      "11:44:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:44:58 [INFO]   Training abgeschlossen in 28.25s (Backend: cuml)\n",
      "11:45:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:45:30 [INFO]   Training abgeschlossen in 27.10s (Backend: cuml)\n",
      "11:45:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:46:04 [INFO]   Training abgeschlossen in 29.61s (Backend: cuml)\n",
      "11:46:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:46:39 [INFO]   Training abgeschlossen in 30.23s (Backend: cuml)\n",
      "11:46:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:47:10 [INFO]   Training abgeschlossen in 27.50s (Backend: cuml)\n",
      "11:47:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:47:44 [INFO]   Training abgeschlossen in 29.70s (Backend: cuml)\n",
      "11:47:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:48:18 [INFO]   Training abgeschlossen in 28.89s (Backend: cuml)\n",
      "11:48:22 [INFO]     60,000 labeled → Accuracy: 0.8836 (Train: 28.9s, Query: 0.00s) | GPU: 2.8/8.0 GB\n",
      "11:48:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:48:53 [INFO]   Training abgeschlossen in 31.16s (Backend: cuml)\n",
      "11:48:58 [INFO]     Final: 60,000 labeled → Accuracy: 0.8840, F1: 0.8833\n",
      "11:48:58 [INFO]   Run 4/5\n",
      "11:48:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:49:03 [INFO]   Training abgeschlossen in 4.64s (Backend: cuml)\n",
      "11:49:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:49:10 [INFO]   Training abgeschlossen in 4.61s (Backend: cuml)\n",
      "11:49:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:49:17 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "11:49:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:49:24 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "11:49:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:49:32 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "11:49:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:49:40 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "11:49:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:49:47 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "11:49:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:49:55 [INFO]   Training abgeschlossen in 5.07s (Backend: cuml)\n",
      "11:49:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:50:04 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "11:50:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:50:12 [INFO]   Training abgeschlossen in 5.41s (Backend: cuml)\n",
      "11:50:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:50:20 [INFO]   Training abgeschlossen in 5.71s (Backend: cuml)\n",
      "11:50:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:50:29 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "11:50:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:50:38 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "11:50:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:50:47 [INFO]   Training abgeschlossen in 5.98s (Backend: cuml)\n",
      "11:50:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:50:56 [INFO]   Training abgeschlossen in 6.07s (Backend: cuml)\n",
      "11:50:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:51:05 [INFO]   Training abgeschlossen in 6.13s (Backend: cuml)\n",
      "11:51:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:51:14 [INFO]   Training abgeschlossen in 6.09s (Backend: cuml)\n",
      "11:51:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:51:23 [INFO]   Training abgeschlossen in 6.20s (Backend: cuml)\n",
      "11:51:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:51:32 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "11:51:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:51:42 [INFO]   Training abgeschlossen in 6.39s (Backend: cuml)\n",
      "11:51:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:51:51 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "11:51:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:52:01 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "11:52:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:52:10 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "11:52:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:52:20 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "11:52:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:52:30 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "11:52:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:52:40 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "11:52:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:52:50 [INFO]   Training abgeschlossen in 6.95s (Backend: cuml)\n",
      "11:52:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:53:00 [INFO]   Training abgeschlossen in 7.21s (Backend: cuml)\n",
      "11:53:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:53:11 [INFO]   Training abgeschlossen in 7.06s (Backend: cuml)\n",
      "11:53:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:53:21 [INFO]   Training abgeschlossen in 7.16s (Backend: cuml)\n",
      "11:53:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:53:32 [INFO]   Training abgeschlossen in 7.27s (Backend: cuml)\n",
      "11:53:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:53:42 [INFO]   Training abgeschlossen in 7.29s (Backend: cuml)\n",
      "11:53:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:53:53 [INFO]   Training abgeschlossen in 7.33s (Backend: cuml)\n",
      "11:53:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:54:04 [INFO]   Training abgeschlossen in 7.63s (Backend: cuml)\n",
      "11:54:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:54:15 [INFO]   Training abgeschlossen in 7.56s (Backend: cuml)\n",
      "11:54:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:54:25 [INFO]   Training abgeschlossen in 7.58s (Backend: cuml)\n",
      "11:54:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:54:36 [INFO]   Training abgeschlossen in 7.66s (Backend: cuml)\n",
      "11:54:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:54:48 [INFO]   Training abgeschlossen in 7.85s (Backend: cuml)\n",
      "11:54:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:54:59 [INFO]   Training abgeschlossen in 7.98s (Backend: cuml)\n",
      "11:55:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:55:11 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "11:55:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:55:22 [INFO]   Training abgeschlossen in 8.10s (Backend: cuml)\n",
      "11:55:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:55:34 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "11:55:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:55:45 [INFO]   Training abgeschlossen in 8.29s (Backend: cuml)\n",
      "11:55:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:55:57 [INFO]   Training abgeschlossen in 8.02s (Backend: cuml)\n",
      "11:56:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:56:08 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "11:56:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:56:20 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "11:56:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:56:32 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "11:56:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:56:44 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "11:56:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:56:56 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "11:56:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:57:08 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "11:57:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:57:20 [INFO]   Training abgeschlossen in 8.83s (Backend: cuml)\n",
      "11:57:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:57:32 [INFO]   Training abgeschlossen in 8.87s (Backend: cuml)\n",
      "11:57:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:57:45 [INFO]   Training abgeschlossen in 9.07s (Backend: cuml)\n",
      "11:57:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:57:58 [INFO]   Training abgeschlossen in 9.15s (Backend: cuml)\n",
      "11:58:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:58:10 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "11:58:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:58:23 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "11:58:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:58:36 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "11:58:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:58:49 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "11:58:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:59:02 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "11:59:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:59:16 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "11:59:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:59:29 [INFO]   Training abgeschlossen in 9.93s (Backend: cuml)\n",
      "11:59:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:59:43 [INFO]   Training abgeschlossen in 9.95s (Backend: cuml)\n",
      "11:59:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:59:56 [INFO]   Training abgeschlossen in 10.04s (Backend: cuml)\n",
      "12:00:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:00:10 [INFO]   Training abgeschlossen in 10.23s (Backend: cuml)\n",
      "12:00:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:00:24 [INFO]   Training abgeschlossen in 10.23s (Backend: cuml)\n",
      "12:00:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:00:38 [INFO]   Training abgeschlossen in 10.24s (Backend: cuml)\n",
      "12:00:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:00:53 [INFO]   Training abgeschlossen in 10.48s (Backend: cuml)\n",
      "12:00:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:01:07 [INFO]   Training abgeschlossen in 10.62s (Backend: cuml)\n",
      "12:01:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:01:21 [INFO]   Training abgeschlossen in 10.56s (Backend: cuml)\n",
      "12:01:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:01:36 [INFO]   Training abgeschlossen in 10.70s (Backend: cuml)\n",
      "12:01:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:01:50 [INFO]   Training abgeschlossen in 10.81s (Backend: cuml)\n",
      "12:01:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:02:05 [INFO]   Training abgeschlossen in 11.06s (Backend: cuml)\n",
      "12:02:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:02:20 [INFO]   Training abgeschlossen in 10.84s (Backend: cuml)\n",
      "12:02:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:02:35 [INFO]   Training abgeschlossen in 10.98s (Backend: cuml)\n",
      "12:02:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:02:50 [INFO]   Training abgeschlossen in 11.17s (Backend: cuml)\n",
      "12:02:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:03:05 [INFO]   Training abgeschlossen in 11.28s (Backend: cuml)\n",
      "12:03:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:03:20 [INFO]   Training abgeschlossen in 11.31s (Backend: cuml)\n",
      "12:03:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:03:35 [INFO]   Training abgeschlossen in 11.47s (Backend: cuml)\n",
      "12:03:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:03:51 [INFO]   Training abgeschlossen in 11.69s (Backend: cuml)\n",
      "12:03:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:04:07 [INFO]   Training abgeschlossen in 11.71s (Backend: cuml)\n",
      "12:04:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:04:22 [INFO]   Training abgeschlossen in 11.75s (Backend: cuml)\n",
      "12:04:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:04:38 [INFO]   Training abgeschlossen in 11.87s (Backend: cuml)\n",
      "12:04:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:04:54 [INFO]   Training abgeschlossen in 12.00s (Backend: cuml)\n",
      "12:04:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:05:10 [INFO]   Training abgeschlossen in 12.12s (Backend: cuml)\n",
      "12:05:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:05:26 [INFO]   Training abgeschlossen in 12.00s (Backend: cuml)\n",
      "12:05:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:05:42 [INFO]   Training abgeschlossen in 12.31s (Backend: cuml)\n",
      "12:05:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:05:59 [INFO]   Training abgeschlossen in 12.41s (Backend: cuml)\n",
      "12:06:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:06:15 [INFO]   Training abgeschlossen in 12.38s (Backend: cuml)\n",
      "12:06:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:06:32 [INFO]   Training abgeschlossen in 12.54s (Backend: cuml)\n",
      "12:06:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:06:49 [INFO]   Training abgeschlossen in 12.80s (Backend: cuml)\n",
      "12:06:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:07:05 [INFO]   Training abgeschlossen in 12.79s (Backend: cuml)\n",
      "12:07:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:07:22 [INFO]   Training abgeschlossen in 12.83s (Backend: cuml)\n",
      "12:07:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:07:39 [INFO]   Training abgeschlossen in 12.98s (Backend: cuml)\n",
      "12:07:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:07:57 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "12:08:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:08:14 [INFO]   Training abgeschlossen in 13.07s (Backend: cuml)\n",
      "12:08:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:08:31 [INFO]   Training abgeschlossen in 13.32s (Backend: cuml)\n",
      "12:08:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:08:49 [INFO]   Training abgeschlossen in 13.57s (Backend: cuml)\n",
      "12:08:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:09:06 [INFO]   Training abgeschlossen in 13.48s (Backend: cuml)\n",
      "12:09:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:09:24 [INFO]   Training abgeschlossen in 13.61s (Backend: cuml)\n",
      "12:09:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:09:54 [INFO]   Training abgeschlossen in 25.28s (Backend: cuml)\n",
      "12:09:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:10:25 [INFO]   Training abgeschlossen in 27.00s (Backend: cuml)\n",
      "12:10:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:10:55 [INFO]   Training abgeschlossen in 25.79s (Backend: cuml)\n",
      "12:10:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:11:26 [INFO]   Training abgeschlossen in 27.35s (Backend: cuml)\n",
      "12:11:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:11:57 [INFO]   Training abgeschlossen in 26.67s (Backend: cuml)\n",
      "12:12:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:12:31 [INFO]   Training abgeschlossen in 29.45s (Backend: cuml)\n",
      "12:12:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:13:01 [INFO]   Training abgeschlossen in 25.69s (Backend: cuml)\n",
      "12:13:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:13:31 [INFO]   Training abgeschlossen in 25.72s (Backend: cuml)\n",
      "12:13:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:14:02 [INFO]   Training abgeschlossen in 27.16s (Backend: cuml)\n",
      "12:14:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:14:35 [INFO]   Training abgeschlossen in 28.38s (Backend: cuml)\n",
      "12:14:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:15:07 [INFO]   Training abgeschlossen in 28.02s (Backend: cuml)\n",
      "12:15:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:15:39 [INFO]   Training abgeschlossen in 26.93s (Backend: cuml)\n",
      "12:15:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:16:10 [INFO]   Training abgeschlossen in 27.09s (Backend: cuml)\n",
      "12:16:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:16:43 [INFO]   Training abgeschlossen in 28.06s (Backend: cuml)\n",
      "12:16:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:17:16 [INFO]   Training abgeschlossen in 29.14s (Backend: cuml)\n",
      "12:17:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:17:49 [INFO]   Training abgeschlossen in 28.20s (Backend: cuml)\n",
      "12:17:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:18:22 [INFO]   Training abgeschlossen in 29.22s (Backend: cuml)\n",
      "12:18:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:18:55 [INFO]   Training abgeschlossen in 28.48s (Backend: cuml)\n",
      "12:18:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:19:27 [INFO]   Training abgeschlossen in 27.89s (Backend: cuml)\n",
      "12:19:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:20:01 [INFO]   Training abgeschlossen in 29.02s (Backend: cuml)\n",
      "12:20:05 [INFO]     60,000 labeled → Accuracy: 0.8844 (Train: 29.0s, Query: 0.00s) | GPU: 2.8/8.0 GB\n",
      "12:20:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:20:35 [INFO]   Training abgeschlossen in 29.55s (Backend: cuml)\n",
      "12:20:39 [INFO]     Final: 60,000 labeled → Accuracy: 0.8835, F1: 0.8829\n",
      "12:20:39 [INFO]   Run 5/5\n",
      "12:20:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:20:44 [INFO]   Training abgeschlossen in 4.63s (Backend: cuml)\n",
      "12:20:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:20:51 [INFO]   Training abgeschlossen in 4.68s (Backend: cuml)\n",
      "12:20:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:20:59 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "12:21:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:21:06 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "12:21:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:21:14 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "12:21:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:21:22 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "12:21:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:21:29 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "12:21:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:21:37 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "12:21:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:21:45 [INFO]   Training abgeschlossen in 5.36s (Backend: cuml)\n",
      "12:21:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:21:54 [INFO]   Training abgeschlossen in 5.42s (Backend: cuml)\n",
      "12:21:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:22:02 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "12:22:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:22:11 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "12:22:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:22:20 [INFO]   Training abgeschlossen in 5.97s (Backend: cuml)\n",
      "12:22:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:22:29 [INFO]   Training abgeschlossen in 6.05s (Backend: cuml)\n",
      "12:22:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:22:38 [INFO]   Training abgeschlossen in 6.02s (Backend: cuml)\n",
      "12:22:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:22:47 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "12:22:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:22:56 [INFO]   Training abgeschlossen in 6.10s (Backend: cuml)\n",
      "12:22:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:23:05 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "12:23:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:23:14 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "12:23:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:23:24 [INFO]   Training abgeschlossen in 6.49s (Backend: cuml)\n",
      "12:23:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:23:34 [INFO]   Training abgeschlossen in 6.43s (Backend: cuml)\n",
      "12:23:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:23:43 [INFO]   Training abgeschlossen in 6.48s (Backend: cuml)\n",
      "12:23:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:23:53 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "12:23:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:24:02 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "12:24:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:24:12 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "12:24:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:24:22 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "12:24:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:24:33 [INFO]   Training abgeschlossen in 7.28s (Backend: cuml)\n",
      "12:24:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:24:43 [INFO]   Training abgeschlossen in 6.99s (Backend: cuml)\n",
      "12:24:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:24:53 [INFO]   Training abgeschlossen in 7.13s (Backend: cuml)\n",
      "12:24:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:25:04 [INFO]   Training abgeschlossen in 7.17s (Backend: cuml)\n",
      "12:25:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:25:14 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "12:25:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:25:25 [INFO]   Training abgeschlossen in 7.38s (Backend: cuml)\n",
      "12:25:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:25:36 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "12:25:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:25:47 [INFO]   Training abgeschlossen in 7.44s (Backend: cuml)\n",
      "12:25:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:25:57 [INFO]   Training abgeschlossen in 7.54s (Backend: cuml)\n",
      "12:26:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:26:08 [INFO]   Training abgeschlossen in 7.58s (Backend: cuml)\n",
      "12:26:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:26:19 [INFO]   Training abgeschlossen in 7.64s (Backend: cuml)\n",
      "12:26:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:26:31 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "12:26:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:26:42 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "12:26:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:26:54 [INFO]   Training abgeschlossen in 8.07s (Backend: cuml)\n",
      "12:26:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:27:05 [INFO]   Training abgeschlossen in 8.08s (Backend: cuml)\n",
      "12:27:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:27:17 [INFO]   Training abgeschlossen in 8.19s (Backend: cuml)\n",
      "12:27:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:27:29 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "12:27:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:27:40 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "12:27:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:27:52 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "12:27:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:28:04 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "12:28:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:28:15 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "12:28:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:28:27 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "12:28:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:28:39 [INFO]   Training abgeschlossen in 8.64s (Backend: cuml)\n",
      "12:28:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:28:51 [INFO]   Training abgeschlossen in 8.58s (Backend: cuml)\n",
      "12:28:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:29:04 [INFO]   Training abgeschlossen in 8.90s (Backend: cuml)\n",
      "12:29:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:29:16 [INFO]   Training abgeschlossen in 8.91s (Backend: cuml)\n",
      "12:29:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:29:29 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "12:29:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:29:42 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "12:29:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:29:55 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "12:29:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:30:08 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "12:30:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:30:21 [INFO]   Training abgeschlossen in 9.26s (Backend: cuml)\n",
      "12:30:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:30:34 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "12:30:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:30:47 [INFO]   Training abgeschlossen in 9.80s (Backend: cuml)\n",
      "12:30:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:31:01 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "12:31:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:31:14 [INFO]   Training abgeschlossen in 9.79s (Backend: cuml)\n",
      "12:31:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:31:28 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "12:31:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:31:41 [INFO]   Training abgeschlossen in 10.27s (Backend: cuml)\n",
      "12:31:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:31:56 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "12:31:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:32:10 [INFO]   Training abgeschlossen in 10.32s (Backend: cuml)\n",
      "12:32:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:32:24 [INFO]   Training abgeschlossen in 10.32s (Backend: cuml)\n",
      "12:32:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:32:38 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "12:32:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:32:52 [INFO]   Training abgeschlossen in 10.82s (Backend: cuml)\n",
      "12:32:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:33:07 [INFO]   Training abgeschlossen in 10.69s (Backend: cuml)\n",
      "12:33:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:33:21 [INFO]   Training abgeschlossen in 10.73s (Backend: cuml)\n",
      "12:33:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:33:36 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "12:33:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:33:51 [INFO]   Training abgeschlossen in 11.14s (Backend: cuml)\n",
      "12:33:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:34:06 [INFO]   Training abgeschlossen in 10.94s (Backend: cuml)\n",
      "12:34:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:34:21 [INFO]   Training abgeschlossen in 11.10s (Backend: cuml)\n",
      "12:34:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:34:36 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "12:34:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:34:51 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "12:34:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:35:06 [INFO]   Training abgeschlossen in 11.42s (Backend: cuml)\n",
      "12:35:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:35:22 [INFO]   Training abgeschlossen in 11.56s (Backend: cuml)\n",
      "12:35:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:35:37 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "12:35:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:35:53 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "12:35:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:36:09 [INFO]   Training abgeschlossen in 11.74s (Backend: cuml)\n",
      "12:36:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:36:25 [INFO]   Training abgeschlossen in 11.84s (Backend: cuml)\n",
      "12:36:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:36:41 [INFO]   Training abgeschlossen in 12.01s (Backend: cuml)\n",
      "12:36:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:36:57 [INFO]   Training abgeschlossen in 12.42s (Backend: cuml)\n",
      "12:37:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:37:13 [INFO]   Training abgeschlossen in 12.08s (Backend: cuml)\n",
      "12:37:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:37:29 [INFO]   Training abgeschlossen in 12.21s (Backend: cuml)\n",
      "12:37:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:37:46 [INFO]   Training abgeschlossen in 12.45s (Backend: cuml)\n",
      "12:37:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:38:03 [INFO]   Training abgeschlossen in 12.66s (Backend: cuml)\n",
      "12:38:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:38:19 [INFO]   Training abgeschlossen in 12.61s (Backend: cuml)\n",
      "12:38:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:38:36 [INFO]   Training abgeschlossen in 12.67s (Backend: cuml)\n",
      "12:38:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:38:53 [INFO]   Training abgeschlossen in 12.96s (Backend: cuml)\n",
      "12:38:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:39:10 [INFO]   Training abgeschlossen in 12.96s (Backend: cuml)\n",
      "12:39:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:39:27 [INFO]   Training abgeschlossen in 12.99s (Backend: cuml)\n",
      "12:39:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:39:44 [INFO]   Training abgeschlossen in 13.10s (Backend: cuml)\n",
      "12:39:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:40:02 [INFO]   Training abgeschlossen in 13.50s (Backend: cuml)\n",
      "12:40:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:40:19 [INFO]   Training abgeschlossen in 13.42s (Backend: cuml)\n",
      "12:40:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:40:37 [INFO]   Training abgeschlossen in 13.34s (Backend: cuml)\n",
      "12:40:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:40:54 [INFO]   Training abgeschlossen in 13.64s (Backend: cuml)\n",
      "12:40:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:41:12 [INFO]   Training abgeschlossen in 13.85s (Backend: cuml)\n",
      "12:41:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:41:42 [INFO]   Training abgeschlossen in 25.70s (Backend: cuml)\n",
      "12:41:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:42:12 [INFO]   Training abgeschlossen in 25.36s (Backend: cuml)\n",
      "12:42:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:42:43 [INFO]   Training abgeschlossen in 27.11s (Backend: cuml)\n",
      "12:42:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:43:15 [INFO]   Training abgeschlossen in 27.28s (Backend: cuml)\n",
      "12:43:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:43:45 [INFO]   Training abgeschlossen in 26.36s (Backend: cuml)\n",
      "12:43:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:44:18 [INFO]   Training abgeschlossen in 28.65s (Backend: cuml)\n",
      "12:44:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:44:50 [INFO]   Training abgeschlossen in 27.07s (Backend: cuml)\n",
      "12:44:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:45:21 [INFO]   Training abgeschlossen in 27.49s (Backend: cuml)\n",
      "12:45:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:45:52 [INFO]   Training abgeschlossen in 26.59s (Backend: cuml)\n",
      "12:45:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:46:24 [INFO]   Training abgeschlossen in 27.32s (Backend: cuml)\n",
      "12:46:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:46:58 [INFO]   Training abgeschlossen in 30.04s (Backend: cuml)\n",
      "12:47:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:47:31 [INFO]   Training abgeschlossen in 27.87s (Backend: cuml)\n",
      "12:47:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:48:03 [INFO]   Training abgeschlossen in 27.87s (Backend: cuml)\n",
      "12:48:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:48:35 [INFO]   Training abgeschlossen in 27.50s (Backend: cuml)\n",
      "12:48:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:49:07 [INFO]   Training abgeschlossen in 27.57s (Backend: cuml)\n",
      "12:49:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:49:40 [INFO]   Training abgeschlossen in 29.23s (Backend: cuml)\n",
      "12:49:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:50:13 [INFO]   Training abgeschlossen in 28.85s (Backend: cuml)\n",
      "12:50:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:50:46 [INFO]   Training abgeschlossen in 28.00s (Backend: cuml)\n",
      "12:50:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:51:22 [INFO]   Training abgeschlossen in 31.90s (Backend: cuml)\n",
      "12:51:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:51:55 [INFO]   Training abgeschlossen in 29.08s (Backend: cuml)\n",
      "12:52:00 [INFO]     60,000 labeled → Accuracy: 0.8830 (Train: 29.1s, Query: 0.00s) | GPU: 2.8/8.0 GB\n",
      "12:52:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:52:29 [INFO]   Training abgeschlossen in 28.84s (Backend: cuml)\n",
      "12:52:33 [INFO]     Final: 60,000 labeled → Accuracy: 0.8826, F1: 0.8820\n",
      "\n",
      "============================================================\n",
      "Strategie: Entropy Sampling\n",
      "============================================================\n",
      "12:52:33 [INFO] \n",
      "GPU-SVM + Entropy Sampling - Budget: 20% (12,000 Samples)\n",
      "12:52:33 [INFO]   Run 1/5\n",
      "12:52:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 0.3/8.0 GB)\n",
      "12:52:38 [INFO]   Training abgeschlossen in 4.57s (Backend: cuml)\n",
      "12:52:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:52:58 [INFO]   Training abgeschlossen in 4.68s (Backend: cuml)\n",
      "12:53:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:53:19 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "12:53:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:53:40 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "12:53:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:54:01 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "12:54:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:54:23 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "12:54:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:54:45 [INFO]   Training abgeschlossen in 5.07s (Backend: cuml)\n",
      "12:55:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:55:08 [INFO]   Training abgeschlossen in 5.23s (Backend: cuml)\n",
      "12:55:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:55:31 [INFO]   Training abgeschlossen in 5.28s (Backend: cuml)\n",
      "12:55:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:55:54 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "12:56:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:56:17 [INFO]   Training abgeschlossen in 5.83s (Backend: cuml)\n",
      "12:56:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:56:41 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "12:56:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:57:05 [INFO]   Training abgeschlossen in 5.83s (Backend: cuml)\n",
      "12:57:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:57:29 [INFO]   Training abgeschlossen in 6.04s (Backend: cuml)\n",
      "12:57:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:57:53 [INFO]   Training abgeschlossen in 6.21s (Backend: cuml)\n",
      "12:58:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:58:18 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "12:58:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:58:44 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "12:59:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:59:10 [INFO]   Training abgeschlossen in 6.65s (Backend: cuml)\n",
      "12:59:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:59:36 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "12:59:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:00:01 [INFO]   Training abgeschlossen in 6.81s (Backend: cuml)\n",
      "13:00:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:00:26 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "13:00:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:00:52 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "13:01:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:01:18 [INFO]   Training abgeschlossen in 7.06s (Backend: cuml)\n",
      "13:01:36 [INFO]     12,000 labeled → Accuracy: 0.8723 (Train: 7.1s, Query: 15.02s) | GPU: 2.7/8.0 GB\n",
      "13:01:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:01:44 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "13:01:47 [INFO]     Final: 12,000 labeled → Accuracy: 0.8725, F1: 0.8725\n",
      "13:01:47 [INFO]   Run 2/5\n",
      "13:01:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:01:52 [INFO]   Training abgeschlossen in 4.56s (Backend: cuml)\n",
      "13:02:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:02:12 [INFO]   Training abgeschlossen in 4.64s (Backend: cuml)\n",
      "13:02:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:02:33 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "13:02:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:02:55 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "13:03:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:03:16 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "13:03:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:03:38 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "13:03:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:04:01 [INFO]   Training abgeschlossen in 5.08s (Backend: cuml)\n",
      "13:04:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:04:24 [INFO]   Training abgeschlossen in 5.13s (Backend: cuml)\n",
      "13:04:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:04:47 [INFO]   Training abgeschlossen in 5.42s (Backend: cuml)\n",
      "13:05:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:05:10 [INFO]   Training abgeschlossen in 5.42s (Backend: cuml)\n",
      "13:05:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:05:33 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "13:05:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:05:57 [INFO]   Training abgeschlossen in 5.70s (Backend: cuml)\n",
      "13:06:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:06:21 [INFO]   Training abgeschlossen in 5.89s (Backend: cuml)\n",
      "13:06:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:06:46 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "13:07:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:07:10 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "13:07:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:07:34 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "13:07:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:07:59 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "13:08:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:08:24 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "13:08:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:08:49 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "13:09:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:09:15 [INFO]   Training abgeschlossen in 6.71s (Backend: cuml)\n",
      "13:09:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:09:40 [INFO]   Training abgeschlossen in 7.02s (Backend: cuml)\n",
      "13:09:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:10:06 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "13:10:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:10:32 [INFO]   Training abgeschlossen in 7.02s (Backend: cuml)\n",
      "13:10:50 [INFO]     12,000 labeled → Accuracy: 0.8698 (Train: 7.0s, Query: 15.10s) | GPU: 2.7/8.0 GB\n",
      "13:10:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:10:58 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "13:11:01 [INFO]     Final: 12,000 labeled → Accuracy: 0.8708, F1: 0.8708\n",
      "13:11:01 [INFO]   Run 3/5\n",
      "13:11:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:11:06 [INFO]   Training abgeschlossen in 4.61s (Backend: cuml)\n",
      "13:11:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:11:26 [INFO]   Training abgeschlossen in 4.63s (Backend: cuml)\n",
      "13:11:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:11:47 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "13:12:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:12:08 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "13:12:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:12:30 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "13:12:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:12:52 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "13:13:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:13:15 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "13:13:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:13:38 [INFO]   Training abgeschlossen in 5.24s (Backend: cuml)\n",
      "13:13:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:14:00 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "13:14:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:14:24 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "13:14:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:14:48 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "13:15:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:15:12 [INFO]   Training abgeschlossen in 5.80s (Backend: cuml)\n",
      "13:15:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:15:36 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "13:15:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:16:01 [INFO]   Training abgeschlossen in 6.07s (Backend: cuml)\n",
      "13:16:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:16:26 [INFO]   Training abgeschlossen in 6.16s (Backend: cuml)\n",
      "13:16:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:16:51 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "13:17:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:17:15 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "13:17:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:17:40 [INFO]   Training abgeschlossen in 6.56s (Backend: cuml)\n",
      "13:17:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:18:06 [INFO]   Training abgeschlossen in 6.54s (Backend: cuml)\n",
      "13:18:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:18:31 [INFO]   Training abgeschlossen in 6.78s (Backend: cuml)\n",
      "13:18:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:18:57 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "13:19:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:19:22 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "13:19:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:19:47 [INFO]   Training abgeschlossen in 7.01s (Backend: cuml)\n",
      "13:20:06 [INFO]     12,000 labeled → Accuracy: 0.8681 (Train: 7.0s, Query: 15.16s) | GPU: 2.7/8.0 GB\n",
      "13:20:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:20:13 [INFO]   Training abgeschlossen in 7.08s (Backend: cuml)\n",
      "13:20:17 [INFO]     Final: 12,000 labeled → Accuracy: 0.8693, F1: 0.8693\n",
      "13:20:17 [INFO]   Run 4/5\n",
      "13:20:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:20:22 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "13:20:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:20:42 [INFO]   Training abgeschlossen in 4.65s (Backend: cuml)\n",
      "13:20:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:21:02 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "13:21:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:21:24 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "13:21:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:21:46 [INFO]   Training abgeschlossen in 4.61s (Backend: cuml)\n",
      "13:22:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:22:08 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "13:22:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:22:30 [INFO]   Training abgeschlossen in 5.13s (Backend: cuml)\n",
      "13:22:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:22:53 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "13:23:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:23:16 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "13:23:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:23:39 [INFO]   Training abgeschlossen in 5.61s (Backend: cuml)\n",
      "13:23:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:24:03 [INFO]   Training abgeschlossen in 5.81s (Backend: cuml)\n",
      "13:24:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:24:27 [INFO]   Training abgeschlossen in 5.77s (Backend: cuml)\n",
      "13:24:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:24:51 [INFO]   Training abgeschlossen in 5.91s (Backend: cuml)\n",
      "13:25:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:25:15 [INFO]   Training abgeschlossen in 5.96s (Backend: cuml)\n",
      "13:25:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:25:40 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "13:25:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:26:04 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "13:26:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:26:30 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "13:26:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:26:55 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "13:27:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:27:20 [INFO]   Training abgeschlossen in 6.61s (Backend: cuml)\n",
      "13:27:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:27:46 [INFO]   Training abgeschlossen in 6.78s (Backend: cuml)\n",
      "13:28:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:28:11 [INFO]   Training abgeschlossen in 6.81s (Backend: cuml)\n",
      "13:28:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:28:37 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "13:28:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:29:03 [INFO]   Training abgeschlossen in 7.01s (Backend: cuml)\n",
      "13:29:22 [INFO]     12,000 labeled → Accuracy: 0.8686 (Train: 7.0s, Query: 15.15s) | GPU: 2.7/8.0 GB\n",
      "13:29:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:29:29 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "13:29:33 [INFO]     Final: 12,000 labeled → Accuracy: 0.8711, F1: 0.8711\n",
      "13:29:33 [INFO]   Run 5/5\n",
      "13:29:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:29:38 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "13:29:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:29:58 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "13:30:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:30:19 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "13:30:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:30:40 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "13:30:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:31:02 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "13:31:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:31:24 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "13:31:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:31:46 [INFO]   Training abgeschlossen in 5.04s (Backend: cuml)\n",
      "13:32:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:32:09 [INFO]   Training abgeschlossen in 5.18s (Backend: cuml)\n",
      "13:32:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:32:32 [INFO]   Training abgeschlossen in 5.42s (Backend: cuml)\n",
      "13:32:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:32:56 [INFO]   Training abgeschlossen in 5.52s (Backend: cuml)\n",
      "13:33:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:33:19 [INFO]   Training abgeschlossen in 5.78s (Backend: cuml)\n",
      "13:33:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:33:44 [INFO]   Training abgeschlossen in 5.77s (Backend: cuml)\n",
      "13:34:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:34:08 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "13:34:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:34:32 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "13:34:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:34:56 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "13:35:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:35:20 [INFO]   Training abgeschlossen in 6.33s (Backend: cuml)\n",
      "13:35:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:35:45 [INFO]   Training abgeschlossen in 6.34s (Backend: cuml)\n",
      "13:36:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:36:10 [INFO]   Training abgeschlossen in 6.48s (Backend: cuml)\n",
      "13:36:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:36:35 [INFO]   Training abgeschlossen in 6.58s (Backend: cuml)\n",
      "13:36:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:37:01 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "13:37:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:37:26 [INFO]   Training abgeschlossen in 6.94s (Backend: cuml)\n",
      "13:37:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:37:52 [INFO]   Training abgeschlossen in 6.92s (Backend: cuml)\n",
      "13:38:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:38:17 [INFO]   Training abgeschlossen in 7.00s (Backend: cuml)\n",
      "13:38:36 [INFO]     12,000 labeled → Accuracy: 0.8725 (Train: 7.0s, Query: 15.14s) | GPU: 2.7/8.0 GB\n",
      "13:38:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:38:43 [INFO]   Training abgeschlossen in 7.06s (Backend: cuml)\n",
      "13:38:46 [INFO]     Final: 12,000 labeled → Accuracy: 0.8737, F1: 0.8736\n",
      "13:38:47 [INFO] \n",
      "GPU-SVM + Entropy Sampling - Budget: 40% (24,000 Samples)\n",
      "13:38:47 [INFO]   Run 1/5\n",
      "13:38:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:38:51 [INFO]   Training abgeschlossen in 4.53s (Backend: cuml)\n",
      "13:39:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:39:11 [INFO]   Training abgeschlossen in 4.62s (Backend: cuml)\n",
      "13:39:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:39:32 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "13:39:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:39:53 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "13:40:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:40:15 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "13:40:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:40:36 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "13:40:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:40:59 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "13:41:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:41:22 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "13:41:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:41:45 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "13:42:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:42:08 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "13:42:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:42:32 [INFO]   Training abgeschlossen in 5.88s (Backend: cuml)\n",
      "13:42:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:42:56 [INFO]   Training abgeschlossen in 5.72s (Backend: cuml)\n",
      "13:43:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:43:20 [INFO]   Training abgeschlossen in 6.13s (Backend: cuml)\n",
      "13:43:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:43:44 [INFO]   Training abgeschlossen in 6.02s (Backend: cuml)\n",
      "13:44:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:44:08 [INFO]   Training abgeschlossen in 6.17s (Backend: cuml)\n",
      "13:44:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:44:33 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "13:44:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:44:58 [INFO]   Training abgeschlossen in 6.33s (Backend: cuml)\n",
      "13:45:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:45:23 [INFO]   Training abgeschlossen in 6.59s (Backend: cuml)\n",
      "13:45:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:45:48 [INFO]   Training abgeschlossen in 6.56s (Backend: cuml)\n",
      "13:46:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:46:14 [INFO]   Training abgeschlossen in 6.92s (Backend: cuml)\n",
      "13:46:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:46:40 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "13:47:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:47:07 [INFO]   Training abgeschlossen in 7.06s (Backend: cuml)\n",
      "13:47:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:47:33 [INFO]   Training abgeschlossen in 7.11s (Backend: cuml)\n",
      "13:47:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:48:00 [INFO]   Training abgeschlossen in 7.16s (Backend: cuml)\n",
      "13:48:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:48:27 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "13:48:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:48:54 [INFO]   Training abgeschlossen in 7.34s (Backend: cuml)\n",
      "13:49:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:49:20 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "13:49:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:49:46 [INFO]   Training abgeschlossen in 7.56s (Backend: cuml)\n",
      "13:50:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:50:12 [INFO]   Training abgeschlossen in 7.77s (Backend: cuml)\n",
      "13:50:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:50:38 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "13:50:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:51:05 [INFO]   Training abgeschlossen in 7.97s (Backend: cuml)\n",
      "13:51:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:51:32 [INFO]   Training abgeschlossen in 7.96s (Backend: cuml)\n",
      "13:51:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:51:59 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "13:52:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:52:26 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "13:52:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:52:54 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "13:53:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:53:20 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "13:53:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:53:47 [INFO]   Training abgeschlossen in 8.47s (Backend: cuml)\n",
      "13:54:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:54:13 [INFO]   Training abgeschlossen in 8.65s (Backend: cuml)\n",
      "13:54:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:54:39 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "13:54:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:55:06 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "13:55:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:55:33 [INFO]   Training abgeschlossen in 8.90s (Backend: cuml)\n",
      "13:55:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:55:59 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "13:56:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:56:26 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "13:56:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:56:52 [INFO]   Training abgeschlossen in 8.96s (Backend: cuml)\n",
      "13:57:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:57:19 [INFO]   Training abgeschlossen in 9.08s (Backend: cuml)\n",
      "13:57:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:57:45 [INFO]   Training abgeschlossen in 9.12s (Backend: cuml)\n",
      "13:58:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:58:11 [INFO]   Training abgeschlossen in 9.30s (Backend: cuml)\n",
      "13:58:28 [INFO]     24,000 labeled → Accuracy: 0.8838 (Train: 9.3s, Query: 12.79s) | GPU: 2.8/8.0 GB\n",
      "13:58:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:58:37 [INFO]   Training abgeschlossen in 9.28s (Backend: cuml)\n",
      "13:58:41 [INFO]     Final: 24,000 labeled → Accuracy: 0.8846, F1: 0.8844\n",
      "13:58:41 [INFO]   Run 2/5\n",
      "13:58:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:58:46 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "13:59:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:59:07 [INFO]   Training abgeschlossen in 4.63s (Backend: cuml)\n",
      "13:59:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:59:28 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "13:59:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:59:50 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "14:00:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:00:11 [INFO]   Training abgeschlossen in 4.69s (Backend: cuml)\n",
      "14:00:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:00:33 [INFO]   Training abgeschlossen in 4.94s (Backend: cuml)\n",
      "14:00:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:00:56 [INFO]   Training abgeschlossen in 5.15s (Backend: cuml)\n",
      "14:01:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:01:19 [INFO]   Training abgeschlossen in 5.17s (Backend: cuml)\n",
      "14:01:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:01:41 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "14:01:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:02:04 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "14:02:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:02:28 [INFO]   Training abgeschlossen in 5.72s (Backend: cuml)\n",
      "14:02:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:02:51 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "14:03:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:03:16 [INFO]   Training abgeschlossen in 5.88s (Backend: cuml)\n",
      "14:03:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:03:40 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "14:03:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:04:05 [INFO]   Training abgeschlossen in 6.19s (Backend: cuml)\n",
      "14:04:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:04:29 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "14:04:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:04:54 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "14:05:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:05:20 [INFO]   Training abgeschlossen in 6.47s (Backend: cuml)\n",
      "14:05:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:05:45 [INFO]   Training abgeschlossen in 6.63s (Backend: cuml)\n",
      "14:06:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:06:11 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "14:06:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:06:36 [INFO]   Training abgeschlossen in 6.86s (Backend: cuml)\n",
      "14:06:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:07:02 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "14:07:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:07:28 [INFO]   Training abgeschlossen in 7.02s (Backend: cuml)\n",
      "14:07:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:07:54 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "14:08:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:08:20 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "14:08:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:08:46 [INFO]   Training abgeschlossen in 7.46s (Backend: cuml)\n",
      "14:09:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:09:12 [INFO]   Training abgeschlossen in 7.48s (Backend: cuml)\n",
      "14:09:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:09:38 [INFO]   Training abgeschlossen in 7.65s (Backend: cuml)\n",
      "14:09:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:10:04 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "14:10:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:10:30 [INFO]   Training abgeschlossen in 7.80s (Backend: cuml)\n",
      "14:10:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:10:57 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "14:11:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:11:23 [INFO]   Training abgeschlossen in 7.89s (Backend: cuml)\n",
      "14:11:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:11:50 [INFO]   Training abgeschlossen in 8.13s (Backend: cuml)\n",
      "14:12:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:12:17 [INFO]   Training abgeschlossen in 8.20s (Backend: cuml)\n",
      "14:12:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:12:45 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "14:13:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:13:11 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "14:13:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:13:37 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "14:13:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:14:04 [INFO]   Training abgeschlossen in 8.53s (Backend: cuml)\n",
      "14:14:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:14:31 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "14:14:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:14:58 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "14:15:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:15:24 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "14:15:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:15:51 [INFO]   Training abgeschlossen in 9.09s (Backend: cuml)\n",
      "14:16:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:16:17 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "14:16:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:16:44 [INFO]   Training abgeschlossen in 9.15s (Backend: cuml)\n",
      "14:17:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:17:10 [INFO]   Training abgeschlossen in 9.07s (Backend: cuml)\n",
      "14:17:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:17:36 [INFO]   Training abgeschlossen in 9.19s (Backend: cuml)\n",
      "14:17:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:18:03 [INFO]   Training abgeschlossen in 9.26s (Backend: cuml)\n",
      "14:18:19 [INFO]     24,000 labeled → Accuracy: 0.8843 (Train: 9.3s, Query: 12.74s) | GPU: 2.8/8.0 GB\n",
      "14:18:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:18:29 [INFO]   Training abgeschlossen in 9.30s (Backend: cuml)\n",
      "14:18:33 [INFO]     Final: 24,000 labeled → Accuracy: 0.8840, F1: 0.8838\n",
      "14:18:33 [INFO]   Run 3/5\n",
      "14:18:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:18:38 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "14:18:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:18:59 [INFO]   Training abgeschlossen in 4.56s (Backend: cuml)\n",
      "14:19:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:19:19 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "14:19:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:19:41 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "14:19:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:20:02 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "14:20:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:20:24 [INFO]   Training abgeschlossen in 4.94s (Backend: cuml)\n",
      "14:20:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:20:47 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "14:21:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:21:10 [INFO]   Training abgeschlossen in 5.24s (Backend: cuml)\n",
      "14:21:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:21:33 [INFO]   Training abgeschlossen in 5.36s (Backend: cuml)\n",
      "14:21:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:21:56 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "14:22:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:22:20 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "14:22:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:22:44 [INFO]   Training abgeschlossen in 5.79s (Backend: cuml)\n",
      "14:23:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:23:08 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "14:23:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:23:33 [INFO]   Training abgeschlossen in 6.15s (Backend: cuml)\n",
      "14:23:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:23:57 [INFO]   Training abgeschlossen in 6.15s (Backend: cuml)\n",
      "14:24:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:24:22 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "14:24:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:24:47 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "14:25:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:25:12 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "14:25:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:25:38 [INFO]   Training abgeschlossen in 6.71s (Backend: cuml)\n",
      "14:25:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:26:03 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "14:26:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:26:29 [INFO]   Training abgeschlossen in 6.81s (Backend: cuml)\n",
      "14:26:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:26:54 [INFO]   Training abgeschlossen in 6.95s (Backend: cuml)\n",
      "14:27:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:27:20 [INFO]   Training abgeschlossen in 7.00s (Backend: cuml)\n",
      "14:27:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:27:47 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "14:28:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:28:13 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "14:28:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:28:39 [INFO]   Training abgeschlossen in 7.41s (Backend: cuml)\n",
      "14:28:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:29:05 [INFO]   Training abgeschlossen in 7.44s (Backend: cuml)\n",
      "14:29:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:29:32 [INFO]   Training abgeschlossen in 7.78s (Backend: cuml)\n",
      "14:29:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:29:58 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "14:30:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:30:24 [INFO]   Training abgeschlossen in 7.83s (Backend: cuml)\n",
      "14:30:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:30:51 [INFO]   Training abgeschlossen in 7.83s (Backend: cuml)\n",
      "14:31:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:31:18 [INFO]   Training abgeschlossen in 7.91s (Backend: cuml)\n",
      "14:31:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:31:45 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "14:32:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:32:12 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "14:32:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:32:40 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "14:32:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:33:06 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "14:33:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:33:33 [INFO]   Training abgeschlossen in 8.62s (Backend: cuml)\n",
      "14:33:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:33:59 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "14:34:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:34:26 [INFO]   Training abgeschlossen in 8.84s (Backend: cuml)\n",
      "14:34:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:34:52 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "14:35:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:35:19 [INFO]   Training abgeschlossen in 8.87s (Backend: cuml)\n",
      "14:35:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:35:45 [INFO]   Training abgeschlossen in 9.04s (Backend: cuml)\n",
      "14:36:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:36:12 [INFO]   Training abgeschlossen in 9.09s (Backend: cuml)\n",
      "14:36:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:36:38 [INFO]   Training abgeschlossen in 8.96s (Backend: cuml)\n",
      "14:36:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:37:04 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "14:37:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:37:30 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "14:37:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:37:56 [INFO]   Training abgeschlossen in 9.34s (Backend: cuml)\n",
      "14:38:13 [INFO]     24,000 labeled → Accuracy: 0.8839 (Train: 9.4s, Query: 12.73s) | GPU: 2.8/8.0 GB\n",
      "14:38:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:38:22 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "14:38:26 [INFO]     Final: 24,000 labeled → Accuracy: 0.8852, F1: 0.8849\n",
      "14:38:27 [INFO]   Run 4/5\n",
      "14:38:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:38:31 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "14:38:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:38:52 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "14:39:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:39:13 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "14:39:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:39:34 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "14:39:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:39:55 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "14:40:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:40:17 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "14:40:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:40:40 [INFO]   Training abgeschlossen in 5.08s (Backend: cuml)\n",
      "14:40:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:41:03 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "14:41:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:41:26 [INFO]   Training abgeschlossen in 5.46s (Backend: cuml)\n",
      "14:41:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:41:49 [INFO]   Training abgeschlossen in 5.46s (Backend: cuml)\n",
      "14:42:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:42:13 [INFO]   Training abgeschlossen in 5.73s (Backend: cuml)\n",
      "14:42:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:42:37 [INFO]   Training abgeschlossen in 5.75s (Backend: cuml)\n",
      "14:42:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:43:00 [INFO]   Training abgeschlossen in 5.90s (Backend: cuml)\n",
      "14:43:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:43:24 [INFO]   Training abgeschlossen in 6.08s (Backend: cuml)\n",
      "14:43:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:43:49 [INFO]   Training abgeschlossen in 6.16s (Backend: cuml)\n",
      "14:44:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:44:15 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "14:44:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:44:40 [INFO]   Training abgeschlossen in 6.42s (Backend: cuml)\n",
      "14:44:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:45:04 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "14:45:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:45:29 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "14:45:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:45:55 [INFO]   Training abgeschlossen in 6.76s (Backend: cuml)\n",
      "14:46:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:46:21 [INFO]   Training abgeschlossen in 7.07s (Backend: cuml)\n",
      "14:46:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:46:46 [INFO]   Training abgeschlossen in 6.95s (Backend: cuml)\n",
      "14:47:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:47:12 [INFO]   Training abgeschlossen in 7.14s (Backend: cuml)\n",
      "14:47:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:47:38 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "14:47:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:48:04 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "14:48:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:48:30 [INFO]   Training abgeschlossen in 7.32s (Backend: cuml)\n",
      "14:48:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:48:56 [INFO]   Training abgeschlossen in 7.44s (Backend: cuml)\n",
      "14:49:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:49:23 [INFO]   Training abgeschlossen in 7.60s (Backend: cuml)\n",
      "14:49:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:49:49 [INFO]   Training abgeschlossen in 7.67s (Backend: cuml)\n",
      "14:50:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:50:16 [INFO]   Training abgeschlossen in 7.86s (Backend: cuml)\n",
      "14:50:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:50:42 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "14:51:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:51:09 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "14:51:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:51:37 [INFO]   Training abgeschlossen in 8.05s (Backend: cuml)\n",
      "14:51:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:52:04 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "14:52:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:52:31 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "14:52:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:52:57 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "14:53:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:53:24 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "14:53:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:53:50 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "14:54:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:54:17 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "14:54:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:54:44 [INFO]   Training abgeschlossen in 8.83s (Backend: cuml)\n",
      "14:55:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:55:10 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "14:55:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:55:37 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "14:55:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:56:04 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "14:56:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:56:30 [INFO]   Training abgeschlossen in 9.01s (Backend: cuml)\n",
      "14:56:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:56:57 [INFO]   Training abgeschlossen in 9.01s (Backend: cuml)\n",
      "14:57:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:57:23 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "14:57:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:57:49 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "14:58:06 [INFO]     24,000 labeled → Accuracy: 0.8838 (Train: 9.2s, Query: 12.91s) | GPU: 2.8/8.0 GB\n",
      "14:58:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:58:15 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "14:58:19 [INFO]     Final: 24,000 labeled → Accuracy: 0.8835, F1: 0.8833\n",
      "14:58:19 [INFO]   Run 5/5\n",
      "14:58:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:58:24 [INFO]   Training abgeschlossen in 4.63s (Backend: cuml)\n",
      "14:58:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:58:45 [INFO]   Training abgeschlossen in 4.65s (Backend: cuml)\n",
      "14:59:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:59:05 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "14:59:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:59:27 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "14:59:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:59:49 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "15:00:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:00:11 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "15:00:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:00:34 [INFO]   Training abgeschlossen in 5.05s (Backend: cuml)\n",
      "15:00:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:00:57 [INFO]   Training abgeschlossen in 5.17s (Backend: cuml)\n",
      "15:01:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:01:19 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "15:01:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:01:43 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "15:02:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:02:07 [INFO]   Training abgeschlossen in 5.83s (Backend: cuml)\n",
      "15:02:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:02:31 [INFO]   Training abgeschlossen in 5.78s (Backend: cuml)\n",
      "15:02:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:02:55 [INFO]   Training abgeschlossen in 5.91s (Backend: cuml)\n",
      "15:03:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:03:20 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "15:03:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:03:44 [INFO]   Training abgeschlossen in 6.13s (Backend: cuml)\n",
      "15:04:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:04:10 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "15:04:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:04:35 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "15:04:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:05:00 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "15:05:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:05:25 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "15:05:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:05:50 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "15:06:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:06:16 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "15:06:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:06:42 [INFO]   Training abgeschlossen in 6.90s (Backend: cuml)\n",
      "15:07:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:07:07 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "15:07:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:07:33 [INFO]   Training abgeschlossen in 7.08s (Backend: cuml)\n",
      "15:07:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:07:59 [INFO]   Training abgeschlossen in 7.56s (Backend: cuml)\n",
      "15:08:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:08:26 [INFO]   Training abgeschlossen in 7.26s (Backend: cuml)\n",
      "15:08:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:08:52 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "15:09:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:09:18 [INFO]   Training abgeschlossen in 7.60s (Backend: cuml)\n",
      "15:09:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:09:44 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "15:10:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:10:10 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "15:10:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:10:37 [INFO]   Training abgeschlossen in 7.83s (Backend: cuml)\n",
      "15:10:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:11:04 [INFO]   Training abgeschlossen in 7.96s (Backend: cuml)\n",
      "15:11:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:11:32 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "15:11:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:11:59 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "15:12:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:12:26 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "15:12:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:12:53 [INFO]   Training abgeschlossen in 8.68s (Backend: cuml)\n",
      "15:13:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:13:20 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "15:13:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:13:46 [INFO]   Training abgeschlossen in 8.67s (Backend: cuml)\n",
      "15:14:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:14:13 [INFO]   Training abgeschlossen in 8.64s (Backend: cuml)\n",
      "15:14:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:14:39 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "15:14:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:15:06 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "15:15:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:15:33 [INFO]   Training abgeschlossen in 8.94s (Backend: cuml)\n",
      "15:15:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:15:59 [INFO]   Training abgeschlossen in 9.07s (Backend: cuml)\n",
      "15:16:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:16:25 [INFO]   Training abgeschlossen in 8.87s (Backend: cuml)\n",
      "15:16:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:16:52 [INFO]   Training abgeschlossen in 9.30s (Backend: cuml)\n",
      "15:17:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:17:18 [INFO]   Training abgeschlossen in 9.12s (Backend: cuml)\n",
      "15:17:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:17:44 [INFO]   Training abgeschlossen in 9.42s (Backend: cuml)\n",
      "15:18:01 [INFO]     24,000 labeled → Accuracy: 0.8833 (Train: 9.4s, Query: 12.51s) | GPU: 2.8/8.0 GB\n",
      "15:18:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:18:10 [INFO]   Training abgeschlossen in 9.30s (Backend: cuml)\n",
      "15:18:14 [INFO]     Final: 24,000 labeled → Accuracy: 0.8842, F1: 0.8839\n",
      "15:18:14 [INFO] \n",
      "GPU-SVM + Entropy Sampling - Budget: 60% (36,000 Samples)\n",
      "15:18:14 [INFO]   Run 1/5\n",
      "15:18:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:18:19 [INFO]   Training abgeschlossen in 4.60s (Backend: cuml)\n",
      "15:18:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:18:39 [INFO]   Training abgeschlossen in 4.64s (Backend: cuml)\n",
      "15:18:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:19:00 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "15:19:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:19:21 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "15:19:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:19:43 [INFO]   Training abgeschlossen in 4.67s (Backend: cuml)\n",
      "15:20:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:20:05 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "15:20:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:20:27 [INFO]   Training abgeschlossen in 5.07s (Backend: cuml)\n",
      "15:20:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:20:50 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "15:21:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:21:13 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "15:21:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:21:36 [INFO]   Training abgeschlossen in 5.52s (Backend: cuml)\n",
      "15:21:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:21:59 [INFO]   Training abgeschlossen in 5.81s (Backend: cuml)\n",
      "15:22:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:22:23 [INFO]   Training abgeschlossen in 5.71s (Backend: cuml)\n",
      "15:22:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:22:47 [INFO]   Training abgeschlossen in 6.05s (Backend: cuml)\n",
      "15:23:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:23:11 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "15:23:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:23:35 [INFO]   Training abgeschlossen in 6.16s (Backend: cuml)\n",
      "15:23:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:24:00 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "15:24:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:24:24 [INFO]   Training abgeschlossen in 6.39s (Backend: cuml)\n",
      "15:24:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:24:49 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "15:25:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:25:15 [INFO]   Training abgeschlossen in 6.59s (Backend: cuml)\n",
      "15:25:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:25:41 [INFO]   Training abgeschlossen in 6.89s (Backend: cuml)\n",
      "15:25:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:26:06 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "15:26:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:26:31 [INFO]   Training abgeschlossen in 6.99s (Backend: cuml)\n",
      "15:26:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:26:57 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "15:27:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:27:23 [INFO]   Training abgeschlossen in 7.12s (Backend: cuml)\n",
      "15:27:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:27:49 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "15:28:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:28:15 [INFO]   Training abgeschlossen in 7.33s (Backend: cuml)\n",
      "15:28:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:28:41 [INFO]   Training abgeschlossen in 7.77s (Backend: cuml)\n",
      "15:28:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:29:07 [INFO]   Training abgeschlossen in 7.65s (Backend: cuml)\n",
      "15:29:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:29:34 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "15:29:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:30:00 [INFO]   Training abgeschlossen in 7.82s (Backend: cuml)\n",
      "15:30:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:30:27 [INFO]   Training abgeschlossen in 7.86s (Backend: cuml)\n",
      "15:30:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:30:54 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "15:31:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:31:22 [INFO]   Training abgeschlossen in 8.06s (Backend: cuml)\n",
      "15:31:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:31:49 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "15:32:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:32:16 [INFO]   Training abgeschlossen in 8.28s (Backend: cuml)\n",
      "15:32:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:32:42 [INFO]   Training abgeschlossen in 8.65s (Backend: cuml)\n",
      "15:33:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:33:09 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "15:33:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:33:36 [INFO]   Training abgeschlossen in 8.83s (Backend: cuml)\n",
      "15:33:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:34:02 [INFO]   Training abgeschlossen in 8.71s (Backend: cuml)\n",
      "15:34:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:34:29 [INFO]   Training abgeschlossen in 8.84s (Backend: cuml)\n",
      "15:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:34:55 [INFO]   Training abgeschlossen in 8.96s (Backend: cuml)\n",
      "15:35:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:35:22 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "15:35:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:35:49 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "15:36:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:36:15 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "15:36:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:36:41 [INFO]   Training abgeschlossen in 9.05s (Backend: cuml)\n",
      "15:36:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:37:08 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "15:37:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:37:34 [INFO]   Training abgeschlossen in 9.39s (Backend: cuml)\n",
      "15:37:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:38:01 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "15:38:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:38:27 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "15:38:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:38:53 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "15:39:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:39:19 [INFO]   Training abgeschlossen in 9.76s (Backend: cuml)\n",
      "15:39:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:39:45 [INFO]   Training abgeschlossen in 9.57s (Backend: cuml)\n",
      "15:40:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:40:11 [INFO]   Training abgeschlossen in 9.77s (Backend: cuml)\n",
      "15:40:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:40:37 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "15:40:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:41:03 [INFO]   Training abgeschlossen in 10.03s (Backend: cuml)\n",
      "15:41:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:41:30 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "15:41:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:41:56 [INFO]   Training abgeschlossen in 10.19s (Backend: cuml)\n",
      "15:42:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:42:21 [INFO]   Training abgeschlossen in 10.43s (Backend: cuml)\n",
      "15:42:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:42:48 [INFO]   Training abgeschlossen in 10.45s (Backend: cuml)\n",
      "15:43:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:43:14 [INFO]   Training abgeschlossen in 10.58s (Backend: cuml)\n",
      "15:43:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:43:39 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "15:43:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:44:05 [INFO]   Training abgeschlossen in 10.86s (Backend: cuml)\n",
      "15:44:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:44:31 [INFO]   Training abgeschlossen in 11.14s (Backend: cuml)\n",
      "15:44:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:44:57 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "15:45:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:45:23 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "15:45:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:45:48 [INFO]   Training abgeschlossen in 11.25s (Backend: cuml)\n",
      "15:46:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:46:14 [INFO]   Training abgeschlossen in 11.39s (Backend: cuml)\n",
      "15:46:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:46:40 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "15:46:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:47:05 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "15:47:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:47:31 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "15:47:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:47:56 [INFO]   Training abgeschlossen in 11.68s (Backend: cuml)\n",
      "15:48:09 [INFO]     36,000 labeled → Accuracy: 0.8854 (Train: 11.7s, Query: 9.25s) | GPU: 2.8/8.0 GB\n",
      "15:48:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:48:21 [INFO]   Training abgeschlossen in 11.84s (Backend: cuml)\n",
      "15:48:26 [INFO]     Final: 36,000 labeled → Accuracy: 0.8854, F1: 0.8847\n",
      "15:48:26 [INFO]   Run 2/5\n",
      "15:48:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:48:30 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "15:48:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:48:51 [INFO]   Training abgeschlossen in 4.65s (Backend: cuml)\n",
      "15:49:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:49:12 [INFO]   Training abgeschlossen in 4.70s (Backend: cuml)\n",
      "15:49:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:49:34 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "15:49:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:49:56 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "15:50:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:50:18 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "15:50:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:50:40 [INFO]   Training abgeschlossen in 5.04s (Backend: cuml)\n",
      "15:50:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:51:02 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "15:51:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:51:25 [INFO]   Training abgeschlossen in 5.36s (Backend: cuml)\n",
      "15:51:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:51:48 [INFO]   Training abgeschlossen in 5.45s (Backend: cuml)\n",
      "15:52:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:52:11 [INFO]   Training abgeschlossen in 5.73s (Backend: cuml)\n",
      "15:52:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:52:35 [INFO]   Training abgeschlossen in 5.73s (Backend: cuml)\n",
      "15:52:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:52:59 [INFO]   Training abgeschlossen in 5.90s (Backend: cuml)\n",
      "15:53:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:53:24 [INFO]   Training abgeschlossen in 6.16s (Backend: cuml)\n",
      "15:53:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:53:48 [INFO]   Training abgeschlossen in 6.11s (Backend: cuml)\n",
      "15:54:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:54:13 [INFO]   Training abgeschlossen in 6.39s (Backend: cuml)\n",
      "15:54:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:54:38 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "15:54:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:55:03 [INFO]   Training abgeschlossen in 6.48s (Backend: cuml)\n",
      "15:55:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:55:28 [INFO]   Training abgeschlossen in 6.54s (Backend: cuml)\n",
      "15:55:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:55:54 [INFO]   Training abgeschlossen in 6.71s (Backend: cuml)\n",
      "15:56:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:56:19 [INFO]   Training abgeschlossen in 7.02s (Backend: cuml)\n",
      "15:56:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:56:45 [INFO]   Training abgeschlossen in 6.92s (Backend: cuml)\n",
      "15:57:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:57:11 [INFO]   Training abgeschlossen in 7.09s (Backend: cuml)\n",
      "15:57:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:57:37 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "15:57:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:58:03 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "15:58:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:58:29 [INFO]   Training abgeschlossen in 7.33s (Backend: cuml)\n",
      "15:58:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:58:55 [INFO]   Training abgeschlossen in 7.45s (Backend: cuml)\n",
      "15:59:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:59:21 [INFO]   Training abgeschlossen in 7.64s (Backend: cuml)\n",
      "15:59:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:59:48 [INFO]   Training abgeschlossen in 7.67s (Backend: cuml)\n",
      "16:00:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:00:14 [INFO]   Training abgeschlossen in 8.06s (Backend: cuml)\n",
      "16:00:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:00:41 [INFO]   Training abgeschlossen in 7.83s (Backend: cuml)\n",
      "16:01:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:01:08 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "16:01:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:01:35 [INFO]   Training abgeschlossen in 8.02s (Backend: cuml)\n",
      "16:01:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:02:02 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "16:02:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:02:30 [INFO]   Training abgeschlossen in 8.28s (Backend: cuml)\n",
      "16:02:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:02:56 [INFO]   Training abgeschlossen in 8.43s (Backend: cuml)\n",
      "16:03:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:03:23 [INFO]   Training abgeschlossen in 8.44s (Backend: cuml)\n",
      "16:03:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:03:49 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "16:04:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:04:16 [INFO]   Training abgeschlossen in 8.75s (Backend: cuml)\n",
      "16:04:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:04:43 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "16:05:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:05:09 [INFO]   Training abgeschlossen in 9.14s (Backend: cuml)\n",
      "16:05:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:05:36 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "16:05:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:06:03 [INFO]   Training abgeschlossen in 9.18s (Backend: cuml)\n",
      "16:06:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:06:29 [INFO]   Training abgeschlossen in 8.93s (Backend: cuml)\n",
      "16:06:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:06:56 [INFO]   Training abgeschlossen in 9.03s (Backend: cuml)\n",
      "16:07:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:07:22 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "16:07:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:07:48 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "16:08:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:08:15 [INFO]   Training abgeschlossen in 9.33s (Backend: cuml)\n",
      "16:08:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:08:41 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "16:08:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:09:07 [INFO]   Training abgeschlossen in 9.63s (Backend: cuml)\n",
      "16:09:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:09:34 [INFO]   Training abgeschlossen in 9.91s (Backend: cuml)\n",
      "16:09:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:10:00 [INFO]   Training abgeschlossen in 9.83s (Backend: cuml)\n",
      "16:10:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:10:26 [INFO]   Training abgeschlossen in 9.77s (Backend: cuml)\n",
      "16:10:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:10:52 [INFO]   Training abgeschlossen in 9.91s (Backend: cuml)\n",
      "16:11:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:11:19 [INFO]   Training abgeschlossen in 10.05s (Backend: cuml)\n",
      "16:11:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:11:45 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "16:12:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:12:11 [INFO]   Training abgeschlossen in 10.19s (Backend: cuml)\n",
      "16:12:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:12:37 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "16:12:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:13:03 [INFO]   Training abgeschlossen in 10.78s (Backend: cuml)\n",
      "16:13:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:13:29 [INFO]   Training abgeschlossen in 10.68s (Backend: cuml)\n",
      "16:13:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:13:55 [INFO]   Training abgeschlossen in 10.83s (Backend: cuml)\n",
      "16:14:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:14:21 [INFO]   Training abgeschlossen in 10.82s (Backend: cuml)\n",
      "16:14:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:14:46 [INFO]   Training abgeschlossen in 10.86s (Backend: cuml)\n",
      "16:15:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:15:13 [INFO]   Training abgeschlossen in 11.08s (Backend: cuml)\n",
      "16:15:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:15:38 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "16:15:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:16:04 [INFO]   Training abgeschlossen in 11.28s (Backend: cuml)\n",
      "16:16:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:16:30 [INFO]   Training abgeschlossen in 11.43s (Backend: cuml)\n",
      "16:16:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:16:56 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "16:17:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:17:21 [INFO]   Training abgeschlossen in 11.63s (Backend: cuml)\n",
      "16:17:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:17:47 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "16:18:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:18:12 [INFO]   Training abgeschlossen in 11.91s (Backend: cuml)\n",
      "16:18:26 [INFO]     36,000 labeled → Accuracy: 0.8853 (Train: 11.9s, Query: 9.39s) | GPU: 2.8/8.0 GB\n",
      "16:18:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:18:38 [INFO]   Training abgeschlossen in 11.88s (Backend: cuml)\n",
      "16:18:42 [INFO]     Final: 36,000 labeled → Accuracy: 0.8860, F1: 0.8853\n",
      "16:18:42 [INFO]   Run 3/5\n",
      "16:18:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:18:47 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "16:19:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:19:07 [INFO]   Training abgeschlossen in 4.63s (Backend: cuml)\n",
      "16:19:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:19:28 [INFO]   Training abgeschlossen in 4.66s (Backend: cuml)\n",
      "16:19:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:19:49 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "16:20:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:20:11 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "16:20:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:20:33 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "16:20:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:20:55 [INFO]   Training abgeschlossen in 5.15s (Backend: cuml)\n",
      "16:21:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:21:18 [INFO]   Training abgeschlossen in 5.20s (Backend: cuml)\n",
      "16:21:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:21:41 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "16:21:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:22:04 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "16:22:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:22:28 [INFO]   Training abgeschlossen in 5.57s (Backend: cuml)\n",
      "16:22:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:22:52 [INFO]   Training abgeschlossen in 5.81s (Backend: cuml)\n",
      "16:23:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:23:16 [INFO]   Training abgeschlossen in 5.85s (Backend: cuml)\n",
      "16:23:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:23:40 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "16:23:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:24:05 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "16:24:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:24:30 [INFO]   Training abgeschlossen in 6.28s (Backend: cuml)\n",
      "16:24:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:24:55 [INFO]   Training abgeschlossen in 6.49s (Backend: cuml)\n",
      "16:25:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:25:20 [INFO]   Training abgeschlossen in 6.49s (Backend: cuml)\n",
      "16:25:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:25:45 [INFO]   Training abgeschlossen in 6.74s (Backend: cuml)\n",
      "16:26:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:26:11 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "16:26:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:26:36 [INFO]   Training abgeschlossen in 6.86s (Backend: cuml)\n",
      "16:26:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:27:02 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "16:27:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:27:28 [INFO]   Training abgeschlossen in 7.07s (Backend: cuml)\n",
      "16:27:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:27:55 [INFO]   Training abgeschlossen in 7.12s (Backend: cuml)\n",
      "16:28:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:28:21 [INFO]   Training abgeschlossen in 7.17s (Backend: cuml)\n",
      "16:28:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:28:48 [INFO]   Training abgeschlossen in 7.56s (Backend: cuml)\n",
      "16:29:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:29:15 [INFO]   Training abgeschlossen in 7.46s (Backend: cuml)\n",
      "16:29:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:29:42 [INFO]   Training abgeschlossen in 7.74s (Backend: cuml)\n",
      "16:30:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:30:09 [INFO]   Training abgeschlossen in 7.63s (Backend: cuml)\n",
      "16:30:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:30:34 [INFO]   Training abgeschlossen in 7.78s (Backend: cuml)\n",
      "16:30:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:31:01 [INFO]   Training abgeschlossen in 7.84s (Backend: cuml)\n",
      "16:31:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:31:27 [INFO]   Training abgeschlossen in 7.91s (Backend: cuml)\n",
      "16:31:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:31:55 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "16:32:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:32:22 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "16:32:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:32:49 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "16:33:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:33:16 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "16:33:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:33:42 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "16:34:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:34:09 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "16:34:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:34:35 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "16:34:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:35:02 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "16:35:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:35:28 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "16:35:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:35:55 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "16:36:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:36:22 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "16:36:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:36:48 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "16:37:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:37:14 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "16:37:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:37:41 [INFO]   Training abgeschlossen in 9.19s (Backend: cuml)\n",
      "16:37:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:38:07 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "16:38:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:38:33 [INFO]   Training abgeschlossen in 9.57s (Backend: cuml)\n",
      "16:38:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:38:59 [INFO]   Training abgeschlossen in 9.42s (Backend: cuml)\n",
      "16:39:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:39:25 [INFO]   Training abgeschlossen in 9.49s (Backend: cuml)\n",
      "16:39:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:39:52 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "16:40:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:40:18 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "16:40:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:40:44 [INFO]   Training abgeschlossen in 9.84s (Backend: cuml)\n",
      "16:41:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:41:10 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "16:41:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:41:36 [INFO]   Training abgeschlossen in 10.21s (Backend: cuml)\n",
      "16:41:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:42:02 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "16:42:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:42:29 [INFO]   Training abgeschlossen in 10.45s (Backend: cuml)\n",
      "16:42:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:42:55 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "16:43:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:43:21 [INFO]   Training abgeschlossen in 10.68s (Backend: cuml)\n",
      "16:43:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:43:46 [INFO]   Training abgeschlossen in 10.57s (Backend: cuml)\n",
      "16:44:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:44:12 [INFO]   Training abgeschlossen in 10.64s (Backend: cuml)\n",
      "16:44:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:44:38 [INFO]   Training abgeschlossen in 10.91s (Backend: cuml)\n",
      "16:44:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:45:04 [INFO]   Training abgeschlossen in 10.94s (Backend: cuml)\n",
      "16:45:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:45:30 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "16:45:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:45:56 [INFO]   Training abgeschlossen in 11.15s (Backend: cuml)\n",
      "16:46:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:46:21 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "16:46:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:46:47 [INFO]   Training abgeschlossen in 11.39s (Backend: cuml)\n",
      "16:47:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:47:13 [INFO]   Training abgeschlossen in 11.44s (Backend: cuml)\n",
      "16:47:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:47:38 [INFO]   Training abgeschlossen in 11.70s (Backend: cuml)\n",
      "16:47:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:48:04 [INFO]   Training abgeschlossen in 11.57s (Backend: cuml)\n",
      "16:48:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:48:29 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "16:48:43 [INFO]     36,000 labeled → Accuracy: 0.8860 (Train: 11.8s, Query: 9.30s) | GPU: 2.8/8.0 GB\n",
      "16:48:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:48:55 [INFO]   Training abgeschlossen in 11.87s (Backend: cuml)\n",
      "16:48:59 [INFO]     Final: 36,000 labeled → Accuracy: 0.8857, F1: 0.8850\n",
      "16:48:59 [INFO]   Run 4/5\n",
      "16:48:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:49:04 [INFO]   Training abgeschlossen in 4.54s (Backend: cuml)\n",
      "16:49:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:49:24 [INFO]   Training abgeschlossen in 4.65s (Backend: cuml)\n",
      "16:49:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:49:45 [INFO]   Training abgeschlossen in 4.67s (Backend: cuml)\n",
      "16:50:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:50:07 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "16:50:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:50:29 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "16:50:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:50:51 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "16:51:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:51:13 [INFO]   Training abgeschlossen in 5.08s (Backend: cuml)\n",
      "16:51:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:51:36 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "16:51:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:51:59 [INFO]   Training abgeschlossen in 5.37s (Backend: cuml)\n",
      "16:52:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:52:22 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "16:52:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:52:46 [INFO]   Training abgeschlossen in 5.79s (Backend: cuml)\n",
      "16:53:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:53:10 [INFO]   Training abgeschlossen in 5.71s (Backend: cuml)\n",
      "16:53:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:53:34 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "16:53:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:53:58 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "16:54:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:54:23 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "16:54:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:54:48 [INFO]   Training abgeschlossen in 6.36s (Backend: cuml)\n",
      "16:55:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:55:13 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "16:55:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:55:39 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "16:55:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:56:04 [INFO]   Training abgeschlossen in 6.58s (Backend: cuml)\n",
      "16:56:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:56:29 [INFO]   Training abgeschlossen in 6.86s (Backend: cuml)\n",
      "16:56:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:56:55 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "16:57:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:57:20 [INFO]   Training abgeschlossen in 7.15s (Backend: cuml)\n",
      "16:57:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:57:46 [INFO]   Training abgeschlossen in 7.05s (Backend: cuml)\n",
      "16:58:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:58:11 [INFO]   Training abgeschlossen in 7.11s (Backend: cuml)\n",
      "16:58:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:58:37 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "16:58:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:59:03 [INFO]   Training abgeschlossen in 7.31s (Backend: cuml)\n",
      "16:59:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:59:29 [INFO]   Training abgeschlossen in 7.59s (Backend: cuml)\n",
      "16:59:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:59:55 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "17:00:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:00:21 [INFO]   Training abgeschlossen in 7.90s (Backend: cuml)\n",
      "17:00:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:00:48 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "17:01:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:01:14 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "17:01:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:01:41 [INFO]   Training abgeschlossen in 7.95s (Backend: cuml)\n",
      "17:01:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:02:07 [INFO]   Training abgeschlossen in 8.07s (Backend: cuml)\n",
      "17:02:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:02:35 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "17:02:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:03:02 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "17:03:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:03:28 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "17:03:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:03:55 [INFO]   Training abgeschlossen in 8.44s (Backend: cuml)\n",
      "17:04:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:04:22 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "17:04:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:04:49 [INFO]   Training abgeschlossen in 8.64s (Backend: cuml)\n",
      "17:05:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:05:16 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "17:05:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:05:42 [INFO]   Training abgeschlossen in 8.87s (Backend: cuml)\n",
      "17:06:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:06:09 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "17:06:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:06:36 [INFO]   Training abgeschlossen in 9.09s (Backend: cuml)\n",
      "17:06:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:07:02 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "17:07:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:07:28 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "17:07:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:07:54 [INFO]   Training abgeschlossen in 9.12s (Backend: cuml)\n",
      "17:08:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:08:20 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "17:08:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:08:47 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "17:09:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:09:13 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "17:09:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:09:39 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "17:09:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:10:05 [INFO]   Training abgeschlossen in 9.82s (Backend: cuml)\n",
      "17:10:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:10:31 [INFO]   Training abgeschlossen in 9.77s (Backend: cuml)\n",
      "17:10:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:10:57 [INFO]   Training abgeschlossen in 9.73s (Backend: cuml)\n",
      "17:11:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:11:24 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "17:11:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:11:49 [INFO]   Training abgeschlossen in 10.07s (Backend: cuml)\n",
      "17:12:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:12:15 [INFO]   Training abgeschlossen in 10.21s (Backend: cuml)\n",
      "17:12:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:12:42 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "17:12:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:13:08 [INFO]   Training abgeschlossen in 10.41s (Backend: cuml)\n",
      "17:13:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:13:34 [INFO]   Training abgeschlossen in 10.51s (Backend: cuml)\n",
      "17:13:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:14:00 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "17:14:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:14:26 [INFO]   Training abgeschlossen in 10.66s (Backend: cuml)\n",
      "17:14:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:14:52 [INFO]   Training abgeschlossen in 10.79s (Backend: cuml)\n",
      "17:15:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:15:18 [INFO]   Training abgeschlossen in 11.02s (Backend: cuml)\n",
      "17:15:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:15:43 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "17:15:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:16:09 [INFO]   Training abgeschlossen in 11.32s (Backend: cuml)\n",
      "17:16:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:16:35 [INFO]   Training abgeschlossen in 11.28s (Backend: cuml)\n",
      "17:16:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:17:01 [INFO]   Training abgeschlossen in 11.42s (Backend: cuml)\n",
      "17:17:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:17:27 [INFO]   Training abgeschlossen in 11.44s (Backend: cuml)\n",
      "17:17:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:17:52 [INFO]   Training abgeschlossen in 11.65s (Backend: cuml)\n",
      "17:18:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:18:18 [INFO]   Training abgeschlossen in 11.75s (Backend: cuml)\n",
      "17:18:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:18:43 [INFO]   Training abgeschlossen in 11.67s (Backend: cuml)\n",
      "17:18:57 [INFO]     36,000 labeled → Accuracy: 0.8858 (Train: 11.7s, Query: 9.39s) | GPU: 2.8/8.0 GB\n",
      "17:18:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:19:09 [INFO]   Training abgeschlossen in 12.12s (Backend: cuml)\n",
      "17:19:13 [INFO]     Final: 36,000 labeled → Accuracy: 0.8849, F1: 0.8842\n",
      "17:19:13 [INFO]   Run 5/5\n",
      "17:19:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:19:18 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "17:19:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:19:38 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "17:19:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:19:59 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "17:20:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:20:21 [INFO]   Training abgeschlossen in 4.67s (Backend: cuml)\n",
      "17:20:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:20:42 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "17:20:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:21:04 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "17:21:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:21:27 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "17:21:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:21:50 [INFO]   Training abgeschlossen in 5.17s (Backend: cuml)\n",
      "17:22:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:22:12 [INFO]   Training abgeschlossen in 5.43s (Backend: cuml)\n",
      "17:22:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:22:36 [INFO]   Training abgeschlossen in 5.51s (Backend: cuml)\n",
      "17:22:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:22:59 [INFO]   Training abgeschlossen in 5.70s (Backend: cuml)\n",
      "17:23:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:23:24 [INFO]   Training abgeschlossen in 5.77s (Backend: cuml)\n",
      "17:23:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:23:47 [INFO]   Training abgeschlossen in 5.88s (Backend: cuml)\n",
      "17:24:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:24:12 [INFO]   Training abgeschlossen in 6.29s (Backend: cuml)\n",
      "17:24:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:24:36 [INFO]   Training abgeschlossen in 6.14s (Backend: cuml)\n",
      "17:24:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:25:01 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "17:25:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:25:26 [INFO]   Training abgeschlossen in 6.35s (Backend: cuml)\n",
      "17:25:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:25:51 [INFO]   Training abgeschlossen in 6.47s (Backend: cuml)\n",
      "17:26:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:26:16 [INFO]   Training abgeschlossen in 6.61s (Backend: cuml)\n",
      "17:26:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:26:41 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "17:26:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:27:06 [INFO]   Training abgeschlossen in 6.99s (Backend: cuml)\n",
      "17:27:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:27:33 [INFO]   Training abgeschlossen in 7.00s (Backend: cuml)\n",
      "17:27:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:27:59 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "17:28:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:28:24 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "17:28:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:28:50 [INFO]   Training abgeschlossen in 7.21s (Backend: cuml)\n",
      "17:29:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:29:16 [INFO]   Training abgeschlossen in 7.29s (Backend: cuml)\n",
      "17:29:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:29:42 [INFO]   Training abgeschlossen in 7.43s (Backend: cuml)\n",
      "17:30:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:30:09 [INFO]   Training abgeschlossen in 7.59s (Backend: cuml)\n",
      "17:30:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:30:35 [INFO]   Training abgeschlossen in 7.64s (Backend: cuml)\n",
      "17:30:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:31:01 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "17:31:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:31:28 [INFO]   Training abgeschlossen in 7.83s (Backend: cuml)\n",
      "17:31:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:31:55 [INFO]   Training abgeschlossen in 8.02s (Backend: cuml)\n",
      "17:32:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:32:23 [INFO]   Training abgeschlossen in 8.05s (Backend: cuml)\n",
      "17:32:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:32:50 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "17:33:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:33:18 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "17:33:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:33:44 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "17:34:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:34:10 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "17:34:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:34:37 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "17:34:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:35:03 [INFO]   Training abgeschlossen in 9.09s (Backend: cuml)\n",
      "17:35:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:35:30 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "17:35:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:35:57 [INFO]   Training abgeschlossen in 9.06s (Backend: cuml)\n",
      "17:36:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:36:23 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "17:36:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:36:50 [INFO]   Training abgeschlossen in 9.11s (Backend: cuml)\n",
      "17:37:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:37:16 [INFO]   Training abgeschlossen in 8.90s (Backend: cuml)\n",
      "17:37:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:37:42 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "17:37:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:38:09 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "17:38:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:38:35 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "17:38:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:39:01 [INFO]   Training abgeschlossen in 9.58s (Backend: cuml)\n",
      "17:39:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:39:28 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "17:39:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:39:54 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "17:40:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:40:21 [INFO]   Training abgeschlossen in 9.77s (Backend: cuml)\n",
      "17:40:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:40:47 [INFO]   Training abgeschlossen in 9.72s (Backend: cuml)\n",
      "17:41:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:41:13 [INFO]   Training abgeschlossen in 9.72s (Backend: cuml)\n",
      "17:41:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:41:39 [INFO]   Training abgeschlossen in 9.91s (Backend: cuml)\n",
      "17:41:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:42:05 [INFO]   Training abgeschlossen in 10.10s (Backend: cuml)\n",
      "17:42:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:42:31 [INFO]   Training abgeschlossen in 10.07s (Backend: cuml)\n",
      "17:42:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:42:57 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "17:43:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:43:23 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "17:43:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:43:49 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "17:44:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:44:15 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "17:44:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:44:41 [INFO]   Training abgeschlossen in 10.65s (Backend: cuml)\n",
      "17:44:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:45:07 [INFO]   Training abgeschlossen in 10.82s (Backend: cuml)\n",
      "17:45:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:45:32 [INFO]   Training abgeschlossen in 10.93s (Backend: cuml)\n",
      "17:45:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:45:58 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "17:46:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:46:24 [INFO]   Training abgeschlossen in 11.14s (Backend: cuml)\n",
      "17:46:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:46:50 [INFO]   Training abgeschlossen in 11.23s (Backend: cuml)\n",
      "17:47:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:47:15 [INFO]   Training abgeschlossen in 11.31s (Backend: cuml)\n",
      "17:47:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:47:41 [INFO]   Training abgeschlossen in 11.29s (Backend: cuml)\n",
      "17:47:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:48:06 [INFO]   Training abgeschlossen in 11.47s (Backend: cuml)\n",
      "17:48:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:48:31 [INFO]   Training abgeschlossen in 11.62s (Backend: cuml)\n",
      "17:48:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:48:57 [INFO]   Training abgeschlossen in 11.87s (Backend: cuml)\n",
      "17:49:10 [INFO]     36,000 labeled → Accuracy: 0.8856 (Train: 11.9s, Query: 9.21s) | GPU: 2.8/8.0 GB\n",
      "17:49:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:49:23 [INFO]   Training abgeschlossen in 11.84s (Backend: cuml)\n",
      "17:49:27 [INFO]     Final: 36,000 labeled → Accuracy: 0.8856, F1: 0.8848\n",
      "17:49:27 [INFO] \n",
      "GPU-SVM + Entropy Sampling - Budget: 80% (48,000 Samples)\n",
      "17:49:27 [INFO]   Run 1/5\n",
      "17:49:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:49:31 [INFO]   Training abgeschlossen in 4.57s (Backend: cuml)\n",
      "17:49:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:49:52 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "17:50:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:50:13 [INFO]   Training abgeschlossen in 4.68s (Backend: cuml)\n",
      "17:50:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:50:34 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "17:50:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:50:55 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "17:51:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:51:17 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "17:51:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:51:40 [INFO]   Training abgeschlossen in 5.08s (Backend: cuml)\n",
      "17:51:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:52:03 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "17:52:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:52:25 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "17:52:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:52:48 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "17:53:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:53:12 [INFO]   Training abgeschlossen in 5.83s (Backend: cuml)\n",
      "17:53:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:53:36 [INFO]   Training abgeschlossen in 5.76s (Backend: cuml)\n",
      "17:53:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:54:00 [INFO]   Training abgeschlossen in 5.87s (Backend: cuml)\n",
      "17:54:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:54:24 [INFO]   Training abgeschlossen in 6.01s (Backend: cuml)\n",
      "17:54:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:54:49 [INFO]   Training abgeschlossen in 6.41s (Backend: cuml)\n",
      "17:55:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:55:14 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "17:55:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:55:39 [INFO]   Training abgeschlossen in 6.42s (Backend: cuml)\n",
      "17:55:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:56:04 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "17:56:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:56:29 [INFO]   Training abgeschlossen in 6.57s (Backend: cuml)\n",
      "17:56:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:56:54 [INFO]   Training abgeschlossen in 6.86s (Backend: cuml)\n",
      "17:57:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:57:20 [INFO]   Training abgeschlossen in 6.85s (Backend: cuml)\n",
      "17:57:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:57:46 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "17:58:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:58:12 [INFO]   Training abgeschlossen in 7.06s (Backend: cuml)\n",
      "17:58:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:58:38 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "17:58:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:59:04 [INFO]   Training abgeschlossen in 7.30s (Backend: cuml)\n",
      "17:59:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:59:30 [INFO]   Training abgeschlossen in 7.36s (Backend: cuml)\n",
      "17:59:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:59:56 [INFO]   Training abgeschlossen in 7.52s (Backend: cuml)\n",
      "18:00:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:00:22 [INFO]   Training abgeschlossen in 7.61s (Backend: cuml)\n",
      "18:00:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:00:48 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "18:01:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:01:14 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "18:01:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:01:41 [INFO]   Training abgeschlossen in 8.07s (Backend: cuml)\n",
      "18:02:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:02:08 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "18:02:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:02:36 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "18:02:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:03:03 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "18:03:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:03:30 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "18:03:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:03:57 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "18:04:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:04:24 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "18:04:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:04:51 [INFO]   Training abgeschlossen in 8.60s (Backend: cuml)\n",
      "18:05:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:05:17 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "18:05:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:05:44 [INFO]   Training abgeschlossen in 8.83s (Backend: cuml)\n",
      "18:06:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:06:11 [INFO]   Training abgeschlossen in 8.90s (Backend: cuml)\n",
      "18:06:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:06:37 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "18:06:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:07:04 [INFO]   Training abgeschlossen in 9.14s (Backend: cuml)\n",
      "18:07:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:07:31 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "18:07:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:07:57 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "18:08:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:08:23 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "18:08:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:08:50 [INFO]   Training abgeschlossen in 9.22s (Backend: cuml)\n",
      "18:09:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:09:16 [INFO]   Training abgeschlossen in 9.30s (Backend: cuml)\n",
      "18:09:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:09:42 [INFO]   Training abgeschlossen in 9.50s (Backend: cuml)\n",
      "18:09:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:10:08 [INFO]   Training abgeschlossen in 9.50s (Backend: cuml)\n",
      "18:10:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:10:35 [INFO]   Training abgeschlossen in 9.97s (Backend: cuml)\n",
      "18:10:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:11:01 [INFO]   Training abgeschlossen in 9.59s (Backend: cuml)\n",
      "18:11:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:11:27 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "18:11:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:11:53 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "18:12:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:12:19 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "18:12:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:12:45 [INFO]   Training abgeschlossen in 10.12s (Backend: cuml)\n",
      "18:13:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:13:11 [INFO]   Training abgeschlossen in 10.26s (Backend: cuml)\n",
      "18:13:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:13:37 [INFO]   Training abgeschlossen in 10.38s (Backend: cuml)\n",
      "18:13:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:14:04 [INFO]   Training abgeschlossen in 10.54s (Backend: cuml)\n",
      "18:14:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:14:30 [INFO]   Training abgeschlossen in 10.74s (Backend: cuml)\n",
      "18:14:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:14:55 [INFO]   Training abgeschlossen in 10.71s (Backend: cuml)\n",
      "18:15:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:15:21 [INFO]   Training abgeschlossen in 10.85s (Backend: cuml)\n",
      "18:15:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:15:47 [INFO]   Training abgeschlossen in 10.88s (Backend: cuml)\n",
      "18:16:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:16:13 [INFO]   Training abgeschlossen in 11.02s (Backend: cuml)\n",
      "18:16:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:16:38 [INFO]   Training abgeschlossen in 11.17s (Backend: cuml)\n",
      "18:16:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:17:04 [INFO]   Training abgeschlossen in 11.28s (Backend: cuml)\n",
      "18:17:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:17:30 [INFO]   Training abgeschlossen in 11.49s (Backend: cuml)\n",
      "18:17:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:17:56 [INFO]   Training abgeschlossen in 11.53s (Backend: cuml)\n",
      "18:18:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:18:22 [INFO]   Training abgeschlossen in 11.72s (Backend: cuml)\n",
      "18:18:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:18:47 [INFO]   Training abgeschlossen in 11.65s (Backend: cuml)\n",
      "18:19:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:19:13 [INFO]   Training abgeschlossen in 11.95s (Backend: cuml)\n",
      "18:19:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:19:38 [INFO]   Training abgeschlossen in 11.79s (Backend: cuml)\n",
      "18:19:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:20:03 [INFO]   Training abgeschlossen in 12.01s (Backend: cuml)\n",
      "18:20:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:20:29 [INFO]   Training abgeschlossen in 12.17s (Backend: cuml)\n",
      "18:20:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:20:54 [INFO]   Training abgeschlossen in 12.29s (Backend: cuml)\n",
      "18:21:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:21:20 [INFO]   Training abgeschlossen in 12.40s (Backend: cuml)\n",
      "18:21:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:21:45 [INFO]   Training abgeschlossen in 12.31s (Backend: cuml)\n",
      "18:21:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:22:10 [INFO]   Training abgeschlossen in 12.70s (Backend: cuml)\n",
      "18:22:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:22:35 [INFO]   Training abgeschlossen in 12.46s (Backend: cuml)\n",
      "18:22:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:23:00 [INFO]   Training abgeschlossen in 12.63s (Backend: cuml)\n",
      "18:23:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:23:25 [INFO]   Training abgeschlossen in 12.76s (Backend: cuml)\n",
      "18:23:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:23:50 [INFO]   Training abgeschlossen in 12.78s (Backend: cuml)\n",
      "18:24:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:24:14 [INFO]   Training abgeschlossen in 13.19s (Backend: cuml)\n",
      "18:24:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:24:39 [INFO]   Training abgeschlossen in 13.00s (Backend: cuml)\n",
      "18:24:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:25:03 [INFO]   Training abgeschlossen in 13.04s (Backend: cuml)\n",
      "18:25:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:25:28 [INFO]   Training abgeschlossen in 13.09s (Backend: cuml)\n",
      "18:25:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:25:52 [INFO]   Training abgeschlossen in 13.16s (Backend: cuml)\n",
      "18:26:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:26:16 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "18:26:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:26:40 [INFO]   Training abgeschlossen in 13.45s (Backend: cuml)\n",
      "18:26:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:27:04 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "18:27:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:27:28 [INFO]   Training abgeschlossen in 13.53s (Backend: cuml)\n",
      "18:27:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:27:52 [INFO]   Training abgeschlossen in 13.63s (Backend: cuml)\n",
      "18:28:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:28:16 [INFO]   Training abgeschlossen in 13.91s (Backend: cuml)\n",
      "18:28:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:28:39 [INFO]   Training abgeschlossen in 13.76s (Backend: cuml)\n",
      "18:28:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:29:02 [INFO]   Training abgeschlossen in 13.92s (Backend: cuml)\n",
      "18:29:12 [INFO]     48,000 labeled → Accuracy: 0.8849 (Train: 13.9s, Query: 4.98s) | GPU: 2.8/8.0 GB\n",
      "18:29:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:29:26 [INFO]   Training abgeschlossen in 13.99s (Backend: cuml)\n",
      "18:29:30 [INFO]     Final: 48,000 labeled → Accuracy: 0.8849, F1: 0.8841\n",
      "18:29:30 [INFO]   Run 2/5\n",
      "18:29:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:29:35 [INFO]   Training abgeschlossen in 4.58s (Backend: cuml)\n",
      "18:29:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:29:55 [INFO]   Training abgeschlossen in 4.61s (Backend: cuml)\n",
      "18:30:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:30:16 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "18:30:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:30:37 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "18:30:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:30:59 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "18:31:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:31:21 [INFO]   Training abgeschlossen in 4.94s (Backend: cuml)\n",
      "18:31:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:31:43 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "18:32:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:32:06 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "18:32:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:32:29 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "18:32:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:32:52 [INFO]   Training abgeschlossen in 5.45s (Backend: cuml)\n",
      "18:33:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:33:16 [INFO]   Training abgeschlossen in 5.70s (Backend: cuml)\n",
      "18:33:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:33:39 [INFO]   Training abgeschlossen in 5.76s (Backend: cuml)\n",
      "18:33:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:34:04 [INFO]   Training abgeschlossen in 6.13s (Backend: cuml)\n",
      "18:34:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:34:28 [INFO]   Training abgeschlossen in 6.04s (Backend: cuml)\n",
      "18:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:34:53 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "18:35:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:35:18 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "18:35:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:35:42 [INFO]   Training abgeschlossen in 6.32s (Backend: cuml)\n",
      "18:36:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:36:07 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "18:36:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:36:33 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "18:36:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:36:58 [INFO]   Training abgeschlossen in 6.86s (Backend: cuml)\n",
      "18:37:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:37:24 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "18:37:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:37:49 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "18:38:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:38:15 [INFO]   Training abgeschlossen in 7.02s (Backend: cuml)\n",
      "18:38:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:38:41 [INFO]   Training abgeschlossen in 7.11s (Backend: cuml)\n",
      "18:39:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:39:07 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "18:39:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:39:33 [INFO]   Training abgeschlossen in 7.34s (Backend: cuml)\n",
      "18:39:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:39:59 [INFO]   Training abgeschlossen in 7.57s (Backend: cuml)\n",
      "18:40:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:40:25 [INFO]   Training abgeschlossen in 7.57s (Backend: cuml)\n",
      "18:40:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:40:51 [INFO]   Training abgeschlossen in 7.69s (Backend: cuml)\n",
      "18:41:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:41:17 [INFO]   Training abgeschlossen in 7.77s (Backend: cuml)\n",
      "18:41:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "18:41:43 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "18:42:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:42:10 [INFO]   Training abgeschlossen in 7.89s (Backend: cuml)\n",
      "18:42:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:42:37 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "18:42:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:43:04 [INFO]   Training abgeschlossen in 8.13s (Backend: cuml)\n",
      "18:43:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:43:31 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "18:43:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:43:58 [INFO]   Training abgeschlossen in 8.53s (Backend: cuml)\n",
      "18:44:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:44:24 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "18:44:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:44:50 [INFO]   Training abgeschlossen in 8.69s (Backend: cuml)\n",
      "18:45:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:45:17 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "18:45:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:45:44 [INFO]   Training abgeschlossen in 8.83s (Backend: cuml)\n",
      "18:46:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:46:10 [INFO]   Training abgeschlossen in 8.85s (Backend: cuml)\n",
      "18:46:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:46:37 [INFO]   Training abgeschlossen in 8.94s (Backend: cuml)\n",
      "18:46:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:47:03 [INFO]   Training abgeschlossen in 9.08s (Backend: cuml)\n",
      "18:47:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:47:30 [INFO]   Training abgeschlossen in 8.90s (Backend: cuml)\n",
      "18:47:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:47:55 [INFO]   Training abgeschlossen in 9.11s (Backend: cuml)\n",
      "18:48:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:48:21 [INFO]   Training abgeschlossen in 9.12s (Backend: cuml)\n",
      "18:48:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:48:48 [INFO]   Training abgeschlossen in 9.37s (Backend: cuml)\n",
      "18:49:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:49:14 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "18:49:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:49:40 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "18:49:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:50:06 [INFO]   Training abgeschlossen in 9.50s (Backend: cuml)\n",
      "18:50:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:50:32 [INFO]   Training abgeschlossen in 9.79s (Backend: cuml)\n",
      "18:50:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:50:58 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "18:51:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:51:24 [INFO]   Training abgeschlossen in 9.78s (Backend: cuml)\n",
      "18:51:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:51:51 [INFO]   Training abgeschlossen in 10.21s (Backend: cuml)\n",
      "18:52:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:52:16 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "18:52:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:52:43 [INFO]   Training abgeschlossen in 10.24s (Backend: cuml)\n",
      "18:52:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:53:09 [INFO]   Training abgeschlossen in 10.22s (Backend: cuml)\n",
      "18:53:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:53:35 [INFO]   Training abgeschlossen in 10.36s (Backend: cuml)\n",
      "18:53:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:54:01 [INFO]   Training abgeschlossen in 10.43s (Backend: cuml)\n",
      "18:54:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:54:26 [INFO]   Training abgeschlossen in 10.54s (Backend: cuml)\n",
      "18:54:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:54:52 [INFO]   Training abgeschlossen in 10.87s (Backend: cuml)\n",
      "18:55:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:55:18 [INFO]   Training abgeschlossen in 10.86s (Backend: cuml)\n",
      "18:55:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:55:44 [INFO]   Training abgeschlossen in 11.04s (Backend: cuml)\n",
      "18:55:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:56:10 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "18:56:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:56:36 [INFO]   Training abgeschlossen in 11.14s (Backend: cuml)\n",
      "18:56:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:57:02 [INFO]   Training abgeschlossen in 11.29s (Backend: cuml)\n",
      "18:57:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:57:27 [INFO]   Training abgeschlossen in 11.46s (Backend: cuml)\n",
      "18:57:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:57:53 [INFO]   Training abgeschlossen in 11.50s (Backend: cuml)\n",
      "18:58:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:58:19 [INFO]   Training abgeschlossen in 11.55s (Backend: cuml)\n",
      "18:58:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:58:45 [INFO]   Training abgeschlossen in 11.86s (Backend: cuml)\n",
      "18:58:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:59:10 [INFO]   Training abgeschlossen in 11.89s (Backend: cuml)\n",
      "18:59:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:59:35 [INFO]   Training abgeschlossen in 11.92s (Backend: cuml)\n",
      "18:59:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:00:01 [INFO]   Training abgeschlossen in 11.98s (Backend: cuml)\n",
      "19:00:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:00:26 [INFO]   Training abgeschlossen in 12.04s (Backend: cuml)\n",
      "19:00:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:00:52 [INFO]   Training abgeschlossen in 12.18s (Backend: cuml)\n",
      "19:01:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:01:17 [INFO]   Training abgeschlossen in 12.19s (Backend: cuml)\n",
      "19:01:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:01:42 [INFO]   Training abgeschlossen in 12.47s (Backend: cuml)\n",
      "19:01:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:02:07 [INFO]   Training abgeschlossen in 12.42s (Backend: cuml)\n",
      "19:02:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:02:32 [INFO]   Training abgeschlossen in 12.75s (Backend: cuml)\n",
      "19:02:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:02:57 [INFO]   Training abgeschlossen in 12.63s (Backend: cuml)\n",
      "19:03:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:03:22 [INFO]   Training abgeschlossen in 12.74s (Backend: cuml)\n",
      "19:03:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:03:47 [INFO]   Training abgeschlossen in 12.79s (Backend: cuml)\n",
      "19:03:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:04:12 [INFO]   Training abgeschlossen in 12.96s (Backend: cuml)\n",
      "19:04:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:04:37 [INFO]   Training abgeschlossen in 13.24s (Backend: cuml)\n",
      "19:04:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:05:01 [INFO]   Training abgeschlossen in 13.01s (Backend: cuml)\n",
      "19:05:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:05:25 [INFO]   Training abgeschlossen in 13.24s (Backend: cuml)\n",
      "19:05:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:05:50 [INFO]   Training abgeschlossen in 13.29s (Backend: cuml)\n",
      "19:06:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:06:14 [INFO]   Training abgeschlossen in 13.42s (Backend: cuml)\n",
      "19:06:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:06:38 [INFO]   Training abgeschlossen in 13.72s (Backend: cuml)\n",
      "19:06:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:07:02 [INFO]   Training abgeschlossen in 13.44s (Backend: cuml)\n",
      "19:07:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:07:26 [INFO]   Training abgeschlossen in 13.83s (Backend: cuml)\n",
      "19:07:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:07:50 [INFO]   Training abgeschlossen in 13.57s (Backend: cuml)\n",
      "19:08:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:08:13 [INFO]   Training abgeschlossen in 13.82s (Backend: cuml)\n",
      "19:08:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:08:37 [INFO]   Training abgeschlossen in 13.93s (Backend: cuml)\n",
      "19:08:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:09:00 [INFO]   Training abgeschlossen in 13.85s (Backend: cuml)\n",
      "19:09:09 [INFO]     48,000 labeled → Accuracy: 0.8863 (Train: 13.9s, Query: 4.94s) | GPU: 2.8/8.0 GB\n",
      "19:09:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:09:24 [INFO]   Training abgeschlossen in 14.23s (Backend: cuml)\n",
      "19:09:28 [INFO]     Final: 48,000 labeled → Accuracy: 0.8863, F1: 0.8856\n",
      "19:09:28 [INFO]   Run 3/5\n",
      "19:09:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:09:33 [INFO]   Training abgeschlossen in 4.63s (Backend: cuml)\n",
      "19:09:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:09:54 [INFO]   Training abgeschlossen in 4.59s (Backend: cuml)\n",
      "19:10:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:10:15 [INFO]   Training abgeschlossen in 4.72s (Backend: cuml)\n",
      "19:10:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:10:36 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "19:10:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:10:58 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "19:11:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:11:20 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "19:11:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:11:43 [INFO]   Training abgeschlossen in 5.07s (Backend: cuml)\n",
      "19:12:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:12:06 [INFO]   Training abgeschlossen in 5.15s (Backend: cuml)\n",
      "19:12:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:12:29 [INFO]   Training abgeschlossen in 5.46s (Backend: cuml)\n",
      "19:12:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:12:52 [INFO]   Training abgeschlossen in 5.53s (Backend: cuml)\n",
      "19:13:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:13:15 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "19:13:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:13:39 [INFO]   Training abgeschlossen in 5.73s (Backend: cuml)\n",
      "19:13:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:14:03 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "19:14:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:14:28 [INFO]   Training abgeschlossen in 6.21s (Backend: cuml)\n",
      "19:14:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:14:53 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "19:15:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:15:18 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "19:15:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:15:43 [INFO]   Training abgeschlossen in 6.38s (Backend: cuml)\n",
      "19:16:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:16:08 [INFO]   Training abgeschlossen in 6.49s (Backend: cuml)\n",
      "19:16:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:16:34 [INFO]   Training abgeschlossen in 6.58s (Backend: cuml)\n",
      "19:16:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:16:59 [INFO]   Training abgeschlossen in 6.73s (Backend: cuml)\n",
      "19:17:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:17:24 [INFO]   Training abgeschlossen in 6.94s (Backend: cuml)\n",
      "19:17:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:17:50 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "19:18:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:18:16 [INFO]   Training abgeschlossen in 7.17s (Backend: cuml)\n",
      "19:18:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:18:41 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "19:19:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:19:08 [INFO]   Training abgeschlossen in 7.27s (Backend: cuml)\n",
      "19:19:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:19:34 [INFO]   Training abgeschlossen in 7.31s (Backend: cuml)\n",
      "19:19:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:19:59 [INFO]   Training abgeschlossen in 7.49s (Backend: cuml)\n",
      "19:20:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:20:26 [INFO]   Training abgeschlossen in 7.59s (Backend: cuml)\n",
      "19:20:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:20:52 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "19:21:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:21:18 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "19:21:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:21:45 [INFO]   Training abgeschlossen in 7.92s (Backend: cuml)\n",
      "19:22:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:22:12 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "19:22:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:23:08 [INFO]   Training abgeschlossen in 12.39s (Backend: cuml)\n",
      "19:24:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:24:18 [INFO]   Training abgeschlossen in 12.62s (Backend: cuml)\n",
      "19:25:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:25:29 [INFO]   Training abgeschlossen in 12.82s (Backend: cuml)\n",
      "19:26:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:26:38 [INFO]   Training abgeschlossen in 13.00s (Backend: cuml)\n",
      "19:27:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:27:47 [INFO]   Training abgeschlossen in 13.18s (Backend: cuml)\n",
      "19:28:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:28:56 [INFO]   Training abgeschlossen in 13.42s (Backend: cuml)\n",
      "19:29:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:30:05 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "19:30:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:31:13 [INFO]   Training abgeschlossen in 13.87s (Backend: cuml)\n",
      "19:32:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:32:22 [INFO]   Training abgeschlossen in 13.93s (Backend: cuml)\n",
      "19:33:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:33:30 [INFO]   Training abgeschlossen in 14.18s (Backend: cuml)\n",
      "19:34:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:34:37 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "19:35:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:35:45 [INFO]   Training abgeschlossen in 14.40s (Backend: cuml)\n",
      "19:36:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:36:52 [INFO]   Training abgeschlossen in 14.61s (Backend: cuml)\n",
      "19:37:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:37:58 [INFO]   Training abgeschlossen in 14.74s (Backend: cuml)\n",
      "19:38:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:39:05 [INFO]   Training abgeschlossen in 14.99s (Backend: cuml)\n",
      "19:39:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:40:11 [INFO]   Training abgeschlossen in 15.25s (Backend: cuml)\n",
      "19:41:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:41:17 [INFO]   Training abgeschlossen in 15.41s (Backend: cuml)\n",
      "19:42:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:42:22 [INFO]   Training abgeschlossen in 15.64s (Backend: cuml)\n",
      "19:43:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:43:27 [INFO]   Training abgeschlossen in 16.02s (Backend: cuml)\n",
      "19:44:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:44:32 [INFO]   Training abgeschlossen in 16.03s (Backend: cuml)\n",
      "19:45:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:45:37 [INFO]   Training abgeschlossen in 16.18s (Backend: cuml)\n",
      "19:46:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:46:41 [INFO]   Training abgeschlossen in 16.48s (Backend: cuml)\n",
      "19:47:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:47:46 [INFO]   Training abgeschlossen in 16.65s (Backend: cuml)\n",
      "19:48:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:48:50 [INFO]   Training abgeschlossen in 16.99s (Backend: cuml)\n",
      "19:49:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:49:53 [INFO]   Training abgeschlossen in 17.23s (Backend: cuml)\n",
      "19:50:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:50:56 [INFO]   Training abgeschlossen in 17.41s (Backend: cuml)\n",
      "19:51:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:51:59 [INFO]   Training abgeschlossen in 17.50s (Backend: cuml)\n",
      "19:52:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:53:02 [INFO]   Training abgeschlossen in 17.75s (Backend: cuml)\n",
      "19:53:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:54:04 [INFO]   Training abgeschlossen in 17.90s (Backend: cuml)\n",
      "19:54:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:55:06 [INFO]   Training abgeschlossen in 18.16s (Backend: cuml)\n",
      "19:55:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:56:08 [INFO]   Training abgeschlossen in 18.41s (Backend: cuml)\n",
      "19:56:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:57:10 [INFO]   Training abgeschlossen in 18.70s (Backend: cuml)\n",
      "19:57:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:58:11 [INFO]   Training abgeschlossen in 18.88s (Backend: cuml)\n",
      "19:58:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:59:12 [INFO]   Training abgeschlossen in 19.21s (Backend: cuml)\n",
      "19:59:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:00:13 [INFO]   Training abgeschlossen in 19.35s (Backend: cuml)\n",
      "20:00:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:01:13 [INFO]   Training abgeschlossen in 19.64s (Backend: cuml)\n",
      "20:01:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:02:12 [INFO]   Training abgeschlossen in 19.72s (Backend: cuml)\n",
      "20:02:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:03:12 [INFO]   Training abgeschlossen in 19.84s (Backend: cuml)\n",
      "20:03:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:04:11 [INFO]   Training abgeschlossen in 20.04s (Backend: cuml)\n",
      "20:04:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:05:10 [INFO]   Training abgeschlossen in 20.33s (Backend: cuml)\n",
      "20:05:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:06:09 [INFO]   Training abgeschlossen in 20.42s (Backend: cuml)\n",
      "20:06:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:07:07 [INFO]   Training abgeschlossen in 20.62s (Backend: cuml)\n",
      "20:07:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:08:05 [INFO]   Training abgeschlossen in 20.88s (Backend: cuml)\n",
      "20:08:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:09:03 [INFO]   Training abgeschlossen in 21.14s (Backend: cuml)\n",
      "20:09:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:10:00 [INFO]   Training abgeschlossen in 21.42s (Backend: cuml)\n",
      "20:10:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:10:57 [INFO]   Training abgeschlossen in 21.45s (Backend: cuml)\n",
      "20:11:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:11:54 [INFO]   Training abgeschlossen in 21.76s (Backend: cuml)\n",
      "20:12:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:12:51 [INFO]   Training abgeschlossen in 21.79s (Backend: cuml)\n",
      "20:13:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:13:46 [INFO]   Training abgeschlossen in 22.02s (Backend: cuml)\n",
      "20:14:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:14:42 [INFO]   Training abgeschlossen in 22.25s (Backend: cuml)\n",
      "20:15:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:15:37 [INFO]   Training abgeschlossen in 22.49s (Backend: cuml)\n",
      "20:16:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:16:32 [INFO]   Training abgeschlossen in 22.66s (Backend: cuml)\n",
      "20:17:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:17:27 [INFO]   Training abgeschlossen in 22.85s (Backend: cuml)\n",
      "20:17:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:18:21 [INFO]   Training abgeschlossen in 23.01s (Backend: cuml)\n",
      "20:18:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:19:15 [INFO]   Training abgeschlossen in 23.17s (Backend: cuml)\n",
      "20:19:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:20:09 [INFO]   Training abgeschlossen in 23.48s (Backend: cuml)\n",
      "20:20:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:21:02 [INFO]   Training abgeschlossen in 23.56s (Backend: cuml)\n",
      "20:21:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:21:55 [INFO]   Training abgeschlossen in 23.82s (Backend: cuml)\n",
      "20:22:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:22:47 [INFO]   Training abgeschlossen in 24.08s (Backend: cuml)\n",
      "20:23:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:23:39 [INFO]   Training abgeschlossen in 24.44s (Backend: cuml)\n",
      "20:24:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:24:31 [INFO]   Training abgeschlossen in 24.42s (Backend: cuml)\n",
      "20:24:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:25:23 [INFO]   Training abgeschlossen in 24.72s (Backend: cuml)\n",
      "20:25:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:26:14 [INFO]   Training abgeschlossen in 24.81s (Backend: cuml)\n",
      "20:26:39 [INFO]     48,000 labeled → Accuracy: 0.8866 (Train: 24.8s, Query: 14.09s) | GPU: 2.8/8.0 GB\n",
      "20:26:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:27:04 [INFO]   Training abgeschlossen in 24.96s (Backend: cuml)\n",
      "20:27:16 [INFO]     Final: 48,000 labeled → Accuracy: 0.8862, F1: 0.8855\n",
      "20:27:16 [INFO]   Run 4/5\n",
      "20:27:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:27:21 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "20:28:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:28:32 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "20:29:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:29:44 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "20:30:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:30:57 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "20:32:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:32:09 [INFO]   Training abgeschlossen in 5.35s (Backend: cuml)\n",
      "20:33:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:33:21 [INFO]   Training abgeschlossen in 5.76s (Backend: cuml)\n",
      "20:34:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:34:34 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "20:35:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:35:46 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "20:36:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:36:58 [INFO]   Training abgeschlossen in 6.63s (Backend: cuml)\n",
      "20:38:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:38:11 [INFO]   Training abgeschlossen in 6.89s (Backend: cuml)\n",
      "20:39:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:39:24 [INFO]   Training abgeschlossen in 7.35s (Backend: cuml)\n",
      "20:40:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:40:37 [INFO]   Training abgeschlossen in 7.72s (Backend: cuml)\n",
      "20:41:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:41:50 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "20:42:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:43:03 [INFO]   Training abgeschlossen in 7.99s (Backend: cuml)\n",
      "20:44:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:44:16 [INFO]   Training abgeschlossen in 8.39s (Backend: cuml)\n",
      "20:45:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:45:29 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "20:46:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:46:42 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "20:47:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:47:55 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "20:48:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:49:07 [INFO]   Training abgeschlossen in 9.35s (Backend: cuml)\n",
      "20:50:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:50:20 [INFO]   Training abgeschlossen in 9.47s (Backend: cuml)\n",
      "20:51:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:51:32 [INFO]   Training abgeschlossen in 9.60s (Backend: cuml)\n",
      "20:52:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:52:44 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "20:53:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:53:56 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "20:54:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:55:08 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "20:56:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:56:19 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "20:57:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:57:31 [INFO]   Training abgeschlossen in 10.78s (Backend: cuml)\n",
      "20:58:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:58:42 [INFO]   Training abgeschlossen in 11.06s (Backend: cuml)\n",
      "20:59:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:59:53 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "21:00:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:01:04 [INFO]   Training abgeschlossen in 11.38s (Backend: cuml)\n",
      "21:02:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:02:14 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "21:03:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:03:25 [INFO]   Training abgeschlossen in 12.08s (Backend: cuml)\n",
      "21:04:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:04:36 [INFO]   Training abgeschlossen in 12.05s (Backend: cuml)\n",
      "21:05:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:05:46 [INFO]   Training abgeschlossen in 12.25s (Backend: cuml)\n",
      "21:06:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:06:57 [INFO]   Training abgeschlossen in 12.51s (Backend: cuml)\n",
      "21:07:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:08:07 [INFO]   Training abgeschlossen in 12.96s (Backend: cuml)\n",
      "21:09:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:09:17 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "21:10:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:10:26 [INFO]   Training abgeschlossen in 13.22s (Backend: cuml)\n",
      "21:11:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:11:35 [INFO]   Training abgeschlossen in 13.34s (Backend: cuml)\n",
      "21:12:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:12:43 [INFO]   Training abgeschlossen in 13.57s (Backend: cuml)\n",
      "21:13:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:13:52 [INFO]   Training abgeschlossen in 13.91s (Backend: cuml)\n",
      "21:14:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:15:00 [INFO]   Training abgeschlossen in 14.03s (Backend: cuml)\n",
      "21:15:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:16:08 [INFO]   Training abgeschlossen in 14.20s (Backend: cuml)\n",
      "21:17:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:17:16 [INFO]   Training abgeschlossen in 14.35s (Backend: cuml)\n",
      "21:18:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:18:23 [INFO]   Training abgeschlossen in 14.25s (Backend: cuml)\n",
      "21:19:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:19:30 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "21:20:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:20:37 [INFO]   Training abgeschlossen in 15.00s (Backend: cuml)\n",
      "21:21:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:21:43 [INFO]   Training abgeschlossen in 15.01s (Backend: cuml)\n",
      "21:22:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:22:49 [INFO]   Training abgeschlossen in 15.17s (Backend: cuml)\n",
      "21:23:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:23:55 [INFO]   Training abgeschlossen in 15.37s (Backend: cuml)\n",
      "21:24:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:25:00 [INFO]   Training abgeschlossen in 15.53s (Backend: cuml)\n",
      "21:25:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:26:06 [INFO]   Training abgeschlossen in 16.07s (Backend: cuml)\n",
      "21:26:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:27:11 [INFO]   Training abgeschlossen in 16.22s (Backend: cuml)\n",
      "21:27:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:28:16 [INFO]   Training abgeschlossen in 16.36s (Backend: cuml)\n",
      "21:29:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:29:20 [INFO]   Training abgeschlossen in 16.56s (Backend: cuml)\n",
      "21:30:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:30:24 [INFO]   Training abgeschlossen in 16.69s (Backend: cuml)\n",
      "21:31:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:31:28 [INFO]   Training abgeschlossen in 16.88s (Backend: cuml)\n",
      "21:32:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:32:32 [INFO]   Training abgeschlossen in 17.04s (Backend: cuml)\n",
      "21:33:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:33:35 [INFO]   Training abgeschlossen in 17.34s (Backend: cuml)\n",
      "21:34:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:34:38 [INFO]   Training abgeschlossen in 17.63s (Backend: cuml)\n",
      "21:35:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:35:41 [INFO]   Training abgeschlossen in 17.80s (Backend: cuml)\n",
      "21:36:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:36:43 [INFO]   Training abgeschlossen in 18.06s (Backend: cuml)\n",
      "21:37:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:37:45 [INFO]   Training abgeschlossen in 18.16s (Backend: cuml)\n",
      "21:38:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:38:47 [INFO]   Training abgeschlossen in 18.44s (Backend: cuml)\n",
      "21:39:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:39:49 [INFO]   Training abgeschlossen in 18.55s (Backend: cuml)\n",
      "21:40:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:40:50 [INFO]   Training abgeschlossen in 18.84s (Backend: cuml)\n",
      "21:41:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:41:51 [INFO]   Training abgeschlossen in 18.94s (Backend: cuml)\n",
      "21:42:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:42:52 [INFO]   Training abgeschlossen in 19.23s (Backend: cuml)\n",
      "21:43:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:43:52 [INFO]   Training abgeschlossen in 19.40s (Backend: cuml)\n",
      "21:44:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:44:52 [INFO]   Training abgeschlossen in 19.71s (Backend: cuml)\n",
      "21:45:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:45:52 [INFO]   Training abgeschlossen in 19.81s (Backend: cuml)\n",
      "21:46:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:46:51 [INFO]   Training abgeschlossen in 19.95s (Backend: cuml)\n",
      "21:47:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:47:50 [INFO]   Training abgeschlossen in 20.21s (Backend: cuml)\n",
      "21:48:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:48:48 [INFO]   Training abgeschlossen in 20.41s (Backend: cuml)\n",
      "21:49:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:49:47 [INFO]   Training abgeschlossen in 20.76s (Backend: cuml)\n",
      "21:50:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:50:45 [INFO]   Training abgeschlossen in 20.87s (Backend: cuml)\n",
      "21:51:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:51:43 [INFO]   Training abgeschlossen in 21.18s (Backend: cuml)\n",
      "21:52:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:52:40 [INFO]   Training abgeschlossen in 21.47s (Backend: cuml)\n",
      "21:53:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:53:38 [INFO]   Training abgeschlossen in 21.52s (Backend: cuml)\n",
      "21:54:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:54:35 [INFO]   Training abgeschlossen in 21.94s (Backend: cuml)\n",
      "21:55:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:55:32 [INFO]   Training abgeschlossen in 22.04s (Backend: cuml)\n",
      "21:56:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:56:28 [INFO]   Training abgeschlossen in 22.26s (Backend: cuml)\n",
      "21:57:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:57:24 [INFO]   Training abgeschlossen in 22.33s (Backend: cuml)\n",
      "21:57:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:58:20 [INFO]   Training abgeschlossen in 22.64s (Backend: cuml)\n",
      "21:58:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:59:15 [INFO]   Training abgeschlossen in 22.78s (Backend: cuml)\n",
      "21:59:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:00:10 [INFO]   Training abgeschlossen in 22.83s (Backend: cuml)\n",
      "22:00:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:01:04 [INFO]   Training abgeschlossen in 23.05s (Backend: cuml)\n",
      "22:01:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:01:58 [INFO]   Training abgeschlossen in 23.28s (Backend: cuml)\n",
      "22:02:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:02:52 [INFO]   Training abgeschlossen in 23.54s (Backend: cuml)\n",
      "22:03:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:03:45 [INFO]   Training abgeschlossen in 23.70s (Backend: cuml)\n",
      "22:04:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:04:38 [INFO]   Training abgeschlossen in 23.79s (Backend: cuml)\n",
      "22:05:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:05:31 [INFO]   Training abgeschlossen in 24.13s (Backend: cuml)\n",
      "22:05:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:06:24 [INFO]   Training abgeschlossen in 24.25s (Backend: cuml)\n",
      "22:06:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:07:15 [INFO]   Training abgeschlossen in 24.48s (Backend: cuml)\n",
      "22:07:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:08:07 [INFO]   Training abgeschlossen in 24.71s (Backend: cuml)\n",
      "22:08:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:08:58 [INFO]   Training abgeschlossen in 24.95s (Backend: cuml)\n",
      "22:09:24 [INFO]     48,000 labeled → Accuracy: 0.8856 (Train: 25.0s, Query: 14.08s) | GPU: 2.8/8.0 GB\n",
      "22:09:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:09:49 [INFO]   Training abgeschlossen in 25.13s (Backend: cuml)\n",
      "22:10:01 [INFO]     Final: 48,000 labeled → Accuracy: 0.8861, F1: 0.8853\n",
      "22:10:01 [INFO]   Run 5/5\n",
      "22:10:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:10:06 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "22:11:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:11:17 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "22:12:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:12:29 [INFO]   Training abgeschlossen in 5.14s (Backend: cuml)\n",
      "22:13:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:13:42 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "22:14:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:14:54 [INFO]   Training abgeschlossen in 5.35s (Backend: cuml)\n",
      "22:16:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:16:06 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "22:17:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:17:18 [INFO]   Training abgeschlossen in 6.04s (Backend: cuml)\n",
      "22:18:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:18:31 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "22:19:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:19:43 [INFO]   Training abgeschlossen in 6.59s (Backend: cuml)\n",
      "22:20:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:20:56 [INFO]   Training abgeschlossen in 7.02s (Backend: cuml)\n",
      "22:22:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:22:09 [INFO]   Training abgeschlossen in 7.21s (Backend: cuml)\n",
      "22:23:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:23:22 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "22:24:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:24:34 [INFO]   Training abgeschlossen in 7.80s (Backend: cuml)\n",
      "22:25:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:25:47 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "22:26:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:27:00 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "22:28:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:28:12 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "22:29:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:29:25 [INFO]   Training abgeschlossen in 8.90s (Backend: cuml)\n",
      "22:30:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:30:38 [INFO]   Training abgeschlossen in 9.01s (Backend: cuml)\n",
      "22:31:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:31:51 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "22:32:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:33:03 [INFO]   Training abgeschlossen in 9.37s (Backend: cuml)\n",
      "22:34:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:34:15 [INFO]   Training abgeschlossen in 9.82s (Backend: cuml)\n",
      "22:35:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:35:27 [INFO]   Training abgeschlossen in 9.87s (Backend: cuml)\n",
      "22:36:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:36:38 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "22:37:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:37:51 [INFO]   Training abgeschlossen in 10.40s (Backend: cuml)\n",
      "22:38:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:39:03 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "22:40:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:40:15 [INFO]   Training abgeschlossen in 10.80s (Backend: cuml)\n",
      "22:41:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:41:26 [INFO]   Training abgeschlossen in 11.03s (Backend: cuml)\n",
      "22:42:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:42:37 [INFO]   Training abgeschlossen in 11.32s (Backend: cuml)\n",
      "22:43:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:43:48 [INFO]   Training abgeschlossen in 11.47s (Backend: cuml)\n",
      "22:44:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:44:59 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "22:45:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:46:10 [INFO]   Training abgeschlossen in 11.86s (Backend: cuml)\n",
      "22:47:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:47:21 [INFO]   Training abgeschlossen in 12.25s (Backend: cuml)\n",
      "22:48:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:48:32 [INFO]   Training abgeschlossen in 12.27s (Backend: cuml)\n",
      "22:49:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:49:43 [INFO]   Training abgeschlossen in 12.48s (Backend: cuml)\n",
      "22:50:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:50:53 [INFO]   Training abgeschlossen in 12.73s (Backend: cuml)\n",
      "22:51:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:52:03 [INFO]   Training abgeschlossen in 13.12s (Backend: cuml)\n",
      "22:52:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:53:12 [INFO]   Training abgeschlossen in 13.23s (Backend: cuml)\n",
      "22:54:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:54:21 [INFO]   Training abgeschlossen in 13.36s (Backend: cuml)\n",
      "22:55:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:55:29 [INFO]   Training abgeschlossen in 13.53s (Backend: cuml)\n",
      "22:56:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:56:38 [INFO]   Training abgeschlossen in 13.79s (Backend: cuml)\n",
      "22:57:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:57:46 [INFO]   Training abgeschlossen in 14.17s (Backend: cuml)\n",
      "22:58:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:58:55 [INFO]   Training abgeschlossen in 14.20s (Backend: cuml)\n",
      "22:59:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:00:02 [INFO]   Training abgeschlossen in 14.37s (Backend: cuml)\n",
      "23:00:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:01:09 [INFO]   Training abgeschlossen in 14.28s (Backend: cuml)\n",
      "23:02:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:02:16 [INFO]   Training abgeschlossen in 14.63s (Backend: cuml)\n",
      "23:03:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:03:23 [INFO]   Training abgeschlossen in 14.83s (Backend: cuml)\n",
      "23:04:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:04:30 [INFO]   Training abgeschlossen in 14.97s (Backend: cuml)\n",
      "23:05:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:05:36 [INFO]   Training abgeschlossen in 15.16s (Backend: cuml)\n",
      "23:06:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:06:42 [INFO]   Training abgeschlossen in 15.35s (Backend: cuml)\n",
      "23:07:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:07:47 [INFO]   Training abgeschlossen in 15.50s (Backend: cuml)\n",
      "23:08:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:08:52 [INFO]   Training abgeschlossen in 16.10s (Backend: cuml)\n",
      "23:09:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:09:57 [INFO]   Training abgeschlossen in 16.15s (Backend: cuml)\n",
      "23:10:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:11:02 [INFO]   Training abgeschlossen in 16.36s (Backend: cuml)\n",
      "23:11:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:12:06 [INFO]   Training abgeschlossen in 16.49s (Backend: cuml)\n",
      "23:12:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:13:10 [INFO]   Training abgeschlossen in 16.58s (Backend: cuml)\n",
      "23:13:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:14:14 [INFO]   Training abgeschlossen in 16.86s (Backend: cuml)\n",
      "23:15:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:15:17 [INFO]   Training abgeschlossen in 17.00s (Backend: cuml)\n",
      "23:16:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:16:21 [INFO]   Training abgeschlossen in 17.32s (Backend: cuml)\n",
      "23:17:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:17:24 [INFO]   Training abgeschlossen in 17.48s (Backend: cuml)\n",
      "23:18:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:18:26 [INFO]   Training abgeschlossen in 17.72s (Backend: cuml)\n",
      "23:19:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:19:29 [INFO]   Training abgeschlossen in 17.98s (Backend: cuml)\n",
      "23:20:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:20:31 [INFO]   Training abgeschlossen in 18.29s (Backend: cuml)\n",
      "23:21:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:21:33 [INFO]   Training abgeschlossen in 18.54s (Backend: cuml)\n",
      "23:22:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:22:34 [INFO]   Training abgeschlossen in 18.55s (Backend: cuml)\n",
      "23:23:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:23:34 [INFO]   Training abgeschlossen in 18.72s (Backend: cuml)\n",
      "23:24:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:24:35 [INFO]   Training abgeschlossen in 18.90s (Backend: cuml)\n",
      "23:25:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:25:36 [INFO]   Training abgeschlossen in 19.20s (Backend: cuml)\n",
      "23:26:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:26:36 [INFO]   Training abgeschlossen in 19.34s (Backend: cuml)\n",
      "23:27:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:27:35 [INFO]   Training abgeschlossen in 19.48s (Backend: cuml)\n",
      "23:28:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:28:35 [INFO]   Training abgeschlossen in 19.76s (Backend: cuml)\n",
      "23:29:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:29:34 [INFO]   Training abgeschlossen in 19.94s (Backend: cuml)\n",
      "23:30:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:30:33 [INFO]   Training abgeschlossen in 20.14s (Backend: cuml)\n",
      "23:31:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:31:32 [INFO]   Training abgeschlossen in 20.43s (Backend: cuml)\n",
      "23:32:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:32:30 [INFO]   Training abgeschlossen in 20.65s (Backend: cuml)\n",
      "23:33:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:33:28 [INFO]   Training abgeschlossen in 20.84s (Backend: cuml)\n",
      "23:34:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:34:25 [INFO]   Training abgeschlossen in 20.97s (Backend: cuml)\n",
      "23:35:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:35:23 [INFO]   Training abgeschlossen in 21.21s (Backend: cuml)\n",
      "23:35:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:36:19 [INFO]   Training abgeschlossen in 21.39s (Backend: cuml)\n",
      "23:36:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:37:16 [INFO]   Training abgeschlossen in 21.70s (Backend: cuml)\n",
      "23:37:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:38:12 [INFO]   Training abgeschlossen in 21.86s (Backend: cuml)\n",
      "23:38:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:39:09 [INFO]   Training abgeschlossen in 22.06s (Backend: cuml)\n",
      "23:39:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:40:04 [INFO]   Training abgeschlossen in 22.34s (Backend: cuml)\n",
      "23:40:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:41:00 [INFO]   Training abgeschlossen in 22.47s (Backend: cuml)\n",
      "23:41:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:41:55 [INFO]   Training abgeschlossen in 22.66s (Backend: cuml)\n",
      "23:42:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:42:49 [INFO]   Training abgeschlossen in 22.78s (Backend: cuml)\n",
      "23:43:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:43:44 [INFO]   Training abgeschlossen in 23.07s (Backend: cuml)\n",
      "23:44:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:44:38 [INFO]   Training abgeschlossen in 23.34s (Backend: cuml)\n",
      "23:45:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:45:31 [INFO]   Training abgeschlossen in 23.45s (Backend: cuml)\n",
      "23:46:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:46:25 [INFO]   Training abgeschlossen in 23.60s (Backend: cuml)\n",
      "23:46:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:47:18 [INFO]   Training abgeschlossen in 23.93s (Backend: cuml)\n",
      "23:47:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:48:10 [INFO]   Training abgeschlossen in 24.14s (Backend: cuml)\n",
      "23:48:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:49:03 [INFO]   Training abgeschlossen in 24.38s (Backend: cuml)\n",
      "23:49:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:49:54 [INFO]   Training abgeschlossen in 24.48s (Backend: cuml)\n",
      "23:50:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:50:46 [INFO]   Training abgeschlossen in 24.67s (Backend: cuml)\n",
      "23:51:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:51:37 [INFO]   Training abgeschlossen in 24.87s (Backend: cuml)\n",
      "23:52:03 [INFO]     48,000 labeled → Accuracy: 0.8863 (Train: 24.9s, Query: 14.03s) | GPU: 2.8/8.0 GB\n",
      "23:52:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:52:28 [INFO]   Training abgeschlossen in 25.16s (Backend: cuml)\n",
      "23:52:39 [INFO]     Final: 48,000 labeled → Accuracy: 0.8860, F1: 0.8852\n",
      "23:52:40 [INFO] \n",
      "GPU-SVM + Entropy Sampling - Budget: 100% (60,000 Samples)\n",
      "23:52:40 [INFO]   Run 1/5\n",
      "23:52:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:52:45 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "23:53:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:53:56 [INFO]   Training abgeschlossen in 4.99s (Backend: cuml)\n",
      "23:55:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:55:08 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "23:56:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:56:19 [INFO]   Training abgeschlossen in 5.25s (Backend: cuml)\n",
      "23:57:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:57:32 [INFO]   Training abgeschlossen in 5.28s (Backend: cuml)\n",
      "23:58:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:58:44 [INFO]   Training abgeschlossen in 5.73s (Backend: cuml)\n",
      "23:59:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:59:56 [INFO]   Training abgeschlossen in 6.02s (Backend: cuml)\n",
      "00:01:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:01:09 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "00:02:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:02:21 [INFO]   Training abgeschlossen in 6.54s (Backend: cuml)\n",
      "00:03:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:03:34 [INFO]   Training abgeschlossen in 6.92s (Backend: cuml)\n",
      "00:04:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:04:47 [INFO]   Training abgeschlossen in 7.50s (Backend: cuml)\n",
      "00:05:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:06:00 [INFO]   Training abgeschlossen in 7.47s (Backend: cuml)\n",
      "00:07:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:07:13 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "00:08:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:08:26 [INFO]   Training abgeschlossen in 8.05s (Backend: cuml)\n",
      "00:09:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:09:38 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "00:10:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:10:52 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "00:11:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:12:05 [INFO]   Training abgeschlossen in 8.74s (Backend: cuml)\n",
      "00:13:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:13:17 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "00:14:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:14:30 [INFO]   Training abgeschlossen in 9.26s (Backend: cuml)\n",
      "00:15:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:15:43 [INFO]   Training abgeschlossen in 9.46s (Backend: cuml)\n",
      "00:16:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:16:55 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "00:17:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:18:07 [INFO]   Training abgeschlossen in 9.93s (Backend: cuml)\n",
      "00:19:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:19:20 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "00:20:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:20:32 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "00:21:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:21:43 [INFO]   Training abgeschlossen in 10.60s (Backend: cuml)\n",
      "00:22:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:22:55 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "00:23:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:24:06 [INFO]   Training abgeschlossen in 11.07s (Backend: cuml)\n",
      "00:25:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:25:17 [INFO]   Training abgeschlossen in 11.26s (Backend: cuml)\n",
      "00:26:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:26:28 [INFO]   Training abgeschlossen in 11.45s (Backend: cuml)\n",
      "00:27:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:27:39 [INFO]   Training abgeschlossen in 11.72s (Backend: cuml)\n",
      "00:28:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:28:50 [INFO]   Training abgeschlossen in 12.17s (Backend: cuml)\n",
      "00:29:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:30:01 [INFO]   Training abgeschlossen in 12.11s (Backend: cuml)\n",
      "00:31:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:31:12 [INFO]   Training abgeschlossen in 12.33s (Backend: cuml)\n",
      "00:32:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:32:23 [INFO]   Training abgeschlossen in 12.62s (Backend: cuml)\n",
      "00:33:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:33:33 [INFO]   Training abgeschlossen in 12.95s (Backend: cuml)\n",
      "00:34:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:34:43 [INFO]   Training abgeschlossen in 13.03s (Backend: cuml)\n",
      "00:35:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:35:53 [INFO]   Training abgeschlossen in 13.20s (Backend: cuml)\n",
      "00:36:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:37:01 [INFO]   Training abgeschlossen in 13.37s (Backend: cuml)\n",
      "00:37:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:38:10 [INFO]   Training abgeschlossen in 13.61s (Backend: cuml)\n",
      "00:39:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:39:19 [INFO]   Training abgeschlossen in 13.84s (Backend: cuml)\n",
      "00:40:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:40:27 [INFO]   Training abgeschlossen in 14.11s (Backend: cuml)\n",
      "00:41:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:41:35 [INFO]   Training abgeschlossen in 14.20s (Backend: cuml)\n",
      "00:42:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:42:43 [INFO]   Training abgeschlossen in 14.39s (Backend: cuml)\n",
      "00:43:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:43:50 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "00:44:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:44:57 [INFO]   Training abgeschlossen in 14.68s (Backend: cuml)\n",
      "00:45:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:46:04 [INFO]   Training abgeschlossen in 14.95s (Backend: cuml)\n",
      "00:46:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:47:10 [INFO]   Training abgeschlossen in 14.92s (Backend: cuml)\n",
      "00:48:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:48:16 [INFO]   Training abgeschlossen in 15.13s (Backend: cuml)\n",
      "00:49:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:49:22 [INFO]   Training abgeschlossen in 15.34s (Backend: cuml)\n",
      "00:50:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:50:27 [INFO]   Training abgeschlossen in 15.51s (Backend: cuml)\n",
      "00:51:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:51:33 [INFO]   Training abgeschlossen in 16.02s (Backend: cuml)\n",
      "00:52:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:52:38 [INFO]   Training abgeschlossen in 16.07s (Backend: cuml)\n",
      "00:53:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:53:42 [INFO]   Training abgeschlossen in 16.32s (Backend: cuml)\n",
      "00:54:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:54:47 [INFO]   Training abgeschlossen in 16.48s (Backend: cuml)\n",
      "00:55:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:55:51 [INFO]   Training abgeschlossen in 16.64s (Backend: cuml)\n",
      "00:56:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:56:55 [INFO]   Training abgeschlossen in 16.89s (Backend: cuml)\n",
      "00:57:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:57:58 [INFO]   Training abgeschlossen in 17.05s (Backend: cuml)\n",
      "00:58:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:59:02 [INFO]   Training abgeschlossen in 17.43s (Backend: cuml)\n",
      "00:59:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:00:05 [INFO]   Training abgeschlossen in 17.52s (Backend: cuml)\n",
      "01:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:01:07 [INFO]   Training abgeschlossen in 17.74s (Backend: cuml)\n",
      "01:01:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:02:10 [INFO]   Training abgeschlossen in 18.04s (Backend: cuml)\n",
      "01:02:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:03:12 [INFO]   Training abgeschlossen in 18.30s (Backend: cuml)\n",
      "01:03:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:04:14 [INFO]   Training abgeschlossen in 18.49s (Backend: cuml)\n",
      "01:04:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:05:16 [INFO]   Training abgeschlossen in 18.86s (Backend: cuml)\n",
      "01:05:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:06:17 [INFO]   Training abgeschlossen in 18.76s (Backend: cuml)\n",
      "01:06:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:07:18 [INFO]   Training abgeschlossen in 19.05s (Backend: cuml)\n",
      "01:07:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:08:18 [INFO]   Training abgeschlossen in 19.25s (Backend: cuml)\n",
      "01:08:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:09:18 [INFO]   Training abgeschlossen in 19.45s (Backend: cuml)\n",
      "01:09:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:10:18 [INFO]   Training abgeschlossen in 19.62s (Backend: cuml)\n",
      "01:10:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:11:18 [INFO]   Training abgeschlossen in 19.83s (Backend: cuml)\n",
      "01:11:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:12:17 [INFO]   Training abgeschlossen in 20.09s (Backend: cuml)\n",
      "01:12:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:13:16 [INFO]   Training abgeschlossen in 20.33s (Backend: cuml)\n",
      "01:13:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:14:15 [INFO]   Training abgeschlossen in 20.60s (Backend: cuml)\n",
      "01:14:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:15:14 [INFO]   Training abgeschlossen in 20.72s (Backend: cuml)\n",
      "01:15:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:16:12 [INFO]   Training abgeschlossen in 20.99s (Backend: cuml)\n",
      "01:16:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:17:10 [INFO]   Training abgeschlossen in 21.13s (Backend: cuml)\n",
      "01:17:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:18:07 [INFO]   Training abgeschlossen in 21.44s (Backend: cuml)\n",
      "01:18:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:19:05 [INFO]   Training abgeschlossen in 21.52s (Backend: cuml)\n",
      "01:19:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:20:01 [INFO]   Training abgeschlossen in 21.65s (Backend: cuml)\n",
      "01:20:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:20:58 [INFO]   Training abgeschlossen in 21.94s (Backend: cuml)\n",
      "01:21:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:21:54 [INFO]   Training abgeschlossen in 22.11s (Backend: cuml)\n",
      "01:22:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:22:50 [INFO]   Training abgeschlossen in 22.33s (Backend: cuml)\n",
      "01:23:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:23:45 [INFO]   Training abgeschlossen in 22.54s (Backend: cuml)\n",
      "01:24:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:24:41 [INFO]   Training abgeschlossen in 22.68s (Backend: cuml)\n",
      "01:25:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:25:35 [INFO]   Training abgeschlossen in 22.85s (Backend: cuml)\n",
      "01:26:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:26:30 [INFO]   Training abgeschlossen in 23.05s (Backend: cuml)\n",
      "01:27:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:27:24 [INFO]   Training abgeschlossen in 23.33s (Backend: cuml)\n",
      "01:27:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:28:17 [INFO]   Training abgeschlossen in 23.52s (Backend: cuml)\n",
      "01:28:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:29:11 [INFO]   Training abgeschlossen in 23.78s (Backend: cuml)\n",
      "01:29:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:30:04 [INFO]   Training abgeschlossen in 24.07s (Backend: cuml)\n",
      "01:30:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:30:57 [INFO]   Training abgeschlossen in 24.39s (Backend: cuml)\n",
      "01:31:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:31:50 [INFO]   Training abgeschlossen in 24.43s (Backend: cuml)\n",
      "01:32:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:32:42 [INFO]   Training abgeschlossen in 24.72s (Backend: cuml)\n",
      "01:33:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:33:33 [INFO]   Training abgeschlossen in 24.73s (Backend: cuml)\n",
      "01:33:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:34:25 [INFO]   Training abgeschlossen in 24.94s (Backend: cuml)\n",
      "01:34:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:35:15 [INFO]   Training abgeschlossen in 25.09s (Backend: cuml)\n",
      "01:35:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:36:06 [INFO]   Training abgeschlossen in 25.31s (Backend: cuml)\n",
      "01:36:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:36:56 [INFO]   Training abgeschlossen in 25.54s (Backend: cuml)\n",
      "01:37:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:37:46 [INFO]   Training abgeschlossen in 25.73s (Backend: cuml)\n",
      "01:38:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:38:46 [INFO]   Training abgeschlossen in 36.51s (Backend: cuml)\n",
      "01:39:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:39:46 [INFO]   Training abgeschlossen in 37.25s (Backend: cuml)\n",
      "01:40:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:40:49 [INFO]   Training abgeschlossen in 40.97s (Backend: cuml)\n",
      "01:41:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:41:50 [INFO]   Training abgeschlossen in 39.04s (Backend: cuml)\n",
      "01:42:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:42:51 [INFO]   Training abgeschlossen in 39.23s (Backend: cuml)\n",
      "01:43:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:43:51 [INFO]   Training abgeschlossen in 40.07s (Backend: cuml)\n",
      "01:44:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:44:49 [INFO]   Training abgeschlossen in 37.86s (Backend: cuml)\n",
      "01:45:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:45:49 [INFO]   Training abgeschlossen in 39.87s (Backend: cuml)\n",
      "01:46:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:46:50 [INFO]   Training abgeschlossen in 41.80s (Backend: cuml)\n",
      "01:47:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:47:48 [INFO]   Training abgeschlossen in 39.55s (Backend: cuml)\n",
      "01:48:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:48:45 [INFO]   Training abgeschlossen in 39.59s (Backend: cuml)\n",
      "01:49:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:49:45 [INFO]   Training abgeschlossen in 42.76s (Backend: cuml)\n",
      "01:50:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:50:45 [INFO]   Training abgeschlossen in 42.36s (Backend: cuml)\n",
      "01:51:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:51:42 [INFO]   Training abgeschlossen in 40.91s (Backend: cuml)\n",
      "01:51:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:52:40 [INFO]   Training abgeschlossen in 42.21s (Backend: cuml)\n",
      "01:52:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:53:37 [INFO]   Training abgeschlossen in 42.05s (Backend: cuml)\n",
      "01:53:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:54:36 [INFO]   Training abgeschlossen in 43.97s (Backend: cuml)\n",
      "01:54:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:55:32 [INFO]   Training abgeschlossen in 41.57s (Backend: cuml)\n",
      "01:55:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:56:28 [INFO]   Training abgeschlossen in 43.03s (Backend: cuml)\n",
      "01:56:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:57:24 [INFO]   Training abgeschlossen in 43.18s (Backend: cuml)\n",
      "01:57:37 [INFO]     60,000 labeled → Accuracy: 0.8849 (Train: 43.2s, Query: 0.66s) | GPU: 2.8/8.0 GB\n",
      "01:57:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:58:20 [INFO]   Training abgeschlossen in 42.78s (Backend: cuml)\n",
      "01:58:31 [INFO]     Final: 60,000 labeled → Accuracy: 0.8849, F1: 0.8841\n",
      "01:58:31 [INFO]   Run 2/5\n",
      "01:58:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:58:36 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "01:59:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:59:48 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "02:00:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:01:00 [INFO]   Training abgeschlossen in 5.14s (Backend: cuml)\n",
      "02:02:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:02:12 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "02:03:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:03:24 [INFO]   Training abgeschlossen in 5.36s (Backend: cuml)\n",
      "02:04:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:04:36 [INFO]   Training abgeschlossen in 5.83s (Backend: cuml)\n",
      "02:05:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:05:49 [INFO]   Training abgeschlossen in 5.98s (Backend: cuml)\n",
      "02:06:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:07:02 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "02:08:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:08:14 [INFO]   Training abgeschlossen in 6.56s (Backend: cuml)\n",
      "02:09:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:09:26 [INFO]   Training abgeschlossen in 6.86s (Backend: cuml)\n",
      "02:10:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:10:39 [INFO]   Training abgeschlossen in 7.42s (Backend: cuml)\n",
      "02:11:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:11:52 [INFO]   Training abgeschlossen in 7.60s (Backend: cuml)\n",
      "02:12:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:13:05 [INFO]   Training abgeschlossen in 7.96s (Backend: cuml)\n",
      "02:14:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:14:18 [INFO]   Training abgeschlossen in 7.99s (Backend: cuml)\n",
      "02:15:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:15:31 [INFO]   Training abgeschlossen in 8.29s (Backend: cuml)\n",
      "02:16:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:16:44 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "02:17:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:17:57 [INFO]   Training abgeschlossen in 8.68s (Backend: cuml)\n",
      "02:19:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:19:10 [INFO]   Training abgeschlossen in 9.12s (Backend: cuml)\n",
      "02:20:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:20:23 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "02:21:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:21:37 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "02:22:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:22:50 [INFO]   Training abgeschlossen in 9.78s (Backend: cuml)\n",
      "02:23:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:24:03 [INFO]   Training abgeschlossen in 9.80s (Backend: cuml)\n",
      "02:25:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:25:14 [INFO]   Training abgeschlossen in 10.05s (Backend: cuml)\n",
      "02:26:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:26:26 [INFO]   Training abgeschlossen in 10.34s (Backend: cuml)\n",
      "02:27:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:27:38 [INFO]   Training abgeschlossen in 10.48s (Backend: cuml)\n",
      "02:28:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:28:49 [INFO]   Training abgeschlossen in 10.71s (Backend: cuml)\n",
      "02:29:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:30:01 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "02:31:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:31:12 [INFO]   Training abgeschlossen in 11.29s (Backend: cuml)\n",
      "02:32:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:32:23 [INFO]   Training abgeschlossen in 11.76s (Backend: cuml)\n",
      "02:33:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:33:34 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "02:34:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:34:44 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "02:35:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:35:55 [INFO]   Training abgeschlossen in 12.16s (Backend: cuml)\n",
      "02:36:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:37:06 [INFO]   Training abgeschlossen in 12.26s (Backend: cuml)\n",
      "02:38:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:38:17 [INFO]   Training abgeschlossen in 12.49s (Backend: cuml)\n",
      "02:39:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:39:27 [INFO]   Training abgeschlossen in 12.86s (Backend: cuml)\n",
      "02:40:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:40:36 [INFO]   Training abgeschlossen in 12.90s (Backend: cuml)\n",
      "02:41:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:41:46 [INFO]   Training abgeschlossen in 13.18s (Backend: cuml)\n",
      "02:42:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:42:55 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "02:43:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:44:04 [INFO]   Training abgeschlossen in 13.55s (Backend: cuml)\n",
      "02:44:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:45:12 [INFO]   Training abgeschlossen in 13.80s (Backend: cuml)\n",
      "02:46:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:46:21 [INFO]   Training abgeschlossen in 14.07s (Backend: cuml)\n",
      "02:47:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:47:29 [INFO]   Training abgeschlossen in 14.30s (Backend: cuml)\n",
      "02:48:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:48:37 [INFO]   Training abgeschlossen in 14.44s (Backend: cuml)\n",
      "02:49:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:49:44 [INFO]   Training abgeschlossen in 14.28s (Backend: cuml)\n",
      "02:50:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:50:51 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "02:51:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:51:57 [INFO]   Training abgeschlossen in 14.86s (Backend: cuml)\n",
      "02:52:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:53:04 [INFO]   Training abgeschlossen in 15.00s (Backend: cuml)\n",
      "02:53:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:54:09 [INFO]   Training abgeschlossen in 15.22s (Backend: cuml)\n",
      "02:55:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:55:15 [INFO]   Training abgeschlossen in 15.42s (Backend: cuml)\n",
      "02:56:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:56:21 [INFO]   Training abgeschlossen in 15.54s (Backend: cuml)\n",
      "02:57:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:57:26 [INFO]   Training abgeschlossen in 16.02s (Backend: cuml)\n",
      "02:58:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:58:31 [INFO]   Training abgeschlossen in 16.01s (Backend: cuml)\n",
      "02:59:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:59:36 [INFO]   Training abgeschlossen in 16.31s (Backend: cuml)\n",
      "03:00:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:00:41 [INFO]   Training abgeschlossen in 16.70s (Backend: cuml)\n",
      "03:01:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:01:45 [INFO]   Training abgeschlossen in 16.79s (Backend: cuml)\n",
      "03:02:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:02:49 [INFO]   Training abgeschlossen in 16.86s (Backend: cuml)\n",
      "03:03:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:03:52 [INFO]   Training abgeschlossen in 17.05s (Backend: cuml)\n",
      "03:04:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:04:56 [INFO]   Training abgeschlossen in 17.28s (Backend: cuml)\n",
      "03:05:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:05:59 [INFO]   Training abgeschlossen in 17.51s (Backend: cuml)\n",
      "03:06:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:07:01 [INFO]   Training abgeschlossen in 17.76s (Backend: cuml)\n",
      "03:07:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:08:03 [INFO]   Training abgeschlossen in 17.83s (Backend: cuml)\n",
      "03:08:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:09:06 [INFO]   Training abgeschlossen in 18.22s (Backend: cuml)\n",
      "03:09:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:10:07 [INFO]   Training abgeschlossen in 18.50s (Backend: cuml)\n",
      "03:10:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:11:09 [INFO]   Training abgeschlossen in 18.81s (Backend: cuml)\n",
      "03:11:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:12:11 [INFO]   Training abgeschlossen in 18.85s (Backend: cuml)\n",
      "03:12:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:13:11 [INFO]   Training abgeschlossen in 19.03s (Backend: cuml)\n",
      "03:13:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:14:12 [INFO]   Training abgeschlossen in 19.31s (Backend: cuml)\n",
      "03:14:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:15:13 [INFO]   Training abgeschlossen in 19.45s (Backend: cuml)\n",
      "03:15:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:16:13 [INFO]   Training abgeschlossen in 19.72s (Backend: cuml)\n",
      "03:16:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:17:12 [INFO]   Training abgeschlossen in 20.00s (Backend: cuml)\n",
      "03:17:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:18:12 [INFO]   Training abgeschlossen in 20.21s (Backend: cuml)\n",
      "03:18:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:19:11 [INFO]   Training abgeschlossen in 20.28s (Backend: cuml)\n",
      "03:19:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:20:10 [INFO]   Training abgeschlossen in 20.48s (Backend: cuml)\n",
      "03:20:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:21:08 [INFO]   Training abgeschlossen in 20.78s (Backend: cuml)\n",
      "03:21:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:22:07 [INFO]   Training abgeschlossen in 20.93s (Backend: cuml)\n",
      "03:22:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:23:05 [INFO]   Training abgeschlossen in 21.19s (Backend: cuml)\n",
      "03:23:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:24:02 [INFO]   Training abgeschlossen in 21.40s (Backend: cuml)\n",
      "03:24:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:25:00 [INFO]   Training abgeschlossen in 21.61s (Backend: cuml)\n",
      "03:25:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:25:56 [INFO]   Training abgeschlossen in 21.73s (Backend: cuml)\n",
      "03:26:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:26:53 [INFO]   Training abgeschlossen in 22.05s (Backend: cuml)\n",
      "03:27:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:27:49 [INFO]   Training abgeschlossen in 22.29s (Backend: cuml)\n",
      "03:28:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:28:45 [INFO]   Training abgeschlossen in 22.43s (Backend: cuml)\n",
      "03:29:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:29:41 [INFO]   Training abgeschlossen in 22.54s (Backend: cuml)\n",
      "03:30:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:30:36 [INFO]   Training abgeschlossen in 22.79s (Backend: cuml)\n",
      "03:31:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:31:31 [INFO]   Training abgeschlossen in 22.86s (Backend: cuml)\n",
      "03:32:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:32:26 [INFO]   Training abgeschlossen in 23.20s (Backend: cuml)\n",
      "03:32:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:33:20 [INFO]   Training abgeschlossen in 23.29s (Backend: cuml)\n",
      "03:33:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:34:14 [INFO]   Training abgeschlossen in 23.67s (Backend: cuml)\n",
      "03:34:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:35:07 [INFO]   Training abgeschlossen in 23.86s (Backend: cuml)\n",
      "03:35:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:36:00 [INFO]   Training abgeschlossen in 24.15s (Backend: cuml)\n",
      "03:36:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:36:53 [INFO]   Training abgeschlossen in 24.38s (Backend: cuml)\n",
      "03:37:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:37:46 [INFO]   Training abgeschlossen in 24.42s (Backend: cuml)\n",
      "03:38:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:38:38 [INFO]   Training abgeschlossen in 24.59s (Backend: cuml)\n",
      "03:39:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:39:30 [INFO]   Training abgeschlossen in 24.77s (Backend: cuml)\n",
      "03:39:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:40:21 [INFO]   Training abgeschlossen in 24.98s (Backend: cuml)\n",
      "03:40:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:41:12 [INFO]   Training abgeschlossen in 25.06s (Backend: cuml)\n",
      "03:41:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:42:02 [INFO]   Training abgeschlossen in 25.25s (Backend: cuml)\n",
      "03:42:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:42:52 [INFO]   Training abgeschlossen in 25.70s (Backend: cuml)\n",
      "03:43:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:43:42 [INFO]   Training abgeschlossen in 25.71s (Backend: cuml)\n",
      "03:44:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:44:43 [INFO]   Training abgeschlossen in 37.79s (Backend: cuml)\n",
      "03:45:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:45:44 [INFO]   Training abgeschlossen in 37.70s (Backend: cuml)\n",
      "03:46:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:46:45 [INFO]   Training abgeschlossen in 38.30s (Backend: cuml)\n",
      "03:47:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:47:44 [INFO]   Training abgeschlossen in 38.09s (Backend: cuml)\n",
      "03:48:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:48:46 [INFO]   Training abgeschlossen in 40.37s (Backend: cuml)\n",
      "03:49:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:49:48 [INFO]   Training abgeschlossen in 40.74s (Backend: cuml)\n",
      "03:50:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:50:48 [INFO]   Training abgeschlossen in 39.97s (Backend: cuml)\n",
      "03:51:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:51:48 [INFO]   Training abgeschlossen in 40.36s (Backend: cuml)\n",
      "03:52:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:52:47 [INFO]   Training abgeschlossen in 40.10s (Backend: cuml)\n",
      "03:53:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:53:45 [INFO]   Training abgeschlossen in 39.45s (Backend: cuml)\n",
      "03:54:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:54:44 [INFO]   Training abgeschlossen in 41.19s (Backend: cuml)\n",
      "03:55:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:55:43 [INFO]   Training abgeschlossen in 41.21s (Backend: cuml)\n",
      "03:55:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:56:40 [INFO]   Training abgeschlossen in 40.91s (Backend: cuml)\n",
      "03:56:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:57:38 [INFO]   Training abgeschlossen in 41.11s (Backend: cuml)\n",
      "03:57:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:58:35 [INFO]   Training abgeschlossen in 40.99s (Backend: cuml)\n",
      "03:58:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:59:31 [INFO]   Training abgeschlossen in 41.27s (Backend: cuml)\n",
      "03:59:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:00:28 [INFO]   Training abgeschlossen in 42.60s (Backend: cuml)\n",
      "04:00:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:01:23 [INFO]   Training abgeschlossen in 40.87s (Backend: cuml)\n",
      "04:01:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:02:18 [INFO]   Training abgeschlossen in 40.91s (Backend: cuml)\n",
      "04:02:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:03:13 [INFO]   Training abgeschlossen in 42.22s (Backend: cuml)\n",
      "04:03:25 [INFO]     60,000 labeled → Accuracy: 0.8863 (Train: 42.2s, Query: 0.66s) | GPU: 2.8/8.0 GB\n",
      "04:03:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:04:06 [INFO]   Training abgeschlossen in 41.05s (Backend: cuml)\n",
      "04:04:18 [INFO]     Final: 60,000 labeled → Accuracy: 0.8861, F1: 0.8854\n",
      "04:04:18 [INFO]   Run 3/5\n",
      "04:04:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:04:23 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "04:05:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:05:35 [INFO]   Training abgeschlossen in 4.94s (Backend: cuml)\n",
      "04:06:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:06:46 [INFO]   Training abgeschlossen in 5.14s (Backend: cuml)\n",
      "04:07:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:07:58 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "04:09:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:09:11 [INFO]   Training abgeschlossen in 5.56s (Backend: cuml)\n",
      "04:10:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:10:23 [INFO]   Training abgeschlossen in 5.75s (Backend: cuml)\n",
      "04:11:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:11:36 [INFO]   Training abgeschlossen in 6.07s (Backend: cuml)\n",
      "04:12:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:12:48 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "04:13:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:14:01 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "04:15:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:15:13 [INFO]   Training abgeschlossen in 6.87s (Backend: cuml)\n",
      "04:16:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:16:26 [INFO]   Training abgeschlossen in 7.12s (Backend: cuml)\n",
      "04:17:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:17:39 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "04:18:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:18:51 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "04:19:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:20:04 [INFO]   Training abgeschlossen in 8.10s (Backend: cuml)\n",
      "04:21:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:21:17 [INFO]   Training abgeschlossen in 8.28s (Backend: cuml)\n",
      "04:22:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:22:30 [INFO]   Training abgeschlossen in 8.73s (Backend: cuml)\n",
      "04:23:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:23:43 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "04:24:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:24:55 [INFO]   Training abgeschlossen in 9.01s (Backend: cuml)\n",
      "04:25:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:26:07 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "04:27:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "04:27:20 [INFO]   Training abgeschlossen in 9.61s (Backend: cuml)\n",
      "04:28:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:28:32 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "04:29:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:29:44 [INFO]   Training abgeschlossen in 9.91s (Backend: cuml)\n",
      "04:30:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:30:56 [INFO]   Training abgeschlossen in 10.16s (Backend: cuml)\n",
      "04:31:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:32:09 [INFO]   Training abgeschlossen in 10.48s (Backend: cuml)\n",
      "04:33:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:33:20 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "04:34:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:34:32 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "04:35:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:35:43 [INFO]   Training abgeschlossen in 10.98s (Backend: cuml)\n",
      "04:36:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:36:55 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "04:37:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:38:06 [INFO]   Training abgeschlossen in 11.43s (Backend: cuml)\n",
      "04:39:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:39:16 [INFO]   Training abgeschlossen in 11.65s (Backend: cuml)\n",
      "04:40:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:40:26 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "04:41:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:41:38 [INFO]   Training abgeschlossen in 12.16s (Backend: cuml)\n",
      "04:42:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:42:48 [INFO]   Training abgeschlossen in 12.25s (Backend: cuml)\n",
      "04:43:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:43:59 [INFO]   Training abgeschlossen in 12.59s (Backend: cuml)\n",
      "04:44:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:45:10 [INFO]   Training abgeschlossen in 12.71s (Backend: cuml)\n",
      "04:46:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:46:19 [INFO]   Training abgeschlossen in 13.06s (Backend: cuml)\n",
      "04:47:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:47:28 [INFO]   Training abgeschlossen in 13.16s (Backend: cuml)\n",
      "04:48:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:48:37 [INFO]   Training abgeschlossen in 13.36s (Backend: cuml)\n",
      "04:49:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:49:46 [INFO]   Training abgeschlossen in 13.50s (Backend: cuml)\n",
      "04:50:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:50:54 [INFO]   Training abgeschlossen in 13.79s (Backend: cuml)\n",
      "04:51:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:52:02 [INFO]   Training abgeschlossen in 14.00s (Backend: cuml)\n",
      "04:52:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:53:10 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "04:54:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:54:18 [INFO]   Training abgeschlossen in 14.43s (Backend: cuml)\n",
      "04:55:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:55:25 [INFO]   Training abgeschlossen in 14.38s (Backend: cuml)\n",
      "04:56:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:56:32 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "04:57:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:57:39 [INFO]   Training abgeschlossen in 14.78s (Backend: cuml)\n",
      "04:58:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:58:45 [INFO]   Training abgeschlossen in 15.00s (Backend: cuml)\n",
      "04:59:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:59:51 [INFO]   Training abgeschlossen in 15.24s (Backend: cuml)\n",
      "05:00:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:00:57 [INFO]   Training abgeschlossen in 15.37s (Backend: cuml)\n",
      "05:01:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:02:03 [INFO]   Training abgeschlossen in 15.61s (Backend: cuml)\n",
      "05:02:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:03:08 [INFO]   Training abgeschlossen in 16.00s (Backend: cuml)\n",
      "05:03:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:04:13 [INFO]   Training abgeschlossen in 15.98s (Backend: cuml)\n",
      "05:05:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:05:18 [INFO]   Training abgeschlossen in 16.23s (Backend: cuml)\n",
      "05:06:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:06:22 [INFO]   Training abgeschlossen in 16.52s (Backend: cuml)\n",
      "05:07:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:07:27 [INFO]   Training abgeschlossen in 16.89s (Backend: cuml)\n",
      "05:08:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:08:30 [INFO]   Training abgeschlossen in 17.02s (Backend: cuml)\n",
      "05:09:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:09:34 [INFO]   Training abgeschlossen in 17.11s (Backend: cuml)\n",
      "05:10:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:10:37 [INFO]   Training abgeschlossen in 17.22s (Backend: cuml)\n",
      "05:11:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:11:40 [INFO]   Training abgeschlossen in 17.47s (Backend: cuml)\n",
      "05:12:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:12:43 [INFO]   Training abgeschlossen in 17.69s (Backend: cuml)\n",
      "05:13:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:13:45 [INFO]   Training abgeschlossen in 17.95s (Backend: cuml)\n",
      "05:14:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:14:47 [INFO]   Training abgeschlossen in 18.18s (Backend: cuml)\n",
      "05:15:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:15:49 [INFO]   Training abgeschlossen in 18.37s (Backend: cuml)\n",
      "05:16:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:16:50 [INFO]   Training abgeschlossen in 18.60s (Backend: cuml)\n",
      "05:17:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:17:51 [INFO]   Training abgeschlossen in 18.85s (Backend: cuml)\n",
      "05:18:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:18:52 [INFO]   Training abgeschlossen in 19.03s (Backend: cuml)\n",
      "05:19:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:19:53 [INFO]   Training abgeschlossen in 19.42s (Backend: cuml)\n",
      "05:20:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:20:53 [INFO]   Training abgeschlossen in 19.60s (Backend: cuml)\n",
      "05:21:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:21:53 [INFO]   Training abgeschlossen in 19.78s (Backend: cuml)\n",
      "05:22:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:22:53 [INFO]   Training abgeschlossen in 19.99s (Backend: cuml)\n",
      "05:23:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:23:53 [INFO]   Training abgeschlossen in 20.15s (Backend: cuml)\n",
      "05:24:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:24:52 [INFO]   Training abgeschlossen in 20.30s (Backend: cuml)\n",
      "05:25:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:25:51 [INFO]   Training abgeschlossen in 20.62s (Backend: cuml)\n",
      "05:26:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:26:49 [INFO]   Training abgeschlossen in 20.74s (Backend: cuml)\n",
      "05:27:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:27:47 [INFO]   Training abgeschlossen in 21.05s (Backend: cuml)\n",
      "05:28:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:28:45 [INFO]   Training abgeschlossen in 21.05s (Backend: cuml)\n",
      "05:29:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:29:42 [INFO]   Training abgeschlossen in 21.23s (Backend: cuml)\n",
      "05:30:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:30:39 [INFO]   Training abgeschlossen in 21.47s (Backend: cuml)\n",
      "05:31:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:31:36 [INFO]   Training abgeschlossen in 21.73s (Backend: cuml)\n",
      "05:32:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:32:32 [INFO]   Training abgeschlossen in 21.98s (Backend: cuml)\n",
      "05:33:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:33:29 [INFO]   Training abgeschlossen in 22.16s (Backend: cuml)\n",
      "05:34:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:34:25 [INFO]   Training abgeschlossen in 22.47s (Backend: cuml)\n",
      "05:34:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:35:20 [INFO]   Training abgeschlossen in 22.68s (Backend: cuml)\n",
      "05:35:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:36:15 [INFO]   Training abgeschlossen in 22.70s (Backend: cuml)\n",
      "05:36:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:37:10 [INFO]   Training abgeschlossen in 23.09s (Backend: cuml)\n",
      "05:37:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:38:05 [INFO]   Training abgeschlossen in 23.23s (Backend: cuml)\n",
      "05:38:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:38:59 [INFO]   Training abgeschlossen in 23.47s (Backend: cuml)\n",
      "05:39:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:39:53 [INFO]   Training abgeschlossen in 23.62s (Backend: cuml)\n",
      "05:40:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:40:46 [INFO]   Training abgeschlossen in 23.80s (Backend: cuml)\n",
      "05:41:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:41:39 [INFO]   Training abgeschlossen in 23.94s (Backend: cuml)\n",
      "05:42:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:42:32 [INFO]   Training abgeschlossen in 24.20s (Backend: cuml)\n",
      "05:43:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:43:24 [INFO]   Training abgeschlossen in 24.26s (Backend: cuml)\n",
      "05:43:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:44:16 [INFO]   Training abgeschlossen in 24.48s (Backend: cuml)\n",
      "05:44:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:45:07 [INFO]   Training abgeschlossen in 24.61s (Backend: cuml)\n",
      "05:45:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:45:59 [INFO]   Training abgeschlossen in 24.81s (Backend: cuml)\n",
      "05:46:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:46:50 [INFO]   Training abgeschlossen in 25.09s (Backend: cuml)\n",
      "05:47:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:47:40 [INFO]   Training abgeschlossen in 25.14s (Backend: cuml)\n",
      "05:48:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:48:30 [INFO]   Training abgeschlossen in 25.44s (Backend: cuml)\n",
      "05:48:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:49:20 [INFO]   Training abgeschlossen in 25.64s (Backend: cuml)\n",
      "05:49:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:50:21 [INFO]   Training abgeschlossen in 37.76s (Backend: cuml)\n",
      "05:50:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:51:24 [INFO]   Training abgeschlossen in 39.99s (Backend: cuml)\n",
      "05:51:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:52:25 [INFO]   Training abgeschlossen in 39.11s (Backend: cuml)\n",
      "05:52:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:53:26 [INFO]   Training abgeschlossen in 38.89s (Backend: cuml)\n",
      "05:53:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:54:24 [INFO]   Training abgeschlossen in 37.20s (Backend: cuml)\n",
      "05:54:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:55:25 [INFO]   Training abgeschlossen in 39.92s (Backend: cuml)\n",
      "05:55:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:56:25 [INFO]   Training abgeschlossen in 40.22s (Backend: cuml)\n",
      "05:56:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:57:26 [INFO]   Training abgeschlossen in 40.80s (Backend: cuml)\n",
      "05:57:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:58:25 [INFO]   Training abgeschlossen in 40.31s (Backend: cuml)\n",
      "05:58:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:59:25 [INFO]   Training abgeschlossen in 40.98s (Backend: cuml)\n",
      "05:59:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:00:24 [INFO]   Training abgeschlossen in 41.48s (Backend: cuml)\n",
      "06:00:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:01:22 [INFO]   Training abgeschlossen in 40.44s (Backend: cuml)\n",
      "06:01:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:02:20 [INFO]   Training abgeschlossen in 41.42s (Backend: cuml)\n",
      "06:02:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:03:16 [INFO]   Training abgeschlossen in 39.29s (Backend: cuml)\n",
      "06:03:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:04:13 [INFO]   Training abgeschlossen in 41.53s (Backend: cuml)\n",
      "06:04:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:05:08 [INFO]   Training abgeschlossen in 39.19s (Backend: cuml)\n",
      "06:05:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:06:04 [INFO]   Training abgeschlossen in 41.31s (Backend: cuml)\n",
      "06:06:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:06:58 [INFO]   Training abgeschlossen in 40.42s (Backend: cuml)\n",
      "06:07:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:07:54 [INFO]   Training abgeschlossen in 42.71s (Backend: cuml)\n",
      "06:08:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:08:49 [INFO]   Training abgeschlossen in 41.91s (Backend: cuml)\n",
      "06:09:02 [INFO]     60,000 labeled → Accuracy: 0.8856 (Train: 41.9s, Query: 0.65s) | GPU: 2.8/8.0 GB\n",
      "06:09:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:09:44 [INFO]   Training abgeschlossen in 41.91s (Backend: cuml)\n",
      "06:09:55 [INFO]     Final: 60,000 labeled → Accuracy: 0.8856, F1: 0.8848\n",
      "06:09:55 [INFO]   Run 4/5\n",
      "06:09:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:10:01 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "06:11:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:11:12 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "06:12:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:12:24 [INFO]   Training abgeschlossen in 5.13s (Backend: cuml)\n",
      "06:13:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:13:36 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "06:14:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:14:47 [INFO]   Training abgeschlossen in 5.21s (Backend: cuml)\n",
      "06:15:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:16:00 [INFO]   Training abgeschlossen in 5.77s (Backend: cuml)\n",
      "06:17:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:17:12 [INFO]   Training abgeschlossen in 5.97s (Backend: cuml)\n",
      "06:18:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:18:25 [INFO]   Training abgeschlossen in 6.47s (Backend: cuml)\n",
      "06:19:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:19:37 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "06:20:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:20:50 [INFO]   Training abgeschlossen in 6.87s (Backend: cuml)\n",
      "06:21:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:22:04 [INFO]   Training abgeschlossen in 7.44s (Backend: cuml)\n",
      "06:23:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:23:16 [INFO]   Training abgeschlossen in 7.59s (Backend: cuml)\n",
      "06:24:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:24:29 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "06:25:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:25:42 [INFO]   Training abgeschlossen in 8.05s (Backend: cuml)\n",
      "06:26:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:26:55 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "06:28:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:28:08 [INFO]   Training abgeschlossen in 8.54s (Backend: cuml)\n",
      "06:29:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:29:21 [INFO]   Training abgeschlossen in 8.69s (Backend: cuml)\n",
      "06:30:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:30:33 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "06:31:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:31:45 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "06:32:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:32:58 [INFO]   Training abgeschlossen in 9.42s (Backend: cuml)\n",
      "06:34:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:34:10 [INFO]   Training abgeschlossen in 9.89s (Backend: cuml)\n",
      "06:35:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:35:22 [INFO]   Training abgeschlossen in 9.83s (Backend: cuml)\n",
      "06:36:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:36:34 [INFO]   Training abgeschlossen in 10.10s (Backend: cuml)\n",
      "06:37:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:37:47 [INFO]   Training abgeschlossen in 10.41s (Backend: cuml)\n",
      "06:38:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:38:58 [INFO]   Training abgeschlossen in 10.51s (Backend: cuml)\n",
      "06:39:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:40:09 [INFO]   Training abgeschlossen in 10.75s (Backend: cuml)\n",
      "06:41:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:41:21 [INFO]   Training abgeschlossen in 10.94s (Backend: cuml)\n",
      "06:42:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:42:32 [INFO]   Training abgeschlossen in 11.21s (Backend: cuml)\n",
      "06:43:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:43:43 [INFO]   Training abgeschlossen in 11.50s (Backend: cuml)\n",
      "06:44:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:44:53 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "06:45:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:46:04 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "06:47:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:47:15 [INFO]   Training abgeschlossen in 12.34s (Backend: cuml)\n",
      "06:48:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:48:26 [INFO]   Training abgeschlossen in 12.31s (Backend: cuml)\n",
      "06:49:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:49:36 [INFO]   Training abgeschlossen in 12.48s (Backend: cuml)\n",
      "06:50:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:50:47 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "06:51:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:51:57 [INFO]   Training abgeschlossen in 13.09s (Backend: cuml)\n",
      "06:52:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:53:06 [INFO]   Training abgeschlossen in 13.21s (Backend: cuml)\n",
      "06:54:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:54:15 [INFO]   Training abgeschlossen in 13.32s (Backend: cuml)\n",
      "06:55:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:55:23 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "06:56:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:56:32 [INFO]   Training abgeschlossen in 13.80s (Backend: cuml)\n",
      "06:57:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:57:40 [INFO]   Training abgeschlossen in 13.98s (Backend: cuml)\n",
      "06:58:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:58:48 [INFO]   Training abgeschlossen in 14.40s (Backend: cuml)\n",
      "06:59:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:59:56 [INFO]   Training abgeschlossen in 14.39s (Backend: cuml)\n",
      "07:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:01:03 [INFO]   Training abgeschlossen in 14.28s (Backend: cuml)\n",
      "07:01:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:02:10 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "07:03:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:03:16 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "07:04:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:04:22 [INFO]   Training abgeschlossen in 15.15s (Backend: cuml)\n",
      "07:05:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:05:29 [INFO]   Training abgeschlossen in 15.20s (Backend: cuml)\n",
      "07:06:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:06:34 [INFO]   Training abgeschlossen in 15.29s (Backend: cuml)\n",
      "07:07:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:07:40 [INFO]   Training abgeschlossen in 15.58s (Backend: cuml)\n",
      "07:08:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:08:45 [INFO]   Training abgeschlossen in 15.97s (Backend: cuml)\n",
      "07:09:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:09:50 [INFO]   Training abgeschlossen in 15.94s (Backend: cuml)\n",
      "07:10:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:10:55 [INFO]   Training abgeschlossen in 16.30s (Backend: cuml)\n",
      "07:11:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:11:59 [INFO]   Training abgeschlossen in 16.62s (Backend: cuml)\n",
      "07:12:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:13:03 [INFO]   Training abgeschlossen in 16.70s (Backend: cuml)\n",
      "07:13:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:14:07 [INFO]   Training abgeschlossen in 16.90s (Backend: cuml)\n",
      "07:14:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:15:10 [INFO]   Training abgeschlossen in 17.07s (Backend: cuml)\n",
      "07:15:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:16:13 [INFO]   Training abgeschlossen in 17.27s (Backend: cuml)\n",
      "07:16:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:17:16 [INFO]   Training abgeschlossen in 17.47s (Backend: cuml)\n",
      "07:18:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:18:19 [INFO]   Training abgeschlossen in 17.74s (Backend: cuml)\n",
      "07:19:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:19:21 [INFO]   Training abgeschlossen in 17.88s (Backend: cuml)\n",
      "07:20:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:20:24 [INFO]   Training abgeschlossen in 18.20s (Backend: cuml)\n",
      "07:21:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:21:25 [INFO]   Training abgeschlossen in 18.40s (Backend: cuml)\n",
      "07:22:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:22:27 [INFO]   Training abgeschlossen in 18.82s (Backend: cuml)\n",
      "07:23:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:23:29 [INFO]   Training abgeschlossen in 18.94s (Backend: cuml)\n",
      "07:24:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:24:29 [INFO]   Training abgeschlossen in 19.02s (Backend: cuml)\n",
      "07:25:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:25:30 [INFO]   Training abgeschlossen in 19.34s (Backend: cuml)\n",
      "07:26:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:26:30 [INFO]   Training abgeschlossen in 19.39s (Backend: cuml)\n",
      "07:27:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:27:30 [INFO]   Training abgeschlossen in 19.82s (Backend: cuml)\n",
      "07:28:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:28:30 [INFO]   Training abgeschlossen in 19.91s (Backend: cuml)\n",
      "07:29:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:29:29 [INFO]   Training abgeschlossen in 19.95s (Backend: cuml)\n",
      "07:30:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:30:28 [INFO]   Training abgeschlossen in 20.37s (Backend: cuml)\n",
      "07:31:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:31:27 [INFO]   Training abgeschlossen in 20.45s (Backend: cuml)\n",
      "07:32:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:32:26 [INFO]   Training abgeschlossen in 20.68s (Backend: cuml)\n",
      "07:33:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:33:24 [INFO]   Training abgeschlossen in 20.87s (Backend: cuml)\n",
      "07:34:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:34:22 [INFO]   Training abgeschlossen in 21.12s (Backend: cuml)\n",
      "07:34:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:35:19 [INFO]   Training abgeschlossen in 21.27s (Backend: cuml)\n",
      "07:35:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:36:16 [INFO]   Training abgeschlossen in 21.46s (Backend: cuml)\n",
      "07:36:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:37:13 [INFO]   Training abgeschlossen in 21.65s (Backend: cuml)\n",
      "07:37:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:38:09 [INFO]   Training abgeschlossen in 21.87s (Backend: cuml)\n",
      "07:38:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:39:06 [INFO]   Training abgeschlossen in 22.03s (Backend: cuml)\n",
      "07:39:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:40:01 [INFO]   Training abgeschlossen in 22.41s (Backend: cuml)\n",
      "07:40:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:40:57 [INFO]   Training abgeschlossen in 22.61s (Backend: cuml)\n",
      "07:41:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:41:52 [INFO]   Training abgeschlossen in 22.68s (Backend: cuml)\n",
      "07:42:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:42:47 [INFO]   Training abgeschlossen in 22.81s (Backend: cuml)\n",
      "07:43:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:43:42 [INFO]   Training abgeschlossen in 23.08s (Backend: cuml)\n",
      "07:44:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:44:36 [INFO]   Training abgeschlossen in 23.30s (Backend: cuml)\n",
      "07:45:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:45:29 [INFO]   Training abgeschlossen in 23.46s (Backend: cuml)\n",
      "07:45:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:46:23 [INFO]   Training abgeschlossen in 23.67s (Backend: cuml)\n",
      "07:46:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:47:16 [INFO]   Training abgeschlossen in 23.84s (Backend: cuml)\n",
      "07:47:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:48:08 [INFO]   Training abgeschlossen in 24.18s (Backend: cuml)\n",
      "07:48:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:49:01 [INFO]   Training abgeschlossen in 24.35s (Backend: cuml)\n",
      "07:49:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:49:53 [INFO]   Training abgeschlossen in 24.48s (Backend: cuml)\n",
      "07:50:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:50:44 [INFO]   Training abgeschlossen in 24.86s (Backend: cuml)\n",
      "07:51:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:51:36 [INFO]   Training abgeschlossen in 25.02s (Backend: cuml)\n",
      "07:52:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:52:27 [INFO]   Training abgeschlossen in 25.15s (Backend: cuml)\n",
      "07:52:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:53:17 [INFO]   Training abgeschlossen in 25.29s (Backend: cuml)\n",
      "07:53:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:54:07 [INFO]   Training abgeschlossen in 25.59s (Backend: cuml)\n",
      "07:54:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:54:57 [INFO]   Training abgeschlossen in 25.60s (Backend: cuml)\n",
      "07:55:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:55:58 [INFO]   Training abgeschlossen in 37.67s (Backend: cuml)\n",
      "07:56:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:57:00 [INFO]   Training abgeschlossen in 38.82s (Backend: cuml)\n",
      "07:57:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:58:02 [INFO]   Training abgeschlossen in 39.58s (Backend: cuml)\n",
      "07:58:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "07:59:02 [INFO]   Training abgeschlossen in 37.33s (Backend: cuml)\n",
      "07:59:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:00:02 [INFO]   Training abgeschlossen in 39.46s (Backend: cuml)\n",
      "08:00:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:01:01 [INFO]   Training abgeschlossen in 38.16s (Backend: cuml)\n",
      "08:01:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:01:59 [INFO]   Training abgeschlossen in 37.43s (Backend: cuml)\n",
      "08:02:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:02:58 [INFO]   Training abgeschlossen in 39.25s (Backend: cuml)\n",
      "08:03:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:03:56 [INFO]   Training abgeschlossen in 39.65s (Backend: cuml)\n",
      "08:04:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:04:54 [INFO]   Training abgeschlossen in 39.44s (Backend: cuml)\n",
      "08:05:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:05:54 [INFO]   Training abgeschlossen in 41.32s (Backend: cuml)\n",
      "08:06:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:06:54 [INFO]   Training abgeschlossen in 43.25s (Backend: cuml)\n",
      "08:07:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:07:51 [INFO]   Training abgeschlossen in 40.54s (Backend: cuml)\n",
      "08:08:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:08:49 [INFO]   Training abgeschlossen in 41.46s (Backend: cuml)\n",
      "08:09:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:09:47 [INFO]   Training abgeschlossen in 41.61s (Backend: cuml)\n",
      "08:10:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:10:42 [INFO]   Training abgeschlossen in 40.01s (Backend: cuml)\n",
      "08:10:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:11:39 [INFO]   Training abgeschlossen in 41.94s (Backend: cuml)\n",
      "08:11:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:12:34 [INFO]   Training abgeschlossen in 40.94s (Backend: cuml)\n",
      "08:12:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:13:29 [INFO]   Training abgeschlossen in 41.54s (Backend: cuml)\n",
      "08:13:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:14:24 [INFO]   Training abgeschlossen in 41.68s (Backend: cuml)\n",
      "08:14:36 [INFO]     60,000 labeled → Accuracy: 0.8850 (Train: 41.7s, Query: 0.66s) | GPU: 2.8/8.0 GB\n",
      "08:14:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:15:20 [INFO]   Training abgeschlossen in 43.85s (Backend: cuml)\n",
      "08:15:31 [INFO]     Final: 60,000 labeled → Accuracy: 0.8850, F1: 0.8842\n",
      "08:15:32 [INFO]   Run 5/5\n",
      "08:15:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:15:37 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "08:16:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:16:48 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "08:17:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:18:00 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "08:19:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:19:12 [INFO]   Training abgeschlossen in 5.14s (Backend: cuml)\n",
      "08:20:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:20:24 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "08:21:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:21:36 [INFO]   Training abgeschlossen in 5.74s (Backend: cuml)\n",
      "08:22:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:22:49 [INFO]   Training abgeschlossen in 6.01s (Backend: cuml)\n",
      "08:23:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:24:01 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "08:25:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:25:14 [INFO]   Training abgeschlossen in 6.62s (Backend: cuml)\n",
      "08:26:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:26:26 [INFO]   Training abgeschlossen in 6.94s (Backend: cuml)\n",
      "08:27:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:27:39 [INFO]   Training abgeschlossen in 7.27s (Backend: cuml)\n",
      "08:28:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:28:52 [INFO]   Training abgeschlossen in 7.48s (Backend: cuml)\n",
      "08:29:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:30:05 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "08:31:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:31:17 [INFO]   Training abgeschlossen in 7.97s (Backend: cuml)\n",
      "08:32:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:32:30 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "08:33:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:33:42 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "08:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:34:55 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "08:35:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:36:08 [INFO]   Training abgeschlossen in 9.03s (Backend: cuml)\n",
      "08:37:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:37:21 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "08:38:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:38:33 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "08:39:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:39:45 [INFO]   Training abgeschlossen in 9.70s (Backend: cuml)\n",
      "08:40:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:40:57 [INFO]   Training abgeschlossen in 9.87s (Backend: cuml)\n",
      "08:41:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:42:09 [INFO]   Training abgeschlossen in 10.06s (Backend: cuml)\n",
      "08:43:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:43:21 [INFO]   Training abgeschlossen in 10.34s (Backend: cuml)\n",
      "08:44:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:44:33 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "08:45:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:45:44 [INFO]   Training abgeschlossen in 10.74s (Backend: cuml)\n",
      "08:46:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:46:55 [INFO]   Training abgeschlossen in 10.98s (Backend: cuml)\n",
      "08:47:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:48:07 [INFO]   Training abgeschlossen in 11.25s (Backend: cuml)\n",
      "08:49:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:49:18 [INFO]   Training abgeschlossen in 11.42s (Backend: cuml)\n",
      "08:50:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:50:29 [INFO]   Training abgeschlossen in 11.63s (Backend: cuml)\n",
      "08:51:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "08:51:40 [INFO]   Training abgeschlossen in 11.90s (Backend: cuml)\n",
      "08:52:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:52:50 [INFO]   Training abgeschlossen in 12.07s (Backend: cuml)\n",
      "08:53:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:54:01 [INFO]   Training abgeschlossen in 12.50s (Backend: cuml)\n",
      "08:54:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:55:12 [INFO]   Training abgeschlossen in 12.57s (Backend: cuml)\n",
      "08:56:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:56:22 [INFO]   Training abgeschlossen in 12.78s (Backend: cuml)\n",
      "08:57:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:57:31 [INFO]   Training abgeschlossen in 12.96s (Backend: cuml)\n",
      "08:58:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:58:41 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "08:59:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:59:49 [INFO]   Training abgeschlossen in 13.40s (Backend: cuml)\n",
      "09:00:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:00:58 [INFO]   Training abgeschlossen in 13.58s (Backend: cuml)\n",
      "09:01:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:02:06 [INFO]   Training abgeschlossen in 13.74s (Backend: cuml)\n",
      "09:03:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:03:14 [INFO]   Training abgeschlossen in 14.01s (Backend: cuml)\n",
      "09:04:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:04:22 [INFO]   Training abgeschlossen in 14.29s (Backend: cuml)\n",
      "09:05:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:05:30 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "09:06:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:06:37 [INFO]   Training abgeschlossen in 14.23s (Backend: cuml)\n",
      "09:07:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:07:43 [INFO]   Training abgeschlossen in 14.45s (Backend: cuml)\n",
      "09:08:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:08:50 [INFO]   Training abgeschlossen in 14.68s (Backend: cuml)\n",
      "09:09:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:09:56 [INFO]   Training abgeschlossen in 14.88s (Backend: cuml)\n",
      "09:10:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:11:02 [INFO]   Training abgeschlossen in 15.18s (Backend: cuml)\n",
      "09:11:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:12:08 [INFO]   Training abgeschlossen in 15.53s (Backend: cuml)\n",
      "09:12:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:13:13 [INFO]   Training abgeschlossen in 15.51s (Backend: cuml)\n",
      "09:14:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:14:19 [INFO]   Training abgeschlossen in 15.95s (Backend: cuml)\n",
      "09:15:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:15:24 [INFO]   Training abgeschlossen in 15.97s (Backend: cuml)\n",
      "09:16:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:16:29 [INFO]   Training abgeschlossen in 16.12s (Backend: cuml)\n",
      "09:17:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:17:33 [INFO]   Training abgeschlossen in 16.41s (Backend: cuml)\n",
      "09:18:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:18:37 [INFO]   Training abgeschlossen in 16.72s (Backend: cuml)\n",
      "09:19:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:19:41 [INFO]   Training abgeschlossen in 16.93s (Backend: cuml)\n",
      "09:20:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:20:44 [INFO]   Training abgeschlossen in 17.04s (Backend: cuml)\n",
      "09:21:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:21:48 [INFO]   Training abgeschlossen in 17.25s (Backend: cuml)\n",
      "09:22:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:22:51 [INFO]   Training abgeschlossen in 17.47s (Backend: cuml)\n",
      "09:23:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:23:53 [INFO]   Training abgeschlossen in 17.74s (Backend: cuml)\n",
      "09:24:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:24:56 [INFO]   Training abgeschlossen in 17.93s (Backend: cuml)\n",
      "09:25:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:25:58 [INFO]   Training abgeschlossen in 18.22s (Backend: cuml)\n",
      "09:26:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:27:00 [INFO]   Training abgeschlossen in 18.51s (Backend: cuml)\n",
      "09:27:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:28:01 [INFO]   Training abgeschlossen in 18.89s (Backend: cuml)\n",
      "09:28:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:29:02 [INFO]   Training abgeschlossen in 18.78s (Backend: cuml)\n",
      "09:29:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:30:03 [INFO]   Training abgeschlossen in 19.03s (Backend: cuml)\n",
      "09:30:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:31:04 [INFO]   Training abgeschlossen in 19.19s (Backend: cuml)\n",
      "09:31:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:32:04 [INFO]   Training abgeschlossen in 19.35s (Backend: cuml)\n",
      "09:32:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:33:03 [INFO]   Training abgeschlossen in 19.50s (Backend: cuml)\n",
      "09:33:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:34:03 [INFO]   Training abgeschlossen in 19.78s (Backend: cuml)\n",
      "09:34:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:35:02 [INFO]   Training abgeschlossen in 19.92s (Backend: cuml)\n",
      "09:35:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:36:01 [INFO]   Training abgeschlossen in 20.19s (Backend: cuml)\n",
      "09:36:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:36:59 [INFO]   Training abgeschlossen in 20.35s (Backend: cuml)\n",
      "09:37:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:37:57 [INFO]   Training abgeschlossen in 20.61s (Backend: cuml)\n",
      "09:38:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:38:55 [INFO]   Training abgeschlossen in 20.82s (Backend: cuml)\n",
      "09:39:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:39:53 [INFO]   Training abgeschlossen in 21.06s (Backend: cuml)\n",
      "09:40:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:40:50 [INFO]   Training abgeschlossen in 21.43s (Backend: cuml)\n",
      "09:41:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:41:47 [INFO]   Training abgeschlossen in 21.50s (Backend: cuml)\n",
      "09:42:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:42:44 [INFO]   Training abgeschlossen in 21.67s (Backend: cuml)\n",
      "09:43:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:43:40 [INFO]   Training abgeschlossen in 21.86s (Backend: cuml)\n",
      "09:44:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:44:36 [INFO]   Training abgeschlossen in 22.07s (Backend: cuml)\n",
      "09:45:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:45:32 [INFO]   Training abgeschlossen in 22.19s (Backend: cuml)\n",
      "09:46:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:46:27 [INFO]   Training abgeschlossen in 22.46s (Backend: cuml)\n",
      "09:46:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:47:22 [INFO]   Training abgeschlossen in 22.59s (Backend: cuml)\n",
      "09:47:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:48:17 [INFO]   Training abgeschlossen in 22.90s (Backend: cuml)\n",
      "09:48:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:49:11 [INFO]   Training abgeschlossen in 23.12s (Backend: cuml)\n",
      "09:49:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:50:05 [INFO]   Training abgeschlossen in 23.23s (Backend: cuml)\n",
      "09:50:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:50:59 [INFO]   Training abgeschlossen in 23.53s (Backend: cuml)\n",
      "09:51:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:51:52 [INFO]   Training abgeschlossen in 23.72s (Backend: cuml)\n",
      "09:52:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:52:45 [INFO]   Training abgeschlossen in 23.85s (Backend: cuml)\n",
      "09:53:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:53:38 [INFO]   Training abgeschlossen in 24.29s (Backend: cuml)\n",
      "09:54:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:54:30 [INFO]   Training abgeschlossen in 24.66s (Backend: cuml)\n",
      "09:54:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:55:22 [INFO]   Training abgeschlossen in 24.55s (Backend: cuml)\n",
      "09:55:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:56:14 [INFO]   Training abgeschlossen in 24.68s (Backend: cuml)\n",
      "09:56:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:57:05 [INFO]   Training abgeschlossen in 24.95s (Backend: cuml)\n",
      "09:57:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:57:56 [INFO]   Training abgeschlossen in 24.98s (Backend: cuml)\n",
      "09:58:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:58:46 [INFO]   Training abgeschlossen in 25.17s (Backend: cuml)\n",
      "09:59:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "09:59:36 [INFO]   Training abgeschlossen in 25.39s (Backend: cuml)\n",
      "10:00:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:00:26 [INFO]   Training abgeschlossen in 25.63s (Backend: cuml)\n",
      "10:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:01:25 [INFO]   Training abgeschlossen in 35.79s (Backend: cuml)\n",
      "10:01:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:02:28 [INFO]   Training abgeschlossen in 39.58s (Backend: cuml)\n",
      "10:02:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:03:28 [INFO]   Training abgeschlossen in 38.28s (Backend: cuml)\n",
      "10:03:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:04:30 [INFO]   Training abgeschlossen in 39.62s (Backend: cuml)\n",
      "10:04:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:05:31 [INFO]   Training abgeschlossen in 39.21s (Backend: cuml)\n",
      "10:05:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:06:29 [INFO]   Training abgeschlossen in 37.74s (Backend: cuml)\n",
      "10:06:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:07:30 [INFO]   Training abgeschlossen in 40.78s (Backend: cuml)\n",
      "10:07:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:08:30 [INFO]   Training abgeschlossen in 39.84s (Backend: cuml)\n",
      "10:08:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:09:27 [INFO]   Training abgeschlossen in 38.10s (Backend: cuml)\n",
      "10:09:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:10:25 [INFO]   Training abgeschlossen in 40.26s (Backend: cuml)\n",
      "10:10:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:11:23 [INFO]   Training abgeschlossen in 40.06s (Backend: cuml)\n",
      "10:11:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:12:23 [INFO]   Training abgeschlossen in 42.14s (Backend: cuml)\n",
      "10:12:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:13:21 [INFO]   Training abgeschlossen in 41.11s (Backend: cuml)\n",
      "10:13:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:14:19 [INFO]   Training abgeschlossen in 41.90s (Backend: cuml)\n",
      "10:14:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:15:15 [INFO]   Training abgeschlossen in 40.37s (Backend: cuml)\n",
      "10:15:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:16:12 [INFO]   Training abgeschlossen in 41.15s (Backend: cuml)\n",
      "10:16:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:17:07 [INFO]   Training abgeschlossen in 40.51s (Backend: cuml)\n",
      "10:17:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:18:03 [INFO]   Training abgeschlossen in 41.72s (Backend: cuml)\n",
      "10:18:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:18:59 [INFO]   Training abgeschlossen in 42.89s (Backend: cuml)\n",
      "10:19:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:19:55 [INFO]   Training abgeschlossen in 43.03s (Backend: cuml)\n",
      "10:20:07 [INFO]     60,000 labeled → Accuracy: 0.8860 (Train: 43.1s, Query: 0.64s) | GPU: 2.8/8.0 GB\n",
      "10:20:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:20:50 [INFO]   Training abgeschlossen in 42.81s (Backend: cuml)\n",
      "10:21:02 [INFO]     Final: 60,000 labeled → Accuracy: 0.8861, F1: 0.8853\n",
      "\n",
      "============================================================\n",
      "Strategie: Margin Sampling\n",
      "============================================================\n",
      "10:21:02 [INFO] \n",
      "GPU-SVM + Margin Sampling - Budget: 20% (12,000 Samples)\n",
      "10:21:02 [INFO]   Run 1/5\n",
      "10:21:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 0.3/8.0 GB)\n",
      "10:21:07 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "10:22:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:22:18 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "10:23:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:23:30 [INFO]   Training abgeschlossen in 5.02s (Backend: cuml)\n",
      "10:24:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:24:42 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "10:25:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:25:54 [INFO]   Training abgeschlossen in 5.34s (Backend: cuml)\n",
      "10:27:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:27:05 [INFO]   Training abgeschlossen in 5.71s (Backend: cuml)\n",
      "10:28:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:28:17 [INFO]   Training abgeschlossen in 5.85s (Backend: cuml)\n",
      "10:29:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:29:29 [INFO]   Training abgeschlossen in 6.21s (Backend: cuml)\n",
      "10:30:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:30:42 [INFO]   Training abgeschlossen in 6.71s (Backend: cuml)\n",
      "10:31:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:31:54 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "10:32:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:33:06 [INFO]   Training abgeschlossen in 7.26s (Backend: cuml)\n",
      "10:34:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:34:18 [INFO]   Training abgeschlossen in 7.77s (Backend: cuml)\n",
      "10:35:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:35:31 [INFO]   Training abgeschlossen in 7.84s (Backend: cuml)\n",
      "10:36:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:36:44 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "10:37:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:37:56 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "10:39:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:39:09 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "10:40:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:40:22 [INFO]   Training abgeschlossen in 8.74s (Backend: cuml)\n",
      "10:41:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:41:34 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "10:42:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:42:47 [INFO]   Training abgeschlossen in 9.33s (Backend: cuml)\n",
      "10:43:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:43:59 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "10:45:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:45:12 [INFO]   Training abgeschlossen in 9.93s (Backend: cuml)\n",
      "10:46:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:46:24 [INFO]   Training abgeschlossen in 9.91s (Backend: cuml)\n",
      "10:47:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:47:35 [INFO]   Training abgeschlossen in 10.04s (Backend: cuml)\n",
      "10:48:36 [INFO]     12,000 labeled → Accuracy: 0.8818 (Train: 10.0s, Query: 49.99s) | GPU: 2.7/8.0 GB\n",
      "10:48:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:48:47 [INFO]   Training abgeschlossen in 10.45s (Backend: cuml)\n",
      "10:48:57 [INFO]     Final: 12,000 labeled → Accuracy: 0.8837, F1: 0.8836\n",
      "10:48:58 [INFO]   Run 2/5\n",
      "10:48:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:49:03 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "10:50:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:50:15 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "10:51:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:51:26 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "10:52:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:52:38 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "10:53:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:53:50 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "10:54:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:55:01 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "10:56:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:56:14 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "10:57:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:57:26 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "10:58:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:58:38 [INFO]   Training abgeschlossen in 6.58s (Backend: cuml)\n",
      "10:59:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:59:50 [INFO]   Training abgeschlossen in 6.81s (Backend: cuml)\n",
      "11:00:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:01:03 [INFO]   Training abgeschlossen in 7.26s (Backend: cuml)\n",
      "11:02:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:02:15 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "11:03:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:03:28 [INFO]   Training abgeschlossen in 7.70s (Backend: cuml)\n",
      "11:04:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:04:40 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "11:05:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:05:53 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "11:06:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:07:05 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "11:08:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:08:17 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "11:09:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:09:29 [INFO]   Training abgeschlossen in 8.89s (Backend: cuml)\n",
      "11:10:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:10:42 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "11:11:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:11:54 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "11:12:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:13:06 [INFO]   Training abgeschlossen in 9.59s (Backend: cuml)\n",
      "11:14:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:14:18 [INFO]   Training abgeschlossen in 9.83s (Backend: cuml)\n",
      "11:15:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:15:30 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "11:16:31 [INFO]     12,000 labeled → Accuracy: 0.8785 (Train: 10.1s, Query: 50.56s) | GPU: 2.7/8.0 GB\n",
      "11:16:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:16:42 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "11:16:52 [INFO]     Final: 12,000 labeled → Accuracy: 0.8785, F1: 0.8785\n",
      "11:16:53 [INFO]   Run 3/5\n",
      "11:16:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:16:58 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "11:18:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:18:09 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "11:19:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:19:20 [INFO]   Training abgeschlossen in 5.04s (Backend: cuml)\n",
      "11:20:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:20:32 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "11:21:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:21:44 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "11:22:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:22:55 [INFO]   Training abgeschlossen in 5.65s (Backend: cuml)\n",
      "11:24:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:24:07 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "11:25:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:25:19 [INFO]   Training abgeschlossen in 6.20s (Backend: cuml)\n",
      "11:26:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:26:31 [INFO]   Training abgeschlossen in 6.56s (Backend: cuml)\n",
      "11:27:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:27:43 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "11:28:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:28:55 [INFO]   Training abgeschlossen in 7.20s (Backend: cuml)\n",
      "11:30:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:30:07 [INFO]   Training abgeschlossen in 7.43s (Backend: cuml)\n",
      "11:31:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:31:20 [INFO]   Training abgeschlossen in 7.69s (Backend: cuml)\n",
      "11:32:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:32:32 [INFO]   Training abgeschlossen in 7.97s (Backend: cuml)\n",
      "11:33:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:33:44 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "11:34:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:34:56 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "11:36:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:36:09 [INFO]   Training abgeschlossen in 8.69s (Backend: cuml)\n",
      "11:37:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:37:21 [INFO]   Training abgeschlossen in 9.01s (Backend: cuml)\n",
      "11:38:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:38:33 [INFO]   Training abgeschlossen in 9.15s (Backend: cuml)\n",
      "11:39:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:39:45 [INFO]   Training abgeschlossen in 9.47s (Backend: cuml)\n",
      "11:40:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:40:57 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "11:41:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:42:09 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "11:43:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:43:22 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "11:44:23 [INFO]     12,000 labeled → Accuracy: 0.8826 (Train: 10.1s, Query: 50.49s) | GPU: 2.6/8.0 GB\n",
      "11:44:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:44:34 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "11:44:45 [INFO]     Final: 12,000 labeled → Accuracy: 0.8845, F1: 0.8842\n",
      "11:44:45 [INFO]   Run 4/5\n",
      "11:44:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:44:50 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "11:45:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:46:01 [INFO]   Training abgeschlossen in 4.98s (Backend: cuml)\n",
      "11:47:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:47:13 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "11:48:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "11:48:25 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "11:49:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:49:37 [INFO]   Training abgeschlossen in 5.53s (Backend: cuml)\n",
      "11:50:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:50:49 [INFO]   Training abgeschlossen in 5.61s (Backend: cuml)\n",
      "11:51:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:52:01 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "11:53:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "11:53:13 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "11:54:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:54:25 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "11:55:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:55:38 [INFO]   Training abgeschlossen in 6.98s (Backend: cuml)\n",
      "11:56:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:56:50 [INFO]   Training abgeschlossen in 7.18s (Backend: cuml)\n",
      "11:57:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:58:02 [INFO]   Training abgeschlossen in 7.56s (Backend: cuml)\n",
      "11:59:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "11:59:15 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "12:00:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:00:27 [INFO]   Training abgeschlossen in 7.96s (Backend: cuml)\n",
      "12:01:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:01:40 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "12:02:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:02:53 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "12:03:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:04:05 [INFO]   Training abgeschlossen in 8.71s (Backend: cuml)\n",
      "12:05:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:05:17 [INFO]   Training abgeschlossen in 8.91s (Backend: cuml)\n",
      "12:06:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:06:29 [INFO]   Training abgeschlossen in 9.34s (Backend: cuml)\n",
      "12:07:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:07:42 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "12:08:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:08:54 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "12:09:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:10:06 [INFO]   Training abgeschlossen in 9.84s (Backend: cuml)\n",
      "12:11:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:11:18 [INFO]   Training abgeschlossen in 10.16s (Backend: cuml)\n",
      "12:12:20 [INFO]     12,000 labeled → Accuracy: 0.8813 (Train: 10.2s, Query: 50.39s) | GPU: 2.6/8.0 GB\n",
      "12:12:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:12:30 [INFO]   Training abgeschlossen in 10.22s (Backend: cuml)\n",
      "12:12:41 [INFO]     Final: 12,000 labeled → Accuracy: 0.8824, F1: 0.8823\n",
      "12:12:41 [INFO]   Run 5/5\n",
      "12:12:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:12:46 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "12:13:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:13:57 [INFO]   Training abgeschlossen in 4.97s (Backend: cuml)\n",
      "12:15:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:15:08 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "12:16:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:16:20 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "12:17:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:17:32 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "12:18:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:18:43 [INFO]   Training abgeschlossen in 5.56s (Backend: cuml)\n",
      "12:19:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:19:55 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "12:21:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:21:07 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "12:22:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:22:19 [INFO]   Training abgeschlossen in 6.48s (Backend: cuml)\n",
      "12:23:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:23:32 [INFO]   Training abgeschlossen in 7.03s (Backend: cuml)\n",
      "12:24:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:24:44 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "12:25:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:25:56 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "12:27:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:27:09 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "12:28:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:28:22 [INFO]   Training abgeschlossen in 8.12s (Backend: cuml)\n",
      "12:29:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:29:34 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "12:30:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:30:46 [INFO]   Training abgeschlossen in 8.48s (Backend: cuml)\n",
      "12:31:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:31:58 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "12:33:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:33:11 [INFO]   Training abgeschlossen in 9.11s (Backend: cuml)\n",
      "12:34:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:34:23 [INFO]   Training abgeschlossen in 9.18s (Backend: cuml)\n",
      "12:35:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:35:34 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "12:36:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:36:46 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "12:37:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:37:59 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "12:39:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:39:11 [INFO]   Training abgeschlossen in 10.05s (Backend: cuml)\n",
      "12:40:13 [INFO]     12,000 labeled → Accuracy: 0.8798 (Train: 10.1s, Query: 50.51s) | GPU: 2.6/8.0 GB\n",
      "12:40:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:40:23 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "12:40:34 [INFO]     Final: 12,000 labeled → Accuracy: 0.8797, F1: 0.8794\n",
      "12:40:34 [INFO] \n",
      "GPU-SVM + Margin Sampling - Budget: 40% (24,000 Samples)\n",
      "12:40:34 [INFO]   Run 1/5\n",
      "12:40:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:40:39 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "12:41:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:41:50 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "12:42:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:43:02 [INFO]   Training abgeschlossen in 5.06s (Backend: cuml)\n",
      "12:44:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:44:14 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "12:45:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:45:25 [INFO]   Training abgeschlossen in 5.42s (Backend: cuml)\n",
      "12:46:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:46:37 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "12:47:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:47:49 [INFO]   Training abgeschlossen in 5.90s (Backend: cuml)\n",
      "12:48:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:49:01 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "12:50:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:50:13 [INFO]   Training abgeschlossen in 6.59s (Backend: cuml)\n",
      "12:51:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:51:26 [INFO]   Training abgeschlossen in 6.86s (Backend: cuml)\n",
      "12:52:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:52:38 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "12:53:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:53:51 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "12:54:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:55:03 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "12:56:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:56:15 [INFO]   Training abgeschlossen in 7.91s (Backend: cuml)\n",
      "12:57:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:57:28 [INFO]   Training abgeschlossen in 8.19s (Backend: cuml)\n",
      "12:58:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:58:40 [INFO]   Training abgeschlossen in 8.61s (Backend: cuml)\n",
      "12:59:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:59:53 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "13:00:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:01:05 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "13:02:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:02:17 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "13:03:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:03:29 [INFO]   Training abgeschlossen in 9.48s (Backend: cuml)\n",
      "13:04:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:04:41 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "13:05:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:05:53 [INFO]   Training abgeschlossen in 9.86s (Backend: cuml)\n",
      "13:06:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:07:05 [INFO]   Training abgeschlossen in 10.12s (Backend: cuml)\n",
      "13:08:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:08:17 [INFO]   Training abgeschlossen in 10.38s (Backend: cuml)\n",
      "13:09:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:09:28 [INFO]   Training abgeschlossen in 10.46s (Backend: cuml)\n",
      "13:10:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:10:39 [INFO]   Training abgeschlossen in 10.68s (Backend: cuml)\n",
      "13:11:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:11:51 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "13:12:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:13:02 [INFO]   Training abgeschlossen in 11.21s (Backend: cuml)\n",
      "13:14:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:14:13 [INFO]   Training abgeschlossen in 11.33s (Backend: cuml)\n",
      "13:15:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:15:24 [INFO]   Training abgeschlossen in 11.63s (Backend: cuml)\n",
      "13:16:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:16:35 [INFO]   Training abgeschlossen in 11.74s (Backend: cuml)\n",
      "13:17:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:17:46 [INFO]   Training abgeschlossen in 12.13s (Backend: cuml)\n",
      "13:18:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:18:57 [INFO]   Training abgeschlossen in 12.20s (Backend: cuml)\n",
      "13:19:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:20:08 [INFO]   Training abgeschlossen in 12.51s (Backend: cuml)\n",
      "13:21:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:21:19 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "13:22:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:22:28 [INFO]   Training abgeschlossen in 13.04s (Backend: cuml)\n",
      "13:23:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:23:37 [INFO]   Training abgeschlossen in 13.13s (Backend: cuml)\n",
      "13:24:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:24:46 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "13:25:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:25:55 [INFO]   Training abgeschlossen in 13.53s (Backend: cuml)\n",
      "13:26:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:27:03 [INFO]   Training abgeschlossen in 13.82s (Backend: cuml)\n",
      "13:27:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:28:11 [INFO]   Training abgeschlossen in 14.10s (Backend: cuml)\n",
      "13:29:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:29:19 [INFO]   Training abgeschlossen in 14.21s (Backend: cuml)\n",
      "13:30:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:30:27 [INFO]   Training abgeschlossen in 14.36s (Backend: cuml)\n",
      "13:31:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:31:34 [INFO]   Training abgeschlossen in 14.24s (Backend: cuml)\n",
      "13:32:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:32:41 [INFO]   Training abgeschlossen in 14.55s (Backend: cuml)\n",
      "13:33:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:33:48 [INFO]   Training abgeschlossen in 14.77s (Backend: cuml)\n",
      "13:34:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:34:54 [INFO]   Training abgeschlossen in 14.97s (Backend: cuml)\n",
      "13:35:45 [INFO]     24,000 labeled → Accuracy: 0.8850 (Train: 15.0s, Query: 39.56s) | GPU: 2.8/8.0 GB\n",
      "13:35:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:36:00 [INFO]   Training abgeschlossen in 15.13s (Backend: cuml)\n",
      "13:36:11 [INFO]     Final: 24,000 labeled → Accuracy: 0.8835, F1: 0.8833\n",
      "13:36:12 [INFO]   Run 2/5\n",
      "13:36:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:36:17 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "13:37:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:37:29 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "13:38:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:38:41 [INFO]   Training abgeschlossen in 5.06s (Backend: cuml)\n",
      "13:39:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:39:53 [INFO]   Training abgeschlossen in 5.28s (Backend: cuml)\n",
      "13:40:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:41:04 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "13:42:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:42:16 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "13:43:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:43:28 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "13:44:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "13:44:40 [INFO]   Training abgeschlossen in 6.21s (Backend: cuml)\n",
      "13:45:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:45:52 [INFO]   Training abgeschlossen in 6.57s (Backend: cuml)\n",
      "13:46:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:47:04 [INFO]   Training abgeschlossen in 6.99s (Backend: cuml)\n",
      "13:48:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:48:17 [INFO]   Training abgeschlossen in 7.12s (Backend: cuml)\n",
      "13:49:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:49:30 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "13:50:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:50:42 [INFO]   Training abgeschlossen in 7.88s (Backend: cuml)\n",
      "13:51:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:51:55 [INFO]   Training abgeschlossen in 8.16s (Backend: cuml)\n",
      "13:52:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:53:07 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "13:54:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:54:20 [INFO]   Training abgeschlossen in 8.48s (Backend: cuml)\n",
      "13:55:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:55:32 [INFO]   Training abgeschlossen in 8.71s (Backend: cuml)\n",
      "13:56:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:56:45 [INFO]   Training abgeschlossen in 9.22s (Backend: cuml)\n",
      "13:57:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:57:57 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "13:59:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:59:09 [INFO]   Training abgeschlossen in 9.39s (Backend: cuml)\n",
      "14:00:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:00:21 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "14:01:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:01:34 [INFO]   Training abgeschlossen in 10.04s (Backend: cuml)\n",
      "14:02:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:02:46 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "14:03:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:03:57 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "14:04:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:05:08 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "14:06:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:06:20 [INFO]   Training abgeschlossen in 10.72s (Backend: cuml)\n",
      "14:07:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:07:32 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "14:08:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:08:44 [INFO]   Training abgeschlossen in 11.21s (Backend: cuml)\n",
      "14:09:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:09:56 [INFO]   Training abgeschlossen in 11.43s (Backend: cuml)\n",
      "14:10:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:11:08 [INFO]   Training abgeschlossen in 11.57s (Backend: cuml)\n",
      "14:12:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:12:19 [INFO]   Training abgeschlossen in 11.84s (Backend: cuml)\n",
      "14:13:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:13:29 [INFO]   Training abgeschlossen in 12.07s (Backend: cuml)\n",
      "14:14:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:14:40 [INFO]   Training abgeschlossen in 12.39s (Backend: cuml)\n",
      "14:15:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:15:51 [INFO]   Training abgeschlossen in 12.59s (Backend: cuml)\n",
      "14:16:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:17:02 [INFO]   Training abgeschlossen in 12.75s (Backend: cuml)\n",
      "14:17:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:18:11 [INFO]   Training abgeschlossen in 12.91s (Backend: cuml)\n",
      "14:19:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:19:21 [INFO]   Training abgeschlossen in 13.21s (Backend: cuml)\n",
      "14:20:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:20:30 [INFO]   Training abgeschlossen in 13.43s (Backend: cuml)\n",
      "14:21:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:21:39 [INFO]   Training abgeschlossen in 13.58s (Backend: cuml)\n",
      "14:22:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:22:47 [INFO]   Training abgeschlossen in 13.79s (Backend: cuml)\n",
      "14:23:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:23:56 [INFO]   Training abgeschlossen in 13.98s (Backend: cuml)\n",
      "14:24:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:25:04 [INFO]   Training abgeschlossen in 14.42s (Backend: cuml)\n",
      "14:25:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:26:12 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "14:27:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:27:19 [INFO]   Training abgeschlossen in 14.30s (Backend: cuml)\n",
      "14:28:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:28:26 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "14:29:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:29:33 [INFO]   Training abgeschlossen in 14.66s (Backend: cuml)\n",
      "14:30:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:30:40 [INFO]   Training abgeschlossen in 14.92s (Backend: cuml)\n",
      "14:31:31 [INFO]     24,000 labeled → Accuracy: 0.8802 (Train: 14.9s, Query: 39.77s) | GPU: 2.8/8.0 GB\n",
      "14:31:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:31:46 [INFO]   Training abgeschlossen in 15.24s (Backend: cuml)\n",
      "14:31:57 [INFO]     Final: 24,000 labeled → Accuracy: 0.8800, F1: 0.8797\n",
      "14:31:57 [INFO]   Run 3/5\n",
      "14:31:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:32:02 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "14:33:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:33:14 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "14:34:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:34:26 [INFO]   Training abgeschlossen in 5.05s (Backend: cuml)\n",
      "14:35:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:35:37 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "14:36:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:36:49 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "14:37:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:38:00 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "14:39:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:39:13 [INFO]   Training abgeschlossen in 6.01s (Backend: cuml)\n",
      "14:40:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:40:25 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "14:41:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:41:36 [INFO]   Training abgeschlossen in 6.58s (Backend: cuml)\n",
      "14:42:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:42:49 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "14:43:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:44:01 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "14:45:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:45:13 [INFO]   Training abgeschlossen in 7.47s (Backend: cuml)\n",
      "14:46:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:46:26 [INFO]   Training abgeschlossen in 7.70s (Backend: cuml)\n",
      "14:47:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:47:38 [INFO]   Training abgeschlossen in 7.91s (Backend: cuml)\n",
      "14:48:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:48:50 [INFO]   Training abgeschlossen in 8.31s (Backend: cuml)\n",
      "14:49:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:50:03 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "14:51:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:51:15 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "14:52:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:52:27 [INFO]   Training abgeschlossen in 8.92s (Backend: cuml)\n",
      "14:53:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:53:40 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "14:54:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:54:52 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "14:55:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:56:05 [INFO]   Training abgeschlossen in 9.61s (Backend: cuml)\n",
      "14:57:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:57:17 [INFO]   Training abgeschlossen in 9.93s (Backend: cuml)\n",
      "14:58:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:58:29 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "14:59:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:59:41 [INFO]   Training abgeschlossen in 10.30s (Backend: cuml)\n",
      "15:00:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:00:52 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "15:01:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:02:04 [INFO]   Training abgeschlossen in 10.85s (Backend: cuml)\n",
      "15:03:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:03:15 [INFO]   Training abgeschlossen in 10.95s (Backend: cuml)\n",
      "15:04:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:04:26 [INFO]   Training abgeschlossen in 11.15s (Backend: cuml)\n",
      "15:05:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:05:37 [INFO]   Training abgeschlossen in 11.33s (Backend: cuml)\n",
      "15:06:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:06:49 [INFO]   Training abgeschlossen in 11.73s (Backend: cuml)\n",
      "15:07:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:08:01 [INFO]   Training abgeschlossen in 11.75s (Backend: cuml)\n",
      "15:09:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:09:12 [INFO]   Training abgeschlossen in 12.07s (Backend: cuml)\n",
      "15:10:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:10:23 [INFO]   Training abgeschlossen in 12.29s (Backend: cuml)\n",
      "15:11:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:11:34 [INFO]   Training abgeschlossen in 12.69s (Backend: cuml)\n",
      "15:12:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:12:44 [INFO]   Training abgeschlossen in 12.69s (Backend: cuml)\n",
      "15:13:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:13:54 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "15:14:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:15:03 [INFO]   Training abgeschlossen in 13.15s (Backend: cuml)\n",
      "15:15:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:16:12 [INFO]   Training abgeschlossen in 13.40s (Backend: cuml)\n",
      "15:17:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:17:21 [INFO]   Training abgeschlossen in 13.55s (Backend: cuml)\n",
      "15:18:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:18:29 [INFO]   Training abgeschlossen in 13.71s (Backend: cuml)\n",
      "15:19:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:19:38 [INFO]   Training abgeschlossen in 13.99s (Backend: cuml)\n",
      "15:20:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:20:46 [INFO]   Training abgeschlossen in 14.20s (Backend: cuml)\n",
      "15:21:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:21:53 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "15:22:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:23:00 [INFO]   Training abgeschlossen in 14.37s (Backend: cuml)\n",
      "15:23:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:24:07 [INFO]   Training abgeschlossen in 14.53s (Backend: cuml)\n",
      "15:24:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:25:13 [INFO]   Training abgeschlossen in 14.74s (Backend: cuml)\n",
      "15:26:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:26:19 [INFO]   Training abgeschlossen in 14.93s (Backend: cuml)\n",
      "15:27:10 [INFO]     24,000 labeled → Accuracy: 0.8839 (Train: 14.9s, Query: 39.59s) | GPU: 2.8/8.0 GB\n",
      "15:27:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:27:25 [INFO]   Training abgeschlossen in 15.17s (Backend: cuml)\n",
      "15:27:36 [INFO]     Final: 24,000 labeled → Accuracy: 0.8840, F1: 0.8838\n",
      "15:27:36 [INFO]   Run 4/5\n",
      "15:27:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:27:41 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "15:28:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:28:52 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "15:29:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:30:04 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "15:31:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:31:17 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "15:32:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:32:28 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "15:33:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:33:40 [INFO]   Training abgeschlossen in 5.65s (Backend: cuml)\n",
      "15:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:34:52 [INFO]   Training abgeschlossen in 6.02s (Backend: cuml)\n",
      "15:35:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:36:04 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "15:37:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:37:16 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "15:38:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:38:28 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "15:39:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:39:41 [INFO]   Training abgeschlossen in 7.35s (Backend: cuml)\n",
      "15:40:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:40:53 [INFO]   Training abgeschlossen in 7.46s (Backend: cuml)\n",
      "15:41:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:42:06 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "15:43:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:43:18 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "15:44:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:44:31 [INFO]   Training abgeschlossen in 8.47s (Backend: cuml)\n",
      "15:45:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:45:43 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "15:46:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:46:56 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "15:47:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:48:08 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "15:49:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:49:21 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "15:50:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:50:33 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "15:51:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:51:45 [INFO]   Training abgeschlossen in 9.60s (Backend: cuml)\n",
      "15:52:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:52:58 [INFO]   Training abgeschlossen in 9.94s (Backend: cuml)\n",
      "15:53:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:54:10 [INFO]   Training abgeschlossen in 10.20s (Backend: cuml)\n",
      "15:55:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:55:21 [INFO]   Training abgeschlossen in 10.30s (Backend: cuml)\n",
      "15:56:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:56:33 [INFO]   Training abgeschlossen in 10.48s (Backend: cuml)\n",
      "15:57:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:57:44 [INFO]   Training abgeschlossen in 10.76s (Backend: cuml)\n",
      "15:58:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:58:56 [INFO]   Training abgeschlossen in 10.90s (Backend: cuml)\n",
      "15:59:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:00:07 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "16:01:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:01:17 [INFO]   Training abgeschlossen in 11.38s (Backend: cuml)\n",
      "16:02:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:02:28 [INFO]   Training abgeschlossen in 11.64s (Backend: cuml)\n",
      "16:03:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:03:40 [INFO]   Training abgeschlossen in 11.91s (Backend: cuml)\n",
      "16:04:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:04:51 [INFO]   Training abgeschlossen in 11.97s (Backend: cuml)\n",
      "16:05:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:06:02 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "16:07:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:07:12 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "16:08:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:08:23 [INFO]   Training abgeschlossen in 12.83s (Backend: cuml)\n",
      "16:09:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:09:33 [INFO]   Training abgeschlossen in 12.90s (Backend: cuml)\n",
      "16:10:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:10:42 [INFO]   Training abgeschlossen in 13.16s (Backend: cuml)\n",
      "16:11:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:11:51 [INFO]   Training abgeschlossen in 13.44s (Backend: cuml)\n",
      "16:12:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:13:00 [INFO]   Training abgeschlossen in 13.83s (Backend: cuml)\n",
      "16:13:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:14:08 [INFO]   Training abgeschlossen in 13.76s (Backend: cuml)\n",
      "16:15:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:15:17 [INFO]   Training abgeschlossen in 13.96s (Backend: cuml)\n",
      "16:16:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:16:25 [INFO]   Training abgeschlossen in 14.17s (Backend: cuml)\n",
      "16:17:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:17:32 [INFO]   Training abgeschlossen in 14.38s (Backend: cuml)\n",
      "16:18:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:18:39 [INFO]   Training abgeschlossen in 14.40s (Backend: cuml)\n",
      "16:19:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:19:46 [INFO]   Training abgeschlossen in 14.53s (Backend: cuml)\n",
      "16:20:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:20:53 [INFO]   Training abgeschlossen in 14.68s (Backend: cuml)\n",
      "16:21:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:21:59 [INFO]   Training abgeschlossen in 14.93s (Backend: cuml)\n",
      "16:22:50 [INFO]     24,000 labeled → Accuracy: 0.8857 (Train: 14.9s, Query: 39.41s) | GPU: 2.8/8.0 GB\n",
      "16:22:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:23:05 [INFO]   Training abgeschlossen in 15.12s (Backend: cuml)\n",
      "16:23:16 [INFO]     Final: 24,000 labeled → Accuracy: 0.8851, F1: 0.8848\n",
      "16:23:16 [INFO]   Run 5/5\n",
      "16:23:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:23:21 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "16:24:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:24:32 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "16:25:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:25:44 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "16:26:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:26:56 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "16:28:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:28:08 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "16:29:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:29:19 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "16:30:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:30:31 [INFO]   Training abgeschlossen in 5.91s (Backend: cuml)\n",
      "16:31:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "16:31:43 [INFO]   Training abgeschlossen in 6.30s (Backend: cuml)\n",
      "16:32:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:32:55 [INFO]   Training abgeschlossen in 6.70s (Backend: cuml)\n",
      "16:34:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:34:08 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "16:35:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:35:20 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "16:36:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:36:32 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "16:37:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:37:44 [INFO]   Training abgeschlossen in 7.74s (Backend: cuml)\n",
      "16:38:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:38:57 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "16:40:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "16:40:09 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "16:41:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:41:21 [INFO]   Training abgeschlossen in 8.65s (Backend: cuml)\n",
      "16:42:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:42:33 [INFO]   Training abgeschlossen in 8.69s (Backend: cuml)\n",
      "16:43:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:43:46 [INFO]   Training abgeschlossen in 9.01s (Backend: cuml)\n",
      "16:44:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:44:58 [INFO]   Training abgeschlossen in 9.19s (Backend: cuml)\n",
      "16:46:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:46:09 [INFO]   Training abgeschlossen in 9.57s (Backend: cuml)\n",
      "16:47:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:47:21 [INFO]   Training abgeschlossen in 9.63s (Backend: cuml)\n",
      "16:48:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:48:33 [INFO]   Training abgeschlossen in 9.87s (Backend: cuml)\n",
      "16:49:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:49:44 [INFO]   Training abgeschlossen in 10.05s (Backend: cuml)\n",
      "16:50:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:50:56 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "16:51:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:52:08 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "16:53:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:53:19 [INFO]   Training abgeschlossen in 10.67s (Backend: cuml)\n",
      "16:54:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:54:31 [INFO]   Training abgeschlossen in 11.07s (Backend: cuml)\n",
      "16:55:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:55:42 [INFO]   Training abgeschlossen in 11.27s (Backend: cuml)\n",
      "16:56:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:56:53 [INFO]   Training abgeschlossen in 11.35s (Backend: cuml)\n",
      "16:57:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:58:05 [INFO]   Training abgeschlossen in 11.52s (Backend: cuml)\n",
      "16:59:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:59:17 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "17:00:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:00:28 [INFO]   Training abgeschlossen in 12.04s (Backend: cuml)\n",
      "17:01:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:01:39 [INFO]   Training abgeschlossen in 12.28s (Backend: cuml)\n",
      "17:02:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:02:49 [INFO]   Training abgeschlossen in 12.54s (Backend: cuml)\n",
      "17:03:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:04:00 [INFO]   Training abgeschlossen in 12.83s (Backend: cuml)\n",
      "17:04:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:05:10 [INFO]   Training abgeschlossen in 12.99s (Backend: cuml)\n",
      "17:06:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:06:19 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "17:07:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:07:28 [INFO]   Training abgeschlossen in 13.30s (Backend: cuml)\n",
      "17:08:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:08:36 [INFO]   Training abgeschlossen in 13.53s (Backend: cuml)\n",
      "17:09:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:09:45 [INFO]   Training abgeschlossen in 13.91s (Backend: cuml)\n",
      "17:10:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:10:53 [INFO]   Training abgeschlossen in 13.96s (Backend: cuml)\n",
      "17:11:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:12:01 [INFO]   Training abgeschlossen in 14.13s (Backend: cuml)\n",
      "17:12:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:13:09 [INFO]   Training abgeschlossen in 14.33s (Backend: cuml)\n",
      "17:14:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:14:16 [INFO]   Training abgeschlossen in 14.32s (Backend: cuml)\n",
      "17:15:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:15:23 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "17:16:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:16:30 [INFO]   Training abgeschlossen in 14.76s (Backend: cuml)\n",
      "17:17:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:17:36 [INFO]   Training abgeschlossen in 14.95s (Backend: cuml)\n",
      "17:18:27 [INFO]     24,000 labeled → Accuracy: 0.8829 (Train: 15.0s, Query: 39.64s) | GPU: 2.8/8.0 GB\n",
      "17:18:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:18:42 [INFO]   Training abgeschlossen in 15.14s (Backend: cuml)\n",
      "17:18:54 [INFO]     Final: 24,000 labeled → Accuracy: 0.8826, F1: 0.8824\n",
      "17:18:54 [INFO] \n",
      "GPU-SVM + Margin Sampling - Budget: 60% (36,000 Samples)\n",
      "17:18:54 [INFO]   Run 1/5\n",
      "17:18:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:18:59 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "17:20:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:20:09 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "17:21:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:21:21 [INFO]   Training abgeschlossen in 5.06s (Backend: cuml)\n",
      "17:22:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:22:33 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "17:23:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:23:44 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "17:24:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:24:56 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "17:26:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:26:08 [INFO]   Training abgeschlossen in 5.86s (Backend: cuml)\n",
      "17:27:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:27:20 [INFO]   Training abgeschlossen in 6.17s (Backend: cuml)\n",
      "17:28:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:28:32 [INFO]   Training abgeschlossen in 6.74s (Backend: cuml)\n",
      "17:29:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:29:44 [INFO]   Training abgeschlossen in 6.86s (Backend: cuml)\n",
      "17:30:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:30:56 [INFO]   Training abgeschlossen in 7.24s (Backend: cuml)\n",
      "17:32:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:32:09 [INFO]   Training abgeschlossen in 7.45s (Backend: cuml)\n",
      "17:33:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:33:21 [INFO]   Training abgeschlossen in 7.94s (Backend: cuml)\n",
      "17:34:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:34:34 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "17:35:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:35:46 [INFO]   Training abgeschlossen in 8.18s (Backend: cuml)\n",
      "17:36:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:36:58 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "17:38:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:38:11 [INFO]   Training abgeschlossen in 8.74s (Backend: cuml)\n",
      "17:39:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:39:23 [INFO]   Training abgeschlossen in 9.05s (Backend: cuml)\n",
      "17:40:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:40:36 [INFO]   Training abgeschlossen in 9.29s (Backend: cuml)\n",
      "17:41:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:41:48 [INFO]   Training abgeschlossen in 9.63s (Backend: cuml)\n",
      "17:42:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:43:01 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "17:44:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:44:12 [INFO]   Training abgeschlossen in 9.83s (Backend: cuml)\n",
      "17:45:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:45:24 [INFO]   Training abgeschlossen in 10.10s (Backend: cuml)\n",
      "17:46:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:46:36 [INFO]   Training abgeschlossen in 10.43s (Backend: cuml)\n",
      "17:47:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:47:47 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "17:48:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:48:59 [INFO]   Training abgeschlossen in 10.70s (Backend: cuml)\n",
      "17:49:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:50:10 [INFO]   Training abgeschlossen in 10.88s (Backend: cuml)\n",
      "17:51:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:51:22 [INFO]   Training abgeschlossen in 11.33s (Backend: cuml)\n",
      "17:52:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:52:34 [INFO]   Training abgeschlossen in 11.34s (Backend: cuml)\n",
      "17:53:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:53:45 [INFO]   Training abgeschlossen in 11.56s (Backend: cuml)\n",
      "17:54:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:54:56 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "17:55:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:56:07 [INFO]   Training abgeschlossen in 12.13s (Backend: cuml)\n",
      "17:57:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:57:18 [INFO]   Training abgeschlossen in 12.24s (Backend: cuml)\n",
      "17:58:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:58:29 [INFO]   Training abgeschlossen in 12.49s (Backend: cuml)\n",
      "17:59:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:59:38 [INFO]   Training abgeschlossen in 12.69s (Backend: cuml)\n",
      "18:00:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:00:48 [INFO]   Training abgeschlossen in 12.99s (Backend: cuml)\n",
      "18:01:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:01:57 [INFO]   Training abgeschlossen in 13.21s (Backend: cuml)\n",
      "18:02:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:03:06 [INFO]   Training abgeschlossen in 13.26s (Backend: cuml)\n",
      "18:04:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:04:15 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "18:05:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:05:23 [INFO]   Training abgeschlossen in 13.77s (Backend: cuml)\n",
      "18:06:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:06:31 [INFO]   Training abgeschlossen in 13.98s (Backend: cuml)\n",
      "18:07:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:07:39 [INFO]   Training abgeschlossen in 14.24s (Backend: cuml)\n",
      "18:08:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:08:47 [INFO]   Training abgeschlossen in 14.37s (Backend: cuml)\n",
      "18:09:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:09:54 [INFO]   Training abgeschlossen in 14.30s (Backend: cuml)\n",
      "18:10:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:11:01 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "18:11:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:12:08 [INFO]   Training abgeschlossen in 14.72s (Backend: cuml)\n",
      "18:12:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:13:15 [INFO]   Training abgeschlossen in 15.03s (Backend: cuml)\n",
      "18:14:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:14:20 [INFO]   Training abgeschlossen in 15.13s (Backend: cuml)\n",
      "18:15:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:15:26 [INFO]   Training abgeschlossen in 15.30s (Backend: cuml)\n",
      "18:16:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:16:31 [INFO]   Training abgeschlossen in 15.57s (Backend: cuml)\n",
      "18:17:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:17:37 [INFO]   Training abgeschlossen in 15.99s (Backend: cuml)\n",
      "18:18:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:18:42 [INFO]   Training abgeschlossen in 15.95s (Backend: cuml)\n",
      "18:19:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:19:47 [INFO]   Training abgeschlossen in 16.23s (Backend: cuml)\n",
      "18:20:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:20:51 [INFO]   Training abgeschlossen in 16.62s (Backend: cuml)\n",
      "18:21:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:21:56 [INFO]   Training abgeschlossen in 16.71s (Backend: cuml)\n",
      "18:22:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:22:59 [INFO]   Training abgeschlossen in 16.87s (Backend: cuml)\n",
      "18:23:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:24:03 [INFO]   Training abgeschlossen in 17.04s (Backend: cuml)\n",
      "18:24:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:25:06 [INFO]   Training abgeschlossen in 17.25s (Backend: cuml)\n",
      "18:25:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:26:09 [INFO]   Training abgeschlossen in 17.49s (Backend: cuml)\n",
      "18:26:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:27:12 [INFO]   Training abgeschlossen in 17.71s (Backend: cuml)\n",
      "18:27:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:28:14 [INFO]   Training abgeschlossen in 17.92s (Backend: cuml)\n",
      "18:28:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:29:16 [INFO]   Training abgeschlossen in 18.34s (Backend: cuml)\n",
      "18:30:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:30:18 [INFO]   Training abgeschlossen in 18.52s (Backend: cuml)\n",
      "18:31:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:31:20 [INFO]   Training abgeschlossen in 18.62s (Backend: cuml)\n",
      "18:32:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:32:21 [INFO]   Training abgeschlossen in 18.92s (Backend: cuml)\n",
      "18:33:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:33:22 [INFO]   Training abgeschlossen in 18.99s (Backend: cuml)\n",
      "18:34:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:34:23 [INFO]   Training abgeschlossen in 19.25s (Backend: cuml)\n",
      "18:35:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:35:23 [INFO]   Training abgeschlossen in 19.44s (Backend: cuml)\n",
      "18:36:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:36:23 [INFO]   Training abgeschlossen in 19.66s (Backend: cuml)\n",
      "18:37:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:37:23 [INFO]   Training abgeschlossen in 19.89s (Backend: cuml)\n",
      "18:38:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:38:22 [INFO]   Training abgeschlossen in 19.92s (Backend: cuml)\n",
      "18:39:00 [INFO]     36,000 labeled → Accuracy: 0.8857 (Train: 19.9s, Query: 27.15s) | GPU: 2.8/8.0 GB\n",
      "18:39:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:39:21 [INFO]   Training abgeschlossen in 20.20s (Backend: cuml)\n",
      "18:39:32 [INFO]     Final: 36,000 labeled → Accuracy: 0.8855, F1: 0.8847\n",
      "18:39:32 [INFO]   Run 2/5\n",
      "18:39:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:39:37 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "18:40:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:40:48 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "18:41:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:42:00 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "18:43:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "18:43:12 [INFO]   Training abgeschlossen in 5.23s (Backend: cuml)\n",
      "18:44:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:44:24 [INFO]   Training abgeschlossen in 5.51s (Backend: cuml)\n",
      "18:45:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:45:36 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "18:46:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:46:48 [INFO]   Training abgeschlossen in 6.01s (Backend: cuml)\n",
      "18:47:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "18:48:00 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "18:49:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:49:12 [INFO]   Training abgeschlossen in 6.57s (Backend: cuml)\n",
      "18:50:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:50:23 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "18:51:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:51:36 [INFO]   Training abgeschlossen in 7.29s (Backend: cuml)\n",
      "18:52:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:52:49 [INFO]   Training abgeschlossen in 7.67s (Backend: cuml)\n",
      "18:53:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:54:01 [INFO]   Training abgeschlossen in 7.80s (Backend: cuml)\n",
      "18:55:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "18:55:13 [INFO]   Training abgeschlossen in 7.96s (Backend: cuml)\n",
      "18:56:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:56:26 [INFO]   Training abgeschlossen in 8.28s (Backend: cuml)\n",
      "18:57:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:57:39 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "18:58:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "18:58:51 [INFO]   Training abgeschlossen in 8.69s (Backend: cuml)\n",
      "18:59:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:00:03 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "19:01:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:01:15 [INFO]   Training abgeschlossen in 9.18s (Backend: cuml)\n",
      "19:02:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:02:28 [INFO]   Training abgeschlossen in 9.63s (Backend: cuml)\n",
      "19:03:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:03:40 [INFO]   Training abgeschlossen in 9.74s (Backend: cuml)\n",
      "19:04:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:04:53 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "19:05:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:06:05 [INFO]   Training abgeschlossen in 10.20s (Backend: cuml)\n",
      "19:07:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:07:18 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "19:08:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:08:29 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "19:09:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:09:41 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "19:10:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:10:53 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "19:11:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:12:04 [INFO]   Training abgeschlossen in 11.14s (Backend: cuml)\n",
      "19:13:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:13:16 [INFO]   Training abgeschlossen in 11.43s (Backend: cuml)\n",
      "19:14:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:14:27 [INFO]   Training abgeschlossen in 11.67s (Backend: cuml)\n",
      "19:15:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:15:39 [INFO]   Training abgeschlossen in 11.89s (Backend: cuml)\n",
      "19:16:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:16:50 [INFO]   Training abgeschlossen in 12.05s (Backend: cuml)\n",
      "19:17:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:18:01 [INFO]   Training abgeschlossen in 12.40s (Backend: cuml)\n",
      "19:19:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:19:12 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "19:20:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:20:23 [INFO]   Training abgeschlossen in 12.81s (Backend: cuml)\n",
      "19:21:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:21:33 [INFO]   Training abgeschlossen in 12.94s (Backend: cuml)\n",
      "19:22:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:22:43 [INFO]   Training abgeschlossen in 13.32s (Backend: cuml)\n",
      "19:23:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:23:52 [INFO]   Training abgeschlossen in 13.35s (Backend: cuml)\n",
      "19:24:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:25:00 [INFO]   Training abgeschlossen in 13.56s (Backend: cuml)\n",
      "19:25:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:26:09 [INFO]   Training abgeschlossen in 13.76s (Backend: cuml)\n",
      "19:27:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:27:17 [INFO]   Training abgeschlossen in 13.99s (Backend: cuml)\n",
      "19:28:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:28:26 [INFO]   Training abgeschlossen in 14.32s (Backend: cuml)\n",
      "19:29:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "19:29:34 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "19:30:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:30:41 [INFO]   Training abgeschlossen in 14.32s (Backend: cuml)\n",
      "19:31:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:31:48 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "19:32:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:32:54 [INFO]   Training abgeschlossen in 14.80s (Backend: cuml)\n",
      "19:33:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:34:01 [INFO]   Training abgeschlossen in 15.18s (Backend: cuml)\n",
      "19:34:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:35:07 [INFO]   Training abgeschlossen in 15.22s (Backend: cuml)\n",
      "19:35:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:36:13 [INFO]   Training abgeschlossen in 15.34s (Backend: cuml)\n",
      "19:37:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:37:19 [INFO]   Training abgeschlossen in 15.56s (Backend: cuml)\n",
      "19:38:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:38:25 [INFO]   Training abgeschlossen in 16.12s (Backend: cuml)\n",
      "19:39:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:39:30 [INFO]   Training abgeschlossen in 15.98s (Backend: cuml)\n",
      "19:40:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:40:34 [INFO]   Training abgeschlossen in 16.33s (Backend: cuml)\n",
      "19:41:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:41:39 [INFO]   Training abgeschlossen in 16.53s (Backend: cuml)\n",
      "19:42:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:42:43 [INFO]   Training abgeschlossen in 16.64s (Backend: cuml)\n",
      "19:43:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:43:47 [INFO]   Training abgeschlossen in 16.83s (Backend: cuml)\n",
      "19:44:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:44:51 [INFO]   Training abgeschlossen in 17.10s (Backend: cuml)\n",
      "19:45:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:45:54 [INFO]   Training abgeschlossen in 17.44s (Backend: cuml)\n",
      "19:46:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:46:57 [INFO]   Training abgeschlossen in 17.58s (Backend: cuml)\n",
      "19:47:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:48:00 [INFO]   Training abgeschlossen in 17.76s (Backend: cuml)\n",
      "19:48:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:49:02 [INFO]   Training abgeschlossen in 17.93s (Backend: cuml)\n",
      "19:49:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:50:05 [INFO]   Training abgeschlossen in 18.18s (Backend: cuml)\n",
      "19:50:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:51:07 [INFO]   Training abgeschlossen in 18.51s (Backend: cuml)\n",
      "19:51:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:52:08 [INFO]   Training abgeschlossen in 18.66s (Backend: cuml)\n",
      "19:52:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:53:10 [INFO]   Training abgeschlossen in 18.92s (Backend: cuml)\n",
      "19:53:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:54:11 [INFO]   Training abgeschlossen in 19.12s (Backend: cuml)\n",
      "19:54:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:55:11 [INFO]   Training abgeschlossen in 19.39s (Backend: cuml)\n",
      "19:55:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:56:12 [INFO]   Training abgeschlossen in 19.59s (Backend: cuml)\n",
      "19:56:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:57:12 [INFO]   Training abgeschlossen in 19.68s (Backend: cuml)\n",
      "19:57:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:58:12 [INFO]   Training abgeschlossen in 19.91s (Backend: cuml)\n",
      "19:58:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "19:59:11 [INFO]   Training abgeschlossen in 20.07s (Backend: cuml)\n",
      "19:59:50 [INFO]     36,000 labeled → Accuracy: 0.8850 (Train: 20.1s, Query: 27.26s) | GPU: 2.8/8.0 GB\n",
      "19:59:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:00:10 [INFO]   Training abgeschlossen in 20.22s (Backend: cuml)\n",
      "20:00:21 [INFO]     Final: 36,000 labeled → Accuracy: 0.8851, F1: 0.8844\n",
      "20:00:22 [INFO]   Run 3/5\n",
      "20:00:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:00:27 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "20:01:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:01:38 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "20:02:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:02:50 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "20:03:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:04:01 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "20:05:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:05:13 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "20:06:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:06:24 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "20:07:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:07:36 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "20:08:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:08:48 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "20:09:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:10:00 [INFO]   Training abgeschlossen in 6.68s (Backend: cuml)\n",
      "20:11:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:11:13 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "20:12:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:12:25 [INFO]   Training abgeschlossen in 7.35s (Backend: cuml)\n",
      "20:13:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:13:37 [INFO]   Training abgeschlossen in 7.52s (Backend: cuml)\n",
      "20:14:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:14:50 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "20:15:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:16:02 [INFO]   Training abgeschlossen in 7.95s (Backend: cuml)\n",
      "20:17:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:17:14 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "20:18:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:18:26 [INFO]   Training abgeschlossen in 8.45s (Backend: cuml)\n",
      "20:19:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:19:39 [INFO]   Training abgeschlossen in 8.85s (Backend: cuml)\n",
      "20:20:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:20:51 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "20:21:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:22:03 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "20:23:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:23:16 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "20:24:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:24:28 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "20:25:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:25:40 [INFO]   Training abgeschlossen in 9.89s (Backend: cuml)\n",
      "20:26:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:26:52 [INFO]   Training abgeschlossen in 10.07s (Backend: cuml)\n",
      "20:27:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:28:04 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "20:29:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:29:16 [INFO]   Training abgeschlossen in 10.57s (Backend: cuml)\n",
      "20:30:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:30:27 [INFO]   Training abgeschlossen in 10.68s (Backend: cuml)\n",
      "20:31:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:31:38 [INFO]   Training abgeschlossen in 10.94s (Backend: cuml)\n",
      "20:32:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:32:49 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "20:33:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:34:01 [INFO]   Training abgeschlossen in 11.36s (Backend: cuml)\n",
      "20:35:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:35:12 [INFO]   Training abgeschlossen in 11.53s (Backend: cuml)\n",
      "20:36:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:36:23 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "20:37:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:37:34 [INFO]   Training abgeschlossen in 12.14s (Backend: cuml)\n",
      "20:38:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:38:46 [INFO]   Training abgeschlossen in 12.26s (Backend: cuml)\n",
      "20:39:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:39:56 [INFO]   Training abgeschlossen in 12.49s (Backend: cuml)\n",
      "20:40:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:41:07 [INFO]   Training abgeschlossen in 12.66s (Backend: cuml)\n",
      "20:42:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:42:16 [INFO]   Training abgeschlossen in 12.96s (Backend: cuml)\n",
      "20:43:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:43:25 [INFO]   Training abgeschlossen in 13.14s (Backend: cuml)\n",
      "20:44:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:44:34 [INFO]   Training abgeschlossen in 13.30s (Backend: cuml)\n",
      "20:45:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:45:43 [INFO]   Training abgeschlossen in 13.56s (Backend: cuml)\n",
      "20:46:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:46:51 [INFO]   Training abgeschlossen in 13.80s (Backend: cuml)\n",
      "20:47:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:48:00 [INFO]   Training abgeschlossen in 14.09s (Backend: cuml)\n",
      "20:48:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:49:08 [INFO]   Training abgeschlossen in 14.26s (Backend: cuml)\n",
      "20:50:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:50:15 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "20:51:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:51:23 [INFO]   Training abgeschlossen in 14.35s (Backend: cuml)\n",
      "20:52:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:52:30 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "20:53:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:53:36 [INFO]   Training abgeschlossen in 14.76s (Backend: cuml)\n",
      "20:54:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:54:43 [INFO]   Training abgeschlossen in 15.18s (Backend: cuml)\n",
      "20:55:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:55:49 [INFO]   Training abgeschlossen in 15.23s (Backend: cuml)\n",
      "20:56:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:56:55 [INFO]   Training abgeschlossen in 15.34s (Backend: cuml)\n",
      "20:57:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:58:00 [INFO]   Training abgeschlossen in 15.56s (Backend: cuml)\n",
      "20:58:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:59:06 [INFO]   Training abgeschlossen in 16.05s (Backend: cuml)\n",
      "20:59:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:00:10 [INFO]   Training abgeschlossen in 15.91s (Backend: cuml)\n",
      "21:00:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:01:15 [INFO]   Training abgeschlossen in 16.33s (Backend: cuml)\n",
      "21:02:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:02:20 [INFO]   Training abgeschlossen in 16.51s (Backend: cuml)\n",
      "21:03:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:03:24 [INFO]   Training abgeschlossen in 16.60s (Backend: cuml)\n",
      "21:04:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:04:28 [INFO]   Training abgeschlossen in 16.81s (Backend: cuml)\n",
      "21:05:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:05:31 [INFO]   Training abgeschlossen in 17.08s (Backend: cuml)\n",
      "21:06:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:06:35 [INFO]   Training abgeschlossen in 17.37s (Backend: cuml)\n",
      "21:07:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:07:38 [INFO]   Training abgeschlossen in 17.51s (Backend: cuml)\n",
      "21:08:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:08:41 [INFO]   Training abgeschlossen in 17.82s (Backend: cuml)\n",
      "21:09:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:09:43 [INFO]   Training abgeschlossen in 18.03s (Backend: cuml)\n",
      "21:10:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:10:46 [INFO]   Training abgeschlossen in 18.42s (Backend: cuml)\n",
      "21:11:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:11:48 [INFO]   Training abgeschlossen in 18.48s (Backend: cuml)\n",
      "21:12:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:12:49 [INFO]   Training abgeschlossen in 18.58s (Backend: cuml)\n",
      "21:13:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:13:50 [INFO]   Training abgeschlossen in 18.73s (Backend: cuml)\n",
      "21:14:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:14:51 [INFO]   Training abgeschlossen in 18.94s (Backend: cuml)\n",
      "21:15:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:15:52 [INFO]   Training abgeschlossen in 19.27s (Backend: cuml)\n",
      "21:16:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:16:52 [INFO]   Training abgeschlossen in 19.43s (Backend: cuml)\n",
      "21:17:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:17:52 [INFO]   Training abgeschlossen in 19.64s (Backend: cuml)\n",
      "21:18:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:18:51 [INFO]   Training abgeschlossen in 19.82s (Backend: cuml)\n",
      "21:19:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:19:51 [INFO]   Training abgeschlossen in 19.97s (Backend: cuml)\n",
      "21:20:29 [INFO]     36,000 labeled → Accuracy: 0.8848 (Train: 20.0s, Query: 27.12s) | GPU: 2.8/8.0 GB\n",
      "21:20:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:20:50 [INFO]   Training abgeschlossen in 20.20s (Backend: cuml)\n",
      "21:21:01 [INFO]     Final: 36,000 labeled → Accuracy: 0.8846, F1: 0.8839\n",
      "21:21:01 [INFO]   Run 4/5\n",
      "21:21:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "21:21:06 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "21:22:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:22:18 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "21:23:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:23:30 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "21:24:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:24:42 [INFO]   Training abgeschlossen in 5.35s (Backend: cuml)\n",
      "21:25:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:25:53 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "21:27:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:27:05 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "21:28:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:28:17 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "21:29:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:29:29 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "21:30:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:30:41 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "21:31:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:31:53 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "21:32:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:33:06 [INFO]   Training abgeschlossen in 7.41s (Backend: cuml)\n",
      "21:34:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:34:18 [INFO]   Training abgeschlossen in 7.50s (Backend: cuml)\n",
      "21:35:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:35:31 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "21:36:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:36:43 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "21:37:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:37:56 [INFO]   Training abgeschlossen in 8.20s (Backend: cuml)\n",
      "21:39:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:39:08 [INFO]   Training abgeschlossen in 8.63s (Backend: cuml)\n",
      "21:40:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:40:21 [INFO]   Training abgeschlossen in 8.76s (Backend: cuml)\n",
      "21:41:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:41:33 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "21:42:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:42:46 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "21:43:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:43:58 [INFO]   Training abgeschlossen in 9.54s (Backend: cuml)\n",
      "21:45:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:45:10 [INFO]   Training abgeschlossen in 9.61s (Backend: cuml)\n",
      "21:46:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:46:22 [INFO]   Training abgeschlossen in 9.84s (Backend: cuml)\n",
      "21:47:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:47:34 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "21:48:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:48:45 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "21:49:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:49:57 [INFO]   Training abgeschlossen in 10.47s (Backend: cuml)\n",
      "21:50:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:51:08 [INFO]   Training abgeschlossen in 10.67s (Backend: cuml)\n",
      "21:52:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:52:20 [INFO]   Training abgeschlossen in 11.08s (Backend: cuml)\n",
      "21:53:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:53:31 [INFO]   Training abgeschlossen in 11.26s (Backend: cuml)\n",
      "21:54:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:54:42 [INFO]   Training abgeschlossen in 11.34s (Backend: cuml)\n",
      "21:55:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:55:53 [INFO]   Training abgeschlossen in 11.57s (Backend: cuml)\n",
      "21:56:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:57:05 [INFO]   Training abgeschlossen in 11.90s (Backend: cuml)\n",
      "21:58:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:58:16 [INFO]   Training abgeschlossen in 12.10s (Backend: cuml)\n",
      "21:59:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:59:27 [INFO]   Training abgeschlossen in 12.24s (Backend: cuml)\n",
      "22:00:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:00:38 [INFO]   Training abgeschlossen in 12.48s (Backend: cuml)\n",
      "22:01:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:01:48 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "22:02:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:02:58 [INFO]   Training abgeschlossen in 13.06s (Backend: cuml)\n",
      "22:03:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:04:07 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "22:05:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:05:16 [INFO]   Training abgeschlossen in 13.31s (Backend: cuml)\n",
      "22:06:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:06:25 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "22:07:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:07:34 [INFO]   Training abgeschlossen in 13.75s (Backend: cuml)\n",
      "22:08:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:08:42 [INFO]   Training abgeschlossen in 14.08s (Backend: cuml)\n",
      "22:09:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:09:50 [INFO]   Training abgeschlossen in 14.18s (Backend: cuml)\n",
      "22:10:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:10:58 [INFO]   Training abgeschlossen in 14.37s (Backend: cuml)\n",
      "22:11:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:12:05 [INFO]   Training abgeschlossen in 14.29s (Backend: cuml)\n",
      "22:12:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:13:12 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "22:14:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:14:18 [INFO]   Training abgeschlossen in 14.81s (Backend: cuml)\n",
      "22:15:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:15:25 [INFO]   Training abgeschlossen in 14.92s (Backend: cuml)\n",
      "22:16:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:16:31 [INFO]   Training abgeschlossen in 15.15s (Backend: cuml)\n",
      "22:17:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:17:37 [INFO]   Training abgeschlossen in 15.33s (Backend: cuml)\n",
      "22:18:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:18:42 [INFO]   Training abgeschlossen in 15.61s (Backend: cuml)\n",
      "22:19:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:19:48 [INFO]   Training abgeschlossen in 16.11s (Backend: cuml)\n",
      "22:20:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:20:53 [INFO]   Training abgeschlossen in 16.18s (Backend: cuml)\n",
      "22:21:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:21:57 [INFO]   Training abgeschlossen in 16.24s (Backend: cuml)\n",
      "22:22:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:23:02 [INFO]   Training abgeschlossen in 16.55s (Backend: cuml)\n",
      "22:23:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:24:06 [INFO]   Training abgeschlossen in 16.59s (Backend: cuml)\n",
      "22:24:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:25:10 [INFO]   Training abgeschlossen in 16.89s (Backend: cuml)\n",
      "22:25:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:26:13 [INFO]   Training abgeschlossen in 17.04s (Backend: cuml)\n",
      "22:26:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:27:16 [INFO]   Training abgeschlossen in 17.36s (Backend: cuml)\n",
      "22:28:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:28:19 [INFO]   Training abgeschlossen in 17.52s (Backend: cuml)\n",
      "22:29:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:29:22 [INFO]   Training abgeschlossen in 17.86s (Backend: cuml)\n",
      "22:30:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:30:25 [INFO]   Training abgeschlossen in 18.10s (Backend: cuml)\n",
      "22:31:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:31:27 [INFO]   Training abgeschlossen in 18.27s (Backend: cuml)\n",
      "22:32:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:32:28 [INFO]   Training abgeschlossen in 18.41s (Backend: cuml)\n",
      "22:33:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:33:30 [INFO]   Training abgeschlossen in 18.58s (Backend: cuml)\n",
      "22:34:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:34:31 [INFO]   Training abgeschlossen in 18.82s (Backend: cuml)\n",
      "22:35:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:35:32 [INFO]   Training abgeschlossen in 19.00s (Backend: cuml)\n",
      "22:36:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:36:32 [INFO]   Training abgeschlossen in 19.40s (Backend: cuml)\n",
      "22:37:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:37:33 [INFO]   Training abgeschlossen in 19.38s (Backend: cuml)\n",
      "22:38:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:38:33 [INFO]   Training abgeschlossen in 19.72s (Backend: cuml)\n",
      "22:39:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:39:32 [INFO]   Training abgeschlossen in 19.90s (Backend: cuml)\n",
      "22:40:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:40:32 [INFO]   Training abgeschlossen in 20.18s (Backend: cuml)\n",
      "22:41:10 [INFO]     36,000 labeled → Accuracy: 0.8859 (Train: 20.2s, Query: 26.96s) | GPU: 2.8/8.0 GB\n",
      "22:41:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:41:31 [INFO]   Training abgeschlossen in 20.26s (Backend: cuml)\n",
      "22:41:42 [INFO]     Final: 36,000 labeled → Accuracy: 0.8859, F1: 0.8852\n",
      "22:41:42 [INFO]   Run 5/5\n",
      "22:41:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:41:47 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "22:42:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:42:58 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "22:44:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:44:10 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "22:45:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:45:21 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "22:46:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:46:33 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "22:47:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:47:44 [INFO]   Training abgeschlossen in 5.61s (Backend: cuml)\n",
      "22:48:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:48:56 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "22:50:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:50:08 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "22:51:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:51:20 [INFO]   Training abgeschlossen in 6.56s (Backend: cuml)\n",
      "22:52:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:52:32 [INFO]   Training abgeschlossen in 6.92s (Backend: cuml)\n",
      "22:53:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:53:45 [INFO]   Training abgeschlossen in 7.38s (Backend: cuml)\n",
      "22:54:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:54:57 [INFO]   Training abgeschlossen in 7.53s (Backend: cuml)\n",
      "22:56:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:56:09 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "22:57:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:57:22 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "22:58:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:58:34 [INFO]   Training abgeschlossen in 8.22s (Backend: cuml)\n",
      "22:59:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:59:47 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "23:00:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:00:59 [INFO]   Training abgeschlossen in 8.73s (Backend: cuml)\n",
      "23:02:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:02:11 [INFO]   Training abgeschlossen in 9.08s (Backend: cuml)\n",
      "23:03:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:03:23 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "23:04:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:04:35 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "23:05:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:05:48 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "23:06:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:06:59 [INFO]   Training abgeschlossen in 10.04s (Backend: cuml)\n",
      "23:08:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:08:11 [INFO]   Training abgeschlossen in 10.06s (Backend: cuml)\n",
      "23:09:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:09:22 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "23:10:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:10:35 [INFO]   Training abgeschlossen in 10.47s (Backend: cuml)\n",
      "23:11:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:11:46 [INFO]   Training abgeschlossen in 10.84s (Backend: cuml)\n",
      "23:12:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:12:58 [INFO]   Training abgeschlossen in 10.95s (Backend: cuml)\n",
      "23:13:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:14:09 [INFO]   Training abgeschlossen in 11.13s (Backend: cuml)\n",
      "23:15:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:15:20 [INFO]   Training abgeschlossen in 11.42s (Backend: cuml)\n",
      "23:16:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:16:32 [INFO]   Training abgeschlossen in 11.74s (Backend: cuml)\n",
      "23:17:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:17:43 [INFO]   Training abgeschlossen in 11.79s (Backend: cuml)\n",
      "23:18:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:18:54 [INFO]   Training abgeschlossen in 12.00s (Backend: cuml)\n",
      "23:19:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:20:05 [INFO]   Training abgeschlossen in 12.29s (Backend: cuml)\n",
      "23:21:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:21:16 [INFO]   Training abgeschlossen in 12.74s (Backend: cuml)\n",
      "23:22:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:22:27 [INFO]   Training abgeschlossen in 12.80s (Backend: cuml)\n",
      "23:23:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:23:36 [INFO]   Training abgeschlossen in 13.02s (Backend: cuml)\n",
      "23:24:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:24:45 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "23:25:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:25:54 [INFO]   Training abgeschlossen in 13.40s (Backend: cuml)\n",
      "23:26:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:27:03 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "23:27:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:28:11 [INFO]   Training abgeschlossen in 13.78s (Backend: cuml)\n",
      "23:29:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:29:19 [INFO]   Training abgeschlossen in 13.99s (Backend: cuml)\n",
      "23:30:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:30:27 [INFO]   Training abgeschlossen in 14.22s (Backend: cuml)\n",
      "23:31:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:31:34 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "23:32:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:32:41 [INFO]   Training abgeschlossen in 14.32s (Backend: cuml)\n",
      "23:33:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:33:48 [INFO]   Training abgeschlossen in 14.45s (Backend: cuml)\n",
      "23:34:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:34:55 [INFO]   Training abgeschlossen in 14.68s (Backend: cuml)\n",
      "23:35:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:36:01 [INFO]   Training abgeschlossen in 14.90s (Backend: cuml)\n",
      "23:36:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:37:07 [INFO]   Training abgeschlossen in 15.12s (Backend: cuml)\n",
      "23:37:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:38:13 [INFO]   Training abgeschlossen in 15.37s (Backend: cuml)\n",
      "23:39:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:39:19 [INFO]   Training abgeschlossen in 15.53s (Backend: cuml)\n",
      "23:40:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:40:24 [INFO]   Training abgeschlossen in 16.00s (Backend: cuml)\n",
      "23:41:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:41:29 [INFO]   Training abgeschlossen in 15.93s (Backend: cuml)\n",
      "23:42:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:42:34 [INFO]   Training abgeschlossen in 16.17s (Backend: cuml)\n",
      "23:43:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:43:38 [INFO]   Training abgeschlossen in 16.36s (Backend: cuml)\n",
      "23:44:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:44:43 [INFO]   Training abgeschlossen in 16.68s (Backend: cuml)\n",
      "23:45:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:45:47 [INFO]   Training abgeschlossen in 16.97s (Backend: cuml)\n",
      "23:46:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:46:50 [INFO]   Training abgeschlossen in 17.08s (Backend: cuml)\n",
      "23:47:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:47:54 [INFO]   Training abgeschlossen in 17.29s (Backend: cuml)\n",
      "23:48:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:48:56 [INFO]   Training abgeschlossen in 17.50s (Backend: cuml)\n",
      "23:49:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:49:59 [INFO]   Training abgeschlossen in 17.73s (Backend: cuml)\n",
      "23:50:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:51:01 [INFO]   Training abgeschlossen in 17.92s (Backend: cuml)\n",
      "23:51:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:52:03 [INFO]   Training abgeschlossen in 18.16s (Backend: cuml)\n",
      "23:52:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:53:05 [INFO]   Training abgeschlossen in 18.52s (Backend: cuml)\n",
      "23:53:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:54:07 [INFO]   Training abgeschlossen in 18.81s (Backend: cuml)\n",
      "23:54:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:55:09 [INFO]   Training abgeschlossen in 18.91s (Backend: cuml)\n",
      "23:55:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:56:10 [INFO]   Training abgeschlossen in 19.04s (Backend: cuml)\n",
      "23:56:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:57:10 [INFO]   Training abgeschlossen in 19.26s (Backend: cuml)\n",
      "23:57:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:58:11 [INFO]   Training abgeschlossen in 19.40s (Backend: cuml)\n",
      "23:58:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:59:10 [INFO]   Training abgeschlossen in 19.62s (Backend: cuml)\n",
      "23:59:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:00:10 [INFO]   Training abgeschlossen in 19.81s (Backend: cuml)\n",
      "00:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:01:09 [INFO]   Training abgeschlossen in 20.07s (Backend: cuml)\n",
      "00:01:48 [INFO]     36,000 labeled → Accuracy: 0.8850 (Train: 20.1s, Query: 27.14s) | GPU: 2.8/8.0 GB\n",
      "00:01:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:02:08 [INFO]   Training abgeschlossen in 20.31s (Backend: cuml)\n",
      "00:02:20 [INFO]     Final: 36,000 labeled → Accuracy: 0.8846, F1: 0.8838\n",
      "00:02:20 [INFO] \n",
      "GPU-SVM + Margin Sampling - Budget: 80% (48,000 Samples)\n",
      "00:02:20 [INFO]   Run 1/5\n",
      "00:02:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:02:25 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "00:03:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:03:37 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "00:04:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:04:48 [INFO]   Training abgeschlossen in 5.05s (Backend: cuml)\n",
      "00:05:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:06:00 [INFO]   Training abgeschlossen in 5.23s (Backend: cuml)\n",
      "00:07:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:07:11 [INFO]   Training abgeschlossen in 5.43s (Backend: cuml)\n",
      "00:08:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:08:23 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "00:09:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:09:35 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "00:10:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:10:47 [INFO]   Training abgeschlossen in 6.20s (Backend: cuml)\n",
      "00:11:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:11:59 [INFO]   Training abgeschlossen in 6.56s (Backend: cuml)\n",
      "00:13:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:13:12 [INFO]   Training abgeschlossen in 6.86s (Backend: cuml)\n",
      "00:14:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:14:24 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "00:15:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:15:37 [INFO]   Training abgeschlossen in 7.68s (Backend: cuml)\n",
      "00:16:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:16:49 [INFO]   Training abgeschlossen in 7.69s (Backend: cuml)\n",
      "00:17:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:18:02 [INFO]   Training abgeschlossen in 7.96s (Backend: cuml)\n",
      "00:19:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:19:14 [INFO]   Training abgeschlossen in 8.25s (Backend: cuml)\n",
      "00:20:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:20:27 [INFO]   Training abgeschlossen in 8.66s (Backend: cuml)\n",
      "00:21:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:21:39 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "00:22:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:22:51 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "00:23:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:24:04 [INFO]   Training abgeschlossen in 9.26s (Backend: cuml)\n",
      "00:25:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:25:16 [INFO]   Training abgeschlossen in 9.50s (Backend: cuml)\n",
      "00:26:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:26:28 [INFO]   Training abgeschlossen in 9.72s (Backend: cuml)\n",
      "00:27:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:27:40 [INFO]   Training abgeschlossen in 9.84s (Backend: cuml)\n",
      "00:28:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:28:52 [INFO]   Training abgeschlossen in 10.25s (Backend: cuml)\n",
      "00:29:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:30:04 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "00:31:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:31:16 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "00:32:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:32:28 [INFO]   Training abgeschlossen in 10.76s (Backend: cuml)\n",
      "00:33:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:33:39 [INFO]   Training abgeschlossen in 11.08s (Backend: cuml)\n",
      "00:34:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:34:50 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "00:35:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:36:02 [INFO]   Training abgeschlossen in 11.34s (Backend: cuml)\n",
      "00:37:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:37:13 [INFO]   Training abgeschlossen in 11.58s (Backend: cuml)\n",
      "00:38:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:38:25 [INFO]   Training abgeschlossen in 11.90s (Backend: cuml)\n",
      "00:39:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:39:36 [INFO]   Training abgeschlossen in 12.00s (Backend: cuml)\n",
      "00:40:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:40:46 [INFO]   Training abgeschlossen in 12.26s (Backend: cuml)\n",
      "00:41:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:41:57 [INFO]   Training abgeschlossen in 12.55s (Backend: cuml)\n",
      "00:42:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:43:08 [INFO]   Training abgeschlossen in 12.87s (Backend: cuml)\n",
      "00:44:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:44:17 [INFO]   Training abgeschlossen in 12.85s (Backend: cuml)\n",
      "00:45:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:45:26 [INFO]   Training abgeschlossen in 13.06s (Backend: cuml)\n",
      "00:46:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:46:35 [INFO]   Training abgeschlossen in 13.32s (Backend: cuml)\n",
      "00:47:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:47:43 [INFO]   Training abgeschlossen in 13.54s (Backend: cuml)\n",
      "00:48:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:48:52 [INFO]   Training abgeschlossen in 13.82s (Backend: cuml)\n",
      "00:49:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:50:00 [INFO]   Training abgeschlossen in 13.96s (Backend: cuml)\n",
      "00:50:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:51:08 [INFO]   Training abgeschlossen in 14.14s (Backend: cuml)\n",
      "00:52:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:52:16 [INFO]   Training abgeschlossen in 14.41s (Backend: cuml)\n",
      "00:53:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:53:23 [INFO]   Training abgeschlossen in 14.41s (Backend: cuml)\n",
      "00:54:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:54:30 [INFO]   Training abgeschlossen in 14.64s (Backend: cuml)\n",
      "00:55:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:55:37 [INFO]   Training abgeschlossen in 14.70s (Backend: cuml)\n",
      "00:56:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:56:43 [INFO]   Training abgeschlossen in 15.01s (Backend: cuml)\n",
      "00:57:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:57:49 [INFO]   Training abgeschlossen in 15.10s (Backend: cuml)\n",
      "00:58:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:58:55 [INFO]   Training abgeschlossen in 15.31s (Backend: cuml)\n",
      "00:59:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:00:01 [INFO]   Training abgeschlossen in 15.69s (Backend: cuml)\n",
      "01:00:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:01:07 [INFO]   Training abgeschlossen in 16.23s (Backend: cuml)\n",
      "01:01:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:02:12 [INFO]   Training abgeschlossen in 15.98s (Backend: cuml)\n",
      "01:03:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:03:16 [INFO]   Training abgeschlossen in 16.15s (Backend: cuml)\n",
      "01:04:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:04:21 [INFO]   Training abgeschlossen in 16.47s (Backend: cuml)\n",
      "01:05:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:05:25 [INFO]   Training abgeschlossen in 16.61s (Backend: cuml)\n",
      "01:06:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:06:28 [INFO]   Training abgeschlossen in 16.84s (Backend: cuml)\n",
      "01:07:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:07:32 [INFO]   Training abgeschlossen in 17.07s (Backend: cuml)\n",
      "01:08:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:08:36 [INFO]   Training abgeschlossen in 17.41s (Backend: cuml)\n",
      "01:09:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:09:38 [INFO]   Training abgeschlossen in 17.52s (Backend: cuml)\n",
      "01:10:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:10:41 [INFO]   Training abgeschlossen in 17.75s (Backend: cuml)\n",
      "01:11:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:11:44 [INFO]   Training abgeschlossen in 17.97s (Backend: cuml)\n",
      "01:12:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:12:46 [INFO]   Training abgeschlossen in 18.17s (Backend: cuml)\n",
      "01:13:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:13:48 [INFO]   Training abgeschlossen in 18.40s (Backend: cuml)\n",
      "01:14:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:14:49 [INFO]   Training abgeschlossen in 18.56s (Backend: cuml)\n",
      "01:15:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:15:50 [INFO]   Training abgeschlossen in 18.74s (Backend: cuml)\n",
      "01:16:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:16:51 [INFO]   Training abgeschlossen in 19.05s (Backend: cuml)\n",
      "01:17:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:17:52 [INFO]   Training abgeschlossen in 19.30s (Backend: cuml)\n",
      "01:18:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:18:52 [INFO]   Training abgeschlossen in 19.52s (Backend: cuml)\n",
      "01:19:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:19:52 [INFO]   Training abgeschlossen in 19.72s (Backend: cuml)\n",
      "01:20:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:20:52 [INFO]   Training abgeschlossen in 19.94s (Backend: cuml)\n",
      "01:21:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:21:51 [INFO]   Training abgeschlossen in 20.11s (Backend: cuml)\n",
      "01:22:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:22:50 [INFO]   Training abgeschlossen in 20.58s (Backend: cuml)\n",
      "01:23:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:23:49 [INFO]   Training abgeschlossen in 20.60s (Backend: cuml)\n",
      "01:24:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:24:48 [INFO]   Training abgeschlossen in 20.78s (Backend: cuml)\n",
      "01:25:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:25:46 [INFO]   Training abgeschlossen in 20.97s (Backend: cuml)\n",
      "01:26:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:26:44 [INFO]   Training abgeschlossen in 21.10s (Backend: cuml)\n",
      "01:27:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:27:41 [INFO]   Training abgeschlossen in 21.47s (Backend: cuml)\n",
      "01:28:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:28:38 [INFO]   Training abgeschlossen in 21.58s (Backend: cuml)\n",
      "01:29:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:29:35 [INFO]   Training abgeschlossen in 21.70s (Backend: cuml)\n",
      "01:30:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:30:32 [INFO]   Training abgeschlossen in 21.90s (Backend: cuml)\n",
      "01:31:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:31:28 [INFO]   Training abgeschlossen in 22.17s (Backend: cuml)\n",
      "01:32:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:32:24 [INFO]   Training abgeschlossen in 22.41s (Backend: cuml)\n",
      "01:32:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:33:19 [INFO]   Training abgeschlossen in 22.51s (Backend: cuml)\n",
      "01:33:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:34:15 [INFO]   Training abgeschlossen in 22.77s (Backend: cuml)\n",
      "01:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:35:09 [INFO]   Training abgeschlossen in 22.95s (Backend: cuml)\n",
      "01:35:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:36:04 [INFO]   Training abgeschlossen in 23.30s (Backend: cuml)\n",
      "01:36:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:36:58 [INFO]   Training abgeschlossen in 23.56s (Backend: cuml)\n",
      "01:37:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:37:52 [INFO]   Training abgeschlossen in 23.68s (Backend: cuml)\n",
      "01:38:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:38:45 [INFO]   Training abgeschlossen in 23.75s (Backend: cuml)\n",
      "01:39:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:39:39 [INFO]   Training abgeschlossen in 24.06s (Backend: cuml)\n",
      "01:40:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:40:31 [INFO]   Training abgeschlossen in 24.24s (Backend: cuml)\n",
      "01:40:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:41:24 [INFO]   Training abgeschlossen in 24.24s (Backend: cuml)\n",
      "01:41:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:42:16 [INFO]   Training abgeschlossen in 24.43s (Backend: cuml)\n",
      "01:42:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:43:07 [INFO]   Training abgeschlossen in 24.58s (Backend: cuml)\n",
      "01:43:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:43:58 [INFO]   Training abgeschlossen in 24.78s (Backend: cuml)\n",
      "01:44:24 [INFO]     48,000 labeled → Accuracy: 0.8856 (Train: 24.8s, Query: 14.22s) | GPU: 2.8/8.0 GB\n",
      "01:44:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:44:49 [INFO]   Training abgeschlossen in 25.02s (Backend: cuml)\n",
      "01:45:01 [INFO]     Final: 48,000 labeled → Accuracy: 0.8856, F1: 0.8848\n",
      "01:45:01 [INFO]   Run 2/5\n",
      "01:45:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:45:06 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "01:46:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:46:17 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "01:47:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:47:29 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "01:48:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:48:41 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "01:49:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:49:53 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "01:50:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:51:04 [INFO]   Training abgeschlossen in 5.65s (Backend: cuml)\n",
      "01:52:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:52:17 [INFO]   Training abgeschlossen in 5.96s (Backend: cuml)\n",
      "01:53:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:53:29 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "01:54:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:54:41 [INFO]   Training abgeschlossen in 6.64s (Backend: cuml)\n",
      "01:55:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:55:53 [INFO]   Training abgeschlossen in 6.82s (Backend: cuml)\n",
      "01:56:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:57:06 [INFO]   Training abgeschlossen in 7.27s (Backend: cuml)\n",
      "01:58:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:58:19 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "01:59:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:59:32 [INFO]   Training abgeschlossen in 7.87s (Backend: cuml)\n",
      "02:00:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:00:44 [INFO]   Training abgeschlossen in 8.02s (Backend: cuml)\n",
      "02:01:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:01:57 [INFO]   Training abgeschlossen in 8.28s (Backend: cuml)\n",
      "02:03:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:03:09 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "02:04:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:04:22 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "02:05:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:05:34 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "02:06:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:06:46 [INFO]   Training abgeschlossen in 9.19s (Backend: cuml)\n",
      "02:07:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:07:58 [INFO]   Training abgeschlossen in 9.62s (Backend: cuml)\n",
      "02:09:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:09:10 [INFO]   Training abgeschlossen in 9.62s (Backend: cuml)\n",
      "02:10:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:10:22 [INFO]   Training abgeschlossen in 9.88s (Backend: cuml)\n",
      "02:11:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:11:35 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "02:12:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:12:47 [INFO]   Training abgeschlossen in 10.46s (Backend: cuml)\n",
      "02:13:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:13:58 [INFO]   Training abgeschlossen in 10.47s (Backend: cuml)\n",
      "02:14:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:15:10 [INFO]   Training abgeschlossen in 10.71s (Backend: cuml)\n",
      "02:16:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:16:21 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "02:17:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:17:34 [INFO]   Training abgeschlossen in 11.39s (Backend: cuml)\n",
      "02:18:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:18:46 [INFO]   Training abgeschlossen in 11.39s (Backend: cuml)\n",
      "02:19:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:19:57 [INFO]   Training abgeschlossen in 11.54s (Backend: cuml)\n",
      "02:20:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:21:09 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "02:22:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:22:20 [INFO]   Training abgeschlossen in 12.10s (Backend: cuml)\n",
      "02:23:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:23:31 [INFO]   Training abgeschlossen in 12.31s (Backend: cuml)\n",
      "02:24:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:24:42 [INFO]   Training abgeschlossen in 12.46s (Backend: cuml)\n",
      "02:25:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:25:53 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "02:26:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:27:02 [INFO]   Training abgeschlossen in 13.01s (Backend: cuml)\n",
      "02:27:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:28:12 [INFO]   Training abgeschlossen in 13.28s (Backend: cuml)\n",
      "02:29:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:29:21 [INFO]   Training abgeschlossen in 13.33s (Backend: cuml)\n",
      "02:30:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:30:29 [INFO]   Training abgeschlossen in 13.57s (Backend: cuml)\n",
      "02:31:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:31:38 [INFO]   Training abgeschlossen in 13.77s (Backend: cuml)\n",
      "02:32:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:32:47 [INFO]   Training abgeschlossen in 14.21s (Backend: cuml)\n",
      "02:33:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:33:55 [INFO]   Training abgeschlossen in 14.35s (Backend: cuml)\n",
      "02:34:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:35:03 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "02:35:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:36:11 [INFO]   Training abgeschlossen in 14.39s (Backend: cuml)\n",
      "02:37:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:37:18 [INFO]   Training abgeschlossen in 14.62s (Backend: cuml)\n",
      "02:38:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:38:25 [INFO]   Training abgeschlossen in 14.94s (Backend: cuml)\n",
      "02:39:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:39:31 [INFO]   Training abgeschlossen in 15.09s (Backend: cuml)\n",
      "02:40:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:40:37 [INFO]   Training abgeschlossen in 15.15s (Backend: cuml)\n",
      "02:41:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:41:44 [INFO]   Training abgeschlossen in 15.44s (Backend: cuml)\n",
      "02:42:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:42:49 [INFO]   Training abgeschlossen in 15.51s (Backend: cuml)\n",
      "02:43:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:43:55 [INFO]   Training abgeschlossen in 16.04s (Backend: cuml)\n",
      "02:44:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:45:00 [INFO]   Training abgeschlossen in 16.15s (Backend: cuml)\n",
      "02:45:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:46:05 [INFO]   Training abgeschlossen in 16.34s (Backend: cuml)\n",
      "02:46:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:47:09 [INFO]   Training abgeschlossen in 16.45s (Backend: cuml)\n",
      "02:47:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:48:13 [INFO]   Training abgeschlossen in 16.60s (Backend: cuml)\n",
      "02:49:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:49:18 [INFO]   Training abgeschlossen in 16.84s (Backend: cuml)\n",
      "02:50:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:50:21 [INFO]   Training abgeschlossen in 17.02s (Backend: cuml)\n",
      "02:51:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:51:24 [INFO]   Training abgeschlossen in 17.34s (Backend: cuml)\n",
      "02:52:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:52:28 [INFO]   Training abgeschlossen in 17.57s (Backend: cuml)\n",
      "02:53:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:53:30 [INFO]   Training abgeschlossen in 17.80s (Backend: cuml)\n",
      "02:54:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:54:33 [INFO]   Training abgeschlossen in 18.12s (Backend: cuml)\n",
      "02:55:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:55:35 [INFO]   Training abgeschlossen in 18.28s (Backend: cuml)\n",
      "02:56:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:56:37 [INFO]   Training abgeschlossen in 18.40s (Backend: cuml)\n",
      "02:57:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:57:38 [INFO]   Training abgeschlossen in 18.57s (Backend: cuml)\n",
      "02:58:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:58:39 [INFO]   Training abgeschlossen in 18.79s (Backend: cuml)\n",
      "02:59:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:59:40 [INFO]   Training abgeschlossen in 18.97s (Backend: cuml)\n",
      "03:00:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:00:41 [INFO]   Training abgeschlossen in 19.30s (Backend: cuml)\n",
      "03:01:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:01:41 [INFO]   Training abgeschlossen in 19.46s (Backend: cuml)\n",
      "03:02:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:02:41 [INFO]   Training abgeschlossen in 19.62s (Backend: cuml)\n",
      "03:03:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:03:41 [INFO]   Training abgeschlossen in 19.96s (Backend: cuml)\n",
      "03:04:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:04:41 [INFO]   Training abgeschlossen in 20.10s (Backend: cuml)\n",
      "03:05:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:05:40 [INFO]   Training abgeschlossen in 20.26s (Backend: cuml)\n",
      "03:06:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:06:39 [INFO]   Training abgeschlossen in 20.54s (Backend: cuml)\n",
      "03:07:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:07:37 [INFO]   Training abgeschlossen in 20.84s (Backend: cuml)\n",
      "03:08:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:08:36 [INFO]   Training abgeschlossen in 21.21s (Backend: cuml)\n",
      "03:09:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:09:33 [INFO]   Training abgeschlossen in 21.22s (Backend: cuml)\n",
      "03:10:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:10:31 [INFO]   Training abgeschlossen in 21.49s (Backend: cuml)\n",
      "03:11:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:11:28 [INFO]   Training abgeschlossen in 21.70s (Backend: cuml)\n",
      "03:12:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:12:25 [INFO]   Training abgeschlossen in 21.75s (Backend: cuml)\n",
      "03:12:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:13:21 [INFO]   Training abgeschlossen in 22.05s (Backend: cuml)\n",
      "03:13:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:14:18 [INFO]   Training abgeschlossen in 22.20s (Backend: cuml)\n",
      "03:14:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:15:14 [INFO]   Training abgeschlossen in 22.58s (Backend: cuml)\n",
      "03:15:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:16:09 [INFO]   Training abgeschlossen in 22.72s (Backend: cuml)\n",
      "03:16:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:17:05 [INFO]   Training abgeschlossen in 22.88s (Backend: cuml)\n",
      "03:17:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:17:59 [INFO]   Training abgeschlossen in 22.95s (Backend: cuml)\n",
      "03:18:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:18:54 [INFO]   Training abgeschlossen in 23.23s (Backend: cuml)\n",
      "03:19:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:19:48 [INFO]   Training abgeschlossen in 23.41s (Backend: cuml)\n",
      "03:20:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:20:42 [INFO]   Training abgeschlossen in 23.65s (Backend: cuml)\n",
      "03:21:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:21:36 [INFO]   Training abgeschlossen in 23.75s (Backend: cuml)\n",
      "03:22:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:22:29 [INFO]   Training abgeschlossen in 23.90s (Backend: cuml)\n",
      "03:22:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:23:21 [INFO]   Training abgeschlossen in 24.15s (Backend: cuml)\n",
      "03:23:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:24:13 [INFO]   Training abgeschlossen in 24.29s (Backend: cuml)\n",
      "03:24:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:25:05 [INFO]   Training abgeschlossen in 24.36s (Backend: cuml)\n",
      "03:25:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:25:57 [INFO]   Training abgeschlossen in 24.77s (Backend: cuml)\n",
      "03:26:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:26:48 [INFO]   Training abgeschlossen in 24.79s (Backend: cuml)\n",
      "03:27:13 [INFO]     48,000 labeled → Accuracy: 0.8853 (Train: 24.8s, Query: 14.10s) | GPU: 2.8/8.0 GB\n",
      "03:27:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:27:39 [INFO]   Training abgeschlossen in 25.03s (Backend: cuml)\n",
      "03:27:50 [INFO]     Final: 48,000 labeled → Accuracy: 0.8851, F1: 0.8843\n",
      "03:27:50 [INFO]   Run 3/5\n",
      "03:27:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:27:55 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "03:29:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:29:07 [INFO]   Training abgeschlossen in 4.87s (Backend: cuml)\n",
      "03:30:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:30:19 [INFO]   Training abgeschlossen in 5.14s (Backend: cuml)\n",
      "03:31:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:31:30 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "03:32:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:32:42 [INFO]   Training abgeschlossen in 5.51s (Backend: cuml)\n",
      "03:33:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:33:53 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "03:35:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:35:06 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "03:36:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:36:18 [INFO]   Training abgeschlossen in 6.28s (Backend: cuml)\n",
      "03:37:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:37:29 [INFO]   Training abgeschlossen in 6.66s (Backend: cuml)\n",
      "03:38:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:38:42 [INFO]   Training abgeschlossen in 7.10s (Backend: cuml)\n",
      "03:39:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:39:54 [INFO]   Training abgeschlossen in 7.23s (Backend: cuml)\n",
      "03:40:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:41:06 [INFO]   Training abgeschlossen in 7.42s (Backend: cuml)\n",
      "03:42:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:42:18 [INFO]   Training abgeschlossen in 7.84s (Backend: cuml)\n",
      "03:43:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:43:31 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "03:44:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:44:43 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "03:45:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:45:55 [INFO]   Training abgeschlossen in 8.47s (Backend: cuml)\n",
      "03:46:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:47:08 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "03:48:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:48:21 [INFO]   Training abgeschlossen in 9.05s (Backend: cuml)\n",
      "03:49:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:49:34 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "03:50:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:50:47 [INFO]   Training abgeschlossen in 9.47s (Backend: cuml)\n",
      "03:51:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:51:59 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "03:53:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:53:11 [INFO]   Training abgeschlossen in 9.87s (Backend: cuml)\n",
      "03:54:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:54:23 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "03:55:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:55:35 [INFO]   Training abgeschlossen in 10.38s (Backend: cuml)\n",
      "03:56:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:56:46 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "03:57:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:57:58 [INFO]   Training abgeschlossen in 10.76s (Backend: cuml)\n",
      "03:58:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:59:09 [INFO]   Training abgeschlossen in 10.89s (Backend: cuml)\n",
      "04:00:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:00:20 [INFO]   Training abgeschlossen in 11.31s (Backend: cuml)\n",
      "04:01:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:01:32 [INFO]   Training abgeschlossen in 11.35s (Backend: cuml)\n",
      "04:02:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "04:02:43 [INFO]   Training abgeschlossen in 11.57s (Backend: cuml)\n",
      "04:03:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:03:54 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "04:04:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:05:06 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "04:06:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:06:17 [INFO]   Training abgeschlossen in 12.21s (Backend: cuml)\n",
      "04:07:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:07:27 [INFO]   Training abgeschlossen in 12.48s (Backend: cuml)\n",
      "04:08:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:08:38 [INFO]   Training abgeschlossen in 12.69s (Backend: cuml)\n",
      "04:09:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:09:47 [INFO]   Training abgeschlossen in 12.98s (Backend: cuml)\n",
      "04:10:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:10:56 [INFO]   Training abgeschlossen in 13.14s (Backend: cuml)\n",
      "04:11:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:12:05 [INFO]   Training abgeschlossen in 13.32s (Backend: cuml)\n",
      "04:13:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:13:14 [INFO]   Training abgeschlossen in 13.46s (Backend: cuml)\n",
      "04:14:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:14:22 [INFO]   Training abgeschlossen in 13.75s (Backend: cuml)\n",
      "04:15:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:15:31 [INFO]   Training abgeschlossen in 14.06s (Backend: cuml)\n",
      "04:16:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:16:39 [INFO]   Training abgeschlossen in 14.17s (Backend: cuml)\n",
      "04:17:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:17:47 [INFO]   Training abgeschlossen in 14.29s (Backend: cuml)\n",
      "04:18:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:18:54 [INFO]   Training abgeschlossen in 14.21s (Backend: cuml)\n",
      "04:19:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:20:00 [INFO]   Training abgeschlossen in 14.42s (Backend: cuml)\n",
      "04:20:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:21:07 [INFO]   Training abgeschlossen in 14.88s (Backend: cuml)\n",
      "04:21:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:22:13 [INFO]   Training abgeschlossen in 15.03s (Backend: cuml)\n",
      "04:23:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:23:19 [INFO]   Training abgeschlossen in 15.17s (Backend: cuml)\n",
      "04:24:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:24:25 [INFO]   Training abgeschlossen in 15.39s (Backend: cuml)\n",
      "04:25:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:25:31 [INFO]   Training abgeschlossen in 15.60s (Backend: cuml)\n",
      "04:26:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:26:36 [INFO]   Training abgeschlossen in 16.09s (Backend: cuml)\n",
      "04:27:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:27:41 [INFO]   Training abgeschlossen in 16.01s (Backend: cuml)\n",
      "04:28:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:28:46 [INFO]   Training abgeschlossen in 16.23s (Backend: cuml)\n",
      "04:29:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:29:50 [INFO]   Training abgeschlossen in 16.37s (Backend: cuml)\n",
      "04:30:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:30:54 [INFO]   Training abgeschlossen in 16.58s (Backend: cuml)\n",
      "04:31:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:31:58 [INFO]   Training abgeschlossen in 16.76s (Backend: cuml)\n",
      "04:32:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:33:02 [INFO]   Training abgeschlossen in 17.05s (Backend: cuml)\n",
      "04:33:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:34:05 [INFO]   Training abgeschlossen in 17.20s (Backend: cuml)\n",
      "04:34:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:35:08 [INFO]   Training abgeschlossen in 17.45s (Backend: cuml)\n",
      "04:35:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:36:11 [INFO]   Training abgeschlossen in 17.79s (Backend: cuml)\n",
      "04:36:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:37:13 [INFO]   Training abgeschlossen in 18.08s (Backend: cuml)\n",
      "04:37:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:38:16 [INFO]   Training abgeschlossen in 18.28s (Backend: cuml)\n",
      "04:38:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:39:17 [INFO]   Training abgeschlossen in 18.35s (Backend: cuml)\n",
      "04:40:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:40:19 [INFO]   Training abgeschlossen in 18.52s (Backend: cuml)\n",
      "04:41:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:41:20 [INFO]   Training abgeschlossen in 18.74s (Backend: cuml)\n",
      "04:42:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:42:21 [INFO]   Training abgeschlossen in 19.00s (Backend: cuml)\n",
      "04:43:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:43:21 [INFO]   Training abgeschlossen in 19.24s (Backend: cuml)\n",
      "04:44:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:44:22 [INFO]   Training abgeschlossen in 19.41s (Backend: cuml)\n",
      "04:45:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:45:22 [INFO]   Training abgeschlossen in 19.59s (Backend: cuml)\n",
      "04:46:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:46:22 [INFO]   Training abgeschlossen in 19.87s (Backend: cuml)\n",
      "04:47:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:47:21 [INFO]   Training abgeschlossen in 20.03s (Backend: cuml)\n",
      "04:48:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:48:20 [INFO]   Training abgeschlossen in 20.30s (Backend: cuml)\n",
      "04:48:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:49:19 [INFO]   Training abgeschlossen in 20.49s (Backend: cuml)\n",
      "04:49:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:50:17 [INFO]   Training abgeschlossen in 20.76s (Backend: cuml)\n",
      "04:50:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:51:16 [INFO]   Training abgeschlossen in 20.94s (Backend: cuml)\n",
      "04:51:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:52:14 [INFO]   Training abgeschlossen in 21.21s (Backend: cuml)\n",
      "04:52:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:53:11 [INFO]   Training abgeschlossen in 21.38s (Backend: cuml)\n",
      "04:53:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:54:08 [INFO]   Training abgeschlossen in 21.67s (Backend: cuml)\n",
      "04:54:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:55:05 [INFO]   Training abgeschlossen in 21.99s (Backend: cuml)\n",
      "04:55:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:56:02 [INFO]   Training abgeschlossen in 21.99s (Backend: cuml)\n",
      "04:56:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:56:58 [INFO]   Training abgeschlossen in 22.25s (Backend: cuml)\n",
      "04:57:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:57:54 [INFO]   Training abgeschlossen in 22.43s (Backend: cuml)\n",
      "04:58:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:58:50 [INFO]   Training abgeschlossen in 22.58s (Backend: cuml)\n",
      "04:59:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "04:59:45 [INFO]   Training abgeschlossen in 22.66s (Backend: cuml)\n",
      "05:00:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:00:40 [INFO]   Training abgeschlossen in 23.01s (Backend: cuml)\n",
      "05:01:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:01:34 [INFO]   Training abgeschlossen in 23.19s (Backend: cuml)\n",
      "05:02:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:02:28 [INFO]   Training abgeschlossen in 23.36s (Backend: cuml)\n",
      "05:02:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:03:22 [INFO]   Training abgeschlossen in 23.42s (Backend: cuml)\n",
      "05:03:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:04:15 [INFO]   Training abgeschlossen in 23.58s (Backend: cuml)\n",
      "05:04:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:05:09 [INFO]   Training abgeschlossen in 23.92s (Backend: cuml)\n",
      "05:05:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:06:01 [INFO]   Training abgeschlossen in 24.10s (Backend: cuml)\n",
      "05:06:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:06:54 [INFO]   Training abgeschlossen in 24.20s (Backend: cuml)\n",
      "05:07:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:07:46 [INFO]   Training abgeschlossen in 24.50s (Backend: cuml)\n",
      "05:08:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:08:37 [INFO]   Training abgeschlossen in 24.60s (Backend: cuml)\n",
      "05:09:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:09:29 [INFO]   Training abgeschlossen in 24.88s (Backend: cuml)\n",
      "05:09:54 [INFO]     48,000 labeled → Accuracy: 0.8848 (Train: 24.9s, Query: 14.11s) | GPU: 2.8/8.0 GB\n",
      "05:09:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:10:20 [INFO]   Training abgeschlossen in 25.13s (Backend: cuml)\n",
      "05:10:31 [INFO]     Final: 48,000 labeled → Accuracy: 0.8848, F1: 0.8839\n",
      "05:10:31 [INFO]   Run 4/5\n",
      "05:10:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "05:10:36 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "05:11:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:11:48 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "05:12:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:13:00 [INFO]   Training abgeschlossen in 5.13s (Backend: cuml)\n",
      "05:14:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "05:14:11 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "05:15:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:15:23 [INFO]   Training abgeschlossen in 5.49s (Backend: cuml)\n",
      "05:16:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:16:35 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "05:17:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:17:47 [INFO]   Training abgeschlossen in 6.11s (Backend: cuml)\n",
      "05:18:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "05:18:59 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "05:20:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:20:11 [INFO]   Training abgeschlossen in 6.49s (Backend: cuml)\n",
      "05:21:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:21:23 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "05:22:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:22:36 [INFO]   Training abgeschlossen in 7.50s (Backend: cuml)\n",
      "05:23:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:23:48 [INFO]   Training abgeschlossen in 7.52s (Backend: cuml)\n",
      "05:24:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:25:01 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "05:26:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:26:13 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "05:27:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:27:25 [INFO]   Training abgeschlossen in 8.29s (Backend: cuml)\n",
      "05:28:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:28:38 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "05:29:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:29:50 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "05:30:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:31:03 [INFO]   Training abgeschlossen in 9.05s (Backend: cuml)\n",
      "05:32:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:32:15 [INFO]   Training abgeschlossen in 9.37s (Backend: cuml)\n",
      "05:33:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:33:28 [INFO]   Training abgeschlossen in 9.49s (Backend: cuml)\n",
      "05:34:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:34:40 [INFO]   Training abgeschlossen in 9.61s (Backend: cuml)\n",
      "05:35:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:35:52 [INFO]   Training abgeschlossen in 9.88s (Backend: cuml)\n",
      "05:36:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:37:04 [INFO]   Training abgeschlossen in 10.16s (Backend: cuml)\n",
      "05:38:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:38:16 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "05:39:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:39:27 [INFO]   Training abgeschlossen in 10.50s (Backend: cuml)\n",
      "05:40:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:40:39 [INFO]   Training abgeschlossen in 10.84s (Backend: cuml)\n",
      "05:41:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:41:50 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "05:42:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:43:01 [INFO]   Training abgeschlossen in 11.23s (Backend: cuml)\n",
      "05:44:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:44:12 [INFO]   Training abgeschlossen in 11.39s (Backend: cuml)\n",
      "05:45:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:45:24 [INFO]   Training abgeschlossen in 11.68s (Backend: cuml)\n",
      "05:46:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:46:35 [INFO]   Training abgeschlossen in 11.79s (Backend: cuml)\n",
      "05:47:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:47:47 [INFO]   Training abgeschlossen in 12.04s (Backend: cuml)\n",
      "05:48:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:48:58 [INFO]   Training abgeschlossen in 12.27s (Backend: cuml)\n",
      "05:49:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:50:09 [INFO]   Training abgeschlossen in 12.58s (Backend: cuml)\n",
      "05:51:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:51:19 [INFO]   Training abgeschlossen in 12.70s (Backend: cuml)\n",
      "05:52:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:52:28 [INFO]   Training abgeschlossen in 12.93s (Backend: cuml)\n",
      "05:53:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:53:37 [INFO]   Training abgeschlossen in 13.12s (Backend: cuml)\n",
      "05:54:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:54:46 [INFO]   Training abgeschlossen in 13.35s (Backend: cuml)\n",
      "05:55:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:55:55 [INFO]   Training abgeschlossen in 13.62s (Backend: cuml)\n",
      "05:56:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:57:04 [INFO]   Training abgeschlossen in 13.76s (Backend: cuml)\n",
      "05:57:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:58:12 [INFO]   Training abgeschlossen in 13.94s (Backend: cuml)\n",
      "05:59:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:59:20 [INFO]   Training abgeschlossen in 14.16s (Backend: cuml)\n",
      "06:00:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:00:27 [INFO]   Training abgeschlossen in 14.32s (Backend: cuml)\n",
      "06:01:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:01:34 [INFO]   Training abgeschlossen in 14.40s (Backend: cuml)\n",
      "06:02:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:02:41 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "06:03:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:03:47 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "06:04:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:04:54 [INFO]   Training abgeschlossen in 14.90s (Backend: cuml)\n",
      "06:05:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:06:00 [INFO]   Training abgeschlossen in 15.07s (Backend: cuml)\n",
      "06:06:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:07:05 [INFO]   Training abgeschlossen in 15.42s (Backend: cuml)\n",
      "06:07:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:08:11 [INFO]   Training abgeschlossen in 15.71s (Backend: cuml)\n",
      "06:09:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:09:16 [INFO]   Training abgeschlossen in 16.07s (Backend: cuml)\n",
      "06:10:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:10:21 [INFO]   Training abgeschlossen in 15.99s (Backend: cuml)\n",
      "06:11:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:11:25 [INFO]   Training abgeschlossen in 16.21s (Backend: cuml)\n",
      "06:12:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:12:30 [INFO]   Training abgeschlossen in 16.38s (Backend: cuml)\n",
      "06:13:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:13:34 [INFO]   Training abgeschlossen in 16.62s (Backend: cuml)\n",
      "06:14:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:14:38 [INFO]   Training abgeschlossen in 16.88s (Backend: cuml)\n",
      "06:15:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:15:42 [INFO]   Training abgeschlossen in 17.19s (Backend: cuml)\n",
      "06:16:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:16:45 [INFO]   Training abgeschlossen in 17.33s (Backend: cuml)\n",
      "06:17:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:17:48 [INFO]   Training abgeschlossen in 17.53s (Backend: cuml)\n",
      "06:18:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:18:50 [INFO]   Training abgeschlossen in 17.67s (Backend: cuml)\n",
      "06:19:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:19:52 [INFO]   Training abgeschlossen in 17.85s (Backend: cuml)\n",
      "06:20:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:20:55 [INFO]   Training abgeschlossen in 18.25s (Backend: cuml)\n",
      "06:21:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:21:56 [INFO]   Training abgeschlossen in 18.33s (Backend: cuml)\n",
      "06:22:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:22:58 [INFO]   Training abgeschlossen in 18.69s (Backend: cuml)\n",
      "06:23:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:23:59 [INFO]   Training abgeschlossen in 18.83s (Backend: cuml)\n",
      "06:24:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:25:00 [INFO]   Training abgeschlossen in 19.01s (Backend: cuml)\n",
      "06:25:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:26:01 [INFO]   Training abgeschlossen in 19.31s (Backend: cuml)\n",
      "06:26:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:27:01 [INFO]   Training abgeschlossen in 19.64s (Backend: cuml)\n",
      "06:27:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:28:01 [INFO]   Training abgeschlossen in 19.71s (Backend: cuml)\n",
      "06:28:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:29:01 [INFO]   Training abgeschlossen in 20.00s (Backend: cuml)\n",
      "06:29:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:30:00 [INFO]   Training abgeschlossen in 20.02s (Backend: cuml)\n",
      "06:30:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:30:59 [INFO]   Training abgeschlossen in 20.33s (Backend: cuml)\n",
      "06:31:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:31:58 [INFO]   Training abgeschlossen in 20.56s (Backend: cuml)\n",
      "06:32:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:32:56 [INFO]   Training abgeschlossen in 20.72s (Backend: cuml)\n",
      "06:33:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:33:54 [INFO]   Training abgeschlossen in 20.84s (Backend: cuml)\n",
      "06:34:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:34:52 [INFO]   Training abgeschlossen in 21.03s (Backend: cuml)\n",
      "06:35:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:35:49 [INFO]   Training abgeschlossen in 21.21s (Backend: cuml)\n",
      "06:36:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:36:46 [INFO]   Training abgeschlossen in 21.50s (Backend: cuml)\n",
      "06:37:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:37:43 [INFO]   Training abgeschlossen in 21.62s (Backend: cuml)\n",
      "06:38:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:38:40 [INFO]   Training abgeschlossen in 21.84s (Backend: cuml)\n",
      "06:39:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:39:36 [INFO]   Training abgeschlossen in 22.08s (Backend: cuml)\n",
      "06:40:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:40:31 [INFO]   Training abgeschlossen in 22.25s (Backend: cuml)\n",
      "06:41:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:41:27 [INFO]   Training abgeschlossen in 22.41s (Backend: cuml)\n",
      "06:41:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:42:22 [INFO]   Training abgeschlossen in 22.73s (Backend: cuml)\n",
      "06:42:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:43:17 [INFO]   Training abgeschlossen in 22.87s (Backend: cuml)\n",
      "06:43:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:44:11 [INFO]   Training abgeschlossen in 23.09s (Backend: cuml)\n",
      "06:44:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:45:05 [INFO]   Training abgeschlossen in 23.32s (Backend: cuml)\n",
      "06:45:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:45:59 [INFO]   Training abgeschlossen in 23.56s (Backend: cuml)\n",
      "06:46:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:46:53 [INFO]   Training abgeschlossen in 23.69s (Backend: cuml)\n",
      "06:47:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:47:46 [INFO]   Training abgeschlossen in 23.94s (Backend: cuml)\n",
      "06:48:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:48:38 [INFO]   Training abgeschlossen in 24.16s (Backend: cuml)\n",
      "06:49:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:49:31 [INFO]   Training abgeschlossen in 24.37s (Backend: cuml)\n",
      "06:49:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:50:23 [INFO]   Training abgeschlossen in 24.43s (Backend: cuml)\n",
      "06:50:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:51:14 [INFO]   Training abgeschlossen in 24.66s (Backend: cuml)\n",
      "06:51:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:52:05 [INFO]   Training abgeschlossen in 24.74s (Backend: cuml)\n",
      "06:52:31 [INFO]     48,000 labeled → Accuracy: 0.8858 (Train: 24.8s, Query: 14.15s) | GPU: 2.8/8.0 GB\n",
      "06:52:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:52:56 [INFO]   Training abgeschlossen in 24.95s (Backend: cuml)\n",
      "06:53:07 [INFO]     Final: 48,000 labeled → Accuracy: 0.8861, F1: 0.8853\n",
      "06:53:07 [INFO]   Run 5/5\n",
      "06:53:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "06:53:12 [INFO]   Training abgeschlossen in 4.82s (Backend: cuml)\n",
      "06:54:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:54:24 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "06:55:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:55:35 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "06:56:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:56:47 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "06:57:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:57:58 [INFO]   Training abgeschlossen in 5.47s (Backend: cuml)\n",
      "06:59:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:59:10 [INFO]   Training abgeschlossen in 5.60s (Backend: cuml)\n",
      "07:00:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:00:22 [INFO]   Training abgeschlossen in 5.86s (Backend: cuml)\n",
      "07:01:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:01:34 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "07:02:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:02:46 [INFO]   Training abgeschlossen in 6.69s (Backend: cuml)\n",
      "07:03:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:03:58 [INFO]   Training abgeschlossen in 6.87s (Backend: cuml)\n",
      "07:05:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:05:10 [INFO]   Training abgeschlossen in 7.19s (Backend: cuml)\n",
      "07:06:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:06:23 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "07:07:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:07:35 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "07:08:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:08:48 [INFO]   Training abgeschlossen in 8.00s (Backend: cuml)\n",
      "07:09:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:10:00 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "07:11:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:11:13 [INFO]   Training abgeschlossen in 8.41s (Backend: cuml)\n",
      "07:12:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:12:26 [INFO]   Training abgeschlossen in 8.75s (Backend: cuml)\n",
      "07:13:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:13:38 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "07:14:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:14:50 [INFO]   Training abgeschlossen in 9.19s (Backend: cuml)\n",
      "07:15:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:16:02 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "07:17:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:17:14 [INFO]   Training abgeschlossen in 9.74s (Backend: cuml)\n",
      "07:18:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:18:26 [INFO]   Training abgeschlossen in 9.84s (Backend: cuml)\n",
      "07:19:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:19:38 [INFO]   Training abgeschlossen in 10.06s (Backend: cuml)\n",
      "07:20:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:20:50 [INFO]   Training abgeschlossen in 10.36s (Backend: cuml)\n",
      "07:21:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:22:01 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "07:23:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:23:13 [INFO]   Training abgeschlossen in 10.76s (Backend: cuml)\n",
      "07:24:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:24:24 [INFO]   Training abgeschlossen in 10.95s (Backend: cuml)\n",
      "07:25:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:25:35 [INFO]   Training abgeschlossen in 11.21s (Backend: cuml)\n",
      "07:26:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:26:47 [INFO]   Training abgeschlossen in 11.44s (Backend: cuml)\n",
      "07:27:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:27:58 [INFO]   Training abgeschlossen in 11.57s (Backend: cuml)\n",
      "07:28:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:29:09 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "07:30:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:30:21 [INFO]   Training abgeschlossen in 12.05s (Backend: cuml)\n",
      "07:31:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:31:32 [INFO]   Training abgeschlossen in 12.34s (Backend: cuml)\n",
      "07:32:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:32:42 [INFO]   Training abgeschlossen in 12.47s (Backend: cuml)\n",
      "07:33:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:33:53 [INFO]   Training abgeschlossen in 12.71s (Backend: cuml)\n",
      "07:34:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:35:02 [INFO]   Training abgeschlossen in 12.91s (Backend: cuml)\n",
      "07:35:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:36:11 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "07:37:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:37:20 [INFO]   Training abgeschlossen in 13.34s (Backend: cuml)\n",
      "07:38:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:38:29 [INFO]   Training abgeschlossen in 13.51s (Backend: cuml)\n",
      "07:39:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:39:37 [INFO]   Training abgeschlossen in 13.73s (Backend: cuml)\n",
      "07:40:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:40:46 [INFO]   Training abgeschlossen in 14.05s (Backend: cuml)\n",
      "07:41:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:41:54 [INFO]   Training abgeschlossen in 14.29s (Backend: cuml)\n",
      "07:42:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:43:01 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "07:43:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:44:08 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "07:45:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:45:15 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "07:46:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "07:46:22 [INFO]   Training abgeschlossen in 14.80s (Backend: cuml)\n",
      "07:47:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:47:28 [INFO]   Training abgeschlossen in 14.98s (Backend: cuml)\n",
      "07:48:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:48:34 [INFO]   Training abgeschlossen in 15.32s (Backend: cuml)\n",
      "07:49:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:49:40 [INFO]   Training abgeschlossen in 15.46s (Backend: cuml)\n",
      "07:50:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:50:45 [INFO]   Training abgeschlossen in 15.57s (Backend: cuml)\n",
      "07:51:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:51:51 [INFO]   Training abgeschlossen in 15.98s (Backend: cuml)\n",
      "07:52:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:52:56 [INFO]   Training abgeschlossen in 15.95s (Backend: cuml)\n",
      "07:53:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:54:00 [INFO]   Training abgeschlossen in 16.13s (Backend: cuml)\n",
      "07:54:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:55:05 [INFO]   Training abgeschlossen in 16.59s (Backend: cuml)\n",
      "07:55:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:56:09 [INFO]   Training abgeschlossen in 16.87s (Backend: cuml)\n",
      "07:56:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:57:13 [INFO]   Training abgeschlossen in 16.87s (Backend: cuml)\n",
      "07:58:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:58:17 [INFO]   Training abgeschlossen in 17.03s (Backend: cuml)\n",
      "07:59:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:59:20 [INFO]   Training abgeschlossen in 17.39s (Backend: cuml)\n",
      "08:00:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:00:23 [INFO]   Training abgeschlossen in 17.49s (Backend: cuml)\n",
      "08:01:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:01:26 [INFO]   Training abgeschlossen in 17.70s (Backend: cuml)\n",
      "08:02:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:02:28 [INFO]   Training abgeschlossen in 17.95s (Backend: cuml)\n",
      "08:03:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:03:30 [INFO]   Training abgeschlossen in 18.24s (Backend: cuml)\n",
      "08:04:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:04:32 [INFO]   Training abgeschlossen in 18.56s (Backend: cuml)\n",
      "08:05:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:05:34 [INFO]   Training abgeschlossen in 18.71s (Backend: cuml)\n",
      "08:06:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:06:35 [INFO]   Training abgeschlossen in 18.96s (Backend: cuml)\n",
      "08:07:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:07:36 [INFO]   Training abgeschlossen in 19.13s (Backend: cuml)\n",
      "08:08:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:08:37 [INFO]   Training abgeschlossen in 19.36s (Backend: cuml)\n",
      "08:09:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:09:37 [INFO]   Training abgeschlossen in 19.53s (Backend: cuml)\n",
      "08:10:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:10:37 [INFO]   Training abgeschlossen in 19.76s (Backend: cuml)\n",
      "08:11:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:11:37 [INFO]   Training abgeschlossen in 19.90s (Backend: cuml)\n",
      "08:12:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:12:36 [INFO]   Training abgeschlossen in 20.09s (Backend: cuml)\n",
      "08:13:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:13:35 [INFO]   Training abgeschlossen in 20.34s (Backend: cuml)\n",
      "08:14:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:14:34 [INFO]   Training abgeschlossen in 20.55s (Backend: cuml)\n",
      "08:15:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:15:32 [INFO]   Training abgeschlossen in 20.68s (Backend: cuml)\n",
      "08:16:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:16:31 [INFO]   Training abgeschlossen in 20.87s (Backend: cuml)\n",
      "08:17:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:17:28 [INFO]   Training abgeschlossen in 21.07s (Backend: cuml)\n",
      "08:18:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:18:26 [INFO]   Training abgeschlossen in 21.42s (Backend: cuml)\n",
      "08:19:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:19:23 [INFO]   Training abgeschlossen in 21.47s (Backend: cuml)\n",
      "08:19:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:20:20 [INFO]   Training abgeschlossen in 21.80s (Backend: cuml)\n",
      "08:20:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:21:17 [INFO]   Training abgeschlossen in 21.97s (Backend: cuml)\n",
      "08:21:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:22:13 [INFO]   Training abgeschlossen in 22.17s (Backend: cuml)\n",
      "08:22:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:23:09 [INFO]   Training abgeschlossen in 22.33s (Backend: cuml)\n",
      "08:23:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:24:05 [INFO]   Training abgeschlossen in 22.68s (Backend: cuml)\n",
      "08:24:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:25:00 [INFO]   Training abgeschlossen in 22.62s (Backend: cuml)\n",
      "08:25:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:25:55 [INFO]   Training abgeschlossen in 22.93s (Backend: cuml)\n",
      "08:26:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:26:50 [INFO]   Training abgeschlossen in 23.16s (Backend: cuml)\n",
      "08:27:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:27:44 [INFO]   Training abgeschlossen in 23.48s (Backend: cuml)\n",
      "08:28:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:28:38 [INFO]   Training abgeschlossen in 23.40s (Backend: cuml)\n",
      "08:29:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:29:31 [INFO]   Training abgeschlossen in 23.73s (Backend: cuml)\n",
      "08:30:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:30:24 [INFO]   Training abgeschlossen in 23.83s (Backend: cuml)\n",
      "08:30:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:31:17 [INFO]   Training abgeschlossen in 24.08s (Backend: cuml)\n",
      "08:31:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:32:09 [INFO]   Training abgeschlossen in 24.20s (Backend: cuml)\n",
      "08:32:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:33:01 [INFO]   Training abgeschlossen in 24.43s (Backend: cuml)\n",
      "08:33:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:33:52 [INFO]   Training abgeschlossen in 24.77s (Backend: cuml)\n",
      "08:34:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:34:44 [INFO]   Training abgeschlossen in 24.84s (Backend: cuml)\n",
      "08:35:09 [INFO]     48,000 labeled → Accuracy: 0.8851 (Train: 24.9s, Query: 14.10s) | GPU: 2.8/8.0 GB\n",
      "08:35:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:35:34 [INFO]   Training abgeschlossen in 25.04s (Backend: cuml)\n",
      "08:35:46 [INFO]     Final: 48,000 labeled → Accuracy: 0.8848, F1: 0.8840\n",
      "08:35:46 [INFO] \n",
      "GPU-SVM + Margin Sampling - Budget: 100% (60,000 Samples)\n",
      "08:35:46 [INFO]   Run 1/5\n",
      "08:35:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "08:35:51 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "08:36:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:37:03 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "08:38:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:38:14 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "08:39:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:39:26 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "08:40:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:40:38 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "08:41:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:41:49 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "08:42:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:43:01 [INFO]   Training abgeschlossen in 5.90s (Backend: cuml)\n",
      "08:44:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:44:13 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "08:45:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:45:25 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "08:46:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:46:37 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "08:47:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:47:50 [INFO]   Training abgeschlossen in 7.47s (Backend: cuml)\n",
      "08:48:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:49:02 [INFO]   Training abgeschlossen in 7.45s (Backend: cuml)\n",
      "08:50:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:50:14 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "08:51:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:51:27 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "08:52:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:52:39 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "08:53:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:53:52 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "08:54:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:55:04 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "08:56:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:56:17 [INFO]   Training abgeschlossen in 9.13s (Backend: cuml)\n",
      "08:57:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:57:29 [INFO]   Training abgeschlossen in 9.20s (Backend: cuml)\n",
      "08:58:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:58:41 [INFO]   Training abgeschlossen in 9.39s (Backend: cuml)\n",
      "08:59:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "08:59:53 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "09:00:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:01:05 [INFO]   Training abgeschlossen in 10.01s (Backend: cuml)\n",
      "09:02:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:02:18 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "09:03:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:03:30 [INFO]   Training abgeschlossen in 10.30s (Backend: cuml)\n",
      "09:04:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:04:41 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "09:05:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:05:53 [INFO]   Training abgeschlossen in 10.93s (Backend: cuml)\n",
      "09:06:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:07:04 [INFO]   Training abgeschlossen in 10.94s (Backend: cuml)\n",
      "09:08:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:08:15 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "09:09:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:09:27 [INFO]   Training abgeschlossen in 11.34s (Backend: cuml)\n",
      "09:10:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:10:39 [INFO]   Training abgeschlossen in 11.78s (Backend: cuml)\n",
      "09:11:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:11:50 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "09:12:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:13:01 [INFO]   Training abgeschlossen in 12.02s (Backend: cuml)\n",
      "09:13:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:14:12 [INFO]   Training abgeschlossen in 12.28s (Backend: cuml)\n",
      "09:15:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:15:23 [INFO]   Training abgeschlossen in 12.67s (Backend: cuml)\n",
      "09:16:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:16:33 [INFO]   Training abgeschlossen in 12.69s (Backend: cuml)\n",
      "09:17:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:17:42 [INFO]   Training abgeschlossen in 12.95s (Backend: cuml)\n",
      "09:18:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:18:52 [INFO]   Training abgeschlossen in 13.10s (Backend: cuml)\n",
      "09:19:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:20:01 [INFO]   Training abgeschlossen in 13.43s (Backend: cuml)\n",
      "09:20:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:21:09 [INFO]   Training abgeschlossen in 13.54s (Backend: cuml)\n",
      "09:22:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:22:18 [INFO]   Training abgeschlossen in 13.79s (Backend: cuml)\n",
      "09:23:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:23:26 [INFO]   Training abgeschlossen in 13.97s (Backend: cuml)\n",
      "09:24:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:24:34 [INFO]   Training abgeschlossen in 14.20s (Backend: cuml)\n",
      "09:25:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:25:42 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "09:26:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:26:49 [INFO]   Training abgeschlossen in 14.40s (Backend: cuml)\n",
      "09:27:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:27:56 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "09:28:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:29:03 [INFO]   Training abgeschlossen in 14.76s (Backend: cuml)\n",
      "09:29:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:30:09 [INFO]   Training abgeschlossen in 14.92s (Backend: cuml)\n",
      "09:31:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:31:15 [INFO]   Training abgeschlossen in 15.17s (Backend: cuml)\n",
      "09:32:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:32:21 [INFO]   Training abgeschlossen in 15.52s (Backend: cuml)\n",
      "09:33:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:33:26 [INFO]   Training abgeschlossen in 15.65s (Backend: cuml)\n",
      "09:34:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:34:32 [INFO]   Training abgeschlossen in 16.06s (Backend: cuml)\n",
      "09:35:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:35:37 [INFO]   Training abgeschlossen in 16.00s (Backend: cuml)\n",
      "09:36:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:36:41 [INFO]   Training abgeschlossen in 16.19s (Backend: cuml)\n",
      "09:37:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:37:46 [INFO]   Training abgeschlossen in 16.43s (Backend: cuml)\n",
      "09:38:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:38:50 [INFO]   Training abgeschlossen in 16.70s (Backend: cuml)\n",
      "09:39:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:39:54 [INFO]   Training abgeschlossen in 16.91s (Backend: cuml)\n",
      "09:40:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:40:58 [INFO]   Training abgeschlossen in 17.15s (Backend: cuml)\n",
      "09:41:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:42:01 [INFO]   Training abgeschlossen in 17.36s (Backend: cuml)\n",
      "09:42:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:43:04 [INFO]   Training abgeschlossen in 17.55s (Backend: cuml)\n",
      "09:43:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:44:07 [INFO]   Training abgeschlossen in 17.75s (Backend: cuml)\n",
      "09:44:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:45:09 [INFO]   Training abgeschlossen in 17.99s (Backend: cuml)\n",
      "09:45:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:46:11 [INFO]   Training abgeschlossen in 18.33s (Backend: cuml)\n",
      "09:46:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:47:13 [INFO]   Training abgeschlossen in 18.46s (Backend: cuml)\n",
      "09:47:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:48:15 [INFO]   Training abgeschlossen in 18.60s (Backend: cuml)\n",
      "09:48:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:49:16 [INFO]   Training abgeschlossen in 18.77s (Backend: cuml)\n",
      "09:49:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:50:17 [INFO]   Training abgeschlossen in 19.08s (Backend: cuml)\n",
      "09:50:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:51:18 [INFO]   Training abgeschlossen in 19.46s (Backend: cuml)\n",
      "09:51:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:52:18 [INFO]   Training abgeschlossen in 19.50s (Backend: cuml)\n",
      "09:52:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:53:18 [INFO]   Training abgeschlossen in 19.77s (Backend: cuml)\n",
      "09:53:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:54:18 [INFO]   Training abgeschlossen in 20.06s (Backend: cuml)\n",
      "09:54:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:55:18 [INFO]   Training abgeschlossen in 19.96s (Backend: cuml)\n",
      "09:55:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:56:17 [INFO]   Training abgeschlossen in 20.21s (Backend: cuml)\n",
      "09:56:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:57:15 [INFO]   Training abgeschlossen in 20.40s (Backend: cuml)\n",
      "09:57:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:58:14 [INFO]   Training abgeschlossen in 20.66s (Backend: cuml)\n",
      "09:58:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:59:12 [INFO]   Training abgeschlossen in 20.92s (Backend: cuml)\n",
      "09:59:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:00:10 [INFO]   Training abgeschlossen in 21.05s (Backend: cuml)\n",
      "10:00:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:01:07 [INFO]   Training abgeschlossen in 21.21s (Backend: cuml)\n",
      "10:01:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:02:04 [INFO]   Training abgeschlossen in 21.50s (Backend: cuml)\n",
      "10:02:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:03:01 [INFO]   Training abgeschlossen in 21.73s (Backend: cuml)\n",
      "10:03:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:03:57 [INFO]   Training abgeschlossen in 22.01s (Backend: cuml)\n",
      "10:04:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:04:54 [INFO]   Training abgeschlossen in 22.13s (Backend: cuml)\n",
      "10:05:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:05:49 [INFO]   Training abgeschlossen in 22.28s (Backend: cuml)\n",
      "10:06:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:06:45 [INFO]   Training abgeschlossen in 22.53s (Backend: cuml)\n",
      "10:07:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:07:40 [INFO]   Training abgeschlossen in 22.67s (Backend: cuml)\n",
      "10:08:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:08:35 [INFO]   Training abgeschlossen in 22.99s (Backend: cuml)\n",
      "10:09:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:09:30 [INFO]   Training abgeschlossen in 23.21s (Backend: cuml)\n",
      "10:10:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:10:24 [INFO]   Training abgeschlossen in 23.41s (Backend: cuml)\n",
      "10:10:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:11:18 [INFO]   Training abgeschlossen in 23.64s (Backend: cuml)\n",
      "10:11:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:12:11 [INFO]   Training abgeschlossen in 23.77s (Backend: cuml)\n",
      "10:12:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:13:04 [INFO]   Training abgeschlossen in 23.95s (Backend: cuml)\n",
      "10:13:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:13:57 [INFO]   Training abgeschlossen in 24.16s (Backend: cuml)\n",
      "10:14:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:14:49 [INFO]   Training abgeschlossen in 24.28s (Backend: cuml)\n",
      "10:15:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:15:41 [INFO]   Training abgeschlossen in 24.41s (Backend: cuml)\n",
      "10:16:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:16:32 [INFO]   Training abgeschlossen in 24.57s (Backend: cuml)\n",
      "10:16:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:17:24 [INFO]   Training abgeschlossen in 24.80s (Backend: cuml)\n",
      "10:17:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:18:15 [INFO]   Training abgeschlossen in 24.91s (Backend: cuml)\n",
      "10:18:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:19:05 [INFO]   Training abgeschlossen in 25.08s (Backend: cuml)\n",
      "10:19:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:19:55 [INFO]   Training abgeschlossen in 25.34s (Backend: cuml)\n",
      "10:20:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:20:44 [INFO]   Training abgeschlossen in 25.60s (Backend: cuml)\n",
      "10:21:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:21:46 [INFO]   Training abgeschlossen in 37.77s (Backend: cuml)\n",
      "10:22:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:22:48 [INFO]   Training abgeschlossen in 39.79s (Backend: cuml)\n",
      "10:23:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:23:49 [INFO]   Training abgeschlossen in 38.46s (Backend: cuml)\n",
      "10:24:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:24:49 [INFO]   Training abgeschlossen in 38.06s (Backend: cuml)\n",
      "10:25:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:25:49 [INFO]   Training abgeschlossen in 38.34s (Backend: cuml)\n",
      "10:26:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:26:49 [INFO]   Training abgeschlossen in 40.18s (Backend: cuml)\n",
      "10:27:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:27:51 [INFO]   Training abgeschlossen in 41.67s (Backend: cuml)\n",
      "10:28:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:28:52 [INFO]   Training abgeschlossen in 40.99s (Backend: cuml)\n",
      "10:29:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:29:50 [INFO]   Training abgeschlossen in 39.40s (Backend: cuml)\n",
      "10:30:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:30:50 [INFO]   Training abgeschlossen in 41.05s (Backend: cuml)\n",
      "10:31:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:31:48 [INFO]   Training abgeschlossen in 40.15s (Backend: cuml)\n",
      "10:32:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:32:46 [INFO]   Training abgeschlossen in 40.74s (Backend: cuml)\n",
      "10:33:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:33:44 [INFO]   Training abgeschlossen in 40.98s (Backend: cuml)\n",
      "10:34:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:34:41 [INFO]   Training abgeschlossen in 41.18s (Backend: cuml)\n",
      "10:34:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:35:38 [INFO]   Training abgeschlossen in 41.10s (Backend: cuml)\n",
      "10:35:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:36:35 [INFO]   Training abgeschlossen in 41.61s (Backend: cuml)\n",
      "10:36:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:37:31 [INFO]   Training abgeschlossen in 41.07s (Backend: cuml)\n",
      "10:37:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:38:27 [INFO]   Training abgeschlossen in 42.03s (Backend: cuml)\n",
      "10:38:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:39:23 [INFO]   Training abgeschlossen in 42.17s (Backend: cuml)\n",
      "10:39:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:40:18 [INFO]   Training abgeschlossen in 42.13s (Backend: cuml)\n",
      "10:40:30 [INFO]     60,000 labeled → Accuracy: 0.8852 (Train: 42.2s, Query: 0.67s) | GPU: 2.8/8.0 GB\n",
      "10:40:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:41:11 [INFO]   Training abgeschlossen in 41.26s (Backend: cuml)\n",
      "10:41:23 [INFO]     Final: 60,000 labeled → Accuracy: 0.8852, F1: 0.8843\n",
      "10:41:23 [INFO]   Run 2/5\n",
      "10:41:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:41:28 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "10:42:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:42:40 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "10:43:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:43:51 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "10:44:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:45:03 [INFO]   Training abgeschlossen in 5.20s (Backend: cuml)\n",
      "10:46:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:46:15 [INFO]   Training abgeschlossen in 5.50s (Backend: cuml)\n",
      "10:47:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:47:26 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "10:48:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:48:39 [INFO]   Training abgeschlossen in 6.01s (Backend: cuml)\n",
      "10:49:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:49:51 [INFO]   Training abgeschlossen in 6.24s (Backend: cuml)\n",
      "10:50:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:51:03 [INFO]   Training abgeschlossen in 6.72s (Backend: cuml)\n",
      "10:52:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:52:16 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "10:53:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:53:28 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "10:54:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:54:41 [INFO]   Training abgeschlossen in 7.49s (Backend: cuml)\n",
      "10:55:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:55:53 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "10:56:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:57:05 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "10:58:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:58:18 [INFO]   Training abgeschlossen in 8.38s (Backend: cuml)\n",
      "10:59:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:59:30 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "11:00:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:00:42 [INFO]   Training abgeschlossen in 8.67s (Backend: cuml)\n",
      "11:01:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:01:55 [INFO]   Training abgeschlossen in 8.98s (Backend: cuml)\n",
      "11:02:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:03:07 [INFO]   Training abgeschlossen in 9.31s (Backend: cuml)\n",
      "11:04:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:04:20 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "11:05:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "11:05:32 [INFO]   Training abgeschlossen in 9.64s (Backend: cuml)\n",
      "11:06:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:06:43 [INFO]   Training abgeschlossen in 9.89s (Backend: cuml)\n",
      "11:07:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:07:56 [INFO]   Training abgeschlossen in 10.10s (Backend: cuml)\n",
      "11:08:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:09:07 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "11:10:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:10:19 [INFO]   Training abgeschlossen in 10.48s (Backend: cuml)\n",
      "11:11:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:11:31 [INFO]   Training abgeschlossen in 10.87s (Backend: cuml)\n",
      "11:12:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:12:43 [INFO]   Training abgeschlossen in 11.10s (Backend: cuml)\n",
      "11:13:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:13:55 [INFO]   Training abgeschlossen in 11.20s (Backend: cuml)\n",
      "11:14:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:15:07 [INFO]   Training abgeschlossen in 11.35s (Backend: cuml)\n",
      "11:16:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:16:19 [INFO]   Training abgeschlossen in 11.64s (Backend: cuml)\n",
      "11:17:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:17:30 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "11:18:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:18:41 [INFO]   Training abgeschlossen in 12.03s (Backend: cuml)\n",
      "11:19:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:19:52 [INFO]   Training abgeschlossen in 12.29s (Backend: cuml)\n",
      "11:20:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:21:03 [INFO]   Training abgeschlossen in 12.64s (Backend: cuml)\n",
      "11:22:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:22:14 [INFO]   Training abgeschlossen in 12.75s (Backend: cuml)\n",
      "11:23:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:23:24 [INFO]   Training abgeschlossen in 12.93s (Backend: cuml)\n",
      "11:24:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:24:33 [INFO]   Training abgeschlossen in 13.13s (Backend: cuml)\n",
      "11:25:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:25:42 [INFO]   Training abgeschlossen in 13.51s (Backend: cuml)\n",
      "11:26:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:26:51 [INFO]   Training abgeschlossen in 13.62s (Backend: cuml)\n",
      "11:27:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:27:59 [INFO]   Training abgeschlossen in 13.80s (Backend: cuml)\n",
      "11:28:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:29:08 [INFO]   Training abgeschlossen in 13.94s (Backend: cuml)\n",
      "11:30:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:30:16 [INFO]   Training abgeschlossen in 14.27s (Backend: cuml)\n",
      "11:31:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:31:24 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "11:32:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:32:32 [INFO]   Training abgeschlossen in 14.44s (Backend: cuml)\n",
      "11:33:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:33:39 [INFO]   Training abgeschlossen in 14.57s (Backend: cuml)\n",
      "11:34:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:34:46 [INFO]   Training abgeschlossen in 14.77s (Backend: cuml)\n",
      "11:35:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:35:52 [INFO]   Training abgeschlossen in 14.94s (Backend: cuml)\n",
      "11:36:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:36:58 [INFO]   Training abgeschlossen in 15.37s (Backend: cuml)\n",
      "11:37:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:38:04 [INFO]   Training abgeschlossen in 15.67s (Backend: cuml)\n",
      "11:38:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:39:10 [INFO]   Training abgeschlossen in 15.67s (Backend: cuml)\n",
      "11:40:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:40:16 [INFO]   Training abgeschlossen in 16.08s (Backend: cuml)\n",
      "11:41:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:41:21 [INFO]   Training abgeschlossen in 16.04s (Backend: cuml)\n",
      "11:42:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:42:26 [INFO]   Training abgeschlossen in 16.16s (Backend: cuml)\n",
      "11:43:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:43:31 [INFO]   Training abgeschlossen in 16.57s (Backend: cuml)\n",
      "11:44:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:44:35 [INFO]   Training abgeschlossen in 16.74s (Backend: cuml)\n",
      "11:45:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:45:39 [INFO]   Training abgeschlossen in 17.05s (Backend: cuml)\n",
      "11:46:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:46:43 [INFO]   Training abgeschlossen in 17.06s (Backend: cuml)\n",
      "11:47:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:47:47 [INFO]   Training abgeschlossen in 17.36s (Backend: cuml)\n",
      "11:48:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:48:50 [INFO]   Training abgeschlossen in 17.51s (Backend: cuml)\n",
      "11:49:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:49:52 [INFO]   Training abgeschlossen in 17.77s (Backend: cuml)\n",
      "11:50:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:50:55 [INFO]   Training abgeschlossen in 17.96s (Backend: cuml)\n",
      "11:51:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:51:57 [INFO]   Training abgeschlossen in 18.24s (Backend: cuml)\n",
      "11:52:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:52:59 [INFO]   Training abgeschlossen in 18.50s (Backend: cuml)\n",
      "11:53:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:54:01 [INFO]   Training abgeschlossen in 18.75s (Backend: cuml)\n",
      "11:54:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:55:02 [INFO]   Training abgeschlossen in 19.01s (Backend: cuml)\n",
      "11:55:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:56:03 [INFO]   Training abgeschlossen in 19.08s (Backend: cuml)\n",
      "11:56:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:57:04 [INFO]   Training abgeschlossen in 19.35s (Backend: cuml)\n",
      "11:57:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:58:04 [INFO]   Training abgeschlossen in 19.51s (Backend: cuml)\n",
      "11:58:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:59:04 [INFO]   Training abgeschlossen in 19.61s (Backend: cuml)\n",
      "11:59:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:00:04 [INFO]   Training abgeschlossen in 19.87s (Backend: cuml)\n",
      "12:00:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:01:03 [INFO]   Training abgeschlossen in 20.06s (Backend: cuml)\n",
      "12:01:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:02:02 [INFO]   Training abgeschlossen in 20.22s (Backend: cuml)\n",
      "12:02:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:03:01 [INFO]   Training abgeschlossen in 20.52s (Backend: cuml)\n",
      "12:03:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:03:59 [INFO]   Training abgeschlossen in 20.69s (Backend: cuml)\n",
      "12:04:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:04:57 [INFO]   Training abgeschlossen in 20.95s (Backend: cuml)\n",
      "12:05:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:05:55 [INFO]   Training abgeschlossen in 21.09s (Backend: cuml)\n",
      "12:06:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:06:52 [INFO]   Training abgeschlossen in 21.30s (Backend: cuml)\n",
      "12:07:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:07:49 [INFO]   Training abgeschlossen in 21.42s (Backend: cuml)\n",
      "12:08:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:08:46 [INFO]   Training abgeschlossen in 21.62s (Backend: cuml)\n",
      "12:09:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "12:09:42 [INFO]   Training abgeschlossen in 21.92s (Backend: cuml)\n",
      "12:10:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:10:39 [INFO]   Training abgeschlossen in 22.18s (Backend: cuml)\n",
      "12:11:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:11:35 [INFO]   Training abgeschlossen in 22.27s (Backend: cuml)\n",
      "12:12:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:12:30 [INFO]   Training abgeschlossen in 22.53s (Backend: cuml)\n",
      "12:13:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:13:25 [INFO]   Training abgeschlossen in 22.64s (Backend: cuml)\n",
      "12:13:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:14:20 [INFO]   Training abgeschlossen in 22.85s (Backend: cuml)\n",
      "12:14:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:15:15 [INFO]   Training abgeschlossen in 23.20s (Backend: cuml)\n",
      "12:15:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:16:09 [INFO]   Training abgeschlossen in 23.30s (Backend: cuml)\n",
      "12:16:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:17:03 [INFO]   Training abgeschlossen in 23.53s (Backend: cuml)\n",
      "12:17:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:17:56 [INFO]   Training abgeschlossen in 23.66s (Backend: cuml)\n",
      "12:18:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:18:49 [INFO]   Training abgeschlossen in 23.82s (Backend: cuml)\n",
      "12:19:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:19:42 [INFO]   Training abgeschlossen in 24.14s (Backend: cuml)\n",
      "12:20:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:20:35 [INFO]   Training abgeschlossen in 24.40s (Backend: cuml)\n",
      "12:21:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:21:27 [INFO]   Training abgeschlossen in 24.55s (Backend: cuml)\n",
      "12:21:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:22:18 [INFO]   Training abgeschlossen in 24.59s (Backend: cuml)\n",
      "12:22:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:23:09 [INFO]   Training abgeschlossen in 24.78s (Backend: cuml)\n",
      "12:23:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:24:00 [INFO]   Training abgeschlossen in 25.01s (Backend: cuml)\n",
      "12:24:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:24:50 [INFO]   Training abgeschlossen in 25.16s (Backend: cuml)\n",
      "12:25:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:25:40 [INFO]   Training abgeschlossen in 25.33s (Backend: cuml)\n",
      "12:26:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:26:30 [INFO]   Training abgeschlossen in 25.62s (Backend: cuml)\n",
      "12:26:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:27:33 [INFO]   Training abgeschlossen in 38.84s (Backend: cuml)\n",
      "12:27:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:28:34 [INFO]   Training abgeschlossen in 38.63s (Backend: cuml)\n",
      "12:28:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:29:36 [INFO]   Training abgeschlossen in 39.21s (Backend: cuml)\n",
      "12:29:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:30:38 [INFO]   Training abgeschlossen in 39.93s (Backend: cuml)\n",
      "12:30:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:31:40 [INFO]   Training abgeschlossen in 41.00s (Backend: cuml)\n",
      "12:32:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:32:40 [INFO]   Training abgeschlossen in 39.23s (Backend: cuml)\n",
      "12:33:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:33:39 [INFO]   Training abgeschlossen in 39.32s (Backend: cuml)\n",
      "12:33:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:34:41 [INFO]   Training abgeschlossen in 41.97s (Backend: cuml)\n",
      "12:35:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:35:40 [INFO]   Training abgeschlossen in 39.91s (Backend: cuml)\n",
      "12:35:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:36:37 [INFO]   Training abgeschlossen in 39.02s (Backend: cuml)\n",
      "12:36:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:37:34 [INFO]   Training abgeschlossen in 38.40s (Backend: cuml)\n",
      "12:37:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:38:31 [INFO]   Training abgeschlossen in 40.02s (Backend: cuml)\n",
      "12:38:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:39:27 [INFO]   Training abgeschlossen in 39.68s (Backend: cuml)\n",
      "12:39:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:40:25 [INFO]   Training abgeschlossen in 41.03s (Backend: cuml)\n",
      "12:40:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:41:23 [INFO]   Training abgeschlossen in 42.20s (Backend: cuml)\n",
      "12:41:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:42:21 [INFO]   Training abgeschlossen in 42.64s (Backend: cuml)\n",
      "12:42:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:43:16 [INFO]   Training abgeschlossen in 40.54s (Backend: cuml)\n",
      "12:43:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:44:13 [INFO]   Training abgeschlossen in 43.16s (Backend: cuml)\n",
      "12:44:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:45:11 [INFO]   Training abgeschlossen in 43.88s (Backend: cuml)\n",
      "12:45:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:46:05 [INFO]   Training abgeschlossen in 40.99s (Backend: cuml)\n",
      "12:46:17 [INFO]     60,000 labeled → Accuracy: 0.8849 (Train: 41.0s, Query: 0.65s) | GPU: 2.8/8.0 GB\n",
      "12:46:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:46:59 [INFO]   Training abgeschlossen in 41.81s (Backend: cuml)\n",
      "12:47:11 [INFO]     Final: 60,000 labeled → Accuracy: 0.8845, F1: 0.8836\n",
      "12:47:11 [INFO]   Run 3/5\n",
      "12:47:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:47:16 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "12:48:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:48:27 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "12:49:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:49:39 [INFO]   Training abgeschlossen in 5.00s (Backend: cuml)\n",
      "12:50:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:50:51 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "12:51:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:52:02 [INFO]   Training abgeschlossen in 5.53s (Backend: cuml)\n",
      "12:53:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:53:14 [INFO]   Training abgeschlossen in 5.63s (Backend: cuml)\n",
      "12:54:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:54:26 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "12:55:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:55:38 [INFO]   Training abgeschlossen in 6.33s (Backend: cuml)\n",
      "12:56:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:56:50 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "12:57:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:58:02 [INFO]   Training abgeschlossen in 6.99s (Backend: cuml)\n",
      "12:59:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:59:15 [INFO]   Training abgeschlossen in 7.52s (Backend: cuml)\n",
      "13:00:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:00:27 [INFO]   Training abgeschlossen in 7.47s (Backend: cuml)\n",
      "13:01:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:01:39 [INFO]   Training abgeschlossen in 7.75s (Backend: cuml)\n",
      "13:02:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:02:51 [INFO]   Training abgeschlossen in 7.95s (Backend: cuml)\n",
      "13:03:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "13:04:04 [INFO]   Training abgeschlossen in 8.14s (Backend: cuml)\n",
      "13:05:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:05:16 [INFO]   Training abgeschlossen in 8.42s (Backend: cuml)\n",
      "13:06:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:06:27 [INFO]   Training abgeschlossen in 8.66s (Backend: cuml)\n",
      "13:07:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:07:40 [INFO]   Training abgeschlossen in 9.06s (Backend: cuml)\n",
      "13:08:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:08:51 [INFO]   Training abgeschlossen in 9.15s (Backend: cuml)\n",
      "13:09:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:10:04 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "13:11:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "13:11:16 [INFO]   Training abgeschlossen in 9.71s (Backend: cuml)\n",
      "13:12:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:12:27 [INFO]   Training abgeschlossen in 9.81s (Backend: cuml)\n",
      "13:13:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:13:39 [INFO]   Training abgeschlossen in 10.01s (Backend: cuml)\n",
      "13:14:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:14:51 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "13:15:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:16:02 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "13:17:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:17:13 [INFO]   Training abgeschlossen in 10.68s (Backend: cuml)\n",
      "13:18:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:18:25 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "13:19:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:19:36 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "13:20:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:20:47 [INFO]   Training abgeschlossen in 11.47s (Backend: cuml)\n",
      "13:21:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "13:21:59 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "13:22:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:23:11 [INFO]   Training abgeschlossen in 11.88s (Backend: cuml)\n",
      "13:24:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:24:22 [INFO]   Training abgeschlossen in 12.00s (Backend: cuml)\n",
      "13:25:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:25:33 [INFO]   Training abgeschlossen in 12.45s (Backend: cuml)\n",
      "13:26:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:26:44 [INFO]   Training abgeschlossen in 12.66s (Backend: cuml)\n",
      "13:27:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:27:55 [INFO]   Training abgeschlossen in 12.71s (Backend: cuml)\n",
      "13:28:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:29:04 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "13:30:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:30:13 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "13:31:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:31:22 [INFO]   Training abgeschlossen in 13.36s (Backend: cuml)\n",
      "13:32:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:32:31 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "13:33:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:33:39 [INFO]   Training abgeschlossen in 13.71s (Backend: cuml)\n",
      "13:34:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:34:47 [INFO]   Training abgeschlossen in 13.93s (Backend: cuml)\n",
      "13:35:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:35:55 [INFO]   Training abgeschlossen in 14.14s (Backend: cuml)\n",
      "13:36:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:37:03 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "13:37:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:38:10 [INFO]   Training abgeschlossen in 14.22s (Backend: cuml)\n",
      "13:39:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:39:17 [INFO]   Training abgeschlossen in 14.51s (Backend: cuml)\n",
      "13:40:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:40:23 [INFO]   Training abgeschlossen in 14.71s (Backend: cuml)\n",
      "13:41:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:41:30 [INFO]   Training abgeschlossen in 14.99s (Backend: cuml)\n",
      "13:42:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:42:35 [INFO]   Training abgeschlossen in 15.15s (Backend: cuml)\n",
      "13:43:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:43:41 [INFO]   Training abgeschlossen in 15.31s (Backend: cuml)\n",
      "13:44:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:44:47 [INFO]   Training abgeschlossen in 15.63s (Backend: cuml)\n",
      "13:45:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:45:53 [INFO]   Training abgeschlossen in 16.13s (Backend: cuml)\n",
      "13:46:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:46:58 [INFO]   Training abgeschlossen in 16.16s (Backend: cuml)\n",
      "13:47:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:48:03 [INFO]   Training abgeschlossen in 16.25s (Backend: cuml)\n",
      "13:48:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:49:07 [INFO]   Training abgeschlossen in 16.45s (Backend: cuml)\n",
      "13:49:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:50:11 [INFO]   Training abgeschlossen in 16.59s (Backend: cuml)\n",
      "13:50:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:51:15 [INFO]   Training abgeschlossen in 16.80s (Backend: cuml)\n",
      "13:52:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:52:18 [INFO]   Training abgeschlossen in 16.93s (Backend: cuml)\n",
      "13:53:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:53:22 [INFO]   Training abgeschlossen in 17.29s (Backend: cuml)\n",
      "13:54:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:54:25 [INFO]   Training abgeschlossen in 17.52s (Backend: cuml)\n",
      "13:55:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:55:28 [INFO]   Training abgeschlossen in 17.76s (Backend: cuml)\n",
      "13:56:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:56:30 [INFO]   Training abgeschlossen in 18.06s (Backend: cuml)\n",
      "13:57:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:57:32 [INFO]   Training abgeschlossen in 18.21s (Backend: cuml)\n",
      "13:58:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:58:34 [INFO]   Training abgeschlossen in 18.51s (Backend: cuml)\n",
      "13:59:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:59:36 [INFO]   Training abgeschlossen in 18.63s (Backend: cuml)\n",
      "14:00:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:00:37 [INFO]   Training abgeschlossen in 18.81s (Backend: cuml)\n",
      "14:01:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:01:38 [INFO]   Training abgeschlossen in 18.98s (Backend: cuml)\n",
      "14:02:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:02:38 [INFO]   Training abgeschlossen in 19.26s (Backend: cuml)\n",
      "14:03:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:03:39 [INFO]   Training abgeschlossen in 19.53s (Backend: cuml)\n",
      "14:04:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:04:39 [INFO]   Training abgeschlossen in 19.68s (Backend: cuml)\n",
      "14:05:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:05:39 [INFO]   Training abgeschlossen in 19.90s (Backend: cuml)\n",
      "14:06:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:06:38 [INFO]   Training abgeschlossen in 20.10s (Backend: cuml)\n",
      "14:07:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:07:37 [INFO]   Training abgeschlossen in 20.26s (Backend: cuml)\n",
      "14:08:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:08:36 [INFO]   Training abgeschlossen in 20.55s (Backend: cuml)\n",
      "14:09:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:09:34 [INFO]   Training abgeschlossen in 20.69s (Backend: cuml)\n",
      "14:10:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:10:33 [INFO]   Training abgeschlossen in 21.02s (Backend: cuml)\n",
      "14:11:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:11:31 [INFO]   Training abgeschlossen in 21.18s (Backend: cuml)\n",
      "14:12:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:12:28 [INFO]   Training abgeschlossen in 21.38s (Backend: cuml)\n",
      "14:13:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:13:26 [INFO]   Training abgeschlossen in 21.53s (Backend: cuml)\n",
      "14:14:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:14:23 [INFO]   Training abgeschlossen in 21.79s (Backend: cuml)\n",
      "14:14:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:15:19 [INFO]   Training abgeschlossen in 22.05s (Backend: cuml)\n",
      "14:15:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:16:16 [INFO]   Training abgeschlossen in 22.30s (Backend: cuml)\n",
      "14:16:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:17:12 [INFO]   Training abgeschlossen in 22.44s (Backend: cuml)\n",
      "14:17:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:18:07 [INFO]   Training abgeschlossen in 22.59s (Backend: cuml)\n",
      "14:18:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:19:03 [INFO]   Training abgeschlossen in 22.78s (Backend: cuml)\n",
      "14:19:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:19:57 [INFO]   Training abgeschlossen in 22.89s (Backend: cuml)\n",
      "14:20:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:20:52 [INFO]   Training abgeschlossen in 23.08s (Backend: cuml)\n",
      "14:21:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:21:46 [INFO]   Training abgeschlossen in 23.24s (Backend: cuml)\n",
      "14:22:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:22:40 [INFO]   Training abgeschlossen in 23.58s (Backend: cuml)\n",
      "14:23:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:23:33 [INFO]   Training abgeschlossen in 23.69s (Backend: cuml)\n",
      "14:24:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:24:27 [INFO]   Training abgeschlossen in 23.96s (Backend: cuml)\n",
      "14:24:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:25:20 [INFO]   Training abgeschlossen in 24.13s (Backend: cuml)\n",
      "14:25:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:26:12 [INFO]   Training abgeschlossen in 24.40s (Backend: cuml)\n",
      "14:26:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:27:04 [INFO]   Training abgeschlossen in 24.51s (Backend: cuml)\n",
      "14:27:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:27:56 [INFO]   Training abgeschlossen in 24.82s (Backend: cuml)\n",
      "14:28:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:28:48 [INFO]   Training abgeschlossen in 25.07s (Backend: cuml)\n",
      "14:29:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:29:39 [INFO]   Training abgeschlossen in 25.07s (Backend: cuml)\n",
      "14:30:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:30:29 [INFO]   Training abgeschlossen in 25.34s (Backend: cuml)\n",
      "14:30:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:31:19 [INFO]   Training abgeschlossen in 25.40s (Backend: cuml)\n",
      "14:31:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:32:09 [INFO]   Training abgeschlossen in 25.75s (Backend: cuml)\n",
      "14:32:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:33:12 [INFO]   Training abgeschlossen in 39.45s (Backend: cuml)\n",
      "14:33:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:34:14 [INFO]   Training abgeschlossen in 39.30s (Backend: cuml)\n",
      "14:34:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:35:15 [INFO]   Training abgeschlossen in 38.68s (Backend: cuml)\n",
      "14:35:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:36:15 [INFO]   Training abgeschlossen in 37.96s (Backend: cuml)\n",
      "14:36:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:37:15 [INFO]   Training abgeschlossen in 38.12s (Backend: cuml)\n",
      "14:37:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:38:14 [INFO]   Training abgeschlossen in 39.22s (Backend: cuml)\n",
      "14:38:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:39:15 [INFO]   Training abgeschlossen in 40.19s (Backend: cuml)\n",
      "14:39:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:40:14 [INFO]   Training abgeschlossen in 39.80s (Backend: cuml)\n",
      "14:40:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:41:14 [INFO]   Training abgeschlossen in 40.48s (Backend: cuml)\n",
      "14:41:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:42:13 [INFO]   Training abgeschlossen in 40.60s (Backend: cuml)\n",
      "14:42:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:43:12 [INFO]   Training abgeschlossen in 41.20s (Backend: cuml)\n",
      "14:43:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:44:10 [INFO]   Training abgeschlossen in 40.74s (Backend: cuml)\n",
      "14:44:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:45:09 [INFO]   Training abgeschlossen in 41.56s (Backend: cuml)\n",
      "14:45:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:46:06 [INFO]   Training abgeschlossen in 40.88s (Backend: cuml)\n",
      "14:46:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:47:05 [INFO]   Training abgeschlossen in 43.05s (Backend: cuml)\n",
      "14:47:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:48:01 [INFO]   Training abgeschlossen in 41.22s (Backend: cuml)\n",
      "14:48:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:49:00 [INFO]   Training abgeschlossen in 43.94s (Backend: cuml)\n",
      "14:49:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:49:58 [INFO]   Training abgeschlossen in 43.67s (Backend: cuml)\n",
      "14:50:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:50:54 [INFO]   Training abgeschlossen in 42.83s (Backend: cuml)\n",
      "14:51:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:51:49 [INFO]   Training abgeschlossen in 41.85s (Backend: cuml)\n",
      "14:52:01 [INFO]     60,000 labeled → Accuracy: 0.8843 (Train: 41.9s, Query: 0.65s) | GPU: 2.8/8.0 GB\n",
      "14:52:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:52:44 [INFO]   Training abgeschlossen in 42.65s (Backend: cuml)\n",
      "14:52:55 [INFO]     Final: 60,000 labeled → Accuracy: 0.8846, F1: 0.8837\n",
      "14:52:56 [INFO]   Run 4/5\n",
      "14:52:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "14:53:01 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "14:54:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:54:12 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "14:55:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:55:24 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "14:56:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "14:56:36 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "14:57:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:57:47 [INFO]   Training abgeschlossen in 5.54s (Backend: cuml)\n",
      "14:58:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:58:59 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "15:00:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:00:11 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "15:01:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:01:23 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "15:02:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:02:35 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "15:03:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:03:47 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "15:04:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:04:59 [INFO]   Training abgeschlossen in 7.34s (Backend: cuml)\n",
      "15:06:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:06:12 [INFO]   Training abgeschlossen in 7.43s (Backend: cuml)\n",
      "15:07:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:07:25 [INFO]   Training abgeschlossen in 7.93s (Backend: cuml)\n",
      "15:08:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:08:38 [INFO]   Training abgeschlossen in 8.01s (Backend: cuml)\n",
      "15:09:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:09:51 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "15:10:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:11:03 [INFO]   Training abgeschlossen in 8.68s (Backend: cuml)\n",
      "15:12:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:12:16 [INFO]   Training abgeschlossen in 8.81s (Backend: cuml)\n",
      "15:13:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:13:28 [INFO]   Training abgeschlossen in 8.96s (Backend: cuml)\n",
      "15:14:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:14:41 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "15:15:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:15:53 [INFO]   Training abgeschlossen in 9.48s (Backend: cuml)\n",
      "15:16:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:17:05 [INFO]   Training abgeschlossen in 9.70s (Backend: cuml)\n",
      "15:18:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:18:17 [INFO]   Training abgeschlossen in 9.98s (Backend: cuml)\n",
      "15:19:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:19:29 [INFO]   Training abgeschlossen in 10.15s (Backend: cuml)\n",
      "15:20:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:20:41 [INFO]   Training abgeschlossen in 10.44s (Backend: cuml)\n",
      "15:21:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:21:52 [INFO]   Training abgeschlossen in 10.46s (Backend: cuml)\n",
      "15:22:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:23:04 [INFO]   Training abgeschlossen in 10.75s (Backend: cuml)\n",
      "15:24:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:24:15 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "15:25:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:25:27 [INFO]   Training abgeschlossen in 11.21s (Backend: cuml)\n",
      "15:26:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "15:26:39 [INFO]   Training abgeschlossen in 11.38s (Backend: cuml)\n",
      "15:27:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:27:51 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "15:28:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:29:02 [INFO]   Training abgeschlossen in 11.77s (Backend: cuml)\n",
      "15:30:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:30:13 [INFO]   Training abgeschlossen in 12.02s (Backend: cuml)\n",
      "15:31:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:31:24 [INFO]   Training abgeschlossen in 12.23s (Backend: cuml)\n",
      "15:32:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:32:35 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "15:33:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:33:46 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "15:34:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:34:55 [INFO]   Training abgeschlossen in 12.92s (Backend: cuml)\n",
      "15:35:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:36:04 [INFO]   Training abgeschlossen in 13.10s (Backend: cuml)\n",
      "15:37:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:37:13 [INFO]   Training abgeschlossen in 13.35s (Backend: cuml)\n",
      "15:38:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:38:22 [INFO]   Training abgeschlossen in 13.56s (Backend: cuml)\n",
      "15:39:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:39:30 [INFO]   Training abgeschlossen in 13.77s (Backend: cuml)\n",
      "15:40:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:40:38 [INFO]   Training abgeschlossen in 13.98s (Backend: cuml)\n",
      "15:41:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:41:46 [INFO]   Training abgeschlossen in 14.15s (Backend: cuml)\n",
      "15:42:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:42:54 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "15:43:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:44:01 [INFO]   Training abgeschlossen in 14.44s (Backend: cuml)\n",
      "15:44:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:45:08 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "15:46:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "15:46:14 [INFO]   Training abgeschlossen in 14.69s (Backend: cuml)\n",
      "15:47:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:47:21 [INFO]   Training abgeschlossen in 14.98s (Backend: cuml)\n",
      "15:48:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:48:27 [INFO]   Training abgeschlossen in 15.13s (Backend: cuml)\n",
      "15:49:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:49:33 [INFO]   Training abgeschlossen in 15.34s (Backend: cuml)\n",
      "15:50:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:50:38 [INFO]   Training abgeschlossen in 15.75s (Backend: cuml)\n",
      "15:51:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:51:44 [INFO]   Training abgeschlossen in 16.16s (Backend: cuml)\n",
      "15:52:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:52:49 [INFO]   Training abgeschlossen in 16.12s (Backend: cuml)\n",
      "15:53:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:53:53 [INFO]   Training abgeschlossen in 16.20s (Backend: cuml)\n",
      "15:54:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:54:57 [INFO]   Training abgeschlossen in 16.51s (Backend: cuml)\n",
      "15:55:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:56:01 [INFO]   Training abgeschlossen in 16.62s (Backend: cuml)\n",
      "15:56:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:57:05 [INFO]   Training abgeschlossen in 16.85s (Backend: cuml)\n",
      "15:57:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:58:09 [INFO]   Training abgeschlossen in 17.28s (Backend: cuml)\n",
      "15:58:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:59:12 [INFO]   Training abgeschlossen in 17.41s (Backend: cuml)\n",
      "15:59:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:00:15 [INFO]   Training abgeschlossen in 17.75s (Backend: cuml)\n",
      "16:01:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:01:18 [INFO]   Training abgeschlossen in 17.83s (Backend: cuml)\n",
      "16:02:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:02:20 [INFO]   Training abgeschlossen in 17.93s (Backend: cuml)\n",
      "16:03:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:03:21 [INFO]   Training abgeschlossen in 18.10s (Backend: cuml)\n",
      "16:04:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:04:23 [INFO]   Training abgeschlossen in 18.35s (Backend: cuml)\n",
      "16:05:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:05:24 [INFO]   Training abgeschlossen in 18.56s (Backend: cuml)\n",
      "16:06:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:06:25 [INFO]   Training abgeschlossen in 18.71s (Backend: cuml)\n",
      "16:07:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:07:26 [INFO]   Training abgeschlossen in 18.95s (Backend: cuml)\n",
      "16:08:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:08:27 [INFO]   Training abgeschlossen in 19.26s (Backend: cuml)\n",
      "16:09:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:09:27 [INFO]   Training abgeschlossen in 19.46s (Backend: cuml)\n",
      "16:10:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:10:27 [INFO]   Training abgeschlossen in 19.74s (Backend: cuml)\n",
      "16:11:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:11:27 [INFO]   Training abgeschlossen in 19.89s (Backend: cuml)\n",
      "16:12:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:12:26 [INFO]   Training abgeschlossen in 20.04s (Backend: cuml)\n",
      "16:13:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:13:25 [INFO]   Training abgeschlossen in 20.33s (Backend: cuml)\n",
      "16:14:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:14:24 [INFO]   Training abgeschlossen in 20.42s (Backend: cuml)\n",
      "16:15:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:15:22 [INFO]   Training abgeschlossen in 20.81s (Backend: cuml)\n",
      "16:15:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:16:20 [INFO]   Training abgeschlossen in 21.10s (Backend: cuml)\n",
      "16:16:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:17:18 [INFO]   Training abgeschlossen in 21.21s (Backend: cuml)\n",
      "16:17:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:18:15 [INFO]   Training abgeschlossen in 21.34s (Backend: cuml)\n",
      "16:18:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:19:13 [INFO]   Training abgeschlossen in 21.67s (Backend: cuml)\n",
      "16:19:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:20:10 [INFO]   Training abgeschlossen in 21.93s (Backend: cuml)\n",
      "16:20:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:21:06 [INFO]   Training abgeschlossen in 22.04s (Backend: cuml)\n",
      "16:21:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:22:03 [INFO]   Training abgeschlossen in 22.42s (Backend: cuml)\n",
      "16:22:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:22:59 [INFO]   Training abgeschlossen in 22.39s (Backend: cuml)\n",
      "16:23:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:23:54 [INFO]   Training abgeschlossen in 22.74s (Backend: cuml)\n",
      "16:24:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:24:49 [INFO]   Training abgeschlossen in 22.72s (Backend: cuml)\n",
      "16:25:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:25:44 [INFO]   Training abgeschlossen in 22.90s (Backend: cuml)\n",
      "16:26:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:26:39 [INFO]   Training abgeschlossen in 23.16s (Backend: cuml)\n",
      "16:27:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:27:33 [INFO]   Training abgeschlossen in 23.35s (Backend: cuml)\n",
      "16:28:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:28:27 [INFO]   Training abgeschlossen in 23.49s (Backend: cuml)\n",
      "16:28:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:29:20 [INFO]   Training abgeschlossen in 23.65s (Backend: cuml)\n",
      "16:29:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:30:13 [INFO]   Training abgeschlossen in 23.79s (Backend: cuml)\n",
      "16:30:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:31:05 [INFO]   Training abgeschlossen in 24.04s (Backend: cuml)\n",
      "16:31:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:31:58 [INFO]   Training abgeschlossen in 24.12s (Backend: cuml)\n",
      "16:32:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:32:49 [INFO]   Training abgeschlossen in 24.32s (Backend: cuml)\n",
      "16:33:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:33:41 [INFO]   Training abgeschlossen in 24.50s (Backend: cuml)\n",
      "16:34:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:34:32 [INFO]   Training abgeschlossen in 24.80s (Backend: cuml)\n",
      "16:34:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:35:22 [INFO]   Training abgeschlossen in 25.02s (Backend: cuml)\n",
      "16:35:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:36:13 [INFO]   Training abgeschlossen in 25.42s (Backend: cuml)\n",
      "16:36:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:37:03 [INFO]   Training abgeschlossen in 25.56s (Backend: cuml)\n",
      "16:37:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:37:53 [INFO]   Training abgeschlossen in 25.78s (Backend: cuml)\n",
      "16:38:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:38:55 [INFO]   Training abgeschlossen in 38.59s (Backend: cuml)\n",
      "16:39:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:39:56 [INFO]   Training abgeschlossen in 38.33s (Backend: cuml)\n",
      "16:40:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:40:58 [INFO]   Training abgeschlossen in 39.16s (Backend: cuml)\n",
      "16:41:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:41:59 [INFO]   Training abgeschlossen in 39.44s (Backend: cuml)\n",
      "16:42:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:42:59 [INFO]   Training abgeschlossen in 38.78s (Backend: cuml)\n",
      "16:43:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:43:58 [INFO]   Training abgeschlossen in 38.21s (Backend: cuml)\n",
      "16:44:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:45:00 [INFO]   Training abgeschlossen in 41.40s (Backend: cuml)\n",
      "16:45:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:45:59 [INFO]   Training abgeschlossen in 39.98s (Backend: cuml)\n",
      "16:46:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:46:57 [INFO]   Training abgeschlossen in 38.85s (Backend: cuml)\n",
      "16:47:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:47:57 [INFO]   Training abgeschlossen in 41.02s (Backend: cuml)\n",
      "16:48:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:48:55 [INFO]   Training abgeschlossen in 39.80s (Backend: cuml)\n",
      "16:49:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:49:51 [INFO]   Training abgeschlossen in 38.57s (Backend: cuml)\n",
      "16:50:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:50:50 [INFO]   Training abgeschlossen in 42.55s (Backend: cuml)\n",
      "16:51:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:51:47 [INFO]   Training abgeschlossen in 40.57s (Backend: cuml)\n",
      "16:52:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:52:46 [INFO]   Training abgeschlossen in 42.67s (Backend: cuml)\n",
      "16:53:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:53:43 [INFO]   Training abgeschlossen in 41.91s (Backend: cuml)\n",
      "16:53:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:54:39 [INFO]   Training abgeschlossen in 41.35s (Backend: cuml)\n",
      "16:54:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:55:35 [INFO]   Training abgeschlossen in 41.45s (Backend: cuml)\n",
      "16:55:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:56:29 [INFO]   Training abgeschlossen in 40.25s (Backend: cuml)\n",
      "16:56:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:57:24 [INFO]   Training abgeschlossen in 42.25s (Backend: cuml)\n",
      "16:57:36 [INFO]     60,000 labeled → Accuracy: 0.8860 (Train: 42.3s, Query: 0.64s) | GPU: 2.8/8.0 GB\n",
      "16:57:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:58:16 [INFO]   Training abgeschlossen in 39.48s (Backend: cuml)\n",
      "16:58:27 [INFO]     Final: 60,000 labeled → Accuracy: 0.8859, F1: 0.8850\n",
      "16:58:27 [INFO]   Run 5/5\n",
      "16:58:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "16:58:32 [INFO]   Training abgeschlossen in 4.80s (Backend: cuml)\n",
      "16:59:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "16:59:44 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "17:00:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:00:56 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "17:02:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:02:08 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "17:03:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:03:19 [INFO]   Training abgeschlossen in 5.46s (Backend: cuml)\n",
      "17:04:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:04:31 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "17:05:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:05:42 [INFO]   Training abgeschlossen in 5.86s (Backend: cuml)\n",
      "17:06:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:06:54 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "17:08:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:08:06 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "17:09:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:09:18 [INFO]   Training abgeschlossen in 6.92s (Backend: cuml)\n",
      "17:10:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:10:31 [INFO]   Training abgeschlossen in 7.22s (Backend: cuml)\n",
      "17:11:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:11:44 [INFO]   Training abgeschlossen in 7.49s (Backend: cuml)\n",
      "17:12:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:12:56 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "17:14:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:14:09 [INFO]   Training abgeschlossen in 8.08s (Backend: cuml)\n",
      "17:15:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:15:21 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "17:16:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:16:34 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "17:17:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:17:46 [INFO]   Training abgeschlossen in 8.82s (Backend: cuml)\n",
      "17:18:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:18:59 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "17:20:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:20:11 [INFO]   Training abgeschlossen in 9.17s (Backend: cuml)\n",
      "17:21:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:21:22 [INFO]   Training abgeschlossen in 9.42s (Backend: cuml)\n",
      "17:22:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:22:34 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "17:23:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:23:47 [INFO]   Training abgeschlossen in 9.85s (Backend: cuml)\n",
      "17:24:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:24:58 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "17:26:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:26:10 [INFO]   Training abgeschlossen in 10.25s (Backend: cuml)\n",
      "17:27:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:27:22 [INFO]   Training abgeschlossen in 10.60s (Backend: cuml)\n",
      "17:28:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:28:35 [INFO]   Training abgeschlossen in 10.70s (Backend: cuml)\n",
      "17:29:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:29:47 [INFO]   Training abgeschlossen in 10.92s (Backend: cuml)\n",
      "17:30:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:30:58 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "17:31:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:32:10 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "17:33:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:33:21 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "17:34:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:34:33 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "17:35:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:35:44 [INFO]   Training abgeschlossen in 11.95s (Backend: cuml)\n",
      "17:36:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:36:55 [INFO]   Training abgeschlossen in 12.41s (Backend: cuml)\n",
      "17:37:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:38:06 [INFO]   Training abgeschlossen in 12.47s (Backend: cuml)\n",
      "17:39:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:39:16 [INFO]   Training abgeschlossen in 12.81s (Backend: cuml)\n",
      "17:40:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:40:26 [INFO]   Training abgeschlossen in 12.95s (Backend: cuml)\n",
      "17:41:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:41:36 [INFO]   Training abgeschlossen in 13.19s (Backend: cuml)\n",
      "17:42:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:42:45 [INFO]   Training abgeschlossen in 13.40s (Backend: cuml)\n",
      "17:43:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:43:53 [INFO]   Training abgeschlossen in 13.51s (Backend: cuml)\n",
      "17:44:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:45:02 [INFO]   Training abgeschlossen in 13.74s (Backend: cuml)\n",
      "17:45:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:46:10 [INFO]   Training abgeschlossen in 13.90s (Backend: cuml)\n",
      "17:47:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:47:18 [INFO]   Training abgeschlossen in 14.21s (Backend: cuml)\n",
      "17:48:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:48:26 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "17:49:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:49:33 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "17:50:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:50:40 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "17:51:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:51:46 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "17:52:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:52:53 [INFO]   Training abgeschlossen in 14.88s (Backend: cuml)\n",
      "17:53:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:53:59 [INFO]   Training abgeschlossen in 15.10s (Backend: cuml)\n",
      "17:54:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:55:05 [INFO]   Training abgeschlossen in 15.47s (Backend: cuml)\n",
      "17:55:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:56:11 [INFO]   Training abgeschlossen in 15.55s (Backend: cuml)\n",
      "17:57:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:57:16 [INFO]   Training abgeschlossen in 16.06s (Backend: cuml)\n",
      "17:58:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:58:21 [INFO]   Training abgeschlossen in 15.92s (Backend: cuml)\n",
      "17:59:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:59:26 [INFO]   Training abgeschlossen in 16.28s (Backend: cuml)\n",
      "18:00:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:00:30 [INFO]   Training abgeschlossen in 16.42s (Backend: cuml)\n",
      "18:01:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:01:34 [INFO]   Training abgeschlossen in 16.69s (Backend: cuml)\n",
      "18:02:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:02:38 [INFO]   Training abgeschlossen in 17.02s (Backend: cuml)\n",
      "18:03:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:03:42 [INFO]   Training abgeschlossen in 17.02s (Backend: cuml)\n",
      "18:04:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:04:45 [INFO]   Training abgeschlossen in 17.29s (Backend: cuml)\n",
      "18:05:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:05:48 [INFO]   Training abgeschlossen in 17.59s (Backend: cuml)\n",
      "18:06:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:06:51 [INFO]   Training abgeschlossen in 17.73s (Backend: cuml)\n",
      "18:07:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:07:54 [INFO]   Training abgeschlossen in 17.90s (Backend: cuml)\n",
      "18:08:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:08:56 [INFO]   Training abgeschlossen in 18.25s (Backend: cuml)\n",
      "18:09:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:09:58 [INFO]   Training abgeschlossen in 18.50s (Backend: cuml)\n",
      "18:10:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:10:59 [INFO]   Training abgeschlossen in 18.63s (Backend: cuml)\n",
      "18:11:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:12:01 [INFO]   Training abgeschlossen in 18.84s (Backend: cuml)\n",
      "18:12:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:13:02 [INFO]   Training abgeschlossen in 19.12s (Backend: cuml)\n",
      "18:13:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:14:02 [INFO]   Training abgeschlossen in 19.27s (Backend: cuml)\n",
      "18:14:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:15:03 [INFO]   Training abgeschlossen in 19.57s (Backend: cuml)\n",
      "18:15:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:16:03 [INFO]   Training abgeschlossen in 19.59s (Backend: cuml)\n",
      "18:16:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:17:02 [INFO]   Training abgeschlossen in 19.78s (Backend: cuml)\n",
      "18:17:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:18:01 [INFO]   Training abgeschlossen in 20.02s (Backend: cuml)\n",
      "18:18:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:19:01 [INFO]   Training abgeschlossen in 20.29s (Backend: cuml)\n",
      "18:19:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:19:59 [INFO]   Training abgeschlossen in 20.48s (Backend: cuml)\n",
      "18:20:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:20:58 [INFO]   Training abgeschlossen in 20.67s (Backend: cuml)\n",
      "18:21:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:21:56 [INFO]   Training abgeschlossen in 20.87s (Backend: cuml)\n",
      "18:22:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:22:54 [INFO]   Training abgeschlossen in 21.05s (Backend: cuml)\n",
      "18:23:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:23:51 [INFO]   Training abgeschlossen in 21.22s (Backend: cuml)\n",
      "18:24:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:24:48 [INFO]   Training abgeschlossen in 21.51s (Backend: cuml)\n",
      "18:25:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:25:45 [INFO]   Training abgeschlossen in 21.79s (Backend: cuml)\n",
      "18:26:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:26:42 [INFO]   Training abgeschlossen in 21.89s (Backend: cuml)\n",
      "18:27:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:27:38 [INFO]   Training abgeschlossen in 22.23s (Backend: cuml)\n",
      "18:28:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:28:34 [INFO]   Training abgeschlossen in 22.39s (Backend: cuml)\n",
      "18:29:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:29:30 [INFO]   Training abgeschlossen in 22.56s (Backend: cuml)\n",
      "18:30:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:30:25 [INFO]   Training abgeschlossen in 22.67s (Backend: cuml)\n",
      "18:30:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:31:19 [INFO]   Training abgeschlossen in 22.80s (Backend: cuml)\n",
      "18:31:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:32:14 [INFO]   Training abgeschlossen in 23.02s (Backend: cuml)\n",
      "18:32:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:33:08 [INFO]   Training abgeschlossen in 23.23s (Backend: cuml)\n",
      "18:33:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:34:02 [INFO]   Training abgeschlossen in 23.51s (Backend: cuml)\n",
      "18:34:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:34:55 [INFO]   Training abgeschlossen in 23.60s (Backend: cuml)\n",
      "18:35:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:35:48 [INFO]   Training abgeschlossen in 23.85s (Backend: cuml)\n",
      "18:36:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:36:41 [INFO]   Training abgeschlossen in 24.11s (Backend: cuml)\n",
      "18:37:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:37:33 [INFO]   Training abgeschlossen in 24.26s (Backend: cuml)\n",
      "18:38:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:38:25 [INFO]   Training abgeschlossen in 24.43s (Backend: cuml)\n",
      "18:38:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:39:16 [INFO]   Training abgeschlossen in 24.65s (Backend: cuml)\n",
      "18:39:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:40:08 [INFO]   Training abgeschlossen in 24.84s (Backend: cuml)\n",
      "18:40:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:40:58 [INFO]   Training abgeschlossen in 24.89s (Backend: cuml)\n",
      "18:41:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:41:49 [INFO]   Training abgeschlossen in 25.21s (Backend: cuml)\n",
      "18:42:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:42:39 [INFO]   Training abgeschlossen in 25.34s (Backend: cuml)\n",
      "18:43:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:43:28 [INFO]   Training abgeschlossen in 25.55s (Backend: cuml)\n",
      "18:43:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:44:30 [INFO]   Training abgeschlossen in 38.17s (Backend: cuml)\n",
      "18:44:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:45:32 [INFO]   Training abgeschlossen in 38.97s (Backend: cuml)\n",
      "18:45:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:46:35 [INFO]   Training abgeschlossen in 40.12s (Backend: cuml)\n",
      "18:46:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:47:34 [INFO]   Training abgeschlossen in 37.45s (Backend: cuml)\n",
      "18:47:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:48:34 [INFO]   Training abgeschlossen in 38.83s (Backend: cuml)\n",
      "18:48:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:49:35 [INFO]   Training abgeschlossen in 39.67s (Backend: cuml)\n",
      "18:49:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:50:35 [INFO]   Training abgeschlossen in 40.59s (Backend: cuml)\n",
      "18:50:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:51:37 [INFO]   Training abgeschlossen in 42.06s (Backend: cuml)\n",
      "18:51:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:52:35 [INFO]   Training abgeschlossen in 38.42s (Backend: cuml)\n",
      "18:52:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:53:33 [INFO]   Training abgeschlossen in 40.13s (Backend: cuml)\n",
      "18:53:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:54:32 [INFO]   Training abgeschlossen in 41.14s (Backend: cuml)\n",
      "18:54:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:55:30 [INFO]   Training abgeschlossen in 40.43s (Backend: cuml)\n",
      "18:55:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:56:27 [INFO]   Training abgeschlossen in 40.33s (Backend: cuml)\n",
      "18:56:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:57:23 [INFO]   Training abgeschlossen in 39.93s (Backend: cuml)\n",
      "18:57:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:58:19 [INFO]   Training abgeschlossen in 40.01s (Backend: cuml)\n",
      "18:58:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:59:16 [INFO]   Training abgeschlossen in 41.14s (Backend: cuml)\n",
      "18:59:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:00:10 [INFO]   Training abgeschlossen in 40.33s (Backend: cuml)\n",
      "19:00:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:01:06 [INFO]   Training abgeschlossen in 41.26s (Backend: cuml)\n",
      "19:01:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:02:01 [INFO]   Training abgeschlossen in 42.20s (Backend: cuml)\n",
      "19:02:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:02:57 [INFO]   Training abgeschlossen in 42.45s (Backend: cuml)\n",
      "19:03:09 [INFO]     60,000 labeled → Accuracy: 0.8854 (Train: 42.5s, Query: 0.65s) | GPU: 2.8/8.0 GB\n",
      "19:03:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:03:50 [INFO]   Training abgeschlossen in 41.20s (Backend: cuml)\n",
      "19:04:02 [INFO]     Final: 60,000 labeled → Accuracy: 0.8852, F1: 0.8843\n",
      "\n",
      "============================================================\n",
      "Strategie: Least Confidence\n",
      "============================================================\n",
      "19:04:02 [INFO] \n",
      "GPU-SVM + Least Confidence - Budget: 20% (12,000 Samples)\n",
      "19:04:02 [INFO]   Run 1/5\n",
      "19:04:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 0.3/8.0 GB)\n",
      "19:04:07 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "19:05:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:05:19 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "19:06:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:06:31 [INFO]   Training abgeschlossen in 5.15s (Backend: cuml)\n",
      "19:07:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:07:43 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "19:08:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:08:55 [INFO]   Training abgeschlossen in 5.38s (Backend: cuml)\n",
      "19:10:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:10:07 [INFO]   Training abgeschlossen in 5.69s (Backend: cuml)\n",
      "19:11:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:11:19 [INFO]   Training abgeschlossen in 6.01s (Backend: cuml)\n",
      "19:12:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:12:31 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "19:13:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:13:44 [INFO]   Training abgeschlossen in 6.54s (Backend: cuml)\n",
      "19:14:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:14:57 [INFO]   Training abgeschlossen in 6.79s (Backend: cuml)\n",
      "19:16:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:16:10 [INFO]   Training abgeschlossen in 7.33s (Backend: cuml)\n",
      "19:17:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:17:23 [INFO]   Training abgeschlossen in 7.50s (Backend: cuml)\n",
      "19:18:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:18:35 [INFO]   Training abgeschlossen in 7.74s (Backend: cuml)\n",
      "19:19:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:19:48 [INFO]   Training abgeschlossen in 7.95s (Backend: cuml)\n",
      "19:20:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:21:02 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "19:22:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:22:14 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "19:23:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:23:27 [INFO]   Training abgeschlossen in 8.71s (Backend: cuml)\n",
      "19:24:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:24:39 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "19:25:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:25:52 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "19:26:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:27:04 [INFO]   Training abgeschlossen in 9.41s (Backend: cuml)\n",
      "19:28:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:28:16 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "19:29:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:29:28 [INFO]   Training abgeschlossen in 9.89s (Backend: cuml)\n",
      "19:30:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:30:41 [INFO]   Training abgeschlossen in 10.17s (Backend: cuml)\n",
      "19:31:43 [INFO]     12,000 labeled → Accuracy: 0.8820 (Train: 10.2s, Query: 50.57s) | GPU: 2.7/8.0 GB\n",
      "19:31:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:31:53 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "19:32:04 [INFO]     Final: 12,000 labeled → Accuracy: 0.8827, F1: 0.8828\n",
      "19:32:04 [INFO]   Run 2/5\n",
      "19:32:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:32:09 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "19:33:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:33:21 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "19:34:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:34:33 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "19:35:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:35:45 [INFO]   Training abgeschlossen in 5.25s (Backend: cuml)\n",
      "19:36:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:36:56 [INFO]   Training abgeschlossen in 5.23s (Backend: cuml)\n",
      "19:38:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:38:08 [INFO]   Training abgeschlossen in 5.66s (Backend: cuml)\n",
      "19:39:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:39:21 [INFO]   Training abgeschlossen in 6.11s (Backend: cuml)\n",
      "19:40:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:40:33 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "19:41:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:41:46 [INFO]   Training abgeschlossen in 6.54s (Backend: cuml)\n",
      "19:42:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:42:59 [INFO]   Training abgeschlossen in 6.95s (Backend: cuml)\n",
      "19:44:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:44:12 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "19:45:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:45:25 [INFO]   Training abgeschlossen in 7.41s (Backend: cuml)\n",
      "19:46:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:46:39 [INFO]   Training abgeschlossen in 7.73s (Backend: cuml)\n",
      "19:47:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:47:51 [INFO]   Training abgeschlossen in 8.07s (Backend: cuml)\n",
      "19:48:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:49:05 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "19:50:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:50:17 [INFO]   Training abgeschlossen in 8.44s (Backend: cuml)\n",
      "19:51:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:51:30 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "19:52:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:52:43 [INFO]   Training abgeschlossen in 9.15s (Backend: cuml)\n",
      "19:53:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:53:56 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "19:54:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:55:08 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "19:56:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:56:20 [INFO]   Training abgeschlossen in 9.72s (Backend: cuml)\n",
      "19:57:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:57:32 [INFO]   Training abgeschlossen in 9.96s (Backend: cuml)\n",
      "19:58:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:58:44 [INFO]   Training abgeschlossen in 10.11s (Backend: cuml)\n",
      "19:59:45 [INFO]     12,000 labeled → Accuracy: 0.8808 (Train: 10.1s, Query: 50.40s) | GPU: 2.7/8.0 GB\n",
      "19:59:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:59:55 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "20:00:06 [INFO]     Final: 12,000 labeled → Accuracy: 0.8820, F1: 0.8819\n",
      "20:00:06 [INFO]   Run 3/5\n",
      "20:00:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:00:11 [INFO]   Training abgeschlossen in 4.71s (Backend: cuml)\n",
      "20:01:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:01:23 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "20:02:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:02:35 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "20:03:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:03:47 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "20:04:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:04:58 [INFO]   Training abgeschlossen in 5.21s (Backend: cuml)\n",
      "20:06:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:06:10 [INFO]   Training abgeschlossen in 5.74s (Backend: cuml)\n",
      "20:07:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:07:22 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "20:08:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:08:35 [INFO]   Training abgeschlossen in 6.19s (Backend: cuml)\n",
      "20:09:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:09:47 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "20:10:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:10:59 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "20:12:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:12:13 [INFO]   Training abgeschlossen in 7.38s (Backend: cuml)\n",
      "20:13:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:13:26 [INFO]   Training abgeschlossen in 7.54s (Backend: cuml)\n",
      "20:14:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:14:38 [INFO]   Training abgeschlossen in 7.72s (Backend: cuml)\n",
      "20:15:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:15:51 [INFO]   Training abgeschlossen in 7.96s (Backend: cuml)\n",
      "20:16:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:17:04 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "20:18:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:18:17 [INFO]   Training abgeschlossen in 8.48s (Backend: cuml)\n",
      "20:19:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:19:30 [INFO]   Training abgeschlossen in 8.75s (Backend: cuml)\n",
      "20:20:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:20:43 [INFO]   Training abgeschlossen in 8.96s (Backend: cuml)\n",
      "20:21:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:21:55 [INFO]   Training abgeschlossen in 9.31s (Backend: cuml)\n",
      "20:22:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:23:08 [INFO]   Training abgeschlossen in 9.42s (Backend: cuml)\n",
      "20:24:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:24:20 [INFO]   Training abgeschlossen in 9.65s (Backend: cuml)\n",
      "20:25:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:25:32 [INFO]   Training abgeschlossen in 9.90s (Backend: cuml)\n",
      "20:26:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:26:44 [INFO]   Training abgeschlossen in 10.34s (Backend: cuml)\n",
      "20:27:46 [INFO]     12,000 labeled → Accuracy: 0.8814 (Train: 10.3s, Query: 50.79s) | GPU: 2.7/8.0 GB\n",
      "20:27:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:27:57 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "20:28:07 [INFO]     Final: 12,000 labeled → Accuracy: 0.8834, F1: 0.8831\n",
      "20:28:07 [INFO]   Run 4/5\n",
      "20:28:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:28:12 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "20:29:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:29:25 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "20:30:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:30:36 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "20:31:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:31:48 [INFO]   Training abgeschlossen in 5.28s (Backend: cuml)\n",
      "20:32:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:33:00 [INFO]   Training abgeschlossen in 5.34s (Backend: cuml)\n",
      "20:34:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:34:13 [INFO]   Training abgeschlossen in 5.78s (Backend: cuml)\n",
      "20:35:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:35:25 [INFO]   Training abgeschlossen in 6.08s (Backend: cuml)\n",
      "20:36:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:36:38 [INFO]   Training abgeschlossen in 6.17s (Backend: cuml)\n",
      "20:37:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:37:50 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "20:38:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:39:03 [INFO]   Training abgeschlossen in 6.97s (Backend: cuml)\n",
      "20:40:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:40:16 [INFO]   Training abgeschlossen in 7.29s (Backend: cuml)\n",
      "20:41:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:41:28 [INFO]   Training abgeschlossen in 7.49s (Backend: cuml)\n",
      "20:42:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "20:42:41 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "20:43:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:43:54 [INFO]   Training abgeschlossen in 8.17s (Backend: cuml)\n",
      "20:44:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:45:07 [INFO]   Training abgeschlossen in 8.21s (Backend: cuml)\n",
      "20:46:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:46:20 [INFO]   Training abgeschlossen in 8.55s (Backend: cuml)\n",
      "20:47:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:47:32 [INFO]   Training abgeschlossen in 8.81s (Backend: cuml)\n",
      "20:48:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:48:45 [INFO]   Training abgeschlossen in 9.16s (Backend: cuml)\n",
      "20:49:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:49:58 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "20:51:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "20:51:10 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "20:52:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:52:23 [INFO]   Training abgeschlossen in 9.77s (Backend: cuml)\n",
      "20:53:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:53:35 [INFO]   Training abgeschlossen in 9.88s (Backend: cuml)\n",
      "20:54:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:54:48 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "20:55:49 [INFO]     12,000 labeled → Accuracy: 0.8801 (Train: 10.1s, Query: 50.55s) | GPU: 2.7/8.0 GB\n",
      "20:55:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:56:00 [INFO]   Training abgeschlossen in 10.29s (Backend: cuml)\n",
      "20:56:11 [INFO]     Final: 12,000 labeled → Accuracy: 0.8821, F1: 0.8819\n",
      "20:56:11 [INFO]   Run 5/5\n",
      "20:56:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:56:16 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "20:57:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:57:27 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "20:58:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "20:58:39 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "20:59:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "20:59:51 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "21:00:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:01:02 [INFO]   Training abgeschlossen in 5.48s (Backend: cuml)\n",
      "21:02:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:02:15 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "21:03:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:03:27 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "21:04:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:04:39 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "21:05:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:05:52 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "21:06:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:07:04 [INFO]   Training abgeschlossen in 6.88s (Backend: cuml)\n",
      "21:08:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:08:17 [INFO]   Training abgeschlossen in 7.41s (Backend: cuml)\n",
      "21:09:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:09:30 [INFO]   Training abgeschlossen in 7.67s (Backend: cuml)\n",
      "21:10:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:10:43 [INFO]   Training abgeschlossen in 7.78s (Backend: cuml)\n",
      "21:11:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:11:56 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "21:13:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:13:09 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "21:14:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:14:22 [INFO]   Training abgeschlossen in 8.60s (Backend: cuml)\n",
      "21:15:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:15:34 [INFO]   Training abgeschlossen in 8.73s (Backend: cuml)\n",
      "21:16:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:16:47 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "21:17:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:17:59 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "21:19:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:19:12 [INFO]   Training abgeschlossen in 9.49s (Backend: cuml)\n",
      "21:20:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:20:25 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "21:21:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:21:37 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "21:22:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:22:50 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "21:23:52 [INFO]     12,000 labeled → Accuracy: 0.8799 (Train: 10.4s, Query: 51.62s) | GPU: 2.7/8.0 GB\n",
      "21:23:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:24:03 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "21:24:13 [INFO]     Final: 12,000 labeled → Accuracy: 0.8814, F1: 0.8813\n",
      "21:24:14 [INFO] \n",
      "GPU-SVM + Least Confidence - Budget: 40% (24,000 Samples)\n",
      "21:24:14 [INFO]   Run 1/5\n",
      "21:24:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:24:19 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "21:25:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:25:30 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "21:26:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:26:42 [INFO]   Training abgeschlossen in 5.16s (Backend: cuml)\n",
      "21:27:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:27:54 [INFO]   Training abgeschlossen in 5.18s (Backend: cuml)\n",
      "21:29:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:29:05 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "21:30:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:30:17 [INFO]   Training abgeschlossen in 5.83s (Backend: cuml)\n",
      "21:31:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:31:30 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "21:32:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:32:42 [INFO]   Training abgeschlossen in 6.21s (Backend: cuml)\n",
      "21:33:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:33:55 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "21:35:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:35:08 [INFO]   Training abgeschlossen in 6.98s (Backend: cuml)\n",
      "21:36:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:36:21 [INFO]   Training abgeschlossen in 7.31s (Backend: cuml)\n",
      "21:37:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:37:34 [INFO]   Training abgeschlossen in 7.46s (Backend: cuml)\n",
      "21:38:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:38:47 [INFO]   Training abgeschlossen in 7.73s (Backend: cuml)\n",
      "21:39:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:40:00 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "21:41:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:41:13 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "21:42:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:42:26 [INFO]   Training abgeschlossen in 8.47s (Backend: cuml)\n",
      "21:43:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:43:39 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "21:44:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:44:51 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "21:45:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:46:04 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "21:47:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:47:16 [INFO]   Training abgeschlossen in 9.49s (Backend: cuml)\n",
      "21:48:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:48:28 [INFO]   Training abgeschlossen in 9.91s (Backend: cuml)\n",
      "21:49:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:49:41 [INFO]   Training abgeschlossen in 9.94s (Backend: cuml)\n",
      "21:50:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:50:53 [INFO]   Training abgeschlossen in 10.15s (Backend: cuml)\n",
      "21:51:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:52:06 [INFO]   Training abgeschlossen in 10.36s (Backend: cuml)\n",
      "21:53:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:53:17 [INFO]   Training abgeschlossen in 10.64s (Backend: cuml)\n",
      "21:54:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:54:29 [INFO]   Training abgeschlossen in 10.77s (Backend: cuml)\n",
      "21:55:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:55:41 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "21:56:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "21:56:53 [INFO]   Training abgeschlossen in 11.20s (Backend: cuml)\n",
      "21:57:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:58:05 [INFO]   Training abgeschlossen in 11.56s (Backend: cuml)\n",
      "21:59:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "21:59:17 [INFO]   Training abgeschlossen in 11.63s (Backend: cuml)\n",
      "22:00:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:00:28 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "22:01:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:01:40 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "22:02:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:02:51 [INFO]   Training abgeschlossen in 12.34s (Backend: cuml)\n",
      "22:03:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:04:02 [INFO]   Training abgeschlossen in 12.47s (Backend: cuml)\n",
      "22:05:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:05:12 [INFO]   Training abgeschlossen in 12.69s (Backend: cuml)\n",
      "22:06:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:06:22 [INFO]   Training abgeschlossen in 12.91s (Backend: cuml)\n",
      "22:07:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:07:31 [INFO]   Training abgeschlossen in 13.35s (Backend: cuml)\n",
      "22:08:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:08:40 [INFO]   Training abgeschlossen in 13.40s (Backend: cuml)\n",
      "22:09:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:09:49 [INFO]   Training abgeschlossen in 13.54s (Backend: cuml)\n",
      "22:10:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:10:58 [INFO]   Training abgeschlossen in 13.80s (Backend: cuml)\n",
      "22:11:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:12:06 [INFO]   Training abgeschlossen in 14.00s (Backend: cuml)\n",
      "22:13:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:13:14 [INFO]   Training abgeschlossen in 14.36s (Backend: cuml)\n",
      "22:14:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:14:22 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "22:15:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:15:30 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "22:16:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:16:37 [INFO]   Training abgeschlossen in 14.58s (Backend: cuml)\n",
      "22:17:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:17:43 [INFO]   Training abgeschlossen in 14.78s (Backend: cuml)\n",
      "22:18:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:18:50 [INFO]   Training abgeschlossen in 15.05s (Backend: cuml)\n",
      "22:19:40 [INFO]     24,000 labeled → Accuracy: 0.8840 (Train: 15.1s, Query: 39.69s) | GPU: 2.8/8.0 GB\n",
      "22:19:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:19:56 [INFO]   Training abgeschlossen in 15.44s (Backend: cuml)\n",
      "22:20:07 [INFO]     Final: 24,000 labeled → Accuracy: 0.8846, F1: 0.8844\n",
      "22:20:07 [INFO]   Run 2/5\n",
      "22:20:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:20:12 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "22:21:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:21:24 [INFO]   Training abgeschlossen in 4.86s (Backend: cuml)\n",
      "22:22:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "22:22:36 [INFO]   Training abgeschlossen in 5.07s (Backend: cuml)\n",
      "22:23:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:23:48 [INFO]   Training abgeschlossen in 5.20s (Backend: cuml)\n",
      "22:24:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:24:59 [INFO]   Training abgeschlossen in 5.27s (Backend: cuml)\n",
      "22:26:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:26:11 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "22:27:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "22:27:23 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "22:28:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:28:36 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "22:29:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:29:48 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "22:30:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:31:01 [INFO]   Training abgeschlossen in 6.95s (Backend: cuml)\n",
      "22:32:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:32:14 [INFO]   Training abgeschlossen in 7.55s (Backend: cuml)\n",
      "22:33:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:33:27 [INFO]   Training abgeschlossen in 7.48s (Backend: cuml)\n",
      "22:34:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "22:34:40 [INFO]   Training abgeschlossen in 7.79s (Backend: cuml)\n",
      "22:35:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:35:53 [INFO]   Training abgeschlossen in 7.97s (Backend: cuml)\n",
      "22:36:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:37:06 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "22:38:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:38:19 [INFO]   Training abgeschlossen in 8.45s (Backend: cuml)\n",
      "22:39:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:39:32 [INFO]   Training abgeschlossen in 8.69s (Backend: cuml)\n",
      "22:40:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:40:45 [INFO]   Training abgeschlossen in 9.10s (Backend: cuml)\n",
      "22:41:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:41:57 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "22:43:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "22:43:09 [INFO]   Training abgeschlossen in 9.47s (Backend: cuml)\n",
      "22:44:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:44:22 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "22:45:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:45:34 [INFO]   Training abgeschlossen in 9.97s (Backend: cuml)\n",
      "22:46:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:46:46 [INFO]   Training abgeschlossen in 10.12s (Backend: cuml)\n",
      "22:47:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:47:58 [INFO]   Training abgeschlossen in 10.36s (Backend: cuml)\n",
      "22:49:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:49:11 [INFO]   Training abgeschlossen in 10.61s (Backend: cuml)\n",
      "22:50:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:50:23 [INFO]   Training abgeschlossen in 10.85s (Backend: cuml)\n",
      "22:51:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:51:35 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "22:52:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:52:48 [INFO]   Training abgeschlossen in 11.21s (Backend: cuml)\n",
      "22:53:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:53:59 [INFO]   Training abgeschlossen in 11.52s (Backend: cuml)\n",
      "22:54:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:55:11 [INFO]   Training abgeschlossen in 11.68s (Backend: cuml)\n",
      "22:56:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:56:23 [INFO]   Training abgeschlossen in 11.87s (Backend: cuml)\n",
      "22:57:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:57:34 [INFO]   Training abgeschlossen in 12.09s (Backend: cuml)\n",
      "22:58:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:58:45 [INFO]   Training abgeschlossen in 12.43s (Backend: cuml)\n",
      "22:59:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:59:56 [INFO]   Training abgeschlossen in 12.55s (Backend: cuml)\n",
      "23:00:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:01:07 [INFO]   Training abgeschlossen in 12.79s (Backend: cuml)\n",
      "23:02:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:02:16 [INFO]   Training abgeschlossen in 13.00s (Backend: cuml)\n",
      "23:03:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:03:26 [INFO]   Training abgeschlossen in 13.23s (Backend: cuml)\n",
      "23:04:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:04:35 [INFO]   Training abgeschlossen in 13.57s (Backend: cuml)\n",
      "23:05:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:05:44 [INFO]   Training abgeschlossen in 13.56s (Backend: cuml)\n",
      "23:06:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:06:53 [INFO]   Training abgeschlossen in 13.77s (Backend: cuml)\n",
      "23:07:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:08:01 [INFO]   Training abgeschlossen in 14.07s (Backend: cuml)\n",
      "23:08:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:09:09 [INFO]   Training abgeschlossen in 14.32s (Backend: cuml)\n",
      "23:10:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:10:17 [INFO]   Training abgeschlossen in 14.51s (Backend: cuml)\n",
      "23:11:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:11:24 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "23:12:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:12:31 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "23:13:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:13:37 [INFO]   Training abgeschlossen in 14.75s (Backend: cuml)\n",
      "23:14:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:14:44 [INFO]   Training abgeschlossen in 14.99s (Backend: cuml)\n",
      "23:15:35 [INFO]     24,000 labeled → Accuracy: 0.8850 (Train: 15.0s, Query: 39.52s) | GPU: 2.8/8.0 GB\n",
      "23:15:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:15:50 [INFO]   Training abgeschlossen in 15.19s (Backend: cuml)\n",
      "23:16:01 [INFO]     Final: 24,000 labeled → Accuracy: 0.8861, F1: 0.8858\n",
      "23:16:01 [INFO]   Run 3/5\n",
      "23:16:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "23:16:06 [INFO]   Training abgeschlossen in 4.73s (Backend: cuml)\n",
      "23:17:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:17:18 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "23:18:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:18:29 [INFO]   Training abgeschlossen in 5.13s (Backend: cuml)\n",
      "23:19:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:19:41 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "23:20:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:20:53 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "23:21:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:22:05 [INFO]   Training abgeschlossen in 5.74s (Backend: cuml)\n",
      "23:23:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:23:18 [INFO]   Training abgeschlossen in 5.97s (Backend: cuml)\n",
      "23:24:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:24:30 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "23:25:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:25:43 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "23:26:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:26:55 [INFO]   Training abgeschlossen in 6.89s (Backend: cuml)\n",
      "23:28:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:28:08 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "23:29:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:29:22 [INFO]   Training abgeschlossen in 7.52s (Backend: cuml)\n",
      "23:30:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:30:34 [INFO]   Training abgeschlossen in 7.72s (Backend: cuml)\n",
      "23:31:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:31:47 [INFO]   Training abgeschlossen in 7.98s (Backend: cuml)\n",
      "23:32:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:33:00 [INFO]   Training abgeschlossen in 8.37s (Backend: cuml)\n",
      "23:34:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:34:13 [INFO]   Training abgeschlossen in 8.59s (Backend: cuml)\n",
      "23:35:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:35:25 [INFO]   Training abgeschlossen in 8.74s (Backend: cuml)\n",
      "23:36:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:36:38 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "23:37:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:37:51 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "23:38:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:39:03 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "23:40:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:40:16 [INFO]   Training abgeschlossen in 9.75s (Backend: cuml)\n",
      "23:41:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:41:28 [INFO]   Training abgeschlossen in 10.00s (Backend: cuml)\n",
      "23:42:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:42:40 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "23:43:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:43:52 [INFO]   Training abgeschlossen in 10.34s (Backend: cuml)\n",
      "23:44:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:45:04 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "23:46:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:46:16 [INFO]   Training abgeschlossen in 10.85s (Backend: cuml)\n",
      "23:47:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "23:47:28 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "23:48:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:48:40 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "23:49:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:49:52 [INFO]   Training abgeschlossen in 11.63s (Backend: cuml)\n",
      "23:50:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:51:04 [INFO]   Training abgeschlossen in 11.62s (Backend: cuml)\n",
      "23:52:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:52:15 [INFO]   Training abgeschlossen in 11.83s (Backend: cuml)\n",
      "23:53:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:53:27 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "23:54:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:54:38 [INFO]   Training abgeschlossen in 12.55s (Backend: cuml)\n",
      "23:55:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:55:48 [INFO]   Training abgeschlossen in 12.51s (Backend: cuml)\n",
      "23:56:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:56:58 [INFO]   Training abgeschlossen in 12.81s (Backend: cuml)\n",
      "23:57:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:58:08 [INFO]   Training abgeschlossen in 13.00s (Backend: cuml)\n",
      "23:59:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "23:59:17 [INFO]   Training abgeschlossen in 13.38s (Backend: cuml)\n",
      "00:00:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:00:27 [INFO]   Training abgeschlossen in 13.39s (Backend: cuml)\n",
      "00:01:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:01:36 [INFO]   Training abgeschlossen in 13.60s (Backend: cuml)\n",
      "00:02:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:02:44 [INFO]   Training abgeschlossen in 13.82s (Backend: cuml)\n",
      "00:03:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:03:52 [INFO]   Training abgeschlossen in 14.02s (Backend: cuml)\n",
      "00:04:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:05:01 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "00:05:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:06:08 [INFO]   Training abgeschlossen in 14.39s (Backend: cuml)\n",
      "00:07:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:07:15 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "00:08:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:08:22 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "00:09:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:09:29 [INFO]   Training abgeschlossen in 14.82s (Backend: cuml)\n",
      "00:10:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:10:35 [INFO]   Training abgeschlossen in 15.00s (Backend: cuml)\n",
      "00:11:26 [INFO]     24,000 labeled → Accuracy: 0.8843 (Train: 15.0s, Query: 39.47s) | GPU: 2.8/8.0 GB\n",
      "00:11:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:11:41 [INFO]   Training abgeschlossen in 15.25s (Backend: cuml)\n",
      "00:11:52 [INFO]     Final: 24,000 labeled → Accuracy: 0.8847, F1: 0.8846\n",
      "00:11:52 [INFO]   Run 4/5\n",
      "00:11:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:11:57 [INFO]   Training abgeschlossen in 4.75s (Backend: cuml)\n",
      "00:13:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:13:09 [INFO]   Training abgeschlossen in 4.92s (Backend: cuml)\n",
      "00:14:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "00:14:21 [INFO]   Training abgeschlossen in 5.17s (Backend: cuml)\n",
      "00:15:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:15:33 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "00:16:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:16:44 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "00:17:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:17:57 [INFO]   Training abgeschlossen in 5.77s (Backend: cuml)\n",
      "00:19:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "00:19:09 [INFO]   Training abgeschlossen in 6.10s (Backend: cuml)\n",
      "00:20:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:20:21 [INFO]   Training abgeschlossen in 6.12s (Backend: cuml)\n",
      "00:21:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:21:34 [INFO]   Training abgeschlossen in 6.53s (Backend: cuml)\n",
      "00:22:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:22:46 [INFO]   Training abgeschlossen in 6.94s (Backend: cuml)\n",
      "00:23:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:23:59 [INFO]   Training abgeschlossen in 7.47s (Backend: cuml)\n",
      "00:25:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:25:12 [INFO]   Training abgeschlossen in 7.50s (Backend: cuml)\n",
      "00:26:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "00:26:25 [INFO]   Training abgeschlossen in 7.79s (Backend: cuml)\n",
      "00:27:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:27:38 [INFO]   Training abgeschlossen in 8.08s (Backend: cuml)\n",
      "00:28:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:28:51 [INFO]   Training abgeschlossen in 8.25s (Backend: cuml)\n",
      "00:29:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:30:03 [INFO]   Training abgeschlossen in 8.55s (Backend: cuml)\n",
      "00:31:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:31:16 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "00:32:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:32:29 [INFO]   Training abgeschlossen in 9.16s (Backend: cuml)\n",
      "00:33:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:33:42 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "00:34:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:34:54 [INFO]   Training abgeschlossen in 9.55s (Backend: cuml)\n",
      "00:35:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:36:07 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "00:37:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:37:20 [INFO]   Training abgeschlossen in 10.09s (Backend: cuml)\n",
      "00:38:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:38:32 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "00:39:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:39:44 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "00:40:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:40:56 [INFO]   Training abgeschlossen in 10.58s (Backend: cuml)\n",
      "00:41:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:42:07 [INFO]   Training abgeschlossen in 10.74s (Backend: cuml)\n",
      "00:43:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:43:19 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "00:44:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:44:31 [INFO]   Training abgeschlossen in 11.18s (Backend: cuml)\n",
      "00:45:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:45:43 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "00:46:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:46:55 [INFO]   Training abgeschlossen in 11.64s (Backend: cuml)\n",
      "00:47:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:48:06 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "00:49:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:49:18 [INFO]   Training abgeschlossen in 12.02s (Backend: cuml)\n",
      "00:50:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:50:29 [INFO]   Training abgeschlossen in 12.45s (Backend: cuml)\n",
      "00:51:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:51:40 [INFO]   Training abgeschlossen in 12.52s (Backend: cuml)\n",
      "00:52:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:52:50 [INFO]   Training abgeschlossen in 12.73s (Backend: cuml)\n",
      "00:53:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:54:00 [INFO]   Training abgeschlossen in 12.90s (Backend: cuml)\n",
      "00:54:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:55:09 [INFO]   Training abgeschlossen in 13.23s (Backend: cuml)\n",
      "00:56:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:56:18 [INFO]   Training abgeschlossen in 13.41s (Backend: cuml)\n",
      "00:57:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:57:27 [INFO]   Training abgeschlossen in 13.60s (Backend: cuml)\n",
      "00:58:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:58:35 [INFO]   Training abgeschlossen in 13.76s (Backend: cuml)\n",
      "00:59:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:59:43 [INFO]   Training abgeschlossen in 13.98s (Backend: cuml)\n",
      "01:00:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:00:52 [INFO]   Training abgeschlossen in 14.35s (Backend: cuml)\n",
      "01:01:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:01:59 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "01:02:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:03:06 [INFO]   Training abgeschlossen in 14.33s (Backend: cuml)\n",
      "01:03:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:04:13 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "01:05:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:05:20 [INFO]   Training abgeschlossen in 14.75s (Backend: cuml)\n",
      "01:06:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:06:27 [INFO]   Training abgeschlossen in 15.11s (Backend: cuml)\n",
      "01:07:17 [INFO]     24,000 labeled → Accuracy: 0.8838 (Train: 15.1s, Query: 39.65s) | GPU: 2.8/8.0 GB\n",
      "01:07:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:07:33 [INFO]   Training abgeschlossen in 15.15s (Backend: cuml)\n",
      "01:07:44 [INFO]     Final: 24,000 labeled → Accuracy: 0.8834, F1: 0.8832\n",
      "01:07:44 [INFO]   Run 5/5\n",
      "01:07:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:07:49 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "01:08:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:09:01 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "01:10:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:10:12 [INFO]   Training abgeschlossen in 5.14s (Backend: cuml)\n",
      "01:11:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:11:24 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "01:12:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:12:37 [INFO]   Training abgeschlossen in 5.51s (Backend: cuml)\n",
      "01:13:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:13:49 [INFO]   Training abgeschlossen in 5.64s (Backend: cuml)\n",
      "01:14:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:15:01 [INFO]   Training abgeschlossen in 6.01s (Backend: cuml)\n",
      "01:16:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:16:13 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "01:17:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:17:26 [INFO]   Training abgeschlossen in 6.57s (Backend: cuml)\n",
      "01:18:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:18:38 [INFO]   Training abgeschlossen in 6.94s (Backend: cuml)\n",
      "01:19:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:19:51 [INFO]   Training abgeschlossen in 7.45s (Backend: cuml)\n",
      "01:20:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:21:04 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "01:22:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:22:17 [INFO]   Training abgeschlossen in 7.79s (Backend: cuml)\n",
      "01:23:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:23:30 [INFO]   Training abgeschlossen in 8.15s (Backend: cuml)\n",
      "01:24:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:24:43 [INFO]   Training abgeschlossen in 8.27s (Backend: cuml)\n",
      "01:25:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:25:55 [INFO]   Training abgeschlossen in 8.45s (Backend: cuml)\n",
      "01:26:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:27:08 [INFO]   Training abgeschlossen in 8.64s (Backend: cuml)\n",
      "01:28:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:28:21 [INFO]   Training abgeschlossen in 9.22s (Backend: cuml)\n",
      "01:29:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:29:33 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "01:30:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "01:30:46 [INFO]   Training abgeschlossen in 9.53s (Backend: cuml)\n",
      "01:31:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:31:58 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "01:33:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:33:11 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "01:34:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:34:23 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "01:35:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:35:35 [INFO]   Training abgeschlossen in 10.32s (Backend: cuml)\n",
      "01:36:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:36:47 [INFO]   Training abgeschlossen in 10.55s (Backend: cuml)\n",
      "01:37:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:38:00 [INFO]   Training abgeschlossen in 10.91s (Backend: cuml)\n",
      "01:39:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "01:39:12 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "01:40:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:40:24 [INFO]   Training abgeschlossen in 11.20s (Backend: cuml)\n",
      "01:41:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:41:36 [INFO]   Training abgeschlossen in 11.44s (Backend: cuml)\n",
      "01:42:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:42:48 [INFO]   Training abgeschlossen in 11.71s (Backend: cuml)\n",
      "01:43:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:44:00 [INFO]   Training abgeschlossen in 11.84s (Backend: cuml)\n",
      "01:44:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:45:10 [INFO]   Training abgeschlossen in 12.05s (Backend: cuml)\n",
      "01:46:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:46:22 [INFO]   Training abgeschlossen in 12.31s (Backend: cuml)\n",
      "01:47:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:47:33 [INFO]   Training abgeschlossen in 12.57s (Backend: cuml)\n",
      "01:48:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:48:43 [INFO]   Training abgeschlossen in 12.80s (Backend: cuml)\n",
      "01:49:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:49:53 [INFO]   Training abgeschlossen in 12.89s (Backend: cuml)\n",
      "01:50:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:51:02 [INFO]   Training abgeschlossen in 13.19s (Backend: cuml)\n",
      "01:51:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:52:11 [INFO]   Training abgeschlossen in 13.44s (Backend: cuml)\n",
      "01:53:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:53:20 [INFO]   Training abgeschlossen in 13.58s (Backend: cuml)\n",
      "01:54:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:54:29 [INFO]   Training abgeschlossen in 13.75s (Backend: cuml)\n",
      "01:55:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:55:37 [INFO]   Training abgeschlossen in 13.94s (Backend: cuml)\n",
      "01:56:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:56:45 [INFO]   Training abgeschlossen in 14.20s (Backend: cuml)\n",
      "01:57:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:57:53 [INFO]   Training abgeschlossen in 14.51s (Backend: cuml)\n",
      "01:58:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "01:59:00 [INFO]   Training abgeschlossen in 14.42s (Backend: cuml)\n",
      "01:59:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:00:07 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "02:00:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:01:14 [INFO]   Training abgeschlossen in 14.71s (Backend: cuml)\n",
      "02:02:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:02:20 [INFO]   Training abgeschlossen in 14.94s (Backend: cuml)\n",
      "02:03:11 [INFO]     24,000 labeled → Accuracy: 0.8850 (Train: 15.0s, Query: 39.66s) | GPU: 2.8/8.0 GB\n",
      "02:03:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:03:27 [INFO]   Training abgeschlossen in 15.29s (Backend: cuml)\n",
      "02:03:38 [INFO]     Final: 24,000 labeled → Accuracy: 0.8842, F1: 0.8839\n",
      "02:03:38 [INFO] \n",
      "GPU-SVM + Least Confidence - Budget: 60% (36,000 Samples)\n",
      "02:03:38 [INFO]   Run 1/5\n",
      "02:03:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:03:43 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "02:04:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:04:55 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "02:06:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "02:06:07 [INFO]   Training abgeschlossen in 5.16s (Backend: cuml)\n",
      "02:07:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:07:19 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "02:08:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:08:30 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "02:09:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:09:43 [INFO]   Training abgeschlossen in 5.72s (Backend: cuml)\n",
      "02:10:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "02:10:55 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "02:12:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:12:07 [INFO]   Training abgeschlossen in 6.20s (Backend: cuml)\n",
      "02:13:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:13:19 [INFO]   Training abgeschlossen in 6.43s (Backend: cuml)\n",
      "02:14:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:14:32 [INFO]   Training abgeschlossen in 6.82s (Backend: cuml)\n",
      "02:15:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:15:45 [INFO]   Training abgeschlossen in 7.38s (Backend: cuml)\n",
      "02:16:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:16:58 [INFO]   Training abgeschlossen in 7.49s (Backend: cuml)\n",
      "02:18:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:18:11 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "02:19:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:19:24 [INFO]   Training abgeschlossen in 7.97s (Backend: cuml)\n",
      "02:20:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:20:37 [INFO]   Training abgeschlossen in 8.53s (Backend: cuml)\n",
      "02:21:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:21:49 [INFO]   Training abgeschlossen in 8.51s (Backend: cuml)\n",
      "02:22:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:23:02 [INFO]   Training abgeschlossen in 8.79s (Backend: cuml)\n",
      "02:24:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:24:15 [INFO]   Training abgeschlossen in 9.09s (Backend: cuml)\n",
      "02:25:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:25:27 [INFO]   Training abgeschlossen in 9.27s (Backend: cuml)\n",
      "02:26:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:26:40 [INFO]   Training abgeschlossen in 9.48s (Backend: cuml)\n",
      "02:27:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:27:52 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "02:28:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:29:04 [INFO]   Training abgeschlossen in 10.05s (Backend: cuml)\n",
      "02:30:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:30:16 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "02:31:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:31:29 [INFO]   Training abgeschlossen in 10.35s (Backend: cuml)\n",
      "02:32:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:32:41 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "02:33:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:33:53 [INFO]   Training abgeschlossen in 10.96s (Backend: cuml)\n",
      "02:34:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:35:06 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "02:36:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:36:18 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "02:37:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:37:30 [INFO]   Training abgeschlossen in 11.50s (Backend: cuml)\n",
      "02:38:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:38:42 [INFO]   Training abgeschlossen in 11.63s (Backend: cuml)\n",
      "02:39:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:39:53 [INFO]   Training abgeschlossen in 11.81s (Backend: cuml)\n",
      "02:40:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:41:04 [INFO]   Training abgeschlossen in 12.00s (Backend: cuml)\n",
      "02:42:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:42:16 [INFO]   Training abgeschlossen in 12.37s (Backend: cuml)\n",
      "02:43:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:43:27 [INFO]   Training abgeschlossen in 12.52s (Backend: cuml)\n",
      "02:44:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:44:37 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "02:45:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:45:47 [INFO]   Training abgeschlossen in 12.93s (Backend: cuml)\n",
      "02:46:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:46:56 [INFO]   Training abgeschlossen in 13.25s (Backend: cuml)\n",
      "02:47:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:48:05 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "02:49:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:49:14 [INFO]   Training abgeschlossen in 13.62s (Backend: cuml)\n",
      "02:50:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:50:23 [INFO]   Training abgeschlossen in 13.84s (Backend: cuml)\n",
      "02:51:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:51:31 [INFO]   Training abgeschlossen in 14.06s (Backend: cuml)\n",
      "02:52:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:52:39 [INFO]   Training abgeschlossen in 14.33s (Backend: cuml)\n",
      "02:53:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:53:47 [INFO]   Training abgeschlossen in 14.45s (Backend: cuml)\n",
      "02:54:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:54:54 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "02:55:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:56:01 [INFO]   Training abgeschlossen in 14.63s (Backend: cuml)\n",
      "02:56:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:57:08 [INFO]   Training abgeschlossen in 14.80s (Backend: cuml)\n",
      "02:58:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:58:15 [INFO]   Training abgeschlossen in 15.12s (Backend: cuml)\n",
      "02:59:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:59:21 [INFO]   Training abgeschlossen in 15.20s (Backend: cuml)\n",
      "03:00:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:00:27 [INFO]   Training abgeschlossen in 15.38s (Backend: cuml)\n",
      "03:01:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:01:33 [INFO]   Training abgeschlossen in 15.58s (Backend: cuml)\n",
      "03:02:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:02:38 [INFO]   Training abgeschlossen in 16.06s (Backend: cuml)\n",
      "03:03:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:03:43 [INFO]   Training abgeschlossen in 16.07s (Backend: cuml)\n",
      "03:04:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:04:48 [INFO]   Training abgeschlossen in 16.25s (Backend: cuml)\n",
      "03:05:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:05:53 [INFO]   Training abgeschlossen in 16.54s (Backend: cuml)\n",
      "03:06:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:06:57 [INFO]   Training abgeschlossen in 16.79s (Backend: cuml)\n",
      "03:07:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:08:01 [INFO]   Training abgeschlossen in 16.89s (Backend: cuml)\n",
      "03:08:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:09:04 [INFO]   Training abgeschlossen in 17.05s (Backend: cuml)\n",
      "03:09:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:10:08 [INFO]   Training abgeschlossen in 17.37s (Backend: cuml)\n",
      "03:10:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:11:11 [INFO]   Training abgeschlossen in 17.53s (Backend: cuml)\n",
      "03:11:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:12:13 [INFO]   Training abgeschlossen in 17.74s (Backend: cuml)\n",
      "03:12:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:13:16 [INFO]   Training abgeschlossen in 18.08s (Backend: cuml)\n",
      "03:14:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:14:18 [INFO]   Training abgeschlossen in 18.39s (Backend: cuml)\n",
      "03:15:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:15:20 [INFO]   Training abgeschlossen in 18.49s (Backend: cuml)\n",
      "03:16:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:16:21 [INFO]   Training abgeschlossen in 18.67s (Backend: cuml)\n",
      "03:17:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:17:23 [INFO]   Training abgeschlossen in 18.91s (Backend: cuml)\n",
      "03:18:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:18:24 [INFO]   Training abgeschlossen in 19.02s (Backend: cuml)\n",
      "03:19:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:19:24 [INFO]   Training abgeschlossen in 19.37s (Backend: cuml)\n",
      "03:20:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:20:25 [INFO]   Training abgeschlossen in 19.49s (Backend: cuml)\n",
      "03:21:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:21:24 [INFO]   Training abgeschlossen in 19.65s (Backend: cuml)\n",
      "03:22:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:22:24 [INFO]   Training abgeschlossen in 19.91s (Backend: cuml)\n",
      "03:23:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:23:23 [INFO]   Training abgeschlossen in 20.06s (Backend: cuml)\n",
      "03:24:02 [INFO]     36,000 labeled → Accuracy: 0.8862 (Train: 20.1s, Query: 27.16s) | GPU: 2.8/8.0 GB\n",
      "03:24:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:24:22 [INFO]   Training abgeschlossen in 20.20s (Backend: cuml)\n",
      "03:24:33 [INFO]     Final: 36,000 labeled → Accuracy: 0.8862, F1: 0.8855\n",
      "03:24:33 [INFO]   Run 2/5\n",
      "03:24:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:24:38 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "03:25:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:25:50 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "03:26:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "03:27:02 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "03:28:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:28:14 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "03:29:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:29:26 [INFO]   Training abgeschlossen in 5.38s (Backend: cuml)\n",
      "03:30:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:30:38 [INFO]   Training abgeschlossen in 5.72s (Backend: cuml)\n",
      "03:31:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "03:31:50 [INFO]   Training abgeschlossen in 5.93s (Backend: cuml)\n",
      "03:32:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:33:02 [INFO]   Training abgeschlossen in 6.19s (Backend: cuml)\n",
      "03:34:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:34:15 [INFO]   Training abgeschlossen in 6.65s (Backend: cuml)\n",
      "03:35:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:35:28 [INFO]   Training abgeschlossen in 6.97s (Backend: cuml)\n",
      "03:36:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:36:41 [INFO]   Training abgeschlossen in 7.35s (Backend: cuml)\n",
      "03:37:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:37:54 [INFO]   Training abgeschlossen in 7.48s (Backend: cuml)\n",
      "03:39:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "03:39:08 [INFO]   Training abgeschlossen in 7.80s (Backend: cuml)\n",
      "03:40:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:40:21 [INFO]   Training abgeschlossen in 7.99s (Backend: cuml)\n",
      "03:41:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:41:33 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "03:42:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:42:46 [INFO]   Training abgeschlossen in 8.53s (Backend: cuml)\n",
      "03:43:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:43:58 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "03:45:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:45:12 [INFO]   Training abgeschlossen in 9.02s (Backend: cuml)\n",
      "03:46:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:46:25 [INFO]   Training abgeschlossen in 9.31s (Backend: cuml)\n",
      "03:47:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "03:47:39 [INFO]   Training abgeschlossen in 9.52s (Backend: cuml)\n",
      "03:48:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:48:52 [INFO]   Training abgeschlossen in 9.66s (Backend: cuml)\n",
      "03:49:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:50:05 [INFO]   Training abgeschlossen in 9.94s (Backend: cuml)\n",
      "03:51:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:51:17 [INFO]   Training abgeschlossen in 10.36s (Backend: cuml)\n",
      "03:52:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:52:29 [INFO]   Training abgeschlossen in 10.34s (Backend: cuml)\n",
      "03:53:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:53:42 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "03:54:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:54:54 [INFO]   Training abgeschlossen in 10.76s (Backend: cuml)\n",
      "03:55:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:56:06 [INFO]   Training abgeschlossen in 11.12s (Backend: cuml)\n",
      "03:57:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "03:57:18 [INFO]   Training abgeschlossen in 11.20s (Backend: cuml)\n",
      "03:58:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:58:30 [INFO]   Training abgeschlossen in 11.45s (Backend: cuml)\n",
      "03:59:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "03:59:42 [INFO]   Training abgeschlossen in 11.69s (Backend: cuml)\n",
      "04:00:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:00:53 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "04:01:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:02:05 [INFO]   Training abgeschlossen in 12.11s (Backend: cuml)\n",
      "04:03:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:03:16 [INFO]   Training abgeschlossen in 12.31s (Backend: cuml)\n",
      "04:04:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:04:27 [INFO]   Training abgeschlossen in 12.52s (Backend: cuml)\n",
      "04:05:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:05:38 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "04:06:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:06:47 [INFO]   Training abgeschlossen in 12.99s (Backend: cuml)\n",
      "04:07:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:07:57 [INFO]   Training abgeschlossen in 13.16s (Backend: cuml)\n",
      "04:08:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:09:06 [INFO]   Training abgeschlossen in 13.42s (Backend: cuml)\n",
      "04:10:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:10:15 [INFO]   Training abgeschlossen in 13.71s (Backend: cuml)\n",
      "04:11:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:11:24 [INFO]   Training abgeschlossen in 14.00s (Backend: cuml)\n",
      "04:12:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:12:32 [INFO]   Training abgeschlossen in 14.03s (Backend: cuml)\n",
      "04:13:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:13:40 [INFO]   Training abgeschlossen in 14.25s (Backend: cuml)\n",
      "04:14:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:14:48 [INFO]   Training abgeschlossen in 14.45s (Backend: cuml)\n",
      "04:15:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "04:15:55 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "04:16:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:17:02 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "04:17:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:18:09 [INFO]   Training abgeschlossen in 14.76s (Backend: cuml)\n",
      "04:19:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:19:15 [INFO]   Training abgeschlossen in 14.96s (Backend: cuml)\n",
      "04:20:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:20:21 [INFO]   Training abgeschlossen in 15.16s (Backend: cuml)\n",
      "04:21:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:21:27 [INFO]   Training abgeschlossen in 15.39s (Backend: cuml)\n",
      "04:22:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:22:33 [INFO]   Training abgeschlossen in 15.69s (Backend: cuml)\n",
      "04:23:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:23:39 [INFO]   Training abgeschlossen in 16.25s (Backend: cuml)\n",
      "04:24:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:24:44 [INFO]   Training abgeschlossen in 16.14s (Backend: cuml)\n",
      "04:25:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:25:48 [INFO]   Training abgeschlossen in 16.29s (Backend: cuml)\n",
      "04:26:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:26:53 [INFO]   Training abgeschlossen in 16.46s (Backend: cuml)\n",
      "04:27:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:27:57 [INFO]   Training abgeschlossen in 16.81s (Backend: cuml)\n",
      "04:28:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:29:01 [INFO]   Training abgeschlossen in 16.88s (Backend: cuml)\n",
      "04:29:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:30:05 [INFO]   Training abgeschlossen in 17.19s (Backend: cuml)\n",
      "04:30:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:31:08 [INFO]   Training abgeschlossen in 17.30s (Backend: cuml)\n",
      "04:31:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:32:11 [INFO]   Training abgeschlossen in 17.55s (Backend: cuml)\n",
      "04:32:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:33:14 [INFO]   Training abgeschlossen in 17.83s (Backend: cuml)\n",
      "04:33:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:34:16 [INFO]   Training abgeschlossen in 18.08s (Backend: cuml)\n",
      "04:35:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:35:19 [INFO]   Training abgeschlossen in 18.28s (Backend: cuml)\n",
      "04:36:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:36:21 [INFO]   Training abgeschlossen in 18.53s (Backend: cuml)\n",
      "04:37:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:37:22 [INFO]   Training abgeschlossen in 18.63s (Backend: cuml)\n",
      "04:38:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:38:24 [INFO]   Training abgeschlossen in 18.82s (Backend: cuml)\n",
      "04:39:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:39:25 [INFO]   Training abgeschlossen in 19.09s (Backend: cuml)\n",
      "04:40:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:40:25 [INFO]   Training abgeschlossen in 19.42s (Backend: cuml)\n",
      "04:41:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:41:26 [INFO]   Training abgeschlossen in 19.47s (Backend: cuml)\n",
      "04:42:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:42:26 [INFO]   Training abgeschlossen in 19.68s (Backend: cuml)\n",
      "04:43:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:43:26 [INFO]   Training abgeschlossen in 19.87s (Backend: cuml)\n",
      "04:44:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:44:25 [INFO]   Training abgeschlossen in 20.11s (Backend: cuml)\n",
      "04:45:04 [INFO]     36,000 labeled → Accuracy: 0.8861 (Train: 20.1s, Query: 27.26s) | GPU: 2.8/8.0 GB\n",
      "04:45:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:45:24 [INFO]   Training abgeschlossen in 20.30s (Backend: cuml)\n",
      "04:45:35 [INFO]     Final: 36,000 labeled → Accuracy: 0.8857, F1: 0.8850\n",
      "04:45:36 [INFO]   Run 3/5\n",
      "04:45:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "04:45:41 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "04:46:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:46:52 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "04:47:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "04:48:04 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "04:49:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:49:16 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "04:50:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:50:28 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "04:51:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:51:40 [INFO]   Training abgeschlossen in 5.74s (Backend: cuml)\n",
      "04:52:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "04:52:52 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "04:53:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:54:05 [INFO]   Training abgeschlossen in 6.22s (Backend: cuml)\n",
      "04:55:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:55:17 [INFO]   Training abgeschlossen in 6.46s (Backend: cuml)\n",
      "04:56:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:56:30 [INFO]   Training abgeschlossen in 6.82s (Backend: cuml)\n",
      "04:57:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:57:43 [INFO]   Training abgeschlossen in 7.46s (Backend: cuml)\n",
      "04:58:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "04:58:56 [INFO]   Training abgeschlossen in 7.49s (Backend: cuml)\n",
      "05:00:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "05:00:08 [INFO]   Training abgeschlossen in 7.70s (Backend: cuml)\n",
      "05:01:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:01:21 [INFO]   Training abgeschlossen in 7.97s (Backend: cuml)\n",
      "05:02:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:02:34 [INFO]   Training abgeschlossen in 8.35s (Backend: cuml)\n",
      "05:03:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:03:47 [INFO]   Training abgeschlossen in 8.50s (Backend: cuml)\n",
      "05:04:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:05:00 [INFO]   Training abgeschlossen in 8.69s (Backend: cuml)\n",
      "05:06:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:06:12 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "05:07:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:07:25 [INFO]   Training abgeschlossen in 9.23s (Backend: cuml)\n",
      "05:08:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:08:37 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "05:09:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "05:09:49 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "05:10:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:11:01 [INFO]   Training abgeschlossen in 10.01s (Backend: cuml)\n",
      "05:12:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:12:14 [INFO]   Training abgeschlossen in 10.16s (Backend: cuml)\n",
      "05:13:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:13:26 [INFO]   Training abgeschlossen in 10.39s (Backend: cuml)\n",
      "05:14:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:14:38 [INFO]   Training abgeschlossen in 10.54s (Backend: cuml)\n",
      "05:15:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:15:50 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "05:16:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "05:17:02 [INFO]   Training abgeschlossen in 11.03s (Backend: cuml)\n",
      "05:18:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:18:14 [INFO]   Training abgeschlossen in 11.17s (Backend: cuml)\n",
      "05:19:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:19:25 [INFO]   Training abgeschlossen in 11.42s (Backend: cuml)\n",
      "05:20:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:20:36 [INFO]   Training abgeschlossen in 11.67s (Backend: cuml)\n",
      "05:21:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:21:48 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "05:22:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:22:59 [INFO]   Training abgeschlossen in 12.04s (Backend: cuml)\n",
      "05:23:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:24:10 [INFO]   Training abgeschlossen in 12.32s (Backend: cuml)\n",
      "05:25:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:25:22 [INFO]   Training abgeschlossen in 12.63s (Backend: cuml)\n",
      "05:26:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:26:32 [INFO]   Training abgeschlossen in 12.74s (Backend: cuml)\n",
      "05:27:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:27:42 [INFO]   Training abgeschlossen in 12.97s (Backend: cuml)\n",
      "05:28:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:28:51 [INFO]   Training abgeschlossen in 13.18s (Backend: cuml)\n",
      "05:29:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:30:01 [INFO]   Training abgeschlossen in 13.44s (Backend: cuml)\n",
      "05:30:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:31:10 [INFO]   Training abgeschlossen in 13.53s (Backend: cuml)\n",
      "05:32:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:32:18 [INFO]   Training abgeschlossen in 13.74s (Backend: cuml)\n",
      "05:33:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:33:26 [INFO]   Training abgeschlossen in 13.96s (Backend: cuml)\n",
      "05:34:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:34:34 [INFO]   Training abgeschlossen in 14.26s (Backend: cuml)\n",
      "05:35:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:35:42 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "05:36:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:36:49 [INFO]   Training abgeschlossen in 14.27s (Backend: cuml)\n",
      "05:37:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:37:56 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "05:38:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:39:02 [INFO]   Training abgeschlossen in 14.67s (Backend: cuml)\n",
      "05:39:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "05:40:08 [INFO]   Training abgeschlossen in 14.91s (Backend: cuml)\n",
      "05:40:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:41:15 [INFO]   Training abgeschlossen in 15.36s (Backend: cuml)\n",
      "05:42:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:42:21 [INFO]   Training abgeschlossen in 15.39s (Backend: cuml)\n",
      "05:43:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:43:26 [INFO]   Training abgeschlossen in 15.67s (Backend: cuml)\n",
      "05:44:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:44:32 [INFO]   Training abgeschlossen in 16.03s (Backend: cuml)\n",
      "05:45:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:45:37 [INFO]   Training abgeschlossen in 16.09s (Backend: cuml)\n",
      "05:46:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:46:41 [INFO]   Training abgeschlossen in 16.22s (Backend: cuml)\n",
      "05:47:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:47:46 [INFO]   Training abgeschlossen in 16.44s (Backend: cuml)\n",
      "05:48:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:48:50 [INFO]   Training abgeschlossen in 16.72s (Backend: cuml)\n",
      "05:49:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:49:54 [INFO]   Training abgeschlossen in 16.99s (Backend: cuml)\n",
      "05:50:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:50:57 [INFO]   Training abgeschlossen in 17.16s (Backend: cuml)\n",
      "05:51:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:52:01 [INFO]   Training abgeschlossen in 17.25s (Backend: cuml)\n",
      "05:52:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:53:04 [INFO]   Training abgeschlossen in 17.53s (Backend: cuml)\n",
      "05:53:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:54:07 [INFO]   Training abgeschlossen in 17.83s (Backend: cuml)\n",
      "05:54:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:55:09 [INFO]   Training abgeschlossen in 18.03s (Backend: cuml)\n",
      "05:55:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:56:11 [INFO]   Training abgeschlossen in 18.22s (Backend: cuml)\n",
      "05:56:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:57:13 [INFO]   Training abgeschlossen in 18.41s (Backend: cuml)\n",
      "05:57:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:58:15 [INFO]   Training abgeschlossen in 18.84s (Backend: cuml)\n",
      "05:58:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "05:59:16 [INFO]   Training abgeschlossen in 19.03s (Backend: cuml)\n",
      "05:59:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:00:17 [INFO]   Training abgeschlossen in 18.99s (Backend: cuml)\n",
      "06:00:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:01:18 [INFO]   Training abgeschlossen in 19.35s (Backend: cuml)\n",
      "06:01:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:02:18 [INFO]   Training abgeschlossen in 19.47s (Backend: cuml)\n",
      "06:02:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:03:18 [INFO]   Training abgeschlossen in 19.67s (Backend: cuml)\n",
      "06:03:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:04:18 [INFO]   Training abgeschlossen in 19.86s (Backend: cuml)\n",
      "06:04:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:05:17 [INFO]   Training abgeschlossen in 20.08s (Backend: cuml)\n",
      "06:05:56 [INFO]     36,000 labeled → Accuracy: 0.8866 (Train: 20.1s, Query: 27.24s) | GPU: 2.8/8.0 GB\n",
      "06:05:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:06:17 [INFO]   Training abgeschlossen in 20.34s (Backend: cuml)\n",
      "06:06:28 [INFO]     Final: 36,000 labeled → Accuracy: 0.8867, F1: 0.8860\n",
      "06:06:28 [INFO]   Run 4/5\n",
      "06:06:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "06:06:33 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "06:07:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:07:45 [INFO]   Training abgeschlossen in 4.83s (Backend: cuml)\n",
      "06:08:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "06:08:56 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "06:10:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:10:08 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "06:11:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:11:20 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "06:12:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:12:32 [INFO]   Training abgeschlossen in 5.76s (Backend: cuml)\n",
      "06:13:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "06:13:44 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "06:14:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:14:57 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "06:16:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:16:10 [INFO]   Training abgeschlossen in 6.75s (Backend: cuml)\n",
      "06:17:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:17:22 [INFO]   Training abgeschlossen in 6.93s (Backend: cuml)\n",
      "06:18:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:18:35 [INFO]   Training abgeschlossen in 7.35s (Backend: cuml)\n",
      "06:19:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:19:48 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "06:20:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "06:21:01 [INFO]   Training abgeschlossen in 7.92s (Backend: cuml)\n",
      "06:22:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:22:13 [INFO]   Training abgeschlossen in 8.09s (Backend: cuml)\n",
      "06:23:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:23:26 [INFO]   Training abgeschlossen in 8.33s (Backend: cuml)\n",
      "06:24:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:24:39 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "06:25:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:25:51 [INFO]   Training abgeschlossen in 8.84s (Backend: cuml)\n",
      "06:26:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:27:04 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "06:28:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:28:16 [INFO]   Training abgeschlossen in 9.18s (Backend: cuml)\n",
      "06:29:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "06:29:29 [INFO]   Training abgeschlossen in 9.61s (Backend: cuml)\n",
      "06:30:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:30:41 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "06:31:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:31:54 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "06:32:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:33:06 [INFO]   Training abgeschlossen in 10.10s (Backend: cuml)\n",
      "06:34:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:34:18 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "06:35:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:35:29 [INFO]   Training abgeschlossen in 10.52s (Backend: cuml)\n",
      "06:36:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:36:41 [INFO]   Training abgeschlossen in 10.71s (Backend: cuml)\n",
      "06:37:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "06:37:52 [INFO]   Training abgeschlossen in 11.10s (Backend: cuml)\n",
      "06:38:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:39:05 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "06:40:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:40:17 [INFO]   Training abgeschlossen in 11.37s (Backend: cuml)\n",
      "06:41:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:41:28 [INFO]   Training abgeschlossen in 11.63s (Backend: cuml)\n",
      "06:42:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:42:40 [INFO]   Training abgeschlossen in 12.01s (Backend: cuml)\n",
      "06:43:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:43:51 [INFO]   Training abgeschlossen in 12.07s (Backend: cuml)\n",
      "06:44:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:45:02 [INFO]   Training abgeschlossen in 12.26s (Backend: cuml)\n",
      "06:46:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:46:13 [INFO]   Training abgeschlossen in 12.48s (Backend: cuml)\n",
      "06:47:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:47:24 [INFO]   Training abgeschlossen in 12.94s (Backend: cuml)\n",
      "06:48:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:48:34 [INFO]   Training abgeschlossen in 13.01s (Backend: cuml)\n",
      "06:49:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:49:43 [INFO]   Training abgeschlossen in 13.11s (Backend: cuml)\n",
      "06:50:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:50:52 [INFO]   Training abgeschlossen in 13.34s (Backend: cuml)\n",
      "06:51:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:52:01 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "06:52:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:53:10 [INFO]   Training abgeschlossen in 13.95s (Backend: cuml)\n",
      "06:54:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:54:18 [INFO]   Training abgeschlossen in 14.01s (Backend: cuml)\n",
      "06:55:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:55:26 [INFO]   Training abgeschlossen in 14.22s (Backend: cuml)\n",
      "06:56:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:56:34 [INFO]   Training abgeschlossen in 14.38s (Backend: cuml)\n",
      "06:57:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:57:41 [INFO]   Training abgeschlossen in 14.32s (Backend: cuml)\n",
      "06:58:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:58:48 [INFO]   Training abgeschlossen in 14.61s (Backend: cuml)\n",
      "06:59:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "06:59:55 [INFO]   Training abgeschlossen in 14.84s (Backend: cuml)\n",
      "07:00:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:01:02 [INFO]   Training abgeschlossen in 15.02s (Backend: cuml)\n",
      "07:01:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:02:08 [INFO]   Training abgeschlossen in 15.23s (Backend: cuml)\n",
      "07:02:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:03:14 [INFO]   Training abgeschlossen in 15.37s (Backend: cuml)\n",
      "07:04:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:04:19 [INFO]   Training abgeschlossen in 15.58s (Backend: cuml)\n",
      "07:05:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:05:25 [INFO]   Training abgeschlossen in 16.17s (Backend: cuml)\n",
      "07:06:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:06:30 [INFO]   Training abgeschlossen in 16.04s (Backend: cuml)\n",
      "07:07:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:07:35 [INFO]   Training abgeschlossen in 16.22s (Backend: cuml)\n",
      "07:08:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:08:40 [INFO]   Training abgeschlossen in 16.41s (Backend: cuml)\n",
      "07:09:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:09:44 [INFO]   Training abgeschlossen in 16.66s (Backend: cuml)\n",
      "07:10:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:10:47 [INFO]   Training abgeschlossen in 16.87s (Backend: cuml)\n",
      "07:11:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:11:51 [INFO]   Training abgeschlossen in 17.07s (Backend: cuml)\n",
      "07:12:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:12:55 [INFO]   Training abgeschlossen in 17.42s (Backend: cuml)\n",
      "07:13:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:13:58 [INFO]   Training abgeschlossen in 17.68s (Backend: cuml)\n",
      "07:14:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:15:01 [INFO]   Training abgeschlossen in 17.86s (Backend: cuml)\n",
      "07:15:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:16:03 [INFO]   Training abgeschlossen in 18.03s (Backend: cuml)\n",
      "07:16:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:17:05 [INFO]   Training abgeschlossen in 18.22s (Backend: cuml)\n",
      "07:17:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:18:07 [INFO]   Training abgeschlossen in 18.39s (Backend: cuml)\n",
      "07:18:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:19:09 [INFO]   Training abgeschlossen in 18.63s (Backend: cuml)\n",
      "07:19:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:20:10 [INFO]   Training abgeschlossen in 18.83s (Backend: cuml)\n",
      "07:20:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:21:11 [INFO]   Training abgeschlossen in 19.01s (Backend: cuml)\n",
      "07:21:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:22:12 [INFO]   Training abgeschlossen in 19.35s (Backend: cuml)\n",
      "07:22:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:23:13 [INFO]   Training abgeschlossen in 19.49s (Backend: cuml)\n",
      "07:23:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:24:13 [INFO]   Training abgeschlossen in 19.69s (Backend: cuml)\n",
      "07:24:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:25:12 [INFO]   Training abgeschlossen in 19.89s (Backend: cuml)\n",
      "07:25:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:26:12 [INFO]   Training abgeschlossen in 20.15s (Backend: cuml)\n",
      "07:26:50 [INFO]     36,000 labeled → Accuracy: 0.8868 (Train: 20.2s, Query: 27.25s) | GPU: 2.8/8.0 GB\n",
      "07:26:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:27:11 [INFO]   Training abgeschlossen in 20.38s (Backend: cuml)\n",
      "07:27:22 [INFO]     Final: 36,000 labeled → Accuracy: 0.8858, F1: 0.8852\n",
      "07:27:22 [INFO]   Run 5/5\n",
      "07:27:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "07:27:27 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "07:28:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:28:39 [INFO]   Training abgeschlossen in 4.89s (Backend: cuml)\n",
      "07:29:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "07:29:51 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "07:30:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:31:03 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "07:32:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:32:14 [INFO]   Training abgeschlossen in 5.36s (Backend: cuml)\n",
      "07:33:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:33:26 [INFO]   Training abgeschlossen in 5.58s (Backend: cuml)\n",
      "07:34:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "07:34:38 [INFO]   Training abgeschlossen in 5.97s (Backend: cuml)\n",
      "07:35:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:35:51 [INFO]   Training abgeschlossen in 6.25s (Backend: cuml)\n",
      "07:36:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:37:03 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "07:38:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:38:16 [INFO]   Training abgeschlossen in 6.85s (Backend: cuml)\n",
      "07:39:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:39:29 [INFO]   Training abgeschlossen in 7.52s (Backend: cuml)\n",
      "07:40:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:40:42 [INFO]   Training abgeschlossen in 7.54s (Backend: cuml)\n",
      "07:41:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "07:41:55 [INFO]   Training abgeschlossen in 7.80s (Backend: cuml)\n",
      "07:42:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:43:07 [INFO]   Training abgeschlossen in 8.04s (Backend: cuml)\n",
      "07:44:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:44:20 [INFO]   Training abgeschlossen in 8.48s (Backend: cuml)\n",
      "07:45:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:45:32 [INFO]   Training abgeschlossen in 8.43s (Backend: cuml)\n",
      "07:46:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:46:45 [INFO]   Training abgeschlossen in 8.71s (Backend: cuml)\n",
      "07:47:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:47:58 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "07:49:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:49:10 [INFO]   Training abgeschlossen in 9.21s (Backend: cuml)\n",
      "07:50:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "07:50:22 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "07:51:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:51:35 [INFO]   Training abgeschlossen in 9.63s (Backend: cuml)\n",
      "07:52:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:52:48 [INFO]   Training abgeschlossen in 10.15s (Backend: cuml)\n",
      "07:53:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:53:59 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "07:55:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:55:12 [INFO]   Training abgeschlossen in 10.30s (Backend: cuml)\n",
      "07:56:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:56:25 [INFO]   Training abgeschlossen in 10.49s (Backend: cuml)\n",
      "07:57:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:57:38 [INFO]   Training abgeschlossen in 10.81s (Backend: cuml)\n",
      "07:58:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "07:58:49 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "07:59:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:00:01 [INFO]   Training abgeschlossen in 11.17s (Backend: cuml)\n",
      "08:01:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:01:13 [INFO]   Training abgeschlossen in 11.57s (Backend: cuml)\n",
      "08:02:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:02:25 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "08:03:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:03:36 [INFO]   Training abgeschlossen in 11.81s (Backend: cuml)\n",
      "08:04:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:04:47 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "08:05:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:05:59 [INFO]   Training abgeschlossen in 12.36s (Backend: cuml)\n",
      "08:06:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:07:10 [INFO]   Training abgeschlossen in 12.48s (Backend: cuml)\n",
      "08:08:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:08:20 [INFO]   Training abgeschlossen in 12.69s (Backend: cuml)\n",
      "08:09:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:09:30 [INFO]   Training abgeschlossen in 12.93s (Backend: cuml)\n",
      "08:10:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:10:39 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "08:11:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:11:49 [INFO]   Training abgeschlossen in 13.44s (Backend: cuml)\n",
      "08:12:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:12:57 [INFO]   Training abgeschlossen in 13.57s (Backend: cuml)\n",
      "08:13:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:14:06 [INFO]   Training abgeschlossen in 13.74s (Backend: cuml)\n",
      "08:15:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:15:14 [INFO]   Training abgeschlossen in 14.00s (Backend: cuml)\n",
      "08:16:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:16:22 [INFO]   Training abgeschlossen in 14.26s (Backend: cuml)\n",
      "08:17:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:17:30 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "08:18:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:18:38 [INFO]   Training abgeschlossen in 14.33s (Backend: cuml)\n",
      "08:19:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:19:45 [INFO]   Training abgeschlossen in 14.53s (Backend: cuml)\n",
      "08:20:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "08:20:51 [INFO]   Training abgeschlossen in 14.76s (Backend: cuml)\n",
      "08:21:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:21:58 [INFO]   Training abgeschlossen in 15.03s (Backend: cuml)\n",
      "08:22:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:23:04 [INFO]   Training abgeschlossen in 15.36s (Backend: cuml)\n",
      "08:23:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:24:10 [INFO]   Training abgeschlossen in 15.60s (Backend: cuml)\n",
      "08:25:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:25:16 [INFO]   Training abgeschlossen in 15.59s (Backend: cuml)\n",
      "08:26:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:26:21 [INFO]   Training abgeschlossen in 16.01s (Backend: cuml)\n",
      "08:27:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:27:26 [INFO]   Training abgeschlossen in 15.96s (Backend: cuml)\n",
      "08:28:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:28:31 [INFO]   Training abgeschlossen in 16.18s (Backend: cuml)\n",
      "08:29:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:29:35 [INFO]   Training abgeschlossen in 16.46s (Backend: cuml)\n",
      "08:30:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:30:39 [INFO]   Training abgeschlossen in 16.69s (Backend: cuml)\n",
      "08:31:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:31:43 [INFO]   Training abgeschlossen in 17.03s (Backend: cuml)\n",
      "08:32:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:32:47 [INFO]   Training abgeschlossen in 17.08s (Backend: cuml)\n",
      "08:33:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:33:50 [INFO]   Training abgeschlossen in 17.30s (Backend: cuml)\n",
      "08:34:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:34:53 [INFO]   Training abgeschlossen in 17.59s (Backend: cuml)\n",
      "08:35:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:35:55 [INFO]   Training abgeschlossen in 17.72s (Backend: cuml)\n",
      "08:36:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:36:58 [INFO]   Training abgeschlossen in 17.98s (Backend: cuml)\n",
      "08:37:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:38:00 [INFO]   Training abgeschlossen in 18.27s (Backend: cuml)\n",
      "08:38:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:39:02 [INFO]   Training abgeschlossen in 18.55s (Backend: cuml)\n",
      "08:39:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:40:04 [INFO]   Training abgeschlossen in 18.58s (Backend: cuml)\n",
      "08:40:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:41:05 [INFO]   Training abgeschlossen in 18.98s (Backend: cuml)\n",
      "08:41:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:42:06 [INFO]   Training abgeschlossen in 19.13s (Backend: cuml)\n",
      "08:42:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:43:07 [INFO]   Training abgeschlossen in 19.61s (Backend: cuml)\n",
      "08:43:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:44:08 [INFO]   Training abgeschlossen in 19.64s (Backend: cuml)\n",
      "08:44:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:45:08 [INFO]   Training abgeschlossen in 19.79s (Backend: cuml)\n",
      "08:45:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:46:08 [INFO]   Training abgeschlossen in 20.01s (Backend: cuml)\n",
      "08:46:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:47:07 [INFO]   Training abgeschlossen in 20.22s (Backend: cuml)\n",
      "08:47:46 [INFO]     36,000 labeled → Accuracy: 0.8862 (Train: 20.2s, Query: 27.12s) | GPU: 2.8/8.0 GB\n",
      "08:47:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:48:06 [INFO]   Training abgeschlossen in 20.38s (Backend: cuml)\n",
      "08:48:17 [INFO]     Final: 36,000 labeled → Accuracy: 0.8861, F1: 0.8855\n",
      "08:48:18 [INFO] \n",
      "GPU-SVM + Least Confidence - Budget: 80% (48,000 Samples)\n",
      "08:48:18 [INFO]   Run 1/5\n",
      "08:48:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "08:48:23 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "08:49:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:49:34 [INFO]   Training abgeschlossen in 4.93s (Backend: cuml)\n",
      "08:50:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "08:50:46 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "08:51:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:51:58 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "08:53:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:53:10 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "08:54:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:54:22 [INFO]   Training abgeschlossen in 5.84s (Backend: cuml)\n",
      "08:55:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "08:55:34 [INFO]   Training abgeschlossen in 5.96s (Backend: cuml)\n",
      "08:56:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:56:47 [INFO]   Training abgeschlossen in 6.19s (Backend: cuml)\n",
      "08:57:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:57:59 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "08:59:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "08:59:12 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "09:00:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:00:25 [INFO]   Training abgeschlossen in 7.25s (Backend: cuml)\n",
      "09:01:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:01:38 [INFO]   Training abgeschlossen in 7.52s (Backend: cuml)\n",
      "09:02:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "09:02:51 [INFO]   Training abgeschlossen in 7.77s (Backend: cuml)\n",
      "09:03:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:04:04 [INFO]   Training abgeschlossen in 8.05s (Backend: cuml)\n",
      "09:05:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:05:16 [INFO]   Training abgeschlossen in 8.32s (Backend: cuml)\n",
      "09:06:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:06:29 [INFO]   Training abgeschlossen in 8.49s (Backend: cuml)\n",
      "09:07:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:07:42 [INFO]   Training abgeschlossen in 8.86s (Backend: cuml)\n",
      "09:08:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:08:54 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "09:09:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:10:06 [INFO]   Training abgeschlossen in 9.18s (Backend: cuml)\n",
      "09:11:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "09:11:19 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "09:12:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:12:32 [INFO]   Training abgeschlossen in 9.74s (Backend: cuml)\n",
      "09:13:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:13:44 [INFO]   Training abgeschlossen in 9.94s (Backend: cuml)\n",
      "09:14:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:14:56 [INFO]   Training abgeschlossen in 10.13s (Backend: cuml)\n",
      "09:15:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:16:07 [INFO]   Training abgeschlossen in 10.36s (Backend: cuml)\n",
      "09:17:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:17:20 [INFO]   Training abgeschlossen in 10.85s (Backend: cuml)\n",
      "09:18:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:18:31 [INFO]   Training abgeschlossen in 10.78s (Backend: cuml)\n",
      "09:19:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:19:43 [INFO]   Training abgeschlossen in 10.97s (Backend: cuml)\n",
      "09:20:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "09:20:55 [INFO]   Training abgeschlossen in 11.19s (Backend: cuml)\n",
      "09:21:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:22:07 [INFO]   Training abgeschlossen in 11.51s (Backend: cuml)\n",
      "09:23:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:23:19 [INFO]   Training abgeschlossen in 11.59s (Backend: cuml)\n",
      "09:24:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:24:30 [INFO]   Training abgeschlossen in 11.80s (Backend: cuml)\n",
      "09:25:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:25:42 [INFO]   Training abgeschlossen in 12.06s (Backend: cuml)\n",
      "09:26:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:26:53 [INFO]   Training abgeschlossen in 12.54s (Backend: cuml)\n",
      "09:27:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:28:04 [INFO]   Training abgeschlossen in 12.47s (Backend: cuml)\n",
      "09:29:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:29:14 [INFO]   Training abgeschlossen in 12.75s (Backend: cuml)\n",
      "09:30:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:30:24 [INFO]   Training abgeschlossen in 12.91s (Backend: cuml)\n",
      "09:31:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:31:33 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "09:32:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:32:43 [INFO]   Training abgeschlossen in 13.42s (Backend: cuml)\n",
      "09:33:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:33:51 [INFO]   Training abgeschlossen in 13.50s (Backend: cuml)\n",
      "09:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:34:59 [INFO]   Training abgeschlossen in 13.76s (Backend: cuml)\n",
      "09:35:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:36:08 [INFO]   Training abgeschlossen in 13.98s (Backend: cuml)\n",
      "09:37:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:37:16 [INFO]   Training abgeschlossen in 14.33s (Backend: cuml)\n",
      "09:38:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:38:24 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "09:39:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:39:31 [INFO]   Training abgeschlossen in 14.34s (Backend: cuml)\n",
      "09:40:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "09:40:38 [INFO]   Training abgeschlossen in 14.52s (Backend: cuml)\n",
      "09:41:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:41:45 [INFO]   Training abgeschlossen in 14.75s (Backend: cuml)\n",
      "09:42:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:42:51 [INFO]   Training abgeschlossen in 14.98s (Backend: cuml)\n",
      "09:43:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:43:57 [INFO]   Training abgeschlossen in 15.32s (Backend: cuml)\n",
      "09:44:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:45:04 [INFO]   Training abgeschlossen in 15.51s (Backend: cuml)\n",
      "09:45:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:46:09 [INFO]   Training abgeschlossen in 15.57s (Backend: cuml)\n",
      "09:46:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:47:14 [INFO]   Training abgeschlossen in 16.01s (Backend: cuml)\n",
      "09:48:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:48:20 [INFO]   Training abgeschlossen in 16.05s (Backend: cuml)\n",
      "09:49:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:49:24 [INFO]   Training abgeschlossen in 16.15s (Backend: cuml)\n",
      "09:50:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:50:29 [INFO]   Training abgeschlossen in 16.64s (Backend: cuml)\n",
      "09:51:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:51:33 [INFO]   Training abgeschlossen in 16.91s (Backend: cuml)\n",
      "09:52:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:52:37 [INFO]   Training abgeschlossen in 16.97s (Backend: cuml)\n",
      "09:53:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:53:41 [INFO]   Training abgeschlossen in 17.24s (Backend: cuml)\n",
      "09:54:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:54:44 [INFO]   Training abgeschlossen in 17.31s (Backend: cuml)\n",
      "09:55:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:55:47 [INFO]   Training abgeschlossen in 17.61s (Backend: cuml)\n",
      "09:56:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:56:50 [INFO]   Training abgeschlossen in 17.83s (Backend: cuml)\n",
      "09:57:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:57:52 [INFO]   Training abgeschlossen in 17.99s (Backend: cuml)\n",
      "09:58:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:58:55 [INFO]   Training abgeschlossen in 18.29s (Backend: cuml)\n",
      "09:59:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "09:59:57 [INFO]   Training abgeschlossen in 18.50s (Backend: cuml)\n",
      "10:00:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:00:58 [INFO]   Training abgeschlossen in 18.88s (Backend: cuml)\n",
      "10:01:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:02:00 [INFO]   Training abgeschlossen in 18.94s (Backend: cuml)\n",
      "10:02:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:03:01 [INFO]   Training abgeschlossen in 19.10s (Backend: cuml)\n",
      "10:03:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:04:02 [INFO]   Training abgeschlossen in 19.39s (Backend: cuml)\n",
      "10:04:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:05:02 [INFO]   Training abgeschlossen in 19.56s (Backend: cuml)\n",
      "10:05:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:06:02 [INFO]   Training abgeschlossen in 19.78s (Backend: cuml)\n",
      "10:06:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:07:02 [INFO]   Training abgeschlossen in 19.94s (Backend: cuml)\n",
      "10:07:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:08:01 [INFO]   Training abgeschlossen in 20.09s (Backend: cuml)\n",
      "10:08:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:09:00 [INFO]   Training abgeschlossen in 20.32s (Backend: cuml)\n",
      "10:09:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:09:59 [INFO]   Training abgeschlossen in 20.49s (Backend: cuml)\n",
      "10:10:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:10:58 [INFO]   Training abgeschlossen in 20.74s (Backend: cuml)\n",
      "10:11:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:11:56 [INFO]   Training abgeschlossen in 20.97s (Backend: cuml)\n",
      "10:12:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:12:54 [INFO]   Training abgeschlossen in 21.25s (Backend: cuml)\n",
      "10:13:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "10:13:51 [INFO]   Training abgeschlossen in 21.24s (Backend: cuml)\n",
      "10:14:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:14:48 [INFO]   Training abgeschlossen in 21.54s (Backend: cuml)\n",
      "10:15:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:15:45 [INFO]   Training abgeschlossen in 21.64s (Backend: cuml)\n",
      "10:16:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:16:42 [INFO]   Training abgeschlossen in 21.81s (Backend: cuml)\n",
      "10:17:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:17:38 [INFO]   Training abgeschlossen in 22.05s (Backend: cuml)\n",
      "10:18:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:18:34 [INFO]   Training abgeschlossen in 22.27s (Backend: cuml)\n",
      "10:19:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:19:29 [INFO]   Training abgeschlossen in 22.49s (Backend: cuml)\n",
      "10:20:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:20:25 [INFO]   Training abgeschlossen in 22.65s (Backend: cuml)\n",
      "10:20:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:21:19 [INFO]   Training abgeschlossen in 22.81s (Backend: cuml)\n",
      "10:21:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:22:14 [INFO]   Training abgeschlossen in 23.10s (Backend: cuml)\n",
      "10:22:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:23:08 [INFO]   Training abgeschlossen in 23.30s (Backend: cuml)\n",
      "10:23:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:24:02 [INFO]   Training abgeschlossen in 23.54s (Backend: cuml)\n",
      "10:24:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:24:55 [INFO]   Training abgeschlossen in 23.60s (Backend: cuml)\n",
      "10:25:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:25:49 [INFO]   Training abgeschlossen in 23.87s (Backend: cuml)\n",
      "10:26:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:26:41 [INFO]   Training abgeschlossen in 24.21s (Backend: cuml)\n",
      "10:27:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:27:34 [INFO]   Training abgeschlossen in 24.25s (Backend: cuml)\n",
      "10:28:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:28:26 [INFO]   Training abgeschlossen in 24.56s (Backend: cuml)\n",
      "10:28:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:29:17 [INFO]   Training abgeschlossen in 24.68s (Backend: cuml)\n",
      "10:29:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:30:08 [INFO]   Training abgeschlossen in 24.95s (Backend: cuml)\n",
      "10:30:34 [INFO]     48,000 labeled → Accuracy: 0.8861 (Train: 25.0s, Query: 14.09s) | GPU: 2.8/8.0 GB\n",
      "10:30:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:30:59 [INFO]   Training abgeschlossen in 25.09s (Backend: cuml)\n",
      "10:31:11 [INFO]     Final: 48,000 labeled → Accuracy: 0.8863, F1: 0.8855\n",
      "10:31:11 [INFO]   Run 2/5\n",
      "10:31:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "10:31:16 [INFO]   Training abgeschlossen in 4.78s (Backend: cuml)\n",
      "10:32:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:32:28 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "10:33:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "10:33:39 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "10:34:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:34:51 [INFO]   Training abgeschlossen in 5.31s (Backend: cuml)\n",
      "10:35:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:36:03 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "10:37:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:37:16 [INFO]   Training abgeschlossen in 5.71s (Backend: cuml)\n",
      "10:38:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "10:38:28 [INFO]   Training abgeschlossen in 6.00s (Backend: cuml)\n",
      "10:39:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:39:40 [INFO]   Training abgeschlossen in 6.23s (Backend: cuml)\n",
      "10:40:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:40:53 [INFO]   Training abgeschlossen in 6.44s (Backend: cuml)\n",
      "10:41:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:42:05 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "10:43:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:43:18 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "10:44:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:44:32 [INFO]   Training abgeschlossen in 7.49s (Backend: cuml)\n",
      "10:45:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "10:45:45 [INFO]   Training abgeschlossen in 7.80s (Backend: cuml)\n",
      "10:46:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:46:57 [INFO]   Training abgeschlossen in 8.03s (Backend: cuml)\n",
      "10:48:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:48:11 [INFO]   Training abgeschlossen in 8.29s (Backend: cuml)\n",
      "10:49:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:49:24 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "10:50:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:50:37 [INFO]   Training abgeschlossen in 8.80s (Backend: cuml)\n",
      "10:51:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:51:49 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "10:52:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:53:02 [INFO]   Training abgeschlossen in 9.26s (Backend: cuml)\n",
      "10:54:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "10:54:14 [INFO]   Training abgeschlossen in 9.48s (Backend: cuml)\n",
      "10:55:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:55:27 [INFO]   Training abgeschlossen in 9.79s (Backend: cuml)\n",
      "10:56:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:56:39 [INFO]   Training abgeschlossen in 9.93s (Backend: cuml)\n",
      "10:57:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:57:51 [INFO]   Training abgeschlossen in 10.15s (Backend: cuml)\n",
      "10:58:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "10:59:03 [INFO]   Training abgeschlossen in 10.41s (Backend: cuml)\n",
      "11:00:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:00:15 [INFO]   Training abgeschlossen in 10.70s (Backend: cuml)\n",
      "11:01:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:01:27 [INFO]   Training abgeschlossen in 10.76s (Backend: cuml)\n",
      "11:02:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:02:39 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "11:03:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "11:03:51 [INFO]   Training abgeschlossen in 11.20s (Backend: cuml)\n",
      "11:04:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:05:03 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "11:06:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:06:15 [INFO]   Training abgeschlossen in 11.67s (Backend: cuml)\n",
      "11:07:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:07:26 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "11:08:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:08:38 [INFO]   Training abgeschlossen in 12.26s (Backend: cuml)\n",
      "11:09:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:09:49 [INFO]   Training abgeschlossen in 12.36s (Backend: cuml)\n",
      "11:10:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:11:00 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "11:11:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:12:11 [INFO]   Training abgeschlossen in 12.75s (Backend: cuml)\n",
      "11:13:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:13:21 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "11:14:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:14:31 [INFO]   Training abgeschlossen in 13.23s (Backend: cuml)\n",
      "11:15:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:15:39 [INFO]   Training abgeschlossen in 13.38s (Backend: cuml)\n",
      "11:16:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:16:48 [INFO]   Training abgeschlossen in 13.56s (Backend: cuml)\n",
      "11:17:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:17:57 [INFO]   Training abgeschlossen in 13.75s (Backend: cuml)\n",
      "11:18:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:19:05 [INFO]   Training abgeschlossen in 14.08s (Backend: cuml)\n",
      "11:19:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:20:13 [INFO]   Training abgeschlossen in 14.29s (Backend: cuml)\n",
      "11:21:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:21:21 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "11:22:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "11:22:28 [INFO]   Training abgeschlossen in 14.29s (Backend: cuml)\n",
      "11:23:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:23:35 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "11:24:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:24:42 [INFO]   Training abgeschlossen in 14.78s (Backend: cuml)\n",
      "11:25:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:25:49 [INFO]   Training abgeschlossen in 15.17s (Backend: cuml)\n",
      "11:26:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:26:55 [INFO]   Training abgeschlossen in 15.14s (Backend: cuml)\n",
      "11:27:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:28:00 [INFO]   Training abgeschlossen in 15.38s (Backend: cuml)\n",
      "11:28:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:29:06 [INFO]   Training abgeschlossen in 15.56s (Backend: cuml)\n",
      "11:29:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:30:11 [INFO]   Training abgeschlossen in 16.05s (Backend: cuml)\n",
      "11:31:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:31:17 [INFO]   Training abgeschlossen in 16.20s (Backend: cuml)\n",
      "11:32:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:32:21 [INFO]   Training abgeschlossen in 16.30s (Backend: cuml)\n",
      "11:33:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:33:26 [INFO]   Training abgeschlossen in 16.45s (Backend: cuml)\n",
      "11:34:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:34:30 [INFO]   Training abgeschlossen in 16.63s (Backend: cuml)\n",
      "11:35:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:35:34 [INFO]   Training abgeschlossen in 16.90s (Backend: cuml)\n",
      "11:36:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:36:37 [INFO]   Training abgeschlossen in 17.10s (Backend: cuml)\n",
      "11:37:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:37:40 [INFO]   Training abgeschlossen in 17.26s (Backend: cuml)\n",
      "11:38:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:38:43 [INFO]   Training abgeschlossen in 17.48s (Backend: cuml)\n",
      "11:39:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:39:46 [INFO]   Training abgeschlossen in 17.83s (Backend: cuml)\n",
      "11:40:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:40:49 [INFO]   Training abgeschlossen in 18.29s (Backend: cuml)\n",
      "11:41:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:41:51 [INFO]   Training abgeschlossen in 18.32s (Backend: cuml)\n",
      "11:42:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:42:53 [INFO]   Training abgeschlossen in 18.55s (Backend: cuml)\n",
      "11:43:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:43:55 [INFO]   Training abgeschlossen in 18.60s (Backend: cuml)\n",
      "11:44:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:44:56 [INFO]   Training abgeschlossen in 18.77s (Backend: cuml)\n",
      "11:45:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:45:57 [INFO]   Training abgeschlossen in 18.97s (Backend: cuml)\n",
      "11:46:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:46:58 [INFO]   Training abgeschlossen in 19.30s (Backend: cuml)\n",
      "11:47:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:47:58 [INFO]   Training abgeschlossen in 19.45s (Backend: cuml)\n",
      "11:48:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:48:58 [INFO]   Training abgeschlossen in 19.63s (Backend: cuml)\n",
      "11:49:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:49:58 [INFO]   Training abgeschlossen in 19.87s (Backend: cuml)\n",
      "11:50:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:50:57 [INFO]   Training abgeschlossen in 20.00s (Backend: cuml)\n",
      "11:51:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:51:57 [INFO]   Training abgeschlossen in 20.30s (Backend: cuml)\n",
      "11:52:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "11:52:56 [INFO]   Training abgeschlossen in 20.52s (Backend: cuml)\n",
      "11:53:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:53:54 [INFO]   Training abgeschlossen in 20.74s (Backend: cuml)\n",
      "11:54:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:54:52 [INFO]   Training abgeschlossen in 21.03s (Backend: cuml)\n",
      "11:55:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:55:50 [INFO]   Training abgeschlossen in 21.13s (Backend: cuml)\n",
      "11:56:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:56:48 [INFO]   Training abgeschlossen in 21.32s (Backend: cuml)\n",
      "11:57:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:57:45 [INFO]   Training abgeschlossen in 21.71s (Backend: cuml)\n",
      "11:58:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:58:42 [INFO]   Training abgeschlossen in 21.74s (Backend: cuml)\n",
      "11:59:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "11:59:39 [INFO]   Training abgeschlossen in 22.07s (Backend: cuml)\n",
      "12:00:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:00:35 [INFO]   Training abgeschlossen in 22.36s (Backend: cuml)\n",
      "12:01:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:01:31 [INFO]   Training abgeschlossen in 22.42s (Backend: cuml)\n",
      "12:02:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:02:27 [INFO]   Training abgeschlossen in 22.78s (Backend: cuml)\n",
      "12:02:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:03:22 [INFO]   Training abgeschlossen in 22.79s (Backend: cuml)\n",
      "12:03:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:04:17 [INFO]   Training abgeschlossen in 23.06s (Backend: cuml)\n",
      "12:04:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:05:12 [INFO]   Training abgeschlossen in 23.29s (Backend: cuml)\n",
      "12:05:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:06:06 [INFO]   Training abgeschlossen in 23.29s (Backend: cuml)\n",
      "12:06:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:07:00 [INFO]   Training abgeschlossen in 23.52s (Backend: cuml)\n",
      "12:07:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:07:54 [INFO]   Training abgeschlossen in 23.71s (Backend: cuml)\n",
      "12:08:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:08:47 [INFO]   Training abgeschlossen in 23.83s (Backend: cuml)\n",
      "12:09:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:09:40 [INFO]   Training abgeschlossen in 24.14s (Backend: cuml)\n",
      "12:10:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:10:32 [INFO]   Training abgeschlossen in 24.29s (Backend: cuml)\n",
      "12:11:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:11:24 [INFO]   Training abgeschlossen in 24.41s (Backend: cuml)\n",
      "12:11:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:12:16 [INFO]   Training abgeschlossen in 24.59s (Backend: cuml)\n",
      "12:12:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:13:07 [INFO]   Training abgeschlossen in 24.94s (Backend: cuml)\n",
      "12:13:33 [INFO]     48,000 labeled → Accuracy: 0.8864 (Train: 25.0s, Query: 14.12s) | GPU: 2.8/8.0 GB\n",
      "12:13:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:13:58 [INFO]   Training abgeschlossen in 25.13s (Backend: cuml)\n",
      "12:14:09 [INFO]     Final: 48,000 labeled → Accuracy: 0.8864, F1: 0.8856\n",
      "12:14:10 [INFO]   Run 3/5\n",
      "12:14:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "12:14:15 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "12:15:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:15:25 [INFO]   Training abgeschlossen in 4.91s (Backend: cuml)\n",
      "12:16:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "12:16:37 [INFO]   Training abgeschlossen in 5.09s (Backend: cuml)\n",
      "12:17:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:17:49 [INFO]   Training abgeschlossen in 5.30s (Backend: cuml)\n",
      "12:18:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:19:01 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "12:20:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:20:13 [INFO]   Training abgeschlossen in 5.73s (Backend: cuml)\n",
      "12:21:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "12:21:25 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "12:22:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:22:37 [INFO]   Training abgeschlossen in 6.16s (Backend: cuml)\n",
      "12:23:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:23:50 [INFO]   Training abgeschlossen in 6.49s (Backend: cuml)\n",
      "12:24:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:25:02 [INFO]   Training abgeschlossen in 6.87s (Backend: cuml)\n",
      "12:26:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:26:15 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "12:27:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:27:28 [INFO]   Training abgeschlossen in 7.52s (Backend: cuml)\n",
      "12:28:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "12:28:41 [INFO]   Training abgeschlossen in 7.74s (Backend: cuml)\n",
      "12:29:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:29:53 [INFO]   Training abgeschlossen in 8.05s (Backend: cuml)\n",
      "12:30:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:31:06 [INFO]   Training abgeschlossen in 8.45s (Backend: cuml)\n",
      "12:32:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:32:19 [INFO]   Training abgeschlossen in 8.52s (Backend: cuml)\n",
      "12:33:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:33:32 [INFO]   Training abgeschlossen in 8.71s (Backend: cuml)\n",
      "12:34:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:34:44 [INFO]   Training abgeschlossen in 9.04s (Backend: cuml)\n",
      "12:35:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:35:57 [INFO]   Training abgeschlossen in 9.26s (Backend: cuml)\n",
      "12:37:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:37:09 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "12:38:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "12:38:22 [INFO]   Training abgeschlossen in 9.72s (Backend: cuml)\n",
      "12:39:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:39:34 [INFO]   Training abgeschlossen in 10.04s (Backend: cuml)\n",
      "12:40:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:40:47 [INFO]   Training abgeschlossen in 10.15s (Backend: cuml)\n",
      "12:41:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:41:59 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "12:43:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:43:11 [INFO]   Training abgeschlossen in 10.63s (Backend: cuml)\n",
      "12:44:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:44:23 [INFO]   Training abgeschlossen in 10.85s (Backend: cuml)\n",
      "12:45:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "12:45:34 [INFO]   Training abgeschlossen in 10.94s (Backend: cuml)\n",
      "12:46:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:46:47 [INFO]   Training abgeschlossen in 11.15s (Backend: cuml)\n",
      "12:47:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:47:58 [INFO]   Training abgeschlossen in 11.38s (Backend: cuml)\n",
      "12:48:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:49:10 [INFO]   Training abgeschlossen in 11.74s (Backend: cuml)\n",
      "12:50:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:50:22 [INFO]   Training abgeschlossen in 11.86s (Backend: cuml)\n",
      "12:51:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:51:33 [INFO]   Training abgeschlossen in 12.09s (Backend: cuml)\n",
      "12:52:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:52:44 [INFO]   Training abgeschlossen in 12.29s (Backend: cuml)\n",
      "12:53:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:53:55 [INFO]   Training abgeschlossen in 12.65s (Backend: cuml)\n",
      "12:54:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:55:06 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "12:56:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:56:15 [INFO]   Training abgeschlossen in 13.02s (Backend: cuml)\n",
      "12:57:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:57:25 [INFO]   Training abgeschlossen in 13.16s (Backend: cuml)\n",
      "12:58:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:58:34 [INFO]   Training abgeschlossen in 13.53s (Backend: cuml)\n",
      "12:59:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "12:59:43 [INFO]   Training abgeschlossen in 13.60s (Backend: cuml)\n",
      "13:00:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:00:51 [INFO]   Training abgeschlossen in 13.79s (Backend: cuml)\n",
      "13:01:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:01:59 [INFO]   Training abgeschlossen in 13.90s (Backend: cuml)\n",
      "13:02:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:03:07 [INFO]   Training abgeschlossen in 14.20s (Backend: cuml)\n",
      "13:04:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:04:15 [INFO]   Training abgeschlossen in 14.61s (Backend: cuml)\n",
      "13:05:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:05:22 [INFO]   Training abgeschlossen in 14.32s (Backend: cuml)\n",
      "13:06:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:06:29 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "13:07:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:07:35 [INFO]   Training abgeschlossen in 14.80s (Backend: cuml)\n",
      "13:08:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "13:08:42 [INFO]   Training abgeschlossen in 15.02s (Backend: cuml)\n",
      "13:09:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:09:48 [INFO]   Training abgeschlossen in 15.35s (Backend: cuml)\n",
      "13:10:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:10:54 [INFO]   Training abgeschlossen in 15.54s (Backend: cuml)\n",
      "13:11:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:12:00 [INFO]   Training abgeschlossen in 15.58s (Backend: cuml)\n",
      "13:12:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:13:06 [INFO]   Training abgeschlossen in 16.03s (Backend: cuml)\n",
      "13:13:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:14:11 [INFO]   Training abgeschlossen in 16.00s (Backend: cuml)\n",
      "13:14:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:15:15 [INFO]   Training abgeschlossen in 16.14s (Backend: cuml)\n",
      "13:16:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:16:20 [INFO]   Training abgeschlossen in 16.43s (Backend: cuml)\n",
      "13:17:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:17:24 [INFO]   Training abgeschlossen in 16.67s (Backend: cuml)\n",
      "13:18:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:18:27 [INFO]   Training abgeschlossen in 16.92s (Backend: cuml)\n",
      "13:19:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:19:31 [INFO]   Training abgeschlossen in 17.07s (Backend: cuml)\n",
      "13:20:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:20:34 [INFO]   Training abgeschlossen in 17.30s (Backend: cuml)\n",
      "13:21:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:21:37 [INFO]   Training abgeschlossen in 17.59s (Backend: cuml)\n",
      "13:22:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:22:40 [INFO]   Training abgeschlossen in 17.75s (Backend: cuml)\n",
      "13:23:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:23:42 [INFO]   Training abgeschlossen in 17.92s (Backend: cuml)\n",
      "13:24:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:24:44 [INFO]   Training abgeschlossen in 18.15s (Backend: cuml)\n",
      "13:25:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:25:46 [INFO]   Training abgeschlossen in 18.35s (Backend: cuml)\n",
      "13:26:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:26:47 [INFO]   Training abgeschlossen in 18.56s (Backend: cuml)\n",
      "13:27:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:27:49 [INFO]   Training abgeschlossen in 18.80s (Backend: cuml)\n",
      "13:28:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:28:50 [INFO]   Training abgeschlossen in 19.08s (Backend: cuml)\n",
      "13:29:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:29:51 [INFO]   Training abgeschlossen in 19.45s (Backend: cuml)\n",
      "13:30:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:30:51 [INFO]   Training abgeschlossen in 19.50s (Backend: cuml)\n",
      "13:31:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:31:51 [INFO]   Training abgeschlossen in 19.70s (Backend: cuml)\n",
      "13:32:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:32:51 [INFO]   Training abgeschlossen in 19.84s (Backend: cuml)\n",
      "13:33:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:33:50 [INFO]   Training abgeschlossen in 20.08s (Backend: cuml)\n",
      "13:34:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:34:49 [INFO]   Training abgeschlossen in 20.39s (Backend: cuml)\n",
      "13:35:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:35:48 [INFO]   Training abgeschlossen in 20.55s (Backend: cuml)\n",
      "13:36:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:36:46 [INFO]   Training abgeschlossen in 20.67s (Backend: cuml)\n",
      "13:37:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "13:37:45 [INFO]   Training abgeschlossen in 21.00s (Backend: cuml)\n",
      "13:38:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:38:42 [INFO]   Training abgeschlossen in 21.17s (Backend: cuml)\n",
      "13:39:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:39:40 [INFO]   Training abgeschlossen in 21.34s (Backend: cuml)\n",
      "13:40:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:40:37 [INFO]   Training abgeschlossen in 21.45s (Backend: cuml)\n",
      "13:41:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:41:34 [INFO]   Training abgeschlossen in 21.80s (Backend: cuml)\n",
      "13:42:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:42:31 [INFO]   Training abgeschlossen in 22.08s (Backend: cuml)\n",
      "13:43:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:43:27 [INFO]   Training abgeschlossen in 22.19s (Backend: cuml)\n",
      "13:44:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:44:23 [INFO]   Training abgeschlossen in 22.47s (Backend: cuml)\n",
      "13:44:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:45:19 [INFO]   Training abgeschlossen in 22.61s (Backend: cuml)\n",
      "13:45:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:46:14 [INFO]   Training abgeschlossen in 22.85s (Backend: cuml)\n",
      "13:46:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:47:09 [INFO]   Training abgeschlossen in 22.88s (Backend: cuml)\n",
      "13:47:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:48:03 [INFO]   Training abgeschlossen in 23.09s (Backend: cuml)\n",
      "13:48:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:48:57 [INFO]   Training abgeschlossen in 23.32s (Backend: cuml)\n",
      "13:49:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:49:51 [INFO]   Training abgeschlossen in 23.47s (Backend: cuml)\n",
      "13:50:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:50:45 [INFO]   Training abgeschlossen in 23.65s (Backend: cuml)\n",
      "13:51:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:51:38 [INFO]   Training abgeschlossen in 24.06s (Backend: cuml)\n",
      "13:52:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:52:30 [INFO]   Training abgeschlossen in 24.28s (Backend: cuml)\n",
      "13:52:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:53:23 [INFO]   Training abgeschlossen in 24.48s (Backend: cuml)\n",
      "13:53:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:54:15 [INFO]   Training abgeschlossen in 24.43s (Backend: cuml)\n",
      "13:54:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:55:07 [INFO]   Training abgeschlossen in 24.76s (Backend: cuml)\n",
      "13:55:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:55:58 [INFO]   Training abgeschlossen in 24.89s (Backend: cuml)\n",
      "13:56:24 [INFO]     48,000 labeled → Accuracy: 0.8854 (Train: 24.9s, Query: 14.10s) | GPU: 2.8/8.0 GB\n",
      "13:56:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:56:49 [INFO]   Training abgeschlossen in 24.98s (Backend: cuml)\n",
      "13:57:00 [INFO]     Final: 48,000 labeled → Accuracy: 0.8857, F1: 0.8849\n",
      "13:57:01 [INFO]   Run 4/5\n",
      "13:57:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "13:57:06 [INFO]   Training abgeschlossen in 4.81s (Backend: cuml)\n",
      "13:58:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:58:17 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "13:59:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "13:59:29 [INFO]   Training abgeschlossen in 5.10s (Backend: cuml)\n",
      "14:00:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:00:41 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "14:01:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:01:52 [INFO]   Training abgeschlossen in 5.24s (Backend: cuml)\n",
      "14:02:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:03:04 [INFO]   Training abgeschlossen in 5.77s (Backend: cuml)\n",
      "14:04:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "14:04:17 [INFO]   Training abgeschlossen in 6.01s (Backend: cuml)\n",
      "14:05:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:05:29 [INFO]   Training abgeschlossen in 6.27s (Backend: cuml)\n",
      "14:06:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:06:42 [INFO]   Training abgeschlossen in 6.52s (Backend: cuml)\n",
      "14:07:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:07:54 [INFO]   Training abgeschlossen in 6.90s (Backend: cuml)\n",
      "14:09:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:09:07 [INFO]   Training abgeschlossen in 7.28s (Backend: cuml)\n",
      "14:10:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:10:20 [INFO]   Training abgeschlossen in 7.54s (Backend: cuml)\n",
      "14:11:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "14:11:33 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "14:12:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:12:45 [INFO]   Training abgeschlossen in 7.97s (Backend: cuml)\n",
      "14:13:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:13:58 [INFO]   Training abgeschlossen in 8.26s (Backend: cuml)\n",
      "14:15:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:15:12 [INFO]   Training abgeschlossen in 8.56s (Backend: cuml)\n",
      "14:16:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:16:25 [INFO]   Training abgeschlossen in 8.73s (Backend: cuml)\n",
      "14:17:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:17:38 [INFO]   Training abgeschlossen in 8.97s (Backend: cuml)\n",
      "14:18:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:18:51 [INFO]   Training abgeschlossen in 9.37s (Backend: cuml)\n",
      "14:19:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "14:20:03 [INFO]   Training abgeschlossen in 9.48s (Backend: cuml)\n",
      "14:21:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:21:15 [INFO]   Training abgeschlossen in 9.66s (Backend: cuml)\n",
      "14:22:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:22:28 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "14:23:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:23:40 [INFO]   Training abgeschlossen in 10.26s (Backend: cuml)\n",
      "14:24:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:24:52 [INFO]   Training abgeschlossen in 10.31s (Backend: cuml)\n",
      "14:25:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:26:04 [INFO]   Training abgeschlossen in 10.56s (Backend: cuml)\n",
      "14:27:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:27:16 [INFO]   Training abgeschlossen in 10.83s (Backend: cuml)\n",
      "14:28:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "14:28:28 [INFO]   Training abgeschlossen in 10.98s (Backend: cuml)\n",
      "14:29:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:29:40 [INFO]   Training abgeschlossen in 11.25s (Backend: cuml)\n",
      "14:30:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:30:52 [INFO]   Training abgeschlossen in 11.41s (Backend: cuml)\n",
      "14:31:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:32:04 [INFO]   Training abgeschlossen in 11.68s (Backend: cuml)\n",
      "14:33:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:33:15 [INFO]   Training abgeschlossen in 11.79s (Backend: cuml)\n",
      "14:34:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:34:26 [INFO]   Training abgeschlossen in 12.05s (Backend: cuml)\n",
      "14:35:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:35:37 [INFO]   Training abgeschlossen in 12.28s (Backend: cuml)\n",
      "14:36:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:36:48 [INFO]   Training abgeschlossen in 12.49s (Backend: cuml)\n",
      "14:37:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:37:59 [INFO]   Training abgeschlossen in 12.80s (Backend: cuml)\n",
      "14:38:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:39:09 [INFO]   Training abgeschlossen in 12.93s (Backend: cuml)\n",
      "14:40:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:40:18 [INFO]   Training abgeschlossen in 13.08s (Backend: cuml)\n",
      "14:41:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:41:27 [INFO]   Training abgeschlossen in 13.30s (Backend: cuml)\n",
      "14:42:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:42:36 [INFO]   Training abgeschlossen in 13.76s (Backend: cuml)\n",
      "14:43:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:43:44 [INFO]   Training abgeschlossen in 13.78s (Backend: cuml)\n",
      "14:44:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:44:52 [INFO]   Training abgeschlossen in 13.99s (Backend: cuml)\n",
      "14:45:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:46:00 [INFO]   Training abgeschlossen in 14.17s (Backend: cuml)\n",
      "14:46:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:47:08 [INFO]   Training abgeschlossen in 14.41s (Backend: cuml)\n",
      "14:48:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:48:16 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "14:49:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:49:23 [INFO]   Training abgeschlossen in 14.51s (Backend: cuml)\n",
      "14:50:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "14:50:29 [INFO]   Training abgeschlossen in 14.72s (Backend: cuml)\n",
      "14:51:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:51:35 [INFO]   Training abgeschlossen in 14.93s (Backend: cuml)\n",
      "14:52:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:52:41 [INFO]   Training abgeschlossen in 15.19s (Backend: cuml)\n",
      "14:53:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:53:47 [INFO]   Training abgeschlossen in 15.34s (Backend: cuml)\n",
      "14:54:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:54:53 [INFO]   Training abgeschlossen in 15.78s (Backend: cuml)\n",
      "14:55:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:55:58 [INFO]   Training abgeschlossen in 16.10s (Backend: cuml)\n",
      "14:56:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:57:03 [INFO]   Training abgeschlossen in 15.98s (Backend: cuml)\n",
      "14:57:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:58:08 [INFO]   Training abgeschlossen in 16.22s (Backend: cuml)\n",
      "14:58:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "14:59:13 [INFO]   Training abgeschlossen in 16.39s (Backend: cuml)\n",
      "15:00:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:00:17 [INFO]   Training abgeschlossen in 16.66s (Backend: cuml)\n",
      "15:01:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:01:21 [INFO]   Training abgeschlossen in 16.97s (Backend: cuml)\n",
      "15:02:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:02:24 [INFO]   Training abgeschlossen in 17.17s (Backend: cuml)\n",
      "15:03:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:03:28 [INFO]   Training abgeschlossen in 17.40s (Backend: cuml)\n",
      "15:04:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:04:31 [INFO]   Training abgeschlossen in 17.58s (Backend: cuml)\n",
      "15:05:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:05:33 [INFO]   Training abgeschlossen in 17.90s (Backend: cuml)\n",
      "15:06:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:06:36 [INFO]   Training abgeschlossen in 18.07s (Backend: cuml)\n",
      "15:07:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:07:38 [INFO]   Training abgeschlossen in 18.25s (Backend: cuml)\n",
      "15:08:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:08:40 [INFO]   Training abgeschlossen in 18.41s (Backend: cuml)\n",
      "15:09:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:09:42 [INFO]   Training abgeschlossen in 18.55s (Backend: cuml)\n",
      "15:10:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:10:43 [INFO]   Training abgeschlossen in 18.84s (Backend: cuml)\n",
      "15:11:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:11:44 [INFO]   Training abgeschlossen in 19.03s (Backend: cuml)\n",
      "15:12:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:12:45 [INFO]   Training abgeschlossen in 19.39s (Backend: cuml)\n",
      "15:13:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:13:45 [INFO]   Training abgeschlossen in 19.49s (Backend: cuml)\n",
      "15:14:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:14:45 [INFO]   Training abgeschlossen in 19.80s (Backend: cuml)\n",
      "15:15:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:15:45 [INFO]   Training abgeschlossen in 20.11s (Backend: cuml)\n",
      "15:16:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:16:45 [INFO]   Training abgeschlossen in 20.27s (Backend: cuml)\n",
      "15:17:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:17:44 [INFO]   Training abgeschlossen in 20.32s (Backend: cuml)\n",
      "15:18:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:18:43 [INFO]   Training abgeschlossen in 20.66s (Backend: cuml)\n",
      "15:19:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:19:41 [INFO]   Training abgeschlossen in 20.74s (Backend: cuml)\n",
      "15:20:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:20:40 [INFO]   Training abgeschlossen in 20.99s (Backend: cuml)\n",
      "15:21:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "15:21:37 [INFO]   Training abgeschlossen in 21.10s (Backend: cuml)\n",
      "15:22:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:22:35 [INFO]   Training abgeschlossen in 21.27s (Backend: cuml)\n",
      "15:23:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:23:32 [INFO]   Training abgeschlossen in 21.65s (Backend: cuml)\n",
      "15:24:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:24:29 [INFO]   Training abgeschlossen in 21.78s (Backend: cuml)\n",
      "15:25:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:25:26 [INFO]   Training abgeschlossen in 22.08s (Backend: cuml)\n",
      "15:26:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:26:22 [INFO]   Training abgeschlossen in 22.09s (Backend: cuml)\n",
      "15:26:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:27:18 [INFO]   Training abgeschlossen in 22.26s (Backend: cuml)\n",
      "15:27:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:28:14 [INFO]   Training abgeschlossen in 22.52s (Backend: cuml)\n",
      "15:28:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:29:09 [INFO]   Training abgeschlossen in 22.66s (Backend: cuml)\n",
      "15:29:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:30:04 [INFO]   Training abgeschlossen in 22.83s (Backend: cuml)\n",
      "15:30:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:30:58 [INFO]   Training abgeschlossen in 23.22s (Backend: cuml)\n",
      "15:31:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:31:52 [INFO]   Training abgeschlossen in 23.30s (Backend: cuml)\n",
      "15:32:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:32:47 [INFO]   Training abgeschlossen in 23.77s (Backend: cuml)\n",
      "15:33:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:33:40 [INFO]   Training abgeschlossen in 23.70s (Backend: cuml)\n",
      "15:34:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:34:33 [INFO]   Training abgeschlossen in 24.13s (Backend: cuml)\n",
      "15:35:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:35:26 [INFO]   Training abgeschlossen in 24.21s (Backend: cuml)\n",
      "15:35:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:36:19 [INFO]   Training abgeschlossen in 24.43s (Backend: cuml)\n",
      "15:36:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:37:11 [INFO]   Training abgeschlossen in 24.45s (Backend: cuml)\n",
      "15:37:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:38:03 [INFO]   Training abgeschlossen in 24.65s (Backend: cuml)\n",
      "15:38:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:38:54 [INFO]   Training abgeschlossen in 24.79s (Backend: cuml)\n",
      "15:39:19 [INFO]     48,000 labeled → Accuracy: 0.8851 (Train: 24.8s, Query: 14.04s) | GPU: 2.8/8.0 GB\n",
      "15:39:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:39:45 [INFO]   Training abgeschlossen in 24.97s (Backend: cuml)\n",
      "15:39:56 [INFO]     Final: 48,000 labeled → Accuracy: 0.8851, F1: 0.8843\n",
      "15:39:56 [INFO]   Run 5/5\n",
      "15:39:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "15:40:01 [INFO]   Training abgeschlossen in 4.76s (Backend: cuml)\n",
      "15:41:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:41:13 [INFO]   Training abgeschlossen in 4.85s (Backend: cuml)\n",
      "15:42:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "15:42:24 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "15:43:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:43:36 [INFO]   Training abgeschlossen in 5.32s (Backend: cuml)\n",
      "15:44:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:44:48 [INFO]   Training abgeschlossen in 5.38s (Backend: cuml)\n",
      "15:45:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:46:00 [INFO]   Training abgeschlossen in 5.62s (Backend: cuml)\n",
      "15:47:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "15:47:12 [INFO]   Training abgeschlossen in 5.95s (Backend: cuml)\n",
      "15:48:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:48:24 [INFO]   Training abgeschlossen in 6.31s (Backend: cuml)\n",
      "15:49:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:49:37 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "15:50:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:50:50 [INFO]   Training abgeschlossen in 6.96s (Backend: cuml)\n",
      "15:51:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:52:03 [INFO]   Training abgeschlossen in 7.41s (Backend: cuml)\n",
      "15:53:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:53:16 [INFO]   Training abgeschlossen in 7.62s (Backend: cuml)\n",
      "15:54:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "15:54:29 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "15:55:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:55:41 [INFO]   Training abgeschlossen in 8.08s (Backend: cuml)\n",
      "15:56:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:56:55 [INFO]   Training abgeschlossen in 8.43s (Backend: cuml)\n",
      "15:57:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:58:07 [INFO]   Training abgeschlossen in 8.44s (Backend: cuml)\n",
      "15:59:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "15:59:20 [INFO]   Training abgeschlossen in 8.68s (Backend: cuml)\n",
      "16:00:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:00:32 [INFO]   Training abgeschlossen in 8.92s (Backend: cuml)\n",
      "16:01:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:01:46 [INFO]   Training abgeschlossen in 9.33s (Backend: cuml)\n",
      "16:02:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "16:02:59 [INFO]   Training abgeschlossen in 9.44s (Backend: cuml)\n",
      "16:04:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:04:11 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "16:05:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:05:24 [INFO]   Training abgeschlossen in 9.92s (Backend: cuml)\n",
      "16:06:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:06:36 [INFO]   Training abgeschlossen in 10.20s (Backend: cuml)\n",
      "16:07:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:07:48 [INFO]   Training abgeschlossen in 10.30s (Backend: cuml)\n",
      "16:08:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:09:00 [INFO]   Training abgeschlossen in 10.51s (Backend: cuml)\n",
      "16:10:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:10:12 [INFO]   Training abgeschlossen in 10.83s (Backend: cuml)\n",
      "16:11:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "16:11:24 [INFO]   Training abgeschlossen in 11.04s (Backend: cuml)\n",
      "16:12:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:12:36 [INFO]   Training abgeschlossen in 11.16s (Backend: cuml)\n",
      "16:13:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:13:48 [INFO]   Training abgeschlossen in 11.40s (Backend: cuml)\n",
      "16:14:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:15:00 [INFO]   Training abgeschlossen in 11.65s (Backend: cuml)\n",
      "16:16:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:16:11 [INFO]   Training abgeschlossen in 11.85s (Backend: cuml)\n",
      "16:17:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:17:23 [INFO]   Training abgeschlossen in 12.03s (Backend: cuml)\n",
      "16:18:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:18:33 [INFO]   Training abgeschlossen in 12.24s (Backend: cuml)\n",
      "16:19:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:19:44 [INFO]   Training abgeschlossen in 12.60s (Backend: cuml)\n",
      "16:20:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:20:55 [INFO]   Training abgeschlossen in 12.74s (Backend: cuml)\n",
      "16:21:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:22:05 [INFO]   Training abgeschlossen in 12.91s (Backend: cuml)\n",
      "16:23:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:23:14 [INFO]   Training abgeschlossen in 13.15s (Backend: cuml)\n",
      "16:24:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:24:24 [INFO]   Training abgeschlossen in 13.39s (Backend: cuml)\n",
      "16:25:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:25:33 [INFO]   Training abgeschlossen in 13.77s (Backend: cuml)\n",
      "16:26:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:26:42 [INFO]   Training abgeschlossen in 13.87s (Backend: cuml)\n",
      "16:27:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:27:50 [INFO]   Training abgeschlossen in 13.96s (Backend: cuml)\n",
      "16:28:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:28:58 [INFO]   Training abgeschlossen in 14.22s (Backend: cuml)\n",
      "16:29:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:30:06 [INFO]   Training abgeschlossen in 14.73s (Backend: cuml)\n",
      "16:30:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:31:13 [INFO]   Training abgeschlossen in 14.46s (Backend: cuml)\n",
      "16:32:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:32:20 [INFO]   Training abgeschlossen in 14.54s (Backend: cuml)\n",
      "16:33:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "16:33:27 [INFO]   Training abgeschlossen in 14.78s (Backend: cuml)\n",
      "16:34:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:34:33 [INFO]   Training abgeschlossen in 15.01s (Backend: cuml)\n",
      "16:35:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:35:39 [INFO]   Training abgeschlossen in 15.26s (Backend: cuml)\n",
      "16:36:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:36:45 [INFO]   Training abgeschlossen in 15.54s (Backend: cuml)\n",
      "16:37:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:37:51 [INFO]   Training abgeschlossen in 15.63s (Backend: cuml)\n",
      "16:38:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:38:56 [INFO]   Training abgeschlossen in 16.04s (Backend: cuml)\n",
      "16:39:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:40:01 [INFO]   Training abgeschlossen in 15.99s (Backend: cuml)\n",
      "16:40:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:41:06 [INFO]   Training abgeschlossen in 16.20s (Backend: cuml)\n",
      "16:41:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:42:10 [INFO]   Training abgeschlossen in 16.51s (Backend: cuml)\n",
      "16:42:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:43:15 [INFO]   Training abgeschlossen in 16.72s (Backend: cuml)\n",
      "16:44:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:44:18 [INFO]   Training abgeschlossen in 16.91s (Backend: cuml)\n",
      "16:45:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:45:22 [INFO]   Training abgeschlossen in 17.09s (Backend: cuml)\n",
      "16:46:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:46:25 [INFO]   Training abgeschlossen in 17.37s (Backend: cuml)\n",
      "16:47:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:47:28 [INFO]   Training abgeschlossen in 17.58s (Backend: cuml)\n",
      "16:48:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:48:31 [INFO]   Training abgeschlossen in 17.75s (Backend: cuml)\n",
      "16:49:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:49:33 [INFO]   Training abgeschlossen in 18.04s (Backend: cuml)\n",
      "16:50:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:50:35 [INFO]   Training abgeschlossen in 18.19s (Backend: cuml)\n",
      "16:51:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:51:37 [INFO]   Training abgeschlossen in 18.43s (Backend: cuml)\n",
      "16:52:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:52:39 [INFO]   Training abgeschlossen in 18.78s (Backend: cuml)\n",
      "16:53:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:53:40 [INFO]   Training abgeschlossen in 18.81s (Backend: cuml)\n",
      "16:54:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:54:41 [INFO]   Training abgeschlossen in 19.01s (Backend: cuml)\n",
      "16:55:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:55:42 [INFO]   Training abgeschlossen in 19.34s (Backend: cuml)\n",
      "16:56:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:56:42 [INFO]   Training abgeschlossen in 19.48s (Backend: cuml)\n",
      "16:57:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:57:42 [INFO]   Training abgeschlossen in 19.61s (Backend: cuml)\n",
      "16:58:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:58:42 [INFO]   Training abgeschlossen in 19.83s (Backend: cuml)\n",
      "16:59:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "16:59:41 [INFO]   Training abgeschlossen in 19.97s (Backend: cuml)\n",
      "17:00:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:00:40 [INFO]   Training abgeschlossen in 20.24s (Backend: cuml)\n",
      "17:01:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:01:39 [INFO]   Training abgeschlossen in 20.53s (Backend: cuml)\n",
      "17:02:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:02:37 [INFO]   Training abgeschlossen in 20.69s (Backend: cuml)\n",
      "17:03:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:03:35 [INFO]   Training abgeschlossen in 20.97s (Backend: cuml)\n",
      "17:04:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "17:04:33 [INFO]   Training abgeschlossen in 21.10s (Backend: cuml)\n",
      "17:05:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:05:31 [INFO]   Training abgeschlossen in 21.32s (Backend: cuml)\n",
      "17:06:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:06:28 [INFO]   Training abgeschlossen in 21.52s (Backend: cuml)\n",
      "17:07:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:07:25 [INFO]   Training abgeschlossen in 21.79s (Backend: cuml)\n",
      "17:07:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:08:21 [INFO]   Training abgeschlossen in 21.93s (Backend: cuml)\n",
      "17:08:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:09:18 [INFO]   Training abgeschlossen in 22.10s (Backend: cuml)\n",
      "17:09:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:10:14 [INFO]   Training abgeschlossen in 22.41s (Backend: cuml)\n",
      "17:10:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:11:09 [INFO]   Training abgeschlossen in 22.57s (Backend: cuml)\n",
      "17:11:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:12:04 [INFO]   Training abgeschlossen in 22.76s (Backend: cuml)\n",
      "17:12:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:13:00 [INFO]   Training abgeschlossen in 23.01s (Backend: cuml)\n",
      "17:13:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:13:54 [INFO]   Training abgeschlossen in 23.20s (Backend: cuml)\n",
      "17:14:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:14:48 [INFO]   Training abgeschlossen in 23.39s (Backend: cuml)\n",
      "17:15:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:15:42 [INFO]   Training abgeschlossen in 23.61s (Backend: cuml)\n",
      "17:16:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:16:36 [INFO]   Training abgeschlossen in 23.79s (Backend: cuml)\n",
      "17:17:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:17:29 [INFO]   Training abgeschlossen in 23.98s (Backend: cuml)\n",
      "17:17:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:18:22 [INFO]   Training abgeschlossen in 24.26s (Backend: cuml)\n",
      "17:18:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:19:15 [INFO]   Training abgeschlossen in 24.40s (Backend: cuml)\n",
      "17:19:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:20:07 [INFO]   Training abgeschlossen in 24.68s (Backend: cuml)\n",
      "17:20:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:20:58 [INFO]   Training abgeschlossen in 24.84s (Backend: cuml)\n",
      "17:21:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:21:50 [INFO]   Training abgeschlossen in 24.98s (Backend: cuml)\n",
      "17:22:15 [INFO]     48,000 labeled → Accuracy: 0.8864 (Train: 25.0s, Query: 14.13s) | GPU: 2.8/8.0 GB\n",
      "17:22:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:22:41 [INFO]   Training abgeschlossen in 25.13s (Backend: cuml)\n",
      "17:22:52 [INFO]     Final: 48,000 labeled → Accuracy: 0.8860, F1: 0.8853\n",
      "17:22:53 [INFO] \n",
      "GPU-SVM + Least Confidence - Budget: 100% (60,000 Samples)\n",
      "17:22:53 [INFO]   Run 1/5\n",
      "17:22:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "17:22:58 [INFO]   Training abgeschlossen in 4.74s (Backend: cuml)\n",
      "17:24:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:24:08 [INFO]   Training abgeschlossen in 4.88s (Backend: cuml)\n",
      "17:25:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "17:25:21 [INFO]   Training abgeschlossen in 5.14s (Backend: cuml)\n",
      "17:26:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:26:33 [INFO]   Training abgeschlossen in 5.33s (Backend: cuml)\n",
      "17:27:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:27:44 [INFO]   Training abgeschlossen in 5.21s (Backend: cuml)\n",
      "17:28:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:28:56 [INFO]   Training abgeschlossen in 5.76s (Backend: cuml)\n",
      "17:30:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "17:30:08 [INFO]   Training abgeschlossen in 6.03s (Backend: cuml)\n",
      "17:31:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:31:21 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "17:32:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:32:33 [INFO]   Training abgeschlossen in 6.45s (Backend: cuml)\n",
      "17:33:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:33:46 [INFO]   Training abgeschlossen in 6.84s (Backend: cuml)\n",
      "17:34:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:34:59 [INFO]   Training abgeschlossen in 7.26s (Backend: cuml)\n",
      "17:36:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:36:11 [INFO]   Training abgeschlossen in 7.51s (Backend: cuml)\n",
      "17:37:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "17:37:24 [INFO]   Training abgeschlossen in 7.71s (Backend: cuml)\n",
      "17:38:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:38:37 [INFO]   Training abgeschlossen in 7.98s (Backend: cuml)\n",
      "17:39:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:39:49 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "17:40:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:41:02 [INFO]   Training abgeschlossen in 8.45s (Backend: cuml)\n",
      "17:42:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:42:15 [INFO]   Training abgeschlossen in 8.73s (Backend: cuml)\n",
      "17:43:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:43:28 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "17:44:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:44:40 [INFO]   Training abgeschlossen in 9.38s (Backend: cuml)\n",
      "17:45:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "17:45:53 [INFO]   Training abgeschlossen in 9.45s (Backend: cuml)\n",
      "17:46:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:47:05 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "17:48:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:48:16 [INFO]   Training abgeschlossen in 10.03s (Backend: cuml)\n",
      "17:49:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:49:29 [INFO]   Training abgeschlossen in 10.28s (Backend: cuml)\n",
      "17:50:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:50:41 [INFO]   Training abgeschlossen in 10.39s (Backend: cuml)\n",
      "17:51:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:51:53 [INFO]   Training abgeschlossen in 10.54s (Backend: cuml)\n",
      "17:52:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:53:05 [INFO]   Training abgeschlossen in 10.83s (Backend: cuml)\n",
      "17:54:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:54:17 [INFO]   Training abgeschlossen in 11.06s (Backend: cuml)\n",
      "17:55:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "17:55:29 [INFO]   Training abgeschlossen in 11.21s (Backend: cuml)\n",
      "17:56:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:56:41 [INFO]   Training abgeschlossen in 11.40s (Backend: cuml)\n",
      "17:57:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:57:52 [INFO]   Training abgeschlossen in 11.74s (Backend: cuml)\n",
      "17:58:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "17:59:04 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "18:00:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:00:15 [INFO]   Training abgeschlossen in 12.07s (Backend: cuml)\n",
      "18:01:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:01:26 [INFO]   Training abgeschlossen in 12.24s (Backend: cuml)\n",
      "18:02:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:02:37 [INFO]   Training abgeschlossen in 12.56s (Backend: cuml)\n",
      "18:03:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:03:48 [INFO]   Training abgeschlossen in 12.72s (Backend: cuml)\n",
      "18:04:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:04:57 [INFO]   Training abgeschlossen in 12.93s (Backend: cuml)\n",
      "18:05:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:06:07 [INFO]   Training abgeschlossen in 13.12s (Backend: cuml)\n",
      "18:07:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:07:16 [INFO]   Training abgeschlossen in 13.34s (Backend: cuml)\n",
      "18:08:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:08:25 [INFO]   Training abgeschlossen in 13.70s (Backend: cuml)\n",
      "18:09:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:09:33 [INFO]   Training abgeschlossen in 13.83s (Backend: cuml)\n",
      "18:10:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:10:41 [INFO]   Training abgeschlossen in 13.97s (Backend: cuml)\n",
      "18:11:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:11:49 [INFO]   Training abgeschlossen in 14.17s (Backend: cuml)\n",
      "18:12:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:12:57 [INFO]   Training abgeschlossen in 14.42s (Backend: cuml)\n",
      "18:13:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:14:04 [INFO]   Training abgeschlossen in 14.43s (Backend: cuml)\n",
      "18:14:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "18:15:11 [INFO]   Training abgeschlossen in 14.57s (Backend: cuml)\n",
      "18:16:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:16:18 [INFO]   Training abgeschlossen in 14.86s (Backend: cuml)\n",
      "18:17:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:17:25 [INFO]   Training abgeschlossen in 14.92s (Backend: cuml)\n",
      "18:18:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:18:31 [INFO]   Training abgeschlossen in 15.18s (Backend: cuml)\n",
      "18:19:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:19:37 [INFO]   Training abgeschlossen in 15.40s (Backend: cuml)\n",
      "18:20:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:20:42 [INFO]   Training abgeschlossen in 15.76s (Backend: cuml)\n",
      "18:21:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:21:48 [INFO]   Training abgeschlossen in 16.07s (Backend: cuml)\n",
      "18:22:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:22:53 [INFO]   Training abgeschlossen in 16.00s (Backend: cuml)\n",
      "18:23:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:23:58 [INFO]   Training abgeschlossen in 16.19s (Backend: cuml)\n",
      "18:24:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:25:02 [INFO]   Training abgeschlossen in 16.46s (Backend: cuml)\n",
      "18:25:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:26:06 [INFO]   Training abgeschlossen in 16.63s (Backend: cuml)\n",
      "18:26:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:27:10 [INFO]   Training abgeschlossen in 16.90s (Backend: cuml)\n",
      "18:27:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:28:14 [INFO]   Training abgeschlossen in 17.31s (Backend: cuml)\n",
      "18:29:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:29:17 [INFO]   Training abgeschlossen in 17.31s (Backend: cuml)\n",
      "18:30:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:30:20 [INFO]   Training abgeschlossen in 17.55s (Backend: cuml)\n",
      "18:31:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:31:23 [INFO]   Training abgeschlossen in 17.75s (Backend: cuml)\n",
      "18:32:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:32:25 [INFO]   Training abgeschlossen in 17.93s (Backend: cuml)\n",
      "18:33:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:33:28 [INFO]   Training abgeschlossen in 18.22s (Backend: cuml)\n",
      "18:34:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:34:30 [INFO]   Training abgeschlossen in 18.43s (Backend: cuml)\n",
      "18:35:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:35:31 [INFO]   Training abgeschlossen in 18.59s (Backend: cuml)\n",
      "18:36:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:36:33 [INFO]   Training abgeschlossen in 19.10s (Backend: cuml)\n",
      "18:37:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:37:34 [INFO]   Training abgeschlossen in 19.22s (Backend: cuml)\n",
      "18:38:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:38:34 [INFO]   Training abgeschlossen in 19.38s (Backend: cuml)\n",
      "18:39:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:39:35 [INFO]   Training abgeschlossen in 19.65s (Backend: cuml)\n",
      "18:40:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:40:35 [INFO]   Training abgeschlossen in 19.75s (Backend: cuml)\n",
      "18:41:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:41:35 [INFO]   Training abgeschlossen in 19.91s (Backend: cuml)\n",
      "18:42:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:42:35 [INFO]   Training abgeschlossen in 20.07s (Backend: cuml)\n",
      "18:43:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:43:34 [INFO]   Training abgeschlossen in 20.28s (Backend: cuml)\n",
      "18:44:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:44:32 [INFO]   Training abgeschlossen in 20.50s (Backend: cuml)\n",
      "18:45:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:45:31 [INFO]   Training abgeschlossen in 20.77s (Backend: cuml)\n",
      "18:46:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:46:29 [INFO]   Training abgeschlossen in 20.90s (Backend: cuml)\n",
      "18:47:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:47:27 [INFO]   Training abgeschlossen in 21.18s (Backend: cuml)\n",
      "18:48:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "18:48:24 [INFO]   Training abgeschlossen in 21.52s (Backend: cuml)\n",
      "18:49:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:49:21 [INFO]   Training abgeschlossen in 21.48s (Backend: cuml)\n",
      "18:49:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:50:18 [INFO]   Training abgeschlossen in 21.71s (Backend: cuml)\n",
      "18:50:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:51:15 [INFO]   Training abgeschlossen in 21.90s (Backend: cuml)\n",
      "18:51:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:52:11 [INFO]   Training abgeschlossen in 22.15s (Backend: cuml)\n",
      "18:52:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:53:07 [INFO]   Training abgeschlossen in 22.29s (Backend: cuml)\n",
      "18:53:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:54:02 [INFO]   Training abgeschlossen in 22.51s (Backend: cuml)\n",
      "18:54:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:54:58 [INFO]   Training abgeschlossen in 22.79s (Backend: cuml)\n",
      "18:55:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:55:53 [INFO]   Training abgeschlossen in 23.01s (Backend: cuml)\n",
      "18:56:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:56:47 [INFO]   Training abgeschlossen in 23.08s (Backend: cuml)\n",
      "18:57:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:57:42 [INFO]   Training abgeschlossen in 23.40s (Backend: cuml)\n",
      "18:58:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:58:35 [INFO]   Training abgeschlossen in 23.50s (Backend: cuml)\n",
      "18:59:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "18:59:29 [INFO]   Training abgeschlossen in 23.71s (Backend: cuml)\n",
      "18:59:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:00:22 [INFO]   Training abgeschlossen in 23.90s (Backend: cuml)\n",
      "19:00:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:01:14 [INFO]   Training abgeschlossen in 24.17s (Backend: cuml)\n",
      "19:01:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:02:07 [INFO]   Training abgeschlossen in 24.33s (Backend: cuml)\n",
      "19:02:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:02:58 [INFO]   Training abgeschlossen in 24.48s (Backend: cuml)\n",
      "19:03:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:03:50 [INFO]   Training abgeschlossen in 24.75s (Backend: cuml)\n",
      "19:04:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:04:41 [INFO]   Training abgeschlossen in 24.92s (Backend: cuml)\n",
      "19:05:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:05:32 [INFO]   Training abgeschlossen in 25.05s (Backend: cuml)\n",
      "19:05:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:06:23 [INFO]   Training abgeschlossen in 25.36s (Backend: cuml)\n",
      "19:06:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:07:13 [INFO]   Training abgeschlossen in 25.31s (Backend: cuml)\n",
      "19:07:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:08:02 [INFO]   Training abgeschlossen in 25.57s (Backend: cuml)\n",
      "19:08:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:09:04 [INFO]   Training abgeschlossen in 37.94s (Backend: cuml)\n",
      "19:09:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:10:05 [INFO]   Training abgeschlossen in 38.53s (Backend: cuml)\n",
      "19:10:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:11:06 [INFO]   Training abgeschlossen in 38.73s (Backend: cuml)\n",
      "19:11:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:12:09 [INFO]   Training abgeschlossen in 40.94s (Backend: cuml)\n",
      "19:12:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:13:09 [INFO]   Training abgeschlossen in 39.16s (Backend: cuml)\n",
      "19:13:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:14:09 [INFO]   Training abgeschlossen in 38.68s (Backend: cuml)\n",
      "19:14:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:15:08 [INFO]   Training abgeschlossen in 39.71s (Backend: cuml)\n",
      "19:15:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:16:07 [INFO]   Training abgeschlossen in 38.85s (Backend: cuml)\n",
      "19:16:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:17:07 [INFO]   Training abgeschlossen in 41.36s (Backend: cuml)\n",
      "19:17:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:18:05 [INFO]   Training abgeschlossen in 39.34s (Backend: cuml)\n",
      "19:18:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:19:03 [INFO]   Training abgeschlossen in 40.54s (Backend: cuml)\n",
      "19:19:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:20:01 [INFO]   Training abgeschlossen in 40.46s (Backend: cuml)\n",
      "19:20:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:20:57 [INFO]   Training abgeschlossen in 39.00s (Backend: cuml)\n",
      "19:21:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:21:55 [INFO]   Training abgeschlossen in 40.84s (Backend: cuml)\n",
      "19:22:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:22:53 [INFO]   Training abgeschlossen in 41.93s (Backend: cuml)\n",
      "19:23:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:23:49 [INFO]   Training abgeschlossen in 41.08s (Backend: cuml)\n",
      "19:24:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:24:44 [INFO]   Training abgeschlossen in 40.74s (Backend: cuml)\n",
      "19:24:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:25:41 [INFO]   Training abgeschlossen in 42.17s (Backend: cuml)\n",
      "19:25:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:26:35 [INFO]   Training abgeschlossen in 40.81s (Backend: cuml)\n",
      "19:26:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:27:30 [INFO]   Training abgeschlossen in 42.32s (Backend: cuml)\n",
      "19:27:42 [INFO]     60,000 labeled → Accuracy: 0.8853 (Train: 42.4s, Query: 0.66s) | GPU: 2.8/8.0 GB\n",
      "19:27:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:28:23 [INFO]   Training abgeschlossen in 40.70s (Backend: cuml)\n",
      "19:28:35 [INFO]     Final: 60,000 labeled → Accuracy: 0.8850, F1: 0.8841\n",
      "19:28:35 [INFO]   Run 2/5\n",
      "19:28:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "19:28:40 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "19:29:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:29:52 [INFO]   Training abgeschlossen in 4.96s (Backend: cuml)\n",
      "19:30:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "19:31:03 [INFO]   Training abgeschlossen in 5.04s (Backend: cuml)\n",
      "19:32:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:32:15 [INFO]   Training abgeschlossen in 5.26s (Backend: cuml)\n",
      "19:33:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:33:27 [INFO]   Training abgeschlossen in 5.22s (Backend: cuml)\n",
      "19:34:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:34:39 [INFO]   Training abgeschlossen in 5.68s (Backend: cuml)\n",
      "19:35:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "19:35:51 [INFO]   Training abgeschlossen in 5.99s (Backend: cuml)\n",
      "19:36:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:37:03 [INFO]   Training abgeschlossen in 6.19s (Backend: cuml)\n",
      "19:38:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:38:16 [INFO]   Training abgeschlossen in 6.50s (Backend: cuml)\n",
      "19:39:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:39:28 [INFO]   Training abgeschlossen in 6.90s (Backend: cuml)\n",
      "19:40:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:40:41 [INFO]   Training abgeschlossen in 7.48s (Backend: cuml)\n",
      "19:41:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:41:54 [INFO]   Training abgeschlossen in 7.48s (Backend: cuml)\n",
      "19:42:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "19:43:07 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "19:44:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:44:20 [INFO]   Training abgeschlossen in 8.06s (Backend: cuml)\n",
      "19:45:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:45:33 [INFO]   Training abgeschlossen in 8.30s (Backend: cuml)\n",
      "19:46:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:46:46 [INFO]   Training abgeschlossen in 8.46s (Backend: cuml)\n",
      "19:47:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:47:59 [INFO]   Training abgeschlossen in 8.72s (Backend: cuml)\n",
      "19:49:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:49:12 [INFO]   Training abgeschlossen in 9.07s (Backend: cuml)\n",
      "19:50:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:50:24 [INFO]   Training abgeschlossen in 9.28s (Backend: cuml)\n",
      "19:51:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "19:51:37 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "19:52:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:52:49 [INFO]   Training abgeschlossen in 9.68s (Backend: cuml)\n",
      "19:53:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:54:01 [INFO]   Training abgeschlossen in 10.00s (Backend: cuml)\n",
      "19:55:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:55:13 [INFO]   Training abgeschlossen in 10.14s (Backend: cuml)\n",
      "19:56:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:56:25 [INFO]   Training abgeschlossen in 10.39s (Backend: cuml)\n",
      "19:57:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:57:37 [INFO]   Training abgeschlossen in 10.64s (Backend: cuml)\n",
      "19:58:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "19:58:49 [INFO]   Training abgeschlossen in 10.81s (Backend: cuml)\n",
      "19:59:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:00:02 [INFO]   Training abgeschlossen in 11.04s (Backend: cuml)\n",
      "20:01:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "20:01:14 [INFO]   Training abgeschlossen in 11.18s (Backend: cuml)\n",
      "20:02:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:02:26 [INFO]   Training abgeschlossen in 11.61s (Backend: cuml)\n",
      "20:03:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:03:38 [INFO]   Training abgeschlossen in 11.68s (Backend: cuml)\n",
      "20:04:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:04:49 [INFO]   Training abgeschlossen in 11.86s (Backend: cuml)\n",
      "20:05:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:06:01 [INFO]   Training abgeschlossen in 12.13s (Backend: cuml)\n",
      "20:06:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:07:12 [INFO]   Training abgeschlossen in 12.37s (Backend: cuml)\n",
      "20:08:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:08:23 [INFO]   Training abgeschlossen in 12.59s (Backend: cuml)\n",
      "20:09:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:09:34 [INFO]   Training abgeschlossen in 12.74s (Backend: cuml)\n",
      "20:10:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:10:43 [INFO]   Training abgeschlossen in 13.04s (Backend: cuml)\n",
      "20:11:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:11:53 [INFO]   Training abgeschlossen in 13.17s (Backend: cuml)\n",
      "20:12:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:13:02 [INFO]   Training abgeschlossen in 13.56s (Backend: cuml)\n",
      "20:13:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:14:11 [INFO]   Training abgeschlossen in 13.57s (Backend: cuml)\n",
      "20:15:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:15:20 [INFO]   Training abgeschlossen in 13.78s (Backend: cuml)\n",
      "20:16:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:16:28 [INFO]   Training abgeschlossen in 13.99s (Backend: cuml)\n",
      "20:17:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:17:36 [INFO]   Training abgeschlossen in 14.19s (Backend: cuml)\n",
      "20:18:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:18:44 [INFO]   Training abgeschlossen in 14.56s (Backend: cuml)\n",
      "20:19:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "20:19:51 [INFO]   Training abgeschlossen in 14.36s (Backend: cuml)\n",
      "20:20:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:20:58 [INFO]   Training abgeschlossen in 14.47s (Backend: cuml)\n",
      "20:21:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:22:05 [INFO]   Training abgeschlossen in 14.77s (Backend: cuml)\n",
      "20:22:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:23:11 [INFO]   Training abgeschlossen in 14.94s (Backend: cuml)\n",
      "20:24:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:24:17 [INFO]   Training abgeschlossen in 15.21s (Backend: cuml)\n",
      "20:25:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:25:23 [INFO]   Training abgeschlossen in 15.50s (Backend: cuml)\n",
      "20:26:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:26:29 [INFO]   Training abgeschlossen in 15.65s (Backend: cuml)\n",
      "20:27:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:27:34 [INFO]   Training abgeschlossen in 16.03s (Backend: cuml)\n",
      "20:28:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:28:39 [INFO]   Training abgeschlossen in 16.02s (Backend: cuml)\n",
      "20:29:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:29:44 [INFO]   Training abgeschlossen in 16.19s (Backend: cuml)\n",
      "20:30:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:30:49 [INFO]   Training abgeschlossen in 16.49s (Backend: cuml)\n",
      "20:31:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:31:53 [INFO]   Training abgeschlossen in 16.68s (Backend: cuml)\n",
      "20:32:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:32:57 [INFO]   Training abgeschlossen in 17.01s (Backend: cuml)\n",
      "20:33:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:34:01 [INFO]   Training abgeschlossen in 17.26s (Backend: cuml)\n",
      "20:34:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:35:04 [INFO]   Training abgeschlossen in 17.37s (Backend: cuml)\n",
      "20:35:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:36:07 [INFO]   Training abgeschlossen in 17.63s (Backend: cuml)\n",
      "20:36:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:37:10 [INFO]   Training abgeschlossen in 17.80s (Backend: cuml)\n",
      "20:37:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:38:13 [INFO]   Training abgeschlossen in 18.00s (Backend: cuml)\n",
      "20:38:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:39:15 [INFO]   Training abgeschlossen in 18.20s (Backend: cuml)\n",
      "20:39:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:40:17 [INFO]   Training abgeschlossen in 18.42s (Backend: cuml)\n",
      "20:41:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:41:18 [INFO]   Training abgeschlossen in 18.58s (Backend: cuml)\n",
      "20:42:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:42:20 [INFO]   Training abgeschlossen in 18.84s (Backend: cuml)\n",
      "20:43:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:43:21 [INFO]   Training abgeschlossen in 19.11s (Backend: cuml)\n",
      "20:44:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:44:21 [INFO]   Training abgeschlossen in 19.36s (Backend: cuml)\n",
      "20:45:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:45:22 [INFO]   Training abgeschlossen in 19.51s (Backend: cuml)\n",
      "20:46:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:46:22 [INFO]   Training abgeschlossen in 19.67s (Backend: cuml)\n",
      "20:47:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:47:22 [INFO]   Training abgeschlossen in 19.91s (Backend: cuml)\n",
      "20:48:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:48:21 [INFO]   Training abgeschlossen in 20.18s (Backend: cuml)\n",
      "20:49:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:49:20 [INFO]   Training abgeschlossen in 20.39s (Backend: cuml)\n",
      "20:49:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "20:50:19 [INFO]   Training abgeschlossen in 20.67s (Backend: cuml)\n",
      "20:50:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:51:18 [INFO]   Training abgeschlossen in 20.82s (Backend: cuml)\n",
      "20:51:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:52:16 [INFO]   Training abgeschlossen in 20.93s (Backend: cuml)\n",
      "20:52:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:53:14 [INFO]   Training abgeschlossen in 21.19s (Backend: cuml)\n",
      "20:53:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:54:12 [INFO]   Training abgeschlossen in 21.43s (Backend: cuml)\n",
      "20:54:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:55:09 [INFO]   Training abgeschlossen in 21.55s (Backend: cuml)\n",
      "20:55:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:56:06 [INFO]   Training abgeschlossen in 21.93s (Backend: cuml)\n",
      "20:56:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:57:02 [INFO]   Training abgeschlossen in 22.04s (Backend: cuml)\n",
      "20:57:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:57:59 [INFO]   Training abgeschlossen in 22.28s (Backend: cuml)\n",
      "20:58:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:58:55 [INFO]   Training abgeschlossen in 22.49s (Backend: cuml)\n",
      "20:59:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "20:59:50 [INFO]   Training abgeschlossen in 22.73s (Backend: cuml)\n",
      "21:00:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:00:46 [INFO]   Training abgeschlossen in 22.84s (Backend: cuml)\n",
      "21:01:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:01:40 [INFO]   Training abgeschlossen in 22.93s (Backend: cuml)\n",
      "21:02:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:02:35 [INFO]   Training abgeschlossen in 23.21s (Backend: cuml)\n",
      "21:03:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:03:29 [INFO]   Training abgeschlossen in 23.37s (Backend: cuml)\n",
      "21:04:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:04:23 [INFO]   Training abgeschlossen in 23.56s (Backend: cuml)\n",
      "21:04:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:05:17 [INFO]   Training abgeschlossen in 23.77s (Backend: cuml)\n",
      "21:05:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:06:10 [INFO]   Training abgeschlossen in 23.94s (Backend: cuml)\n",
      "21:06:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:07:03 [INFO]   Training abgeschlossen in 24.12s (Backend: cuml)\n",
      "21:07:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:07:56 [INFO]   Training abgeschlossen in 24.37s (Backend: cuml)\n",
      "21:08:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:08:48 [INFO]   Training abgeschlossen in 24.45s (Backend: cuml)\n",
      "21:09:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:09:40 [INFO]   Training abgeschlossen in 24.69s (Backend: cuml)\n",
      "21:10:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:10:31 [INFO]   Training abgeschlossen in 24.95s (Backend: cuml)\n",
      "21:10:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:11:22 [INFO]   Training abgeschlossen in 25.06s (Backend: cuml)\n",
      "21:11:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:12:12 [INFO]   Training abgeschlossen in 25.38s (Backend: cuml)\n",
      "21:12:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:13:02 [INFO]   Training abgeschlossen in 25.50s (Backend: cuml)\n",
      "21:13:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:13:52 [INFO]   Training abgeschlossen in 25.79s (Backend: cuml)\n",
      "21:14:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:14:54 [INFO]   Training abgeschlossen in 37.78s (Backend: cuml)\n",
      "21:15:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:15:55 [INFO]   Training abgeschlossen in 37.96s (Backend: cuml)\n",
      "21:16:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:16:56 [INFO]   Training abgeschlossen in 39.03s (Backend: cuml)\n",
      "21:17:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:17:57 [INFO]   Training abgeschlossen in 38.92s (Backend: cuml)\n",
      "21:18:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:19:00 [INFO]   Training abgeschlossen in 41.67s (Backend: cuml)\n",
      "21:19:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:20:00 [INFO]   Training abgeschlossen in 39.26s (Backend: cuml)\n",
      "21:20:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:21:00 [INFO]   Training abgeschlossen in 40.15s (Backend: cuml)\n",
      "21:21:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:22:00 [INFO]   Training abgeschlossen in 39.88s (Backend: cuml)\n",
      "21:22:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:22:59 [INFO]   Training abgeschlossen in 39.75s (Backend: cuml)\n",
      "21:23:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:24:00 [INFO]   Training abgeschlossen in 42.10s (Backend: cuml)\n",
      "21:24:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:24:59 [INFO]   Training abgeschlossen in 41.29s (Backend: cuml)\n",
      "21:25:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:25:58 [INFO]   Training abgeschlossen in 41.95s (Backend: cuml)\n",
      "21:26:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:26:56 [INFO]   Training abgeschlossen in 41.32s (Backend: cuml)\n",
      "21:27:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:27:52 [INFO]   Training abgeschlossen in 39.18s (Backend: cuml)\n",
      "21:28:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:28:49 [INFO]   Training abgeschlossen in 41.21s (Backend: cuml)\n",
      "21:29:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:29:45 [INFO]   Training abgeschlossen in 41.14s (Backend: cuml)\n",
      "21:30:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:30:41 [INFO]   Training abgeschlossen in 41.29s (Backend: cuml)\n",
      "21:30:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:31:37 [INFO]   Training abgeschlossen in 41.64s (Backend: cuml)\n",
      "21:31:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:32:34 [INFO]   Training abgeschlossen in 43.49s (Backend: cuml)\n",
      "21:32:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:33:30 [INFO]   Training abgeschlossen in 42.56s (Backend: cuml)\n",
      "21:33:42 [INFO]     60,000 labeled → Accuracy: 0.8849 (Train: 42.6s, Query: 0.65s) | GPU: 2.8/8.0 GB\n",
      "21:33:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:34:26 [INFO]   Training abgeschlossen in 43.94s (Backend: cuml)\n",
      "21:34:38 [INFO]     Final: 60,000 labeled → Accuracy: 0.8850, F1: 0.8841\n",
      "21:34:38 [INFO]   Run 3/5\n",
      "21:34:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "21:34:43 [INFO]   Training abgeschlossen in 4.77s (Backend: cuml)\n",
      "21:35:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:35:54 [INFO]   Training abgeschlossen in 4.95s (Backend: cuml)\n",
      "21:37:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "21:37:06 [INFO]   Training abgeschlossen in 5.12s (Backend: cuml)\n",
      "21:38:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:38:18 [INFO]   Training abgeschlossen in 5.29s (Backend: cuml)\n",
      "21:39:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:39:29 [INFO]   Training abgeschlossen in 5.25s (Backend: cuml)\n",
      "21:40:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:40:42 [INFO]   Training abgeschlossen in 5.74s (Backend: cuml)\n",
      "21:41:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "21:41:54 [INFO]   Training abgeschlossen in 5.92s (Backend: cuml)\n",
      "21:43:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:43:06 [INFO]   Training abgeschlossen in 6.18s (Backend: cuml)\n",
      "21:44:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:44:19 [INFO]   Training abgeschlossen in 6.55s (Backend: cuml)\n",
      "21:45:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:45:31 [INFO]   Training abgeschlossen in 6.83s (Backend: cuml)\n",
      "21:46:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:46:44 [INFO]   Training abgeschlossen in 7.37s (Backend: cuml)\n",
      "21:47:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:47:57 [INFO]   Training abgeschlossen in 7.56s (Backend: cuml)\n",
      "21:49:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "21:49:10 [INFO]   Training abgeschlossen in 7.81s (Backend: cuml)\n",
      "21:50:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:50:23 [INFO]   Training abgeschlossen in 7.99s (Backend: cuml)\n",
      "21:51:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:51:36 [INFO]   Training abgeschlossen in 8.24s (Backend: cuml)\n",
      "21:52:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:52:48 [INFO]   Training abgeschlossen in 8.60s (Backend: cuml)\n",
      "21:53:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:54:01 [INFO]   Training abgeschlossen in 8.71s (Backend: cuml)\n",
      "21:55:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:55:14 [INFO]   Training abgeschlossen in 8.99s (Backend: cuml)\n",
      "21:56:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:56:26 [INFO]   Training abgeschlossen in 9.22s (Backend: cuml)\n",
      "21:57:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:57:39 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "21:58:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "21:58:51 [INFO]   Training abgeschlossen in 9.75s (Backend: cuml)\n",
      "21:59:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:00:04 [INFO]   Training abgeschlossen in 9.90s (Backend: cuml)\n",
      "22:01:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:01:16 [INFO]   Training abgeschlossen in 10.15s (Backend: cuml)\n",
      "22:02:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:02:30 [INFO]   Training abgeschlossen in 10.62s (Backend: cuml)\n",
      "22:03:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:03:42 [INFO]   Training abgeschlossen in 10.63s (Backend: cuml)\n",
      "22:04:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:04:53 [INFO]   Training abgeschlossen in 10.80s (Backend: cuml)\n",
      "22:05:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "22:06:05 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "22:07:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:07:17 [INFO]   Training abgeschlossen in 11.29s (Backend: cuml)\n",
      "22:08:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:08:29 [INFO]   Training abgeschlossen in 11.48s (Backend: cuml)\n",
      "22:09:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:09:41 [INFO]   Training abgeschlossen in 11.60s (Backend: cuml)\n",
      "22:10:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:10:52 [INFO]   Training abgeschlossen in 11.83s (Backend: cuml)\n",
      "22:11:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:12:04 [INFO]   Training abgeschlossen in 12.08s (Backend: cuml)\n",
      "22:13:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:13:15 [INFO]   Training abgeschlossen in 12.33s (Backend: cuml)\n",
      "22:14:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:14:26 [INFO]   Training abgeschlossen in 12.51s (Backend: cuml)\n",
      "22:15:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:15:36 [INFO]   Training abgeschlossen in 12.77s (Backend: cuml)\n",
      "22:16:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:16:46 [INFO]   Training abgeschlossen in 12.93s (Backend: cuml)\n",
      "22:17:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:17:55 [INFO]   Training abgeschlossen in 13.27s (Backend: cuml)\n",
      "22:18:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:19:05 [INFO]   Training abgeschlossen in 13.34s (Backend: cuml)\n",
      "22:20:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:20:13 [INFO]   Training abgeschlossen in 13.52s (Backend: cuml)\n",
      "22:21:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:21:21 [INFO]   Training abgeschlossen in 13.77s (Backend: cuml)\n",
      "22:22:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:22:30 [INFO]   Training abgeschlossen in 13.92s (Backend: cuml)\n",
      "22:23:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:23:38 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "22:24:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:24:46 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "22:25:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:25:53 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "22:26:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:27:00 [INFO]   Training abgeschlossen in 14.49s (Backend: cuml)\n",
      "22:27:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:28:06 [INFO]   Training abgeschlossen in 14.71s (Backend: cuml)\n",
      "22:28:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "22:29:13 [INFO]   Training abgeschlossen in 14.91s (Backend: cuml)\n",
      "22:30:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:30:19 [INFO]   Training abgeschlossen in 15.25s (Backend: cuml)\n",
      "22:31:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:31:25 [INFO]   Training abgeschlossen in 15.50s (Backend: cuml)\n",
      "22:32:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:32:31 [INFO]   Training abgeschlossen in 15.73s (Backend: cuml)\n",
      "22:33:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:33:36 [INFO]   Training abgeschlossen in 16.04s (Backend: cuml)\n",
      "22:34:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:34:41 [INFO]   Training abgeschlossen in 15.96s (Backend: cuml)\n",
      "22:35:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:35:46 [INFO]   Training abgeschlossen in 16.17s (Backend: cuml)\n",
      "22:36:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:36:50 [INFO]   Training abgeschlossen in 16.44s (Backend: cuml)\n",
      "22:37:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:37:55 [INFO]   Training abgeschlossen in 16.62s (Backend: cuml)\n",
      "22:38:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:38:59 [INFO]   Training abgeschlossen in 17.08s (Backend: cuml)\n",
      "22:39:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:40:02 [INFO]   Training abgeschlossen in 17.30s (Backend: cuml)\n",
      "22:40:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:41:06 [INFO]   Training abgeschlossen in 17.57s (Backend: cuml)\n",
      "22:41:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:42:09 [INFO]   Training abgeschlossen in 17.52s (Backend: cuml)\n",
      "22:42:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:43:12 [INFO]   Training abgeschlossen in 17.76s (Backend: cuml)\n",
      "22:43:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:44:14 [INFO]   Training abgeschlossen in 17.92s (Backend: cuml)\n",
      "22:44:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:45:16 [INFO]   Training abgeschlossen in 18.34s (Backend: cuml)\n",
      "22:46:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:46:18 [INFO]   Training abgeschlossen in 18.51s (Backend: cuml)\n",
      "22:47:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:47:20 [INFO]   Training abgeschlossen in 18.75s (Backend: cuml)\n",
      "22:48:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:48:22 [INFO]   Training abgeschlossen in 19.05s (Backend: cuml)\n",
      "22:49:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:49:23 [INFO]   Training abgeschlossen in 19.16s (Backend: cuml)\n",
      "22:50:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:50:23 [INFO]   Training abgeschlossen in 19.38s (Backend: cuml)\n",
      "22:51:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:51:24 [INFO]   Training abgeschlossen in 19.64s (Backend: cuml)\n",
      "22:52:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:52:24 [INFO]   Training abgeschlossen in 19.75s (Backend: cuml)\n",
      "22:53:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:53:24 [INFO]   Training abgeschlossen in 20.03s (Backend: cuml)\n",
      "22:54:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:54:23 [INFO]   Training abgeschlossen in 20.16s (Backend: cuml)\n",
      "22:55:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:55:22 [INFO]   Training abgeschlossen in 20.44s (Backend: cuml)\n",
      "22:56:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:56:21 [INFO]   Training abgeschlossen in 20.54s (Backend: cuml)\n",
      "22:56:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:57:19 [INFO]   Training abgeschlossen in 20.68s (Backend: cuml)\n",
      "22:57:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "22:58:18 [INFO]   Training abgeschlossen in 20.92s (Backend: cuml)\n",
      "22:58:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "22:59:15 [INFO]   Training abgeschlossen in 21.16s (Backend: cuml)\n",
      "22:59:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:00:13 [INFO]   Training abgeschlossen in 21.27s (Backend: cuml)\n",
      "23:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:01:10 [INFO]   Training abgeschlossen in 21.56s (Backend: cuml)\n",
      "23:01:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:02:07 [INFO]   Training abgeschlossen in 21.80s (Backend: cuml)\n",
      "23:02:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:03:04 [INFO]   Training abgeschlossen in 21.92s (Backend: cuml)\n",
      "23:03:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:04:00 [INFO]   Training abgeschlossen in 22.14s (Backend: cuml)\n",
      "23:04:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:04:56 [INFO]   Training abgeschlossen in 22.33s (Backend: cuml)\n",
      "23:05:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:05:51 [INFO]   Training abgeschlossen in 22.56s (Backend: cuml)\n",
      "23:06:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:06:47 [INFO]   Training abgeschlossen in 22.69s (Backend: cuml)\n",
      "23:07:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:07:41 [INFO]   Training abgeschlossen in 22.91s (Backend: cuml)\n",
      "23:08:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:08:36 [INFO]   Training abgeschlossen in 23.19s (Backend: cuml)\n",
      "23:09:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:09:31 [INFO]   Training abgeschlossen in 23.64s (Backend: cuml)\n",
      "23:10:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:10:25 [INFO]   Training abgeschlossen in 23.68s (Backend: cuml)\n",
      "23:10:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:11:18 [INFO]   Training abgeschlossen in 23.95s (Backend: cuml)\n",
      "23:11:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:12:12 [INFO]   Training abgeschlossen in 24.04s (Backend: cuml)\n",
      "23:12:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:13:04 [INFO]   Training abgeschlossen in 24.31s (Backend: cuml)\n",
      "23:13:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:13:57 [INFO]   Training abgeschlossen in 24.37s (Backend: cuml)\n",
      "23:14:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:14:49 [INFO]   Training abgeschlossen in 24.43s (Backend: cuml)\n",
      "23:15:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:15:41 [INFO]   Training abgeschlossen in 24.61s (Backend: cuml)\n",
      "23:16:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:16:32 [INFO]   Training abgeschlossen in 24.78s (Backend: cuml)\n",
      "23:16:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:17:22 [INFO]   Training abgeschlossen in 24.92s (Backend: cuml)\n",
      "23:17:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:18:13 [INFO]   Training abgeschlossen in 25.17s (Backend: cuml)\n",
      "23:18:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:19:03 [INFO]   Training abgeschlossen in 25.47s (Backend: cuml)\n",
      "23:19:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:19:53 [INFO]   Training abgeschlossen in 25.78s (Backend: cuml)\n",
      "23:20:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:20:54 [INFO]   Training abgeschlossen in 38.04s (Backend: cuml)\n",
      "23:21:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:21:54 [INFO]   Training abgeschlossen in 36.72s (Backend: cuml)\n",
      "23:22:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:22:55 [INFO]   Training abgeschlossen in 38.86s (Backend: cuml)\n",
      "23:23:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:23:54 [INFO]   Training abgeschlossen in 37.15s (Backend: cuml)\n",
      "23:24:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:24:55 [INFO]   Training abgeschlossen in 40.00s (Backend: cuml)\n",
      "23:25:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:25:57 [INFO]   Training abgeschlossen in 41.29s (Backend: cuml)\n",
      "23:26:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:26:58 [INFO]   Training abgeschlossen in 40.51s (Backend: cuml)\n",
      "23:27:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:27:58 [INFO]   Training abgeschlossen in 40.34s (Backend: cuml)\n",
      "23:28:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:28:58 [INFO]   Training abgeschlossen in 40.85s (Backend: cuml)\n",
      "23:29:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:29:54 [INFO]   Training abgeschlossen in 37.61s (Backend: cuml)\n",
      "23:30:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:30:54 [INFO]   Training abgeschlossen in 41.99s (Backend: cuml)\n",
      "23:31:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:31:52 [INFO]   Training abgeschlossen in 40.87s (Backend: cuml)\n",
      "23:32:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:32:50 [INFO]   Training abgeschlossen in 41.14s (Backend: cuml)\n",
      "23:33:06 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:33:47 [INFO]   Training abgeschlossen in 40.51s (Backend: cuml)\n",
      "23:34:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:34:43 [INFO]   Training abgeschlossen in 39.75s (Backend: cuml)\n",
      "23:34:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:35:40 [INFO]   Training abgeschlossen in 41.40s (Backend: cuml)\n",
      "23:35:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:36:37 [INFO]   Training abgeschlossen in 42.75s (Backend: cuml)\n",
      "23:36:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:37:32 [INFO]   Training abgeschlossen in 41.17s (Backend: cuml)\n",
      "23:37:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:38:31 [INFO]   Training abgeschlossen in 45.14s (Backend: cuml)\n",
      "23:38:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:39:27 [INFO]   Training abgeschlossen in 43.08s (Backend: cuml)\n",
      "23:39:39 [INFO]     60,000 labeled → Accuracy: 0.8854 (Train: 43.1s, Query: 0.67s) | GPU: 2.8/8.0 GB\n",
      "23:39:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:40:23 [INFO]   Training abgeschlossen in 43.24s (Backend: cuml)\n",
      "23:40:34 [INFO]     Final: 60,000 labeled → Accuracy: 0.8855, F1: 0.8846\n",
      "23:40:34 [INFO]   Run 4/5\n",
      "23:40:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "23:40:39 [INFO]   Training abgeschlossen in 4.79s (Backend: cuml)\n",
      "23:41:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:41:51 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "23:42:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "23:43:02 [INFO]   Training abgeschlossen in 5.17s (Backend: cuml)\n",
      "23:44:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:44:14 [INFO]   Training abgeschlossen in 5.34s (Backend: cuml)\n",
      "23:45:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:45:26 [INFO]   Training abgeschlossen in 5.37s (Backend: cuml)\n",
      "23:46:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:46:38 [INFO]   Training abgeschlossen in 5.78s (Backend: cuml)\n",
      "23:47:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "23:47:51 [INFO]   Training abgeschlossen in 6.02s (Backend: cuml)\n",
      "23:48:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:49:03 [INFO]   Training abgeschlossen in 6.26s (Backend: cuml)\n",
      "23:50:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:50:16 [INFO]   Training abgeschlossen in 6.51s (Backend: cuml)\n",
      "23:51:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:51:28 [INFO]   Training abgeschlossen in 6.98s (Backend: cuml)\n",
      "23:52:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:52:41 [INFO]   Training abgeschlossen in 7.29s (Backend: cuml)\n",
      "23:53:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:53:54 [INFO]   Training abgeschlossen in 7.49s (Backend: cuml)\n",
      "23:54:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "23:55:07 [INFO]   Training abgeschlossen in 7.76s (Backend: cuml)\n",
      "23:56:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:56:19 [INFO]   Training abgeschlossen in 7.99s (Backend: cuml)\n",
      "23:57:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:57:32 [INFO]   Training abgeschlossen in 8.40s (Backend: cuml)\n",
      "23:58:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:58:45 [INFO]   Training abgeschlossen in 8.60s (Backend: cuml)\n",
      "23:59:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "23:59:57 [INFO]   Training abgeschlossen in 8.70s (Backend: cuml)\n",
      "00:01:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:01:09 [INFO]   Training abgeschlossen in 9.00s (Backend: cuml)\n",
      "00:02:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:02:22 [INFO]   Training abgeschlossen in 9.24s (Backend: cuml)\n",
      "00:03:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "00:03:34 [INFO]   Training abgeschlossen in 9.43s (Backend: cuml)\n",
      "00:04:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:04:46 [INFO]   Training abgeschlossen in 9.69s (Backend: cuml)\n",
      "00:05:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:05:59 [INFO]   Training abgeschlossen in 10.08s (Backend: cuml)\n",
      "00:07:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:07:11 [INFO]   Training abgeschlossen in 10.15s (Backend: cuml)\n",
      "00:08:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:08:23 [INFO]   Training abgeschlossen in 10.33s (Backend: cuml)\n",
      "00:09:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:09:35 [INFO]   Training abgeschlossen in 10.53s (Backend: cuml)\n",
      "00:10:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:10:47 [INFO]   Training abgeschlossen in 11.00s (Backend: cuml)\n",
      "00:11:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "00:11:59 [INFO]   Training abgeschlossen in 10.99s (Backend: cuml)\n",
      "00:13:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:13:11 [INFO]   Training abgeschlossen in 11.24s (Backend: cuml)\n",
      "00:14:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:14:23 [INFO]   Training abgeschlossen in 11.49s (Backend: cuml)\n",
      "00:15:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:15:35 [INFO]   Training abgeschlossen in 11.67s (Backend: cuml)\n",
      "00:16:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:16:46 [INFO]   Training abgeschlossen in 11.84s (Backend: cuml)\n",
      "00:17:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:17:58 [INFO]   Training abgeschlossen in 12.05s (Backend: cuml)\n",
      "00:18:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:19:09 [INFO]   Training abgeschlossen in 12.42s (Backend: cuml)\n",
      "00:20:07 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:20:20 [INFO]   Training abgeschlossen in 12.58s (Backend: cuml)\n",
      "00:21:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:21:30 [INFO]   Training abgeschlossen in 12.75s (Backend: cuml)\n",
      "00:22:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:22:40 [INFO]   Training abgeschlossen in 12.92s (Backend: cuml)\n",
      "00:23:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:23:49 [INFO]   Training abgeschlossen in 13.29s (Backend: cuml)\n",
      "00:24:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:24:59 [INFO]   Training abgeschlossen in 13.63s (Backend: cuml)\n",
      "00:25:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:26:07 [INFO]   Training abgeschlossen in 13.59s (Backend: cuml)\n",
      "00:27:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:27:16 [INFO]   Training abgeschlossen in 13.78s (Backend: cuml)\n",
      "00:28:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:28:24 [INFO]   Training abgeschlossen in 13.98s (Backend: cuml)\n",
      "00:29:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:29:32 [INFO]   Training abgeschlossen in 14.32s (Backend: cuml)\n",
      "00:30:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:30:40 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "00:31:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:31:48 [INFO]   Training abgeschlossen in 14.35s (Backend: cuml)\n",
      "00:32:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:32:54 [INFO]   Training abgeschlossen in 14.50s (Backend: cuml)\n",
      "00:33:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "00:34:01 [INFO]   Training abgeschlossen in 14.69s (Backend: cuml)\n",
      "00:34:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:35:07 [INFO]   Training abgeschlossen in 14.95s (Backend: cuml)\n",
      "00:35:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:36:14 [INFO]   Training abgeschlossen in 15.28s (Backend: cuml)\n",
      "00:37:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:37:20 [INFO]   Training abgeschlossen in 15.63s (Backend: cuml)\n",
      "00:38:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:38:25 [INFO]   Training abgeschlossen in 15.58s (Backend: cuml)\n",
      "00:39:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:39:31 [INFO]   Training abgeschlossen in 16.04s (Backend: cuml)\n",
      "00:40:20 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:40:36 [INFO]   Training abgeschlossen in 15.96s (Backend: cuml)\n",
      "00:41:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:41:40 [INFO]   Training abgeschlossen in 16.20s (Backend: cuml)\n",
      "00:42:28 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:42:45 [INFO]   Training abgeschlossen in 16.42s (Backend: cuml)\n",
      "00:43:32 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:43:49 [INFO]   Training abgeschlossen in 16.71s (Backend: cuml)\n",
      "00:44:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:44:53 [INFO]   Training abgeschlossen in 16.85s (Backend: cuml)\n",
      "00:45:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:45:56 [INFO]   Training abgeschlossen in 17.07s (Backend: cuml)\n",
      "00:46:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:47:00 [INFO]   Training abgeschlossen in 17.41s (Backend: cuml)\n",
      "00:47:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:48:03 [INFO]   Training abgeschlossen in 17.70s (Backend: cuml)\n",
      "00:48:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:49:06 [INFO]   Training abgeschlossen in 17.89s (Backend: cuml)\n",
      "00:49:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:50:08 [INFO]   Training abgeschlossen in 17.98s (Backend: cuml)\n",
      "00:50:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:51:11 [INFO]   Training abgeschlossen in 18.24s (Backend: cuml)\n",
      "00:51:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:52:12 [INFO]   Training abgeschlossen in 18.46s (Backend: cuml)\n",
      "00:52:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:53:14 [INFO]   Training abgeschlossen in 18.60s (Backend: cuml)\n",
      "00:53:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:54:15 [INFO]   Training abgeschlossen in 18.80s (Backend: cuml)\n",
      "00:54:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:55:16 [INFO]   Training abgeschlossen in 18.99s (Backend: cuml)\n",
      "00:55:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:56:17 [INFO]   Training abgeschlossen in 19.34s (Backend: cuml)\n",
      "00:56:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:57:17 [INFO]   Training abgeschlossen in 19.48s (Backend: cuml)\n",
      "00:57:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:58:18 [INFO]   Training abgeschlossen in 19.76s (Backend: cuml)\n",
      "00:58:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "00:59:17 [INFO]   Training abgeschlossen in 19.95s (Backend: cuml)\n",
      "00:59:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:00:17 [INFO]   Training abgeschlossen in 20.13s (Backend: cuml)\n",
      "01:00:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:01:16 [INFO]   Training abgeschlossen in 20.36s (Backend: cuml)\n",
      "01:01:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:02:15 [INFO]   Training abgeschlossen in 20.74s (Backend: cuml)\n",
      "01:02:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:03:14 [INFO]   Training abgeschlossen in 20.90s (Backend: cuml)\n",
      "01:03:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:04:12 [INFO]   Training abgeschlossen in 21.11s (Backend: cuml)\n",
      "01:04:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "01:05:10 [INFO]   Training abgeschlossen in 21.35s (Backend: cuml)\n",
      "01:05:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:06:08 [INFO]   Training abgeschlossen in 21.42s (Backend: cuml)\n",
      "01:06:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:07:05 [INFO]   Training abgeschlossen in 21.75s (Backend: cuml)\n",
      "01:07:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:08:02 [INFO]   Training abgeschlossen in 21.85s (Backend: cuml)\n",
      "01:08:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:08:59 [INFO]   Training abgeschlossen in 21.99s (Backend: cuml)\n",
      "01:09:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:09:55 [INFO]   Training abgeschlossen in 22.17s (Backend: cuml)\n",
      "01:10:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:10:51 [INFO]   Training abgeschlossen in 22.34s (Backend: cuml)\n",
      "01:11:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:11:47 [INFO]   Training abgeschlossen in 22.66s (Backend: cuml)\n",
      "01:12:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:12:42 [INFO]   Training abgeschlossen in 22.77s (Backend: cuml)\n",
      "01:13:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:13:37 [INFO]   Training abgeschlossen in 22.95s (Backend: cuml)\n",
      "01:14:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:14:31 [INFO]   Training abgeschlossen in 23.09s (Backend: cuml)\n",
      "01:15:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:15:26 [INFO]   Training abgeschlossen in 23.44s (Backend: cuml)\n",
      "01:15:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:16:20 [INFO]   Training abgeschlossen in 23.49s (Backend: cuml)\n",
      "01:16:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:17:13 [INFO]   Training abgeschlossen in 23.65s (Backend: cuml)\n",
      "01:17:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:18:06 [INFO]   Training abgeschlossen in 23.80s (Backend: cuml)\n",
      "01:18:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:18:59 [INFO]   Training abgeschlossen in 24.16s (Backend: cuml)\n",
      "01:19:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:19:52 [INFO]   Training abgeschlossen in 24.35s (Backend: cuml)\n",
      "01:20:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:20:44 [INFO]   Training abgeschlossen in 24.45s (Backend: cuml)\n",
      "01:21:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:21:35 [INFO]   Training abgeschlossen in 24.73s (Backend: cuml)\n",
      "01:22:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:22:27 [INFO]   Training abgeschlossen in 24.96s (Backend: cuml)\n",
      "01:22:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:23:18 [INFO]   Training abgeschlossen in 25.12s (Backend: cuml)\n",
      "01:23:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:24:08 [INFO]   Training abgeschlossen in 25.25s (Backend: cuml)\n",
      "01:24:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:24:58 [INFO]   Training abgeschlossen in 25.45s (Backend: cuml)\n",
      "01:25:22 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:25:48 [INFO]   Training abgeschlossen in 25.61s (Backend: cuml)\n",
      "01:26:11 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:26:49 [INFO]   Training abgeschlossen in 37.66s (Backend: cuml)\n",
      "01:27:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:27:50 [INFO]   Training abgeschlossen in 38.23s (Backend: cuml)\n",
      "01:28:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:28:50 [INFO]   Training abgeschlossen in 37.07s (Backend: cuml)\n",
      "01:29:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:29:49 [INFO]   Training abgeschlossen in 37.26s (Backend: cuml)\n",
      "01:30:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:30:49 [INFO]   Training abgeschlossen in 38.50s (Backend: cuml)\n",
      "01:31:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:31:50 [INFO]   Training abgeschlossen in 40.63s (Backend: cuml)\n",
      "01:32:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:32:49 [INFO]   Training abgeschlossen in 38.88s (Backend: cuml)\n",
      "01:33:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:33:49 [INFO]   Training abgeschlossen in 40.37s (Backend: cuml)\n",
      "01:34:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:34:46 [INFO]   Training abgeschlossen in 38.09s (Backend: cuml)\n",
      "01:35:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:35:46 [INFO]   Training abgeschlossen in 41.23s (Backend: cuml)\n",
      "01:36:04 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:36:45 [INFO]   Training abgeschlossen in 40.61s (Backend: cuml)\n",
      "01:37:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:37:45 [INFO]   Training abgeschlossen in 42.94s (Backend: cuml)\n",
      "01:38:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:38:44 [INFO]   Training abgeschlossen in 42.19s (Backend: cuml)\n",
      "01:39:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:39:40 [INFO]   Training abgeschlossen in 39.72s (Backend: cuml)\n",
      "01:39:56 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:40:38 [INFO]   Training abgeschlossen in 42.16s (Backend: cuml)\n",
      "01:40:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:41:32 [INFO]   Training abgeschlossen in 39.05s (Backend: cuml)\n",
      "01:41:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:42:29 [INFO]   Training abgeschlossen in 42.20s (Backend: cuml)\n",
      "01:42:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:43:24 [INFO]   Training abgeschlossen in 40.50s (Backend: cuml)\n",
      "01:43:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:44:20 [INFO]   Training abgeschlossen in 42.45s (Backend: cuml)\n",
      "01:44:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:45:16 [INFO]   Training abgeschlossen in 43.39s (Backend: cuml)\n",
      "01:45:29 [INFO]     60,000 labeled → Accuracy: 0.8848 (Train: 43.4s, Query: 0.65s) | GPU: 2.8/8.0 GB\n",
      "01:45:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:46:11 [INFO]   Training abgeschlossen in 41.99s (Backend: cuml)\n",
      "01:46:22 [INFO]     Final: 60,000 labeled → Accuracy: 0.8850, F1: 0.8841\n",
      "01:46:23 [INFO]   Run 5/5\n",
      "01:46:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "01:46:28 [INFO]   Training abgeschlossen in 4.84s (Backend: cuml)\n",
      "01:47:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:47:39 [INFO]   Training abgeschlossen in 4.90s (Backend: cuml)\n",
      "01:48:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.1/8.0 GB)\n",
      "01:48:51 [INFO]   Training abgeschlossen in 5.11s (Backend: cuml)\n",
      "01:49:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:50:03 [INFO]   Training abgeschlossen in 5.39s (Backend: cuml)\n",
      "01:51:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:51:15 [INFO]   Training abgeschlossen in 5.42s (Backend: cuml)\n",
      "01:52:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:52:26 [INFO]   Training abgeschlossen in 5.67s (Backend: cuml)\n",
      "01:53:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.2/8.0 GB)\n",
      "01:53:39 [INFO]   Training abgeschlossen in 5.94s (Backend: cuml)\n",
      "01:54:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:54:51 [INFO]   Training abgeschlossen in 6.37s (Backend: cuml)\n",
      "01:55:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:56:04 [INFO]   Training abgeschlossen in 6.57s (Backend: cuml)\n",
      "01:57:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:57:16 [INFO]   Training abgeschlossen in 6.81s (Backend: cuml)\n",
      "01:58:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:58:29 [INFO]   Training abgeschlossen in 7.43s (Backend: cuml)\n",
      "01:59:34 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "01:59:41 [INFO]   Training abgeschlossen in 7.48s (Backend: cuml)\n",
      "02:00:46 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.3/8.0 GB)\n",
      "02:00:54 [INFO]   Training abgeschlossen in 7.77s (Backend: cuml)\n",
      "02:01:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:02:07 [INFO]   Training abgeschlossen in 8.05s (Backend: cuml)\n",
      "02:03:12 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:03:20 [INFO]   Training abgeschlossen in 8.23s (Backend: cuml)\n",
      "02:04:25 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:04:33 [INFO]   Training abgeschlossen in 8.40s (Backend: cuml)\n",
      "02:05:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:05:46 [INFO]   Training abgeschlossen in 8.77s (Backend: cuml)\n",
      "02:06:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:06:58 [INFO]   Training abgeschlossen in 8.95s (Backend: cuml)\n",
      "02:08:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:08:11 [INFO]   Training abgeschlossen in 9.25s (Backend: cuml)\n",
      "02:09:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.4/8.0 GB)\n",
      "02:09:23 [INFO]   Training abgeschlossen in 9.40s (Backend: cuml)\n",
      "02:10:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:10:35 [INFO]   Training abgeschlossen in 9.67s (Backend: cuml)\n",
      "02:11:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:11:48 [INFO]   Training abgeschlossen in 10.01s (Backend: cuml)\n",
      "02:12:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:13:01 [INFO]   Training abgeschlossen in 10.10s (Backend: cuml)\n",
      "02:14:02 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:14:13 [INFO]   Training abgeschlossen in 10.45s (Backend: cuml)\n",
      "02:15:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:15:25 [INFO]   Training abgeschlossen in 10.56s (Backend: cuml)\n",
      "02:16:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:16:37 [INFO]   Training abgeschlossen in 10.91s (Backend: cuml)\n",
      "02:17:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.5/8.0 GB)\n",
      "02:17:49 [INFO]   Training abgeschlossen in 11.11s (Backend: cuml)\n",
      "02:18:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:19:01 [INFO]   Training abgeschlossen in 11.15s (Backend: cuml)\n",
      "02:20:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:20:13 [INFO]   Training abgeschlossen in 11.48s (Backend: cuml)\n",
      "02:21:13 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:21:25 [INFO]   Training abgeschlossen in 11.82s (Backend: cuml)\n",
      "02:22:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:22:36 [INFO]   Training abgeschlossen in 11.83s (Backend: cuml)\n",
      "02:23:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:23:48 [INFO]   Training abgeschlossen in 12.11s (Backend: cuml)\n",
      "02:24:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:24:59 [INFO]   Training abgeschlossen in 12.47s (Backend: cuml)\n",
      "02:25:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:26:10 [INFO]   Training abgeschlossen in 12.52s (Backend: cuml)\n",
      "02:27:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:27:21 [INFO]   Training abgeschlossen in 12.75s (Backend: cuml)\n",
      "02:28:17 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:28:30 [INFO]   Training abgeschlossen in 12.94s (Backend: cuml)\n",
      "02:29:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:29:40 [INFO]   Training abgeschlossen in 13.21s (Backend: cuml)\n",
      "02:30:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:30:49 [INFO]   Training abgeschlossen in 13.49s (Backend: cuml)\n",
      "02:31:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:31:58 [INFO]   Training abgeschlossen in 13.58s (Backend: cuml)\n",
      "02:32:53 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:33:06 [INFO]   Training abgeschlossen in 13.79s (Backend: cuml)\n",
      "02:34:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:34:15 [INFO]   Training abgeschlossen in 14.05s (Backend: cuml)\n",
      "02:35:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:35:23 [INFO]   Training abgeschlossen in 14.31s (Backend: cuml)\n",
      "02:36:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:36:31 [INFO]   Training abgeschlossen in 14.53s (Backend: cuml)\n",
      "02:37:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:37:38 [INFO]   Training abgeschlossen in 14.48s (Backend: cuml)\n",
      "02:38:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:38:45 [INFO]   Training abgeschlossen in 14.60s (Backend: cuml)\n",
      "02:39:37 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.6/8.0 GB)\n",
      "02:39:51 [INFO]   Training abgeschlossen in 14.77s (Backend: cuml)\n",
      "02:40:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:40:58 [INFO]   Training abgeschlossen in 15.10s (Backend: cuml)\n",
      "02:41:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:42:05 [INFO]   Training abgeschlossen in 15.40s (Backend: cuml)\n",
      "02:42:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:43:10 [INFO]   Training abgeschlossen in 15.45s (Backend: cuml)\n",
      "02:44:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:44:16 [INFO]   Training abgeschlossen in 15.59s (Backend: cuml)\n",
      "02:45:05 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:45:21 [INFO]   Training abgeschlossen in 16.05s (Backend: cuml)\n",
      "02:46:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:46:26 [INFO]   Training abgeschlossen in 15.99s (Backend: cuml)\n",
      "02:47:15 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:47:31 [INFO]   Training abgeschlossen in 16.22s (Backend: cuml)\n",
      "02:48:19 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:48:36 [INFO]   Training abgeschlossen in 16.67s (Backend: cuml)\n",
      "02:49:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:49:40 [INFO]   Training abgeschlossen in 16.92s (Backend: cuml)\n",
      "02:50:27 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:50:44 [INFO]   Training abgeschlossen in 16.95s (Backend: cuml)\n",
      "02:51:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:51:47 [INFO]   Training abgeschlossen in 17.10s (Backend: cuml)\n",
      "02:52:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:52:51 [INFO]   Training abgeschlossen in 17.30s (Backend: cuml)\n",
      "02:53:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:53:54 [INFO]   Training abgeschlossen in 17.54s (Backend: cuml)\n",
      "02:54:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:54:57 [INFO]   Training abgeschlossen in 17.84s (Backend: cuml)\n",
      "02:55:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:55:59 [INFO]   Training abgeschlossen in 17.98s (Backend: cuml)\n",
      "02:56:43 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:57:02 [INFO]   Training abgeschlossen in 18.26s (Backend: cuml)\n",
      "02:57:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:58:04 [INFO]   Training abgeschlossen in 18.57s (Backend: cuml)\n",
      "02:58:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "02:59:05 [INFO]   Training abgeschlossen in 18.82s (Backend: cuml)\n",
      "02:59:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:00:07 [INFO]   Training abgeschlossen in 18.84s (Backend: cuml)\n",
      "03:00:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:01:08 [INFO]   Training abgeschlossen in 18.98s (Backend: cuml)\n",
      "03:01:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:02:08 [INFO]   Training abgeschlossen in 19.29s (Backend: cuml)\n",
      "03:02:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:03:09 [INFO]   Training abgeschlossen in 19.50s (Backend: cuml)\n",
      "03:03:49 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:04:09 [INFO]   Training abgeschlossen in 19.71s (Backend: cuml)\n",
      "03:04:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:05:08 [INFO]   Training abgeschlossen in 19.96s (Backend: cuml)\n",
      "03:05:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:06:08 [INFO]   Training abgeschlossen in 19.98s (Backend: cuml)\n",
      "03:06:47 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:07:07 [INFO]   Training abgeschlossen in 20.27s (Backend: cuml)\n",
      "03:07:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:08:06 [INFO]   Training abgeschlossen in 20.49s (Backend: cuml)\n",
      "03:08:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:09:04 [INFO]   Training abgeschlossen in 20.71s (Backend: cuml)\n",
      "03:09:42 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.7/8.0 GB)\n",
      "03:10:03 [INFO]   Training abgeschlossen in 20.96s (Backend: cuml)\n",
      "03:10:39 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:11:00 [INFO]   Training abgeschlossen in 21.11s (Backend: cuml)\n",
      "03:11:36 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:11:58 [INFO]   Training abgeschlossen in 21.28s (Backend: cuml)\n",
      "03:12:33 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:12:55 [INFO]   Training abgeschlossen in 21.49s (Backend: cuml)\n",
      "03:13:30 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:13:52 [INFO]   Training abgeschlossen in 21.67s (Backend: cuml)\n",
      "03:14:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:14:48 [INFO]   Training abgeschlossen in 21.90s (Backend: cuml)\n",
      "03:15:23 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:15:45 [INFO]   Training abgeschlossen in 22.08s (Backend: cuml)\n",
      "03:16:18 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:16:41 [INFO]   Training abgeschlossen in 22.34s (Backend: cuml)\n",
      "03:17:14 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:17:36 [INFO]   Training abgeschlossen in 22.47s (Backend: cuml)\n",
      "03:18:09 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:18:31 [INFO]   Training abgeschlossen in 22.62s (Backend: cuml)\n",
      "03:19:03 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:19:26 [INFO]   Training abgeschlossen in 22.89s (Backend: cuml)\n",
      "03:19:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:20:21 [INFO]   Training abgeschlossen in 23.05s (Backend: cuml)\n",
      "03:20:51 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:21:15 [INFO]   Training abgeschlossen in 23.27s (Backend: cuml)\n",
      "03:21:45 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:22:09 [INFO]   Training abgeschlossen in 23.50s (Backend: cuml)\n",
      "03:22:38 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:23:02 [INFO]   Training abgeschlossen in 23.66s (Backend: cuml)\n",
      "03:23:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:23:55 [INFO]   Training abgeschlossen in 23.82s (Backend: cuml)\n",
      "03:24:24 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:24:48 [INFO]   Training abgeschlossen in 24.11s (Backend: cuml)\n",
      "03:25:16 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:25:40 [INFO]   Training abgeschlossen in 24.42s (Backend: cuml)\n",
      "03:26:08 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:26:33 [INFO]   Training abgeschlossen in 24.56s (Backend: cuml)\n",
      "03:26:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:27:24 [INFO]   Training abgeschlossen in 24.84s (Backend: cuml)\n",
      "03:27:50 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:28:15 [INFO]   Training abgeschlossen in 24.97s (Backend: cuml)\n",
      "03:28:41 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:29:06 [INFO]   Training abgeschlossen in 25.01s (Backend: cuml)\n",
      "03:29:31 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:29:56 [INFO]   Training abgeschlossen in 25.24s (Backend: cuml)\n",
      "03:30:21 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:30:47 [INFO]   Training abgeschlossen in 25.50s (Backend: cuml)\n",
      "03:31:10 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:31:36 [INFO]   Training abgeschlossen in 25.64s (Backend: cuml)\n",
      "03:32:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:32:38 [INFO]   Training abgeschlossen in 38.21s (Backend: cuml)\n",
      "03:33:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:33:38 [INFO]   Training abgeschlossen in 36.99s (Backend: cuml)\n",
      "03:34:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:34:39 [INFO]   Training abgeschlossen in 38.33s (Backend: cuml)\n",
      "03:35:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:35:40 [INFO]   Training abgeschlossen in 39.72s (Backend: cuml)\n",
      "03:36:01 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:36:39 [INFO]   Training abgeschlossen in 37.79s (Backend: cuml)\n",
      "03:37:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:37:38 [INFO]   Training abgeschlossen in 38.21s (Backend: cuml)\n",
      "03:37:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:38:38 [INFO]   Training abgeschlossen in 40.13s (Backend: cuml)\n",
      "03:38:58 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:39:40 [INFO]   Training abgeschlossen in 42.38s (Backend: cuml)\n",
      "03:39:59 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:40:41 [INFO]   Training abgeschlossen in 42.05s (Backend: cuml)\n",
      "03:41:00 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:41:39 [INFO]   Training abgeschlossen in 39.63s (Backend: cuml)\n",
      "03:41:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:42:39 [INFO]   Training abgeschlossen in 42.13s (Backend: cuml)\n",
      "03:42:57 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:43:39 [INFO]   Training abgeschlossen in 41.80s (Backend: cuml)\n",
      "03:43:55 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:44:37 [INFO]   Training abgeschlossen in 42.03s (Backend: cuml)\n",
      "03:44:54 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:45:36 [INFO]   Training abgeschlossen in 42.07s (Backend: cuml)\n",
      "03:45:52 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:46:33 [INFO]   Training abgeschlossen in 41.03s (Backend: cuml)\n",
      "03:46:48 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:47:30 [INFO]   Training abgeschlossen in 41.77s (Backend: cuml)\n",
      "03:47:44 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:48:26 [INFO]   Training abgeschlossen in 41.28s (Backend: cuml)\n",
      "03:48:40 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:49:22 [INFO]   Training abgeschlossen in 42.30s (Backend: cuml)\n",
      "03:49:35 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:50:17 [INFO]   Training abgeschlossen in 41.11s (Backend: cuml)\n",
      "03:50:29 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:51:14 [INFO]   Training abgeschlossen in 43.95s (Backend: cuml)\n",
      "03:51:26 [INFO]     60,000 labeled → Accuracy: 0.8866 (Train: 44.0s, Query: 0.66s) | GPU: 2.8/8.0 GB\n",
      "03:51:26 [INFO] ✓ Verwende RAPIDS cuML SVM (GPU: 2.8/8.0 GB)\n",
      "03:52:08 [INFO]   Training abgeschlossen in 41.60s (Backend: cuml)\n",
      "03:52:19 [INFO]     Final: 60,000 labeled → Accuracy: 0.8866, F1: 0.8858\n",
      "\n",
      "✓ Alle Experimente abgeschlossen in 5600.6 Minuten\n",
      "\n",
      "Führe statistische Analyse durch...\n",
      "\n",
      "====================================================================================================\n",
      "DETAILLIERTER STATISTISCHER BERICHT - GPU-SVM ACTIVE LEARNING (FASHION-MNIST)\n",
      "====================================================================================================\n",
      "Signifikanzniveau: 0.05 (mit Bonferroni-Korrektur)\n",
      "Anzahl Runs pro Experiment: 5\n",
      "Statistischer Test: Wilcoxon Signed-Rank Test\n",
      "Effektstärkemaß: Cliff's Delta\n",
      "\n",
      "\n",
      "Keine signifikanten Verbesserungen gefunden!\n",
      "\n",
      "\n",
      "ZUSAMMENFASSUNG NACH STRATEGIE:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Entropie-Auswahl:\n",
      "  - Signifikante Verbesserungen: 0/5 (0.0%)\n",
      "  - Durchschnittliche Verbesserung: 1.04%\n",
      "  - Durchschnittliche Effektstärke: 1.000\n",
      "\n",
      "Margin-Auswahl:\n",
      "  - Signifikante Verbesserungen: 0/5 (0.0%)\n",
      "  - Durchschnittliche Verbesserung: 1.22%\n",
      "  - Durchschnittliche Effektstärke: 1.000\n",
      "\n",
      "Geringste Konfidenz:\n",
      "  - Signifikante Verbesserungen: 0/5 (0.0%)\n",
      "  - Durchschnittliche Verbesserung: 1.31%\n",
      "  - Durchschnittliche Effektstärke: 1.000\n",
      "\n",
      "\n",
      "EMPFEHLUNG:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Die Active Learning Strategien zeigen keine signifikanten Verbesserungen\n",
      "gegenüber der zufälligen Auswahl in diesem Experiment.\n",
      "\n",
      "====================================================================================================\n",
      "03:52:19 [INFO] ✓ Statistischer Bericht gespeichert: reports/gpu_svm_fashion_mnist_statistischer_bericht.txt\n",
      "\n",
      "Erstelle Visualisierungen...\n",
      "03:52:20 [INFO] ✓ Visualisierung erstellt: plots/gpu_svm_fashion_mnist_performance.png\n",
      "03:52:20 [INFO] ✓ Leistungsmetriken erstellt: plots/gpu_svm_fashion_mnist_metriken.png\n",
      "03:52:21 [INFO] ✓ Detaillierte Analyse erstellt: plots/gpu_svm_fashion_mnist_detaillierte_analyse.png\n",
      "\n",
      "Berechne Label-Einsparungen...\n",
      "03:52:21 [INFO] ✓ Label-Einsparungs-Analyse erstellt: plots/gpu_svm_fashion_mnist_label_einsparung.png\n",
      "\n",
      "================================================================================\n",
      "LABEL-EINSPARUNGS-BERICHT - GPU-SVM ACTIVE LEARNING (FASHION-MNIST)\n",
      "================================================================================\n",
      "\n",
      "HAUPTERGEBNIS:\n",
      "Die Margin-Auswahl-Strategie\n",
      "benötigt nur 3,400 Labels\n",
      "um 95% der Baseline-Performance zu erreichen.\n",
      "Das entspricht einer Einsparung von 94.3%!\n",
      "\n",
      "\n",
      "ZIEL: 90% der Baseline-Performance\n",
      "------------------------------------------------------------\n",
      "Baseline-Genauigkeit (100% Daten): 0.8836\n",
      "Ziel-Genauigkeit: 0.7952\n",
      "\n",
      "Benötigte Labels:\n",
      "  - Zufällige Auswahl   :  1,600 ±    0 ( 97.3% Einsparung)\n",
      "  - Geringste Konfidenz :  1,600 ±    0 ( 97.3% Einsparung)\n",
      "  - Margin-Auswahl      :  1,700 ±  200 ( 97.2% Einsparung)\n",
      "  - Entropie-Auswahl    :  3,100 ±  447 ( 94.8% Einsparung)\n",
      "\n",
      "\n",
      "ZIEL: 95% der Baseline-Performance\n",
      "------------------------------------------------------------\n",
      "Baseline-Genauigkeit (100% Daten): 0.8836\n",
      "Ziel-Genauigkeit: 0.8394\n",
      "\n",
      "Benötigte Labels:\n",
      "  - Margin-Auswahl      :  3,400 ±  244 ( 94.3% Einsparung)\n",
      "    → 41.4% weniger Labels als Zufällige Auswahl\n",
      "  - Geringste Konfidenz :  3,700 ±  374 ( 93.8% Einsparung)\n",
      "    → 36.2% weniger Labels als Zufällige Auswahl\n",
      "  - Zufällige Auswahl   :  5,800 ±  400 ( 90.3% Einsparung)\n",
      "  - Entropie-Auswahl    :  5,900 ±  509 ( 90.2% Einsparung)\n",
      "\n",
      "\n",
      "ZIEL: 98% der Baseline-Performance\n",
      "------------------------------------------------------------\n",
      "Baseline-Genauigkeit (100% Daten): 0.8836\n",
      "Ziel-Genauigkeit: 0.8659\n",
      "\n",
      "Benötigte Labels:\n",
      "  - Geringste Konfidenz :  7,400 ±  509 ( 87.7% Einsparung)\n",
      "    → 73.2% weniger Labels als Zufällige Auswahl\n",
      "  - Margin-Auswahl      :  7,400 ±  600 ( 87.7% Einsparung)\n",
      "    → 73.2% weniger Labels als Zufällige Auswahl\n",
      "  - Entropie-Auswahl    : 10,500 ±  734 ( 82.5% Einsparung)\n",
      "    → 62.0% weniger Labels als Zufällige Auswahl\n",
      "  - Zufällige Auswahl   : 27,600 ± 16205 ( 54.0% Einsparung)\n",
      "\n",
      "\n",
      "GPU-PERFORMANCE:\n",
      "------------------------------------------------------------\n",
      "Backend: CUML\n",
      "GPU verfügbar: Ja\n",
      "TensorFloat-32: Aktiviert\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "VRAM: 7.6 GB\n",
      "Tensor Cores: ✓ Verfügbar und aktiviert\n",
      "\n",
      "================================================================================\n",
      "03:52:21 [INFO] ✓ Label-Einsparungs-Bericht gespeichert: reports/gpu_svm_fashion_mnist_label_einsparungs_bericht.txt\n",
      "\n",
      "✓ Ergebnisse gespeichert: results/gpu_svm_fashion_mnist_results.csv\n",
      "✓ Statistische Analyse gespeichert: results/gpu_svm_fashion_mnist_statistical_analysis.csv\n",
      "✓ Label-Einsparungen gespeichert: results/gpu_svm_fashion_mnist_label_savings.csv\n",
      "✓ Excel-Zusammenfassung gespeichert: results/gpu_svm_fashion_mnist_summary.xlsx\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT ERFOLGREICH ABGESCHLOSSEN\n",
      "================================================================================\n",
      "Datensatz: Fashion-MNIST\n",
      "GPU Backend verwendet: cuml\n",
      "Gesamtanzahl Experimente: 100\n",
      "Durchschnittliche Trainingszeit: 11.26s\n",
      "\n",
      "Signifikante Verbesserungen: 0/15 (0.0%)\n",
      "\n",
      "Output-Dateien:\n",
      "- Visualisierungen: plots/\n",
      "  - gpu_svm_fashion_mnist_performance.png\n",
      "  - gpu_svm_fashion_mnist_metriken.png\n",
      "  - gpu_svm_fashion_mnist_detaillierte_analyse.png\n",
      "  - gpu_svm_fashion_mnist_label_einsparung.png\n",
      "- Ergebnisse: results/\n",
      "  - gpu_svm_fashion_mnist_results.csv\n",
      "  - gpu_svm_fashion_mnist_statistical_analysis.csv\n",
      "  - gpu_svm_fashion_mnist_label_savings.csv\n",
      "  - gpu_svm_fashion_mnist_summary.xlsx\n",
      "- Berichte: reports/\n",
      "  - gpu_svm_fashion_mnist_statistischer_bericht.txt\n",
      "  - gpu_svm_fashion_mnist_label_einsparungs_bericht.txt\n",
      "- Logs: logs/\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "=================================================================\n",
    "GPU-Optimiertes Active Learning für SVM auf Fashion-MNIST\n",
    "=================================================================\n",
    "Professionelles Framework für GPU-beschleunigte SVM Active Learning\n",
    "Experimente mit statistischer Analyse für Bachelorarbeit.\n",
    "\n",
    "Optimiert für NVIDIA RTX 4060 (8GB VRAM) mit RAPIDS cuML/ThunderSVM.\n",
    "Mit TensorFloat-32 (TF32) Optimierungen für Ampere GPUs.\n",
    "\n",
    "Version: 2.0 - GPU-Optimiert mit TF32 und Memory Management\n",
    "            \n",
    "GPU-SVM Implementierungen:\n",
    "- RAPIDS cuML SVC (primär)\n",
    "- ThunderSVM (Fallback)\n",
    "- Sklearn SVC (CPU Fallback)\n",
    "\n",
    "Query-Strategien:\n",
    "- Random Sampling (Baseline)\n",
    "- Entropy Sampling\n",
    "- Margin Sampling\n",
    "- Least Confidence\n",
    "\n",
    "Statistische Analyse:\n",
    "- Wilcoxon Signed-Rank Test\n",
    "- Cliff's Delta Effektstärke\n",
    "- Bonferroni-Korrektur für multiple Vergleiche\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Matplotlib Backend setzen\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Für Server ohne GUI\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn mit Fehlerbehandlung\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    try:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    except:\n",
    "        try:\n",
    "            plt.style.use('seaborn-whitegrid')\n",
    "        except:\n",
    "            plt.style.use('ggplot')\n",
    "except ImportError:\n",
    "    print(\"Warnung: Seaborn nicht installiert. Verwende Standard-Matplotlib.\")\n",
    "    sns = None\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# TensorFloat-32 (TF32) Optimierungen für RTX 4060 (Ampere)\n",
    "# -------------------------------------------------------------------------------\n",
    "if torch.cuda.is_available():\n",
    "    # Aktiviere TF32 für Matrix-Multiplikationen (10x schneller auf Tensor Cores!)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    # Setze Float32 MatMul Präzision für optimale Performance\n",
    "    torch.set_float32_matmul_precision('high')  # 'high', 'medium', oder 'highest'\n",
    "    \n",
    "    # Weitere Optimierungen für RTX 4060\n",
    "    torch.cuda.set_per_process_memory_fraction(0.85)  # 85% VRAM nutzen\n",
    "    \n",
    "    print(\"✓ TensorFloat-32 (TF32) aktiviert für RTX 40xx Serie\")\n",
    "    print(\"  → Bis zu 10x schnellere Matrix-Operationen mit Tensor Cores\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC as SklearnSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "# Statistische Tests\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# GPU-spezifische Imports mit Fehlerbehandlung\n",
    "GPU_AVAILABLE = False\n",
    "CUML_AVAILABLE = False\n",
    "THUNDERSVM_AVAILABLE = False\n",
    "RMM_AVAILABLE = False\n",
    "\n",
    "# Versuche RAPIDS cuML zu importieren\n",
    "try:\n",
    "    import cupy as cp\n",
    "    import cuml\n",
    "    from cuml.svm import SVC as cuMLSVC\n",
    "    \n",
    "    # WICHTIGE OPTIMIERUNG: Setze Output auf NumPy um GPU-CPU Transfers zu vermeiden\n",
    "    cuml.set_global_output_type('numpy')\n",
    "    \n",
    "    CUML_AVAILABLE = True\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"✓ RAPIDS cuML verfügbar - primäre GPU-Beschleunigung aktiviert\")\n",
    "    print(\"✓ cuML Output-Type auf 'numpy' gesetzt - verhindert unnötige GPU→CPU Kopien\")\n",
    "    \n",
    "    # RMM ist optional\n",
    "    try:\n",
    "        import rmm\n",
    "        from rmm.allocators.cupy import rmm_cupy_allocator\n",
    "        RMM_AVAILABLE = True\n",
    "    except:\n",
    "        RMM_AVAILABLE = False\n",
    "        print(\"  Info: RMM Memory Manager nicht verfügbar, verwende Standard CuPy Memory\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"⚠ RAPIDS cuML nicht verfügbar: {e}\")\n",
    "\n",
    "# Versuche ThunderSVM zu importieren (mit besserer Fehlerbehandlung)\n",
    "try:\n",
    "    # Prüfe CUDA Version Kompatibilität\n",
    "    import subprocess\n",
    "    try:\n",
    "        cuda_version = subprocess.check_output(['nvcc', '--version']).decode()\n",
    "        print(f\"CUDA Version gefunden: {cuda_version.split('release')[-1].split(',')[0].strip()}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    from thundersvm import SVC as ThunderSVC\n",
    "    # Test ob ThunderSVM wirklich funktioniert\n",
    "    test = ThunderSVC()\n",
    "    THUNDERSVM_AVAILABLE = True\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"✓ ThunderSVM verfügbar - alternative GPU-Beschleunigung aktiviert\")\n",
    "except (ImportError, OSError) as e:\n",
    "    if \"libcusparse\" in str(e):\n",
    "        print(\"⚠ ThunderSVM benötigt ältere CUDA-Version (9.x/10.x). Aktuelle CUDA-Version inkompatibel.\")\n",
    "        print(\"  Tipp: Verwenden Sie RAPIDS cuML stattdessen für moderne GPUs.\")\n",
    "    else:\n",
    "        print(f\"⚠ ThunderSVM nicht verfügbar: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ ThunderSVM Test fehlgeschlagen: {e}\")\n",
    "\n",
    "if not GPU_AVAILABLE:\n",
    "    print(\"\\n⚠ WARNUNG: Keine GPU-Beschleunigung verfügbar! Verwende CPU-basiertes sklearn.\")\n",
    "    print(\"\\nEmpfohlene Installation für RTX 4060:\")\n",
    "    print(\"conda create -n rapids-gpu python=3.11\")\n",
    "    print(\"conda activate rapids-gpu\")\n",
    "    print(\"conda install -c rapidsai -c conda-forge -c nvidia rapids=24.12 python=3.11 cudatoolkit=12.0\")\n",
    "\n",
    "# Excel-Export\n",
    "try:\n",
    "    import openpyxl\n",
    "    EXCEL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warnung: openpyxl nicht installiert. Excel-Export wird deaktiviert.\")\n",
    "    EXCEL_AVAILABLE = False\n",
    "\n",
    "# Weitere GPU-Optimierungen wenn verfügbar\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA Cache für wiederholte Kernel-Launches\n",
    "    os.environ['CUDA_CACHE_MAXSIZE'] = '2147483648'  # 2GB Kernel Cache\n",
    "    \n",
    "    # Reduziere CUDA Synchronisierungen\n",
    "    os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "    \n",
    "    # Aktiviere CUDA Graphs für wiederholte Operationen (wenn verfügbar)\n",
    "    if hasattr(torch.cuda, 'graph'):\n",
    "        torch.cuda.set_sync_debug_mode(0)\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Konfiguration\n",
    "# -------------------------------------------------------------------------------\n",
    "USE_MEMORY_POOL = False  # Memory Pool deaktivieren bei Problemen\n",
    "BUDGET_PERCENTAGES = [0.2, 0.4, 0.6, 0.8, 1.0]  # 20%, 40%, 60%, 80%, 100%\n",
    "BATCH_SIZE = 500  # Größere Batches für effizienteres GPU Training\n",
    "N_RUNS = 5  # Anzahl Wiederholungen\n",
    "INITIAL_PERCENTAGE = 0.01  # 1% initial labeling\n",
    "SIGNIFICANCE_LEVEL = 0.05  # Für statistische Tests\n",
    "SEED = 42\n",
    "\n",
    "# SVM-spezifische Konfiguration\n",
    "SVM_CONFIGS = {\n",
    "    'cuml': {\n",
    "        'kernel': 'rbf',\n",
    "        'gamma': 'scale',\n",
    "        'C': 1.0,\n",
    "        'cache_size': 1000,\n",
    "        'probability': True,\n",
    "        'max_iter': 5000,\n",
    "        'tol': 1e-3  # Toleranz hinzugefügt\n",
    "    },\n",
    "    'thundersvm': {\n",
    "        'kernel': 'rbf',\n",
    "        'gamma': 'auto',\n",
    "        'C': 1.0,\n",
    "        'gpu_id': 0,\n",
    "        'max_iter': 5000\n",
    "    },\n",
    "    'sklearn': {\n",
    "        'kernel': 'rbf',\n",
    "        'gamma': 'scale',\n",
    "        'C': 1.0,\n",
    "        'cache_size': 2000,\n",
    "        'probability': True,\n",
    "        'max_iter': 5000,\n",
    "        'decision_function_shape': 'ovr'\n",
    "    }\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# GPU Memory Management\n",
    "# -------------------------------------------------------------------------------\n",
    "def setup_gpu_memory():\n",
    "    \"\"\"Konfiguriert optimales GPU Memory Management für RTX 4060.\"\"\"\n",
    "    if not CUML_AVAILABLE:\n",
    "        return False\n",
    "        \n",
    "    if not USE_MEMORY_POOL or not RMM_AVAILABLE:\n",
    "        if not RMM_AVAILABLE and USE_MEMORY_POOL:\n",
    "            print(\"✓ RMM nicht verfügbar, verwende Standard GPU Memory Management\")\n",
    "        else:\n",
    "            print(\"✓ Verwende Standard GPU Memory Management (RMM Pool deaktiviert)\")\n",
    "            \n",
    "        # Zeige GPU Info wenn möglich\n",
    "        try:\n",
    "            import subprocess\n",
    "            result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', \n",
    "                                   '--format=csv,noheader'], \n",
    "                                  capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                gpu_info = result.stdout.strip()\n",
    "                print(f\"  GPU: {gpu_info}\")\n",
    "        except:\n",
    "            pass\n",
    "        return True\n",
    "    \n",
    "    # RMM Pool Setup (wenn aktiviert und verfügbar)\n",
    "    try:\n",
    "        # Alte Allocations bereinigen\n",
    "        if hasattr(cp, 'get_default_memory_pool'):\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        gc.collect()\n",
    "        \n",
    "        # RMM mit optimierten Einstellungen für 8GB VRAM\n",
    "        rmm.reinitialize(\n",
    "            pool_allocator=True,\n",
    "            initial_pool_size=\"5GB\",    # Konservativ für SVM\n",
    "            maximum_pool_size=\"6.5GB\",  # 1.5GB Reserve\n",
    "            managed_memory=False        # Bessere Performance\n",
    "        )\n",
    "        \n",
    "        # CuPy mit RMM verknüpfen\n",
    "        cp.cuda.set_allocator(rmm_cupy_allocator)\n",
    "        \n",
    "        print(f\"✓ RMM Memory Pool konfiguriert (5GB initial, 6.5GB max)\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ RMM Pool Setup fehlgeschlagen: {e}\")\n",
    "        print(\"  Verwende Standard GPU Memory Management\")\n",
    "        return True\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Räumt GPU-Speicher auf.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    if CUML_AVAILABLE:\n",
    "        try:\n",
    "            mempool = cp.get_default_memory_pool()\n",
    "            pinned_mempool = cp.get_default_pinned_memory_pool()\n",
    "            mempool.free_all_blocks()\n",
    "            pinned_mempool.free_all_blocks()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "def get_gpu_memory_info():\n",
    "    \"\"\"Gibt aktuelle GPU-Speichernutzung zurück.\"\"\"\n",
    "    info = {}\n",
    "    \n",
    "    # Versuche nvidia-smi (funktioniert fast immer)\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.total', \n",
    "                               '--format=csv,noheader,nounits'], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            values = result.stdout.strip().split(', ')\n",
    "            info['gpu_used'] = float(values[0]) / 1024  # MB to GB\n",
    "            info['gpu_total'] = float(values[1]) / 1024\n",
    "            info['gpu_free'] = info['gpu_total'] - info['gpu_used']\n",
    "            return info\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback: Keine GPU Info verfügbar\n",
    "    return {'gpu_used': 0.0, 'gpu_total': 0.0, 'gpu_free': 0.0}\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Reproduzierbarkeit\n",
    "# -------------------------------------------------------------------------------\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Logging konfigurieren\n",
    "# -------------------------------------------------------------------------------\n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            os.path.join(log_dir, f\"gpu_svm_fashion_mnist_{time.strftime('%Y%m%d_%H%M%S')}.log\"),\n",
    "            encoding='utf-8'\n",
    "        ),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Erstelle Output-Verzeichnisse\n",
    "output_dirs = [\"plots\", \"results\", \"reports\"]\n",
    "for dir_name in output_dirs:\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "        logger.info(f\"Erstellt Verzeichnis: {dir_name}\")\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Fashion-MNIST Daten laden (ANGEPASST FÜR FASHION-MNIST)\n",
    "# -------------------------------------------------------------------------------\n",
    "def load_fashion_mnist_data():\n",
    "    \"\"\"Lädt Fashion-MNIST-Datensatz optimiert für GPU-Verarbeitung.\"\"\"\n",
    "    logger.info(\"Lade Fashion-MNIST-Datensatz...\")\n",
    "    \n",
    "    # Fashion-MNIST Klassen\n",
    "    classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.2860,), (0.3530,))  # Fashion-MNIST spezifische Normalisierung\n",
    "    ])\n",
    "    \n",
    "    data_dir = './data'\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    try:\n",
    "        # Lade Fashion-MNIST statt MNIST\n",
    "        train_dataset = torchvision.datasets.FashionMNIST(\n",
    "            root=data_dir, train=True, download=True, transform=transform\n",
    "        )\n",
    "        test_dataset = torchvision.datasets.FashionMNIST(\n",
    "            root=data_dir, train=False, download=True, transform=transform\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler beim Laden des Fashion-MNIST-Datensatzes: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Konvertiere zu numpy arrays\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    \n",
    "    X_train, y_train = next(iter(train_loader))\n",
    "    X_test, y_test = next(iter(test_loader))\n",
    "    \n",
    "    # Flatten für SVM (2D: batch, features)\n",
    "    X_train_flat = X_train.view(X_train.size(0), -1).numpy()\n",
    "    X_test_flat = X_test.view(X_test.size(0), -1).numpy()\n",
    "    \n",
    "    y_train = y_train.numpy()\n",
    "    y_test = y_test.numpy()\n",
    "    \n",
    "    logger.info(f\"✓ Fashion-MNIST geladen: {len(X_train_flat):,} Trainingsbilder, {len(X_test_flat):,} Testbilder\")\n",
    "    logger.info(f\"  Feature-Dimensionen: {X_train_flat.shape[1]}\")\n",
    "    logger.info(f\"  Klassen: {len(classes)} - {', '.join(classes)}\")\n",
    "    logger.info(f\"  Speicherbedarf: {(X_train_flat.nbytes + X_test_flat.nbytes) / 1024**2:.1f} MB\")\n",
    "    \n",
    "    return X_train_flat, y_train, X_test_flat, y_test\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# GPU-SVM Wrapper Klasse\n",
    "# -------------------------------------------------------------------------------\n",
    "class GPUOptimizedSVM:\n",
    "    \"\"\"\n",
    "    Wrapper für verschiedene SVM-Implementierungen mit automatischer GPU-Auswahl.\n",
    "    Priorisiert RAPIDS cuML > ThunderSVM > sklearn basierend auf Verfügbarkeit.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_samples=None):\n",
    "        self.n_samples = n_samples\n",
    "        self.backend = None\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_fitted = False\n",
    "        \n",
    "        # Wähle Backend basierend auf Verfügbarkeit\n",
    "        self._select_backend()\n",
    "        \n",
    "    def _select_backend(self):\n",
    "        \"\"\"Wählt optimales Backend basierend auf Verfügbarkeit.\"\"\"\n",
    "        if CUML_AVAILABLE:\n",
    "            try:\n",
    "                # Test ob cuML wirklich funktioniert\n",
    "                test_data = cp.random.rand(100, 10, dtype=cp.float32)\n",
    "                test_labels = cp.random.randint(0, 2, 100, dtype=cp.int32)\n",
    "                test_model = cuMLSVC(max_iter=1)\n",
    "                test_model.fit(test_data, test_labels)\n",
    "                self.backend = 'cuml'\n",
    "                \n",
    "                # Zeige Memory Info\n",
    "                mem_info = get_gpu_memory_info()\n",
    "                if 'gpu_total' in mem_info:\n",
    "                    logger.info(f\"✓ Verwende RAPIDS cuML SVM (GPU: {mem_info.get('gpu_used', 0):.1f}/{mem_info.get('gpu_total', 0):.1f} GB)\")\n",
    "                else:\n",
    "                    logger.info(\"✓ Verwende RAPIDS cuML SVM\")\n",
    "                    \n",
    "                del test_data, test_labels, test_model\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"cuML Test fehlgeschlagen: {e}\")\n",
    "                \n",
    "        if self.backend is None and THUNDERSVM_AVAILABLE:\n",
    "            try:\n",
    "                # Einfacher Test ohne Daten\n",
    "                test_model = ThunderSVC(max_iter=1)\n",
    "                self.backend = 'thundersvm'\n",
    "                logger.info(\"✓ Verwende ThunderSVM (GPU)\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"ThunderSVM Test fehlgeschlagen: {e}\")\n",
    "        \n",
    "        if self.backend is None:\n",
    "            self.backend = 'sklearn'\n",
    "            logger.warning(\"⚠ Verwende sklearn SVM (CPU) - keine GPU-Beschleunigung verfügbar!\")\n",
    "            logger.info(\"  Dies wird deutlich langsamer sein als GPU-beschleunigte Alternativen.\")\n",
    "            logger.info(\"  Empfehlung: Installieren Sie RAPIDS cuML für optimale Performance.\")\n",
    "    \n",
    "    def _create_model(self):\n",
    "        \"\"\"Erstellt SVM-Modell basierend auf gewähltem Backend.\"\"\"\n",
    "        if self.backend == 'cuml':\n",
    "            return cuMLSVC(**SVM_CONFIGS['cuml'])\n",
    "        elif self.backend == 'thundersvm':\n",
    "            return ThunderSVC(**SVM_CONFIGS['thundersvm'])\n",
    "        else:\n",
    "            return SklearnSVC(**SVM_CONFIGS['sklearn'])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Trainiert SVM mit automatischer GPU-Optimierung.\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Feature Scaling\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Normales Training mit Error Handling\n",
    "        try:\n",
    "            self.model = self._create_model()\n",
    "            \n",
    "            if self.backend == 'cuml':\n",
    "                # Konvertiere zu CuPy Arrays\n",
    "                X_gpu = cp.asarray(X_scaled, dtype=cp.float32)\n",
    "                y_gpu = cp.asarray(y, dtype=cp.int32)\n",
    "                \n",
    "                # Explizite CUDA Synchronisation\n",
    "                cp.cuda.Stream.null.synchronize()\n",
    "                \n",
    "                self.model.fit(X_gpu, y_gpu)\n",
    "                \n",
    "                # Cleanup\n",
    "                del X_gpu, y_gpu\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "            else:\n",
    "                self.model.fit(X_scaled, y)\n",
    "                \n",
    "        except Exception as e:\n",
    "            if self.backend == 'cuml':\n",
    "                logger.warning(f\"  GPU Training fehlgeschlagen: {e}\")\n",
    "                logger.info(\"  Fallback zu CPU...\")\n",
    "                \n",
    "                # Fallback zu sklearn\n",
    "                self.backend = 'sklearn'\n",
    "                self.model = self._create_model()\n",
    "                self.model.fit(X_scaled, y)\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        logger.info(f\"  Training abgeschlossen in {train_time:.2f}s (Backend: {self.backend})\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Gibt Wahrscheinlichkeiten zurück.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model not fitted!\")\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        if self.backend == 'cuml':\n",
    "            X_gpu = cp.asarray(X_scaled, dtype=cp.float32)\n",
    "            # cuML gibt bereits NumPy Arrays zurück dank set_global_output_type('numpy')\n",
    "            probs = self.model.predict_proba(X_gpu)\n",
    "            return probs  # Bereits NumPy, keine Konvertierung nötig!\n",
    "        elif self.backend == 'thundersvm':\n",
    "            # ThunderSVM probability prediction\n",
    "            if hasattr(self.model, 'predict_proba'):\n",
    "                return self.model.predict_proba(X_scaled)\n",
    "            else:\n",
    "                # Fallback für ThunderSVM ohne probability\n",
    "                predictions = self.model.predict(X_scaled)\n",
    "                n_classes = 10  # Fashion-MNIST\n",
    "                probs = np.zeros((len(predictions), n_classes))\n",
    "                for i, pred in enumerate(predictions):\n",
    "                    probs[i, int(pred)] = 1.0\n",
    "                return probs\n",
    "        else:\n",
    "            return self.model.predict_proba(X_scaled)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Gibt Vorhersagen zurück.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model not fitted!\")\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        if self.backend == 'cuml':\n",
    "            X_gpu = cp.asarray(X_scaled, dtype=cp.float32)\n",
    "            # cuML gibt bereits NumPy Arrays zurück dank set_global_output_type('numpy')\n",
    "            predictions = self.model.predict(X_gpu)\n",
    "            return predictions.astype(int)  # Bereits NumPy Array\n",
    "        else:\n",
    "            return self.model.predict(X_scaled)\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Query-Strategien (unverändert)\n",
    "# -------------------------------------------------------------------------------\n",
    "def entropy_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"Wählt Samples mit höchster Entropie aus.\"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        epsilon = 1e-10\n",
    "        probs = np.clip(probs, epsilon, 1.0 - epsilon)\n",
    "        entropies = -np.sum(probs * np.log(probs), axis=1)\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        return np.argsort(entropies)[-n_instances:]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Entropy Sampling: {e}\")\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def margin_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"Wählt Samples mit kleinstem Margin zwischen Top-2 Klassen.\"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        sorted_probs = np.sort(probs, axis=1)\n",
    "        \n",
    "        if sorted_probs.shape[1] >= 2:\n",
    "            margins = sorted_probs[:, -1] - sorted_probs[:, -2]\n",
    "        else:\n",
    "            margins = 1.0 - sorted_probs[:, -1]\n",
    "        \n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        return np.argsort(margins)[:n_instances]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Margin Sampling: {e}\")\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def least_confidence_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"Wählt Samples mit geringster Konfidenz.\"\"\"\n",
    "    try:\n",
    "        probs = model.predict_proba(X_pool)\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        return np.argsort(confidences)[:n_instances]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Least Confidence Sampling: {e}\")\n",
    "        return random_sampling(model, X_pool, n_instances)\n",
    "\n",
    "def random_sampling(model, X_pool, n_instances=1):\n",
    "    \"\"\"Zufällige Auswahl (Baseline).\"\"\"\n",
    "    try:\n",
    "        n_instances = min(n_instances, len(X_pool))\n",
    "        if n_instances <= 0:\n",
    "            return np.array([], dtype=int)\n",
    "        return np.random.choice(len(X_pool), size=n_instances, replace=False)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Random Sampling: {e}\")\n",
    "        return np.arange(min(n_instances, len(X_pool)))\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Active Learning Hauptfunktion (unverändert)\n",
    "# -------------------------------------------------------------------------------\n",
    "def run_gpu_svm_active_learning(X_train, y_train, X_test, y_test,\n",
    "                               strategy_name, strategy_func,\n",
    "                               budget_percentages, batch_size=500):\n",
    "    \"\"\"\n",
    "    Führt GPU-optimiertes Active Learning Experiment mit SVM durch.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    n_total = len(y_train)\n",
    "    \n",
    "    for budget_pct in budget_percentages:\n",
    "        n_budget = int(budget_pct * n_total)\n",
    "        \n",
    "        logger.info(f\"\\nGPU-SVM + {strategy_name} - Budget: {budget_pct:.0%} ({n_budget:,} Samples)\")\n",
    "        \n",
    "        for run in range(N_RUNS):\n",
    "            logger.info(f\"  Run {run+1}/{N_RUNS}\")\n",
    "            \n",
    "            try:\n",
    "                # Set seed for reproducibility\n",
    "                np.random.seed(SEED + run)\n",
    "                \n",
    "                # Initialisierung\n",
    "                pool_indices = np.arange(n_total)\n",
    "                labeled_indices = []\n",
    "                \n",
    "                # Initiale zufällige Auswahl\n",
    "                n_initial = max(100, int(INITIAL_PERCENTAGE * n_total))\n",
    "                n_initial = min(n_initial, len(pool_indices))\n",
    "                \n",
    "                initial_indices = np.random.choice(pool_indices, size=n_initial, replace=False)\n",
    "                labeled_indices = list(initial_indices)\n",
    "                pool_indices = np.setdiff1d(pool_indices, labeled_indices)\n",
    "                \n",
    "                # Tracking\n",
    "                accuracies = []\n",
    "                n_labeled_list = []\n",
    "                query_times = []\n",
    "                train_times = []\n",
    "                \n",
    "                while len(labeled_indices) < n_budget and len(pool_indices) > 0:\n",
    "                    # Clear GPU memory before training\n",
    "                    clear_gpu_memory()\n",
    "                    \n",
    "                    # Modell erstellen und trainieren\n",
    "                    model = GPUOptimizedSVM(n_samples=len(labeled_indices))\n",
    "                    \n",
    "                    train_start = time.time()\n",
    "                    model.fit(X_train[labeled_indices], y_train[labeled_indices])\n",
    "                    train_time = time.time() - train_start\n",
    "                    train_times.append(train_time)\n",
    "                    \n",
    "                    # Evaluation\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    acc = accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    accuracies.append(acc)\n",
    "                    n_labeled_list.append(len(labeled_indices))\n",
    "                    \n",
    "                    # Nächste Batch auswählen\n",
    "                    n_query = min(batch_size, n_budget - len(labeled_indices), len(pool_indices))\n",
    "                    if n_query <= 0:\n",
    "                        break\n",
    "                    \n",
    "                    # Query mit Zeitmessung\n",
    "                    query_start = time.time()\n",
    "                    query_indices = strategy_func(model, X_train[pool_indices], n_query)\n",
    "                    query_time = time.time() - query_start\n",
    "                    query_times.append(query_time)\n",
    "                    \n",
    "                    # Validierung der Query-Indizes\n",
    "                    query_indices = np.asarray(query_indices)\n",
    "                    query_indices = query_indices[query_indices < len(pool_indices)]\n",
    "                    \n",
    "                    if len(query_indices) == 0:\n",
    "                        logger.warning(f\"Keine gültigen Query-Indizes in Run {run+1}\")\n",
    "                        break\n",
    "                    \n",
    "                    selected_indices = pool_indices[query_indices]\n",
    "                    \n",
    "                    # Update\n",
    "                    labeled_indices.extend(selected_indices)\n",
    "                    pool_indices = np.setdiff1d(pool_indices, selected_indices)\n",
    "                    \n",
    "                    # Progress logging - nur bei wichtigen Meilensteinen\n",
    "                    if len(labeled_indices) % 10000 == 0 or len(labeled_indices) == n_budget:\n",
    "                        mem_info = get_gpu_memory_info()\n",
    "                        gpu_mem_str = \"\"\n",
    "                        if model.backend in ['cuml', 'thundersvm'] and 'gpu_used' in mem_info:\n",
    "                            gpu_mem_str = f\" | GPU: {mem_info['gpu_used']:.1f}/{mem_info['gpu_total']:.1f} GB\"\n",
    "                        \n",
    "                        logger.info(f\"    {len(labeled_indices):,} labeled → Accuracy: {acc:.4f} \"\n",
    "                                  f\"(Train: {train_time:.1f}s, Query: {query_time:.2f}s){gpu_mem_str}\")\n",
    "                \n",
    "                # Finale Evaluation mit mehr Training\n",
    "                if len(labeled_indices) > 0:\n",
    "                    clear_gpu_memory()\n",
    "                    model = GPUOptimizedSVM(n_samples=len(labeled_indices))\n",
    "                    model.fit(X_train[labeled_indices], y_train[labeled_indices])\n",
    "                    \n",
    "                    y_pred = model.predict(X_test)\n",
    "                    final_acc = accuracy_score(y_test, y_pred)\n",
    "                    final_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                    \n",
    "                    results.append({\n",
    "                        'strategy': strategy_name,\n",
    "                        'budget_pct': budget_pct,\n",
    "                        'run': run,\n",
    "                        'n_labeled': len(labeled_indices),\n",
    "                        'accuracy': final_acc,\n",
    "                        'f1_score': final_f1,\n",
    "                        'accuracies': accuracies,\n",
    "                        'n_labeled_list': n_labeled_list,\n",
    "                        'avg_query_time': np.mean(query_times) if query_times else 0,\n",
    "                        'avg_train_time': np.mean(train_times) if train_times else 0,\n",
    "                        'backend': model.backend\n",
    "                    })\n",
    "                    \n",
    "                    logger.info(f\"    Final: {len(labeled_indices):,} labeled → \"\n",
    "                              f\"Accuracy: {final_acc:.4f}, F1: {final_f1:.4f}\")\n",
    "                \n",
    "                # Cleanup\n",
    "                clear_gpu_memory()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Fehler in Run {run+1}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Statistische Analyse (unverändert)\n",
    "# -------------------------------------------------------------------------------\n",
    "def cliffs_delta(x, y):\n",
    "    \"\"\"Berechnet Cliff's Delta als Effektstärkemaß.\"\"\"\n",
    "    try:\n",
    "        nx = len(x)\n",
    "        ny = len(y)\n",
    "        \n",
    "        if nx == 0 or ny == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        greater = 0\n",
    "        less = 0\n",
    "        \n",
    "        for xi in x:\n",
    "            greater += np.sum(xi > y)\n",
    "            less += np.sum(xi < y)\n",
    "        \n",
    "        d = (greater - less) / (nx * ny)\n",
    "        d = np.clip(d, -1.0, 1.0)\n",
    "        \n",
    "        return d\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei Cliff's Delta: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def interpret_cliffs_delta(d):\n",
    "    \"\"\"Interpretiert die Effektstärke.\"\"\"\n",
    "    try:\n",
    "        abs_d = abs(float(d))\n",
    "        if abs_d < 0.147:\n",
    "            return \"negligible\"\n",
    "        elif abs_d < 0.33:\n",
    "            return \"small\"\n",
    "        elif abs_d < 0.474:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"large\"\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "def perform_statistical_analysis(results_df, metric='accuracy'):\n",
    "    \"\"\"Führt statistische Analyse durch.\"\"\"\n",
    "    statistical_results = []\n",
    "    \n",
    "    try:\n",
    "        strategies = results_df['strategy'].unique()\n",
    "        budget_levels = results_df['budget_pct'].unique()\n",
    "        \n",
    "        for budget_pct in budget_levels:\n",
    "            # Random Sampling als Baseline\n",
    "            baseline_data = results_df[\n",
    "                (results_df['strategy'] == 'Random Sampling') & \n",
    "                (results_df['budget_pct'] == budget_pct)\n",
    "            ][metric].values\n",
    "            \n",
    "            for strategy in strategies:\n",
    "                if strategy == 'Random Sampling':\n",
    "                    continue\n",
    "                    \n",
    "                strategy_data = results_df[\n",
    "                    (results_df['strategy'] == strategy) & \n",
    "                    (results_df['budget_pct'] == budget_pct)\n",
    "                ][metric].values\n",
    "                \n",
    "                if len(baseline_data) >= N_RUNS and len(strategy_data) >= N_RUNS:\n",
    "                    # Wilcoxon Test\n",
    "                    try:\n",
    "                        if np.allclose(strategy_data, baseline_data):\n",
    "                            statistic, p_value = 0.0, 1.0\n",
    "                        else:\n",
    "                            statistic, p_value = wilcoxon(\n",
    "                                strategy_data, baseline_data, \n",
    "                                alternative='greater',\n",
    "                                zero_method='zsplit'\n",
    "                            )\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Wilcoxon Test fehlgeschlagen: {e}\")\n",
    "                        statistic, p_value = 0.0, 1.0\n",
    "                    \n",
    "                    # Effektstärke\n",
    "                    effect_size = cliffs_delta(strategy_data, baseline_data)\n",
    "                    effect_interpretation = interpret_cliffs_delta(effect_size)\n",
    "                    \n",
    "                    # Statistiken\n",
    "                    baseline_mean = np.mean(baseline_data)\n",
    "                    baseline_std = np.std(baseline_data)\n",
    "                    strategy_mean = np.mean(strategy_data)\n",
    "                    strategy_std = np.std(strategy_data)\n",
    "                    \n",
    "                    improvement = strategy_mean - baseline_mean\n",
    "                    improvement_pct = ((improvement / baseline_mean) * 100) if baseline_mean > 0 else 0\n",
    "                    \n",
    "                    statistical_results.append({\n",
    "                        'strategy': strategy,\n",
    "                        'budget_pct': budget_pct,\n",
    "                        'baseline_mean': baseline_mean,\n",
    "                        'baseline_std': baseline_std,\n",
    "                        'strategy_mean': strategy_mean,\n",
    "                        'strategy_std': strategy_std,\n",
    "                        'improvement': improvement,\n",
    "                        'improvement_pct': improvement_pct,\n",
    "                        'wilcoxon_statistic': float(statistic),\n",
    "                        'p_value': float(p_value),\n",
    "                        'cliffs_delta': float(effect_size),\n",
    "                        'effect_size': effect_interpretation,\n",
    "                        'n_samples': len(strategy_data)\n",
    "                    })\n",
    "        \n",
    "        stat_df = pd.DataFrame(statistical_results)\n",
    "        \n",
    "        if len(stat_df) > 0:\n",
    "            # Bonferroni-Korrektur\n",
    "            n_comparisons = len(stat_df)\n",
    "            stat_df['p_value_corrected'] = np.minimum(stat_df['p_value'] * n_comparisons, 1.0)\n",
    "            stat_df['significant'] = stat_df['p_value_corrected'] < SIGNIFICANCE_LEVEL\n",
    "        \n",
    "        return stat_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei statistischer Analyse: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def create_statistical_report(stat_results):\n",
    "    \"\"\"Erstellt deutschen statistischen Bericht.\"\"\"\n",
    "    strategy_labels_de = {\n",
    "        'Random Sampling': 'Zufällige Auswahl',\n",
    "        'Entropy Sampling': 'Entropie-Auswahl',\n",
    "        'Margin Sampling': 'Margin-Auswahl',\n",
    "        'Least Confidence': 'Geringste Konfidenz'\n",
    "    }\n",
    "    \n",
    "    effect_labels_de = {\n",
    "        'negligible': 'vernachlässigbar',\n",
    "        'small': 'klein',\n",
    "        'medium': 'mittel',\n",
    "        'large': 'groß'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Sortiere nach Effektstärke\n",
    "        if not stat_results.empty and 'cliffs_delta' in stat_results.columns:\n",
    "            stat_results_sorted = stat_results.sort_values('cliffs_delta', ascending=False)\n",
    "        else:\n",
    "            stat_results_sorted = stat_results\n",
    "        \n",
    "        # Erstelle formatierten Bericht\n",
    "        report = []\n",
    "        report.append(\"\\n\" + \"=\"*100)\n",
    "        report.append(\"DETAILLIERTER STATISTISCHER BERICHT - GPU-SVM ACTIVE LEARNING (FASHION-MNIST)\")\n",
    "        report.append(\"=\"*100)\n",
    "        report.append(f\"Signifikanzniveau: {SIGNIFICANCE_LEVEL} (mit Bonferroni-Korrektur)\")\n",
    "        report.append(f\"Anzahl Runs pro Experiment: {N_RUNS}\")\n",
    "        report.append(f\"Statistischer Test: Wilcoxon Signed-Rank Test\")\n",
    "        report.append(f\"Effektstärkemaß: Cliff's Delta\")\n",
    "        report.append(\"\\n\")\n",
    "        \n",
    "        # Signifikante Ergebnisse\n",
    "        if 'significant' in stat_results_sorted.columns:\n",
    "            sig_results = stat_results_sorted[stat_results_sorted['significant']]\n",
    "        else:\n",
    "            sig_results = pd.DataFrame()\n",
    "        \n",
    "        if not sig_results.empty:\n",
    "            report.append(\"SIGNIFIKANTE VERBESSERUNGEN GEGENÜBER ZUFÄLLIGER AUSWAHL:\")\n",
    "            report.append(\"-\"*100)\n",
    "            report.append(f\"{'Strategie':<20} {'Budget':<10} {'Verbesserung':<15} \"\n",
    "                         f\"{'p-Wert':<12} {'Effekt':<15} {'Interpretation':<20}\")\n",
    "            report.append(\"-\"*100)\n",
    "            \n",
    "            for _, row in sig_results.iterrows():\n",
    "                strategy_de = strategy_labels_de.get(row['strategy'], row['strategy'])\n",
    "                effect_de = effect_labels_de.get(row['effect_size'], row['effect_size'])\n",
    "                \n",
    "                report.append(f\"{strategy_de:<20} \"\n",
    "                             f\"{int(row['budget_pct']*100):>8}% \"\n",
    "                             f\"{row['improvement_pct']:>13.2f}% \"\n",
    "                             f\"{row['p_value_corrected']:>11.4f} \"\n",
    "                             f\"{row['cliffs_delta']:>14.3f} \"\n",
    "                             f\"{effect_de:<20}\")\n",
    "        else:\n",
    "            report.append(\"Keine signifikanten Verbesserungen gefunden!\")\n",
    "        \n",
    "        # Zusammenfassung nach Strategie\n",
    "        report.append(\"\\n\\nZUSAMMENFASSUNG NACH STRATEGIE:\")\n",
    "        report.append(\"-\"*100)\n",
    "        \n",
    "        for strategy in ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "            if 'strategy' in stat_results.columns:\n",
    "                strategy_data = stat_results[stat_results['strategy'] == strategy]\n",
    "                if not strategy_data.empty:\n",
    "                    sig_count = strategy_data['significant'].sum() if 'significant' in strategy_data.columns else 0\n",
    "                    avg_improvement = strategy_data['improvement_pct'].mean() if 'improvement_pct' in strategy_data.columns else 0\n",
    "                    avg_effect = strategy_data['cliffs_delta'].mean() if 'cliffs_delta' in strategy_data.columns else 0\n",
    "                    \n",
    "                    strategy_de = strategy_labels_de.get(strategy, strategy)\n",
    "                    report.append(f\"\\n{strategy_de}:\")\n",
    "                    report.append(f\"  - Signifikante Verbesserungen: {sig_count}/{len(strategy_data)} \"\n",
    "                                 f\"({sig_count/len(strategy_data)*100:.1f}%)\")\n",
    "                    report.append(f\"  - Durchschnittliche Verbesserung: {avg_improvement:.2f}%\")\n",
    "                    report.append(f\"  - Durchschnittliche Effektstärke: {avg_effect:.3f}\")\n",
    "        \n",
    "        # Empfehlung\n",
    "        report.append(\"\\n\\nEMPFEHLUNG:\")\n",
    "        report.append(\"-\"*100)\n",
    "        \n",
    "        if not sig_results.empty:\n",
    "            best_row = sig_results.iloc[0]\n",
    "            strategy_de = strategy_labels_de.get(best_row['strategy'], best_row['strategy'])\n",
    "            report.append(f\"Die beste Active Learning Strategie ist {strategy_de}\")\n",
    "            report.append(f\"mit einer durchschnittlichen Verbesserung von {best_row['improvement_pct']:.2f}%\")\n",
    "            report.append(f\"und einer {effect_labels_de.get(best_row['effect_size'], best_row['effect_size'])}en Effektstärke.\")\n",
    "        else:\n",
    "            report.append(\"Die Active Learning Strategien zeigen keine signifikanten Verbesserungen\")\n",
    "            report.append(\"gegenüber der zufälligen Auswahl in diesem Experiment.\")\n",
    "        \n",
    "        report.append(\"\\n\" + \"=\"*100)\n",
    "        \n",
    "        # Ausgabe\n",
    "        report_text = \"\\n\".join(report)\n",
    "        print(report_text)\n",
    "        \n",
    "        # Speichern\n",
    "        report_filename = 'reports/gpu_svm_fashion_mnist_statistischer_bericht.txt'\n",
    "        try:\n",
    "            with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(report_text)\n",
    "            logger.info(f\"✓ Statistischer Bericht gespeichert: {report_filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Speichern des Berichts: {e}\")\n",
    "        \n",
    "        return report_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fehler bei create_statistical_report: {e}\")\n",
    "        return \"Fehler bei der Berichterstellung\"\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Visualisierungen (Angepasst für Fashion-MNIST)\n",
    "# -------------------------------------------------------------------------------\n",
    "def plot_gpu_svm_results(all_results, stat_results):\n",
    "    \"\"\"Erstellt GPU-SVM spezifische Visualisierungen auf Deutsch für Fashion-MNIST.\"\"\"\n",
    "    # Deutsche Matplotlib Konfiguration\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    try:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    except:\n",
    "        plt.style.use('ggplot')\n",
    "    \n",
    "    # Farben für Strategien\n",
    "    strategy_colors = {\n",
    "        'Random Sampling': '#808080',\n",
    "        'Entropy Sampling': '#1f77b4',\n",
    "        'Margin Sampling': '#ff7f0e',\n",
    "        'Least Confidence': '#2ca02c'\n",
    "    }\n",
    "    \n",
    "    # Deutsche Labels\n",
    "    strategy_labels_de = {\n",
    "        'Random Sampling': 'Zufällige Auswahl',\n",
    "        'Entropy Sampling': 'Entropie-Auswahl',\n",
    "        'Margin Sampling': 'Margin-Auswahl',\n",
    "        'Least Confidence': 'Geringste Konfidenz'\n",
    "    }\n",
    "    \n",
    "    effect_labels_de = {\n",
    "        'negligible': 'vernachlässigbar',\n",
    "        'small': 'klein',\n",
    "        'medium': 'mittel',\n",
    "        'large': 'groß'\n",
    "    }\n",
    "    \n",
    "    # 1. Hauptvisualisierung: Lernkurven mit Signifikanz\n",
    "    fig, axes = plt.subplots(1, len(BUDGET_PERCENTAGES), figsize=(20, 5))\n",
    "    \n",
    "    if len(BUDGET_PERCENTAGES) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    fig.suptitle('GPU-optimierte SVM Active Learning Performance (Fashion-MNIST)', fontsize=16, y=1.02)\n",
    "    \n",
    "    # Sammle alle y-Werte für dynamische Skalierung\n",
    "    all_y_values = []\n",
    "    \n",
    "    for budget_idx, budget_pct in enumerate(BUDGET_PERCENTAGES):\n",
    "        ax = axes[budget_idx]\n",
    "        \n",
    "        for strategy, color in strategy_colors.items():\n",
    "            strategy_results = [r for r in all_results \n",
    "                              if r['strategy'] == strategy \n",
    "                              and r['budget_pct'] == budget_pct]\n",
    "            \n",
    "            if strategy_results:\n",
    "                # Lernkurven aggregieren\n",
    "                max_samples = int(budget_pct * 60000)\n",
    "                x_common = np.linspace(100, max_samples, 100)\n",
    "                y_interpolated = []\n",
    "                \n",
    "                for r in strategy_results:\n",
    "                    if len(r['n_labeled_list']) > 1:\n",
    "                        try:\n",
    "                            y_interp = np.interp(x_common, r['n_labeled_list'], r['accuracies'])\n",
    "                            y_interpolated.append(y_interp)\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                if y_interpolated:\n",
    "                    y_mean = np.mean(y_interpolated, axis=0)\n",
    "                    y_std = np.std(y_interpolated, axis=0)\n",
    "                    \n",
    "                    # Sammle Werte für Skalierung\n",
    "                    all_y_values.extend(y_mean - y_std)\n",
    "                    all_y_values.extend(y_mean + y_std)\n",
    "                    \n",
    "                    # Signifikanz prüfen\n",
    "                    is_significant = False\n",
    "                    effect_size = \"\"\n",
    "                    if strategy != 'Random Sampling' and not stat_results.empty:\n",
    "                        sig_data = stat_results[\n",
    "                            (stat_results['strategy'] == strategy) & \n",
    "                            (stat_results['budget_pct'] == budget_pct)\n",
    "                        ]\n",
    "                        if not sig_data.empty:\n",
    "                            is_significant = sig_data.iloc[0]['significant']\n",
    "                            effect_size = effect_labels_de.get(\n",
    "                                sig_data.iloc[0]['effect_size'], \n",
    "                                sig_data.iloc[0]['effect_size']\n",
    "                            )\n",
    "                    \n",
    "                    label = strategy_labels_de.get(strategy, strategy)\n",
    "                    if is_significant:\n",
    "                        label += f\" *({effect_size})\"\n",
    "                    \n",
    "                    # Backend info\n",
    "                    backend = strategy_results[0].get('backend', 'unknown')\n",
    "                    if strategy == 'Random Sampling':\n",
    "                        label += f\" [{backend}]\"\n",
    "                    \n",
    "                    ax.plot(x_common, y_mean, \n",
    "                           label=label, \n",
    "                           color=color, \n",
    "                           linewidth=2.5,\n",
    "                           linestyle='-' if not is_significant or strategy == 'Random Sampling' else '--')\n",
    "                    \n",
    "                    ax.fill_between(x_common, \n",
    "                                  y_mean - y_std, \n",
    "                                  y_mean + y_std, \n",
    "                                  color=color, \n",
    "                                  alpha=0.2)\n",
    "        \n",
    "        ax.set_xlabel('Anzahl gelabelter Beispiele', fontsize=12)\n",
    "        ax.set_ylabel('Test-Genauigkeit', fontsize=12)\n",
    "        ax.set_title(f'Budget: {int(budget_pct*100)}%', fontsize=13)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Dynamische Y-Achsen-Skalierung\n",
    "        if all_y_values:\n",
    "            y_min = min(all_y_values)\n",
    "            y_max = max(all_y_values)\n",
    "            y_range = y_max - y_min\n",
    "            \n",
    "            # Füge 10% Padding hinzu\n",
    "            y_min_adj = y_min - 0.1 * y_range\n",
    "            y_max_adj = y_max + 0.1 * y_range\n",
    "            \n",
    "            # Stelle sicher, dass die Skalierung sinnvoll ist\n",
    "            if y_range < 0.05:  # Wenn Bereich sehr klein\n",
    "                center = (y_min + y_max) / 2\n",
    "                y_min_adj = center - 0.03\n",
    "                y_max_adj = center + 0.03\n",
    "            \n",
    "            ax.set_ylim([max(0.0, y_min_adj), min(1.0, y_max_adj)])\n",
    "        \n",
    "        # X-Achse formatieren\n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}k'))\n",
    "        \n",
    "        if budget_idx == 0:\n",
    "            ax.legend(loc='lower right', fontsize=10, framealpha=0.9)\n",
    "        \n",
    "        # Reset für nächste Iteration\n",
    "        all_y_values = []\n",
    "    \n",
    "    fig.text(0.5, -0.05, \n",
    "            '* = statistisch signifikant (p < 0,05); Effektstärke: vernachlässigbar/klein/mittel/groß',\n",
    "            ha='center', fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = 'plots/gpu_svm_fashion_mnist_performance.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"✓ Visualisierung erstellt: {filename}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. GPU Performance Metriken\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('GPU-SVM Leistungsmetriken (Fashion-MNIST)', fontsize=16)\n",
    "    \n",
    "    # Training Zeit Vergleich\n",
    "    ax1 = axes[0, 0]\n",
    "    train_times = []\n",
    "    for strategy in strategy_colors.keys():\n",
    "        times = [r['avg_train_time'] for r in all_results if r['strategy'] == strategy]\n",
    "        if times:\n",
    "            train_times.append({\n",
    "                'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                'Zeit': np.mean(times),\n",
    "                'Std': np.std(times)\n",
    "            })\n",
    "    \n",
    "    if train_times:\n",
    "        df_times = pd.DataFrame(train_times)\n",
    "        bars = ax1.bar(df_times['Strategie'], df_times['Zeit'], \n",
    "                       yerr=df_times['Std'], capsize=5, color='steelblue')\n",
    "        ax1.set_title('Durchschnittliche Trainingszeit pro Batch', fontsize=13)\n",
    "        ax1.set_ylabel('Zeit (Sekunden)', fontsize=11)\n",
    "        ax1.set_xlabel('')\n",
    "        ax1.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Rotiere Labels für bessere Lesbarkeit\n",
    "        ax1.set_xticklabels(df_times['Strategie'], rotation=25, ha='right')\n",
    "        \n",
    "        # Dynamische Y-Achsen-Skalierung\n",
    "        if df_times['Zeit'].max() > 0:\n",
    "            ax1.set_ylim([0, df_times['Zeit'].max() * 1.2])\n",
    "    \n",
    "    # Query Zeit Vergleich\n",
    "    ax2 = axes[0, 1]\n",
    "    query_times = []\n",
    "    for strategy in strategy_colors.keys():\n",
    "        times = [r['avg_query_time'] for r in all_results if r['strategy'] == strategy]\n",
    "        if times:\n",
    "            query_times.append({\n",
    "                'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                'Zeit': np.mean(times),\n",
    "                'Std': np.std(times)\n",
    "            })\n",
    "    \n",
    "    if query_times:\n",
    "        df_query = pd.DataFrame(query_times)\n",
    "        bars = ax2.bar(df_query['Strategie'], df_query['Zeit'], \n",
    "                       yerr=df_query['Std'], capsize=5, color='darkorange')\n",
    "        ax2.set_title('Durchschnittliche Query-Zeit pro Batch', fontsize=13)\n",
    "        ax2.set_ylabel('Zeit (Sekunden)', fontsize=11)\n",
    "        ax2.set_xlabel('')\n",
    "        ax2.grid(axis='y', alpha=0.3)\n",
    "        ax2.set_xticklabels(df_query['Strategie'], rotation=25, ha='right')\n",
    "        \n",
    "        # Dynamische Y-Achsen-Skalierung\n",
    "        if df_query['Zeit'].max() > 0:\n",
    "            ax2.set_ylim([0, df_query['Zeit'].max() * 1.2])\n",
    "    \n",
    "    # Finale Accuracy Heatmap\n",
    "    ax3 = axes[1, 0]\n",
    "    final_acc = []\n",
    "    for strategy in strategy_colors.keys():\n",
    "        for budget in BUDGET_PERCENTAGES:\n",
    "            results = [r for r in all_results \n",
    "                      if r['strategy'] == strategy and r['budget_pct'] == budget]\n",
    "            if results:\n",
    "                final_acc.append({\n",
    "                    'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                    'Budget': f\"{int(budget*100)}%\",\n",
    "                    'Genauigkeit': np.mean([r['accuracy'] for r in results])\n",
    "                })\n",
    "    \n",
    "    if final_acc:\n",
    "        df_acc = pd.DataFrame(final_acc)\n",
    "        pivot_acc = df_acc.pivot(index='Strategie', columns='Budget', values='Genauigkeit')\n",
    "        \n",
    "        # Dynamische Skalierung für Heatmap\n",
    "        vmin = pivot_acc.min().min()\n",
    "        vmax = pivot_acc.max().max()\n",
    "        vcenter = (vmin + vmax) / 2\n",
    "        \n",
    "        # Wenn Unterschiede sehr klein sind, passe Skala an\n",
    "        if vmax - vmin < 0.02:\n",
    "            vmin = vcenter - 0.01\n",
    "            vmax = vcenter + 0.01\n",
    "        \n",
    "        if sns is not None:\n",
    "            sns.heatmap(pivot_acc, annot=True, fmt='.4f', cmap='RdYlGn', \n",
    "                       vmin=vmin, vmax=vmax, center=vcenter,\n",
    "                       ax=ax3, cbar_kws={'label': 'Genauigkeit'})\n",
    "        ax3.set_title('Finale Test-Genauigkeit', fontsize=13)\n",
    "        ax3.set_xlabel('Budget', fontsize=11)\n",
    "        ax3.set_ylabel('Strategie', fontsize=11)\n",
    "    \n",
    "    # Backend Info (auf Deutsch)\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('off')\n",
    "    backend_info = all_results[0].get('backend', 'unknown') if all_results else 'unknown'\n",
    "    \n",
    "    info_text = f\"\"\"GPU-SVM Backend-Informationen:\n",
    "    \n",
    "Datensatz: Fashion-MNIST\n",
    "Primäres Backend: {backend_info.upper()}\n",
    "GPU verfügbar: {'Ja' if GPU_AVAILABLE else 'Nein'}\n",
    "RAPIDS cuML: {'Ja' if CUML_AVAILABLE else 'Nein'}\n",
    "ThunderSVM: {'Ja' if THUNDERSVM_AVAILABLE else 'Nein'}\n",
    "TensorFloat-32: {'Aktiviert' if torch.cuda.is_available() else 'N/A'}\n",
    "\n",
    "Konfiguration:\n",
    "- Kernel: RBF\n",
    "- C: 1.0\n",
    "- Batch-Größe: {BATCH_SIZE}\n",
    "- Initiale Auswahl: {int(INITIAL_PERCENTAGE * 100)}%\n",
    "\n",
    "Hardware:\n",
    "- Gerät: {'GPU' if GPU_AVAILABLE else 'CPU'}\n",
    "\"\"\"\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        info_text += f\"- GPU: {torch.cuda.get_device_name(0)}\\n\"\n",
    "        info_text += f\"- VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\\n\"\n",
    "        info_text += f\"- Tensor Cores: {'Ja' if 'RTX' in torch.cuda.get_device_name(0) else 'Möglich'}\\n\"\n",
    "    \n",
    "    ax4.text(0.1, 0.9, info_text, transform=ax4.transAxes, \n",
    "            fontsize=11, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = 'plots/gpu_svm_fashion_mnist_metriken.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"✓ Leistungsmetriken erstellt: {filename}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Detaillierte Vergleichsvisualisierung mit Zoom\n",
    "    if len(all_results) > 0:\n",
    "        create_detailed_comparison_plot(all_results, stat_results)\n",
    "\n",
    "def create_detailed_comparison_plot(all_results, stat_results):\n",
    "    \"\"\"Erstellt detaillierte Vergleichsplots mit Zoom für kleine Unterschiede.\"\"\"\n",
    "    # Deutsche Labels\n",
    "    strategy_labels_de = {\n",
    "        'Random Sampling': 'Zufällige Auswahl',\n",
    "        'Entropy Sampling': 'Entropie-Auswahl',\n",
    "        'Margin Sampling': 'Margin-Auswahl',\n",
    "        'Least Confidence': 'Geringste Konfidenz'\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Detaillierte Active Learning Analyse (Fashion-MNIST)', fontsize=16)\n",
    "    \n",
    "    # 1. Verbesserung über Random Sampling\n",
    "    ax1 = axes[0, 0]\n",
    "    improvements = []\n",
    "    \n",
    "    for budget_pct in BUDGET_PERCENTAGES:\n",
    "        random_results = [r['accuracy'] for r in all_results \n",
    "                         if r['strategy'] == 'Random Sampling' and r['budget_pct'] == budget_pct]\n",
    "        \n",
    "        if random_results:\n",
    "            random_mean = np.mean(random_results)\n",
    "            \n",
    "            for strategy in ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "                strategy_results = [r['accuracy'] for r in all_results \n",
    "                                  if r['strategy'] == strategy and r['budget_pct'] == budget_pct]\n",
    "                \n",
    "                if strategy_results:\n",
    "                    strategy_mean = np.mean(strategy_results)\n",
    "                    improvement = (strategy_mean - random_mean) * 100  # In Prozentpunkten\n",
    "                    \n",
    "                    improvements.append({\n",
    "                        'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                        'Budget': int(budget_pct * 100),\n",
    "                        'Verbesserung': improvement\n",
    "                    })\n",
    "    \n",
    "    if improvements:\n",
    "        df_imp = pd.DataFrame(improvements)\n",
    "        \n",
    "        # Gruppierter Barplot\n",
    "        strategies = df_imp['Strategie'].unique()\n",
    "        x = np.arange(len(BUDGET_PERCENTAGES))\n",
    "        width = 0.25\n",
    "        \n",
    "        for i, strategy in enumerate(strategies):\n",
    "            data = df_imp[df_imp['Strategie'] == strategy]\n",
    "            values = []\n",
    "            for b in BUDGET_PERCENTAGES:\n",
    "                budget_data = data[data['Budget'] == int(b*100)]\n",
    "                if not budget_data.empty:\n",
    "                    values.append(budget_data['Verbesserung'].values[0])\n",
    "                else:\n",
    "                    values.append(0)\n",
    "            \n",
    "            bars = ax1.bar(x + i*width - width, values, width, \n",
    "                           label=strategy, alpha=0.8)\n",
    "            \n",
    "            # Werte auf Balken\n",
    "            for bar, value in zip(bars, values):\n",
    "                if value != 0:\n",
    "                    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "                            f'{value:.2f}%', ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        ax1.set_xlabel('Budget (%)', fontsize=11)\n",
    "        ax1.set_ylabel('Verbesserung (Prozentpunkte)', fontsize=11)\n",
    "        ax1.set_title('Verbesserung gegenüber zufälliger Auswahl', fontsize=13)\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels([f'{int(b*100)}%' for b in BUDGET_PERCENTAGES])\n",
    "        ax1.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. Box Plots für finale Genauigkeit\n",
    "    ax2 = axes[0, 1]\n",
    "    final_data = []\n",
    "    \n",
    "    for strategy in ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "        results_100 = [r['accuracy'] for r in all_results \n",
    "                      if r['strategy'] == strategy and r['budget_pct'] == 1.0]\n",
    "        if results_100:\n",
    "            for acc in results_100:\n",
    "                final_data.append({\n",
    "                    'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                    'Genauigkeit': acc\n",
    "                })\n",
    "    \n",
    "    if final_data:\n",
    "        df_final = pd.DataFrame(final_data)\n",
    "        \n",
    "        # Box Plot\n",
    "        box_plot = df_final.boxplot(column='Genauigkeit', by='Strategie', ax=ax2, \n",
    "                                    patch_artist=True, return_type='dict')\n",
    "        \n",
    "        # Farben für Boxen\n",
    "        colors = ['lightgray', 'lightblue', 'lightcoral', 'lightgreen']\n",
    "        for patch, color in zip(box_plot['Genauigkeit']['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "        ax2.set_title('Verteilung der finalen Genauigkeit (100% Budget)', fontsize=13)\n",
    "        ax2.set_xlabel('')\n",
    "        ax2.set_ylabel('Test-Genauigkeit', fontsize=11)\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Entferne automatischen Titel\n",
    "        ax2.get_figure().suptitle('')\n",
    "        \n",
    "        # Dynamische Y-Achsen-Skalierung für Box Plot\n",
    "        y_data = df_final['Genauigkeit'].values\n",
    "        y_min, y_max = y_data.min(), y_data.max()\n",
    "        y_range = y_max - y_min\n",
    "        \n",
    "        if y_range < 0.02:  # Sehr kleine Unterschiede\n",
    "            center = (y_min + y_max) / 2\n",
    "            ax2.set_ylim([center - 0.015, center + 0.015])\n",
    "        else:\n",
    "            ax2.set_ylim([y_min - 0.1*y_range, y_max + 0.1*y_range])\n",
    "    \n",
    "    # 3. Lerngeschwindigkeit (Samples bis 95% Genauigkeit)\n",
    "    ax3 = axes[1, 0]\n",
    "    learning_speed = []\n",
    "    \n",
    "    # Ziel: 95% der Random Sampling Performance bei 100%\n",
    "    random_100_results = [r['accuracy'] for r in all_results \n",
    "                         if r['strategy'] == 'Random Sampling' and r['budget_pct'] == 1.0]\n",
    "    \n",
    "    if random_100_results:\n",
    "        target_acc = np.mean(random_100_results) * 0.95\n",
    "        \n",
    "        for strategy in ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "            strategy_results = [r for r in all_results if r['strategy'] == strategy]\n",
    "            \n",
    "            samples_needed = []\n",
    "            for r in strategy_results:\n",
    "                if 'n_labeled_list' in r and 'accuracies' in r:\n",
    "                    for i, acc in enumerate(r['accuracies']):\n",
    "                        if acc >= target_acc:\n",
    "                            samples_needed.append(r['n_labeled_list'][i])\n",
    "                            break\n",
    "            \n",
    "            if samples_needed:\n",
    "                learning_speed.append({\n",
    "                    'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                    'Samples': np.mean(samples_needed),\n",
    "                    'Std': np.std(samples_needed)\n",
    "                })\n",
    "    \n",
    "    if learning_speed:\n",
    "        df_speed = pd.DataFrame(learning_speed)\n",
    "        bars = ax3.bar(df_speed['Strategie'], df_speed['Samples'], \n",
    "                       yerr=df_speed['Std'], capsize=5, color='purple', alpha=0.7)\n",
    "        \n",
    "        # Werte auf Balken\n",
    "        for bar, (_, row) in zip(bars, df_speed.iterrows()):\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "                    f'{int(row[\"Samples\"]):,}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        ax3.set_title('Benötigte Samples für 95% der Baseline-Performance', fontsize=13)\n",
    "        ax3.set_ylabel('Anzahl Samples', fontsize=11)\n",
    "        ax3.set_xlabel('')\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "        ax3.set_xticklabels(df_speed['Strategie'], rotation=25, ha='right')\n",
    "        \n",
    "        # Referenzlinie\n",
    "        ax3.axhline(y=60000, color='red', linestyle='--', alpha=0.5, \n",
    "                   label='Vollständiger Datensatz')\n",
    "        ax3.legend()\n",
    "    \n",
    "    # 4. Effizienz-Matrix\n",
    "    ax4 = axes[1, 1]\n",
    "    efficiency_data = []\n",
    "    \n",
    "    for strategy in ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "        for budget_pct in BUDGET_PERCENTAGES:\n",
    "            results = [r for r in all_results \n",
    "                      if r['strategy'] == strategy and r['budget_pct'] == budget_pct]\n",
    "            \n",
    "            if results:\n",
    "                avg_acc = np.mean([r['accuracy'] for r in results])\n",
    "                avg_time = np.mean([r['avg_train_time'] + r['avg_query_time'] for r in results])\n",
    "                \n",
    "                # Effizienz = Genauigkeit / Zeit (normalisiert)\n",
    "                efficiency = avg_acc / avg_time if avg_time > 0 else 0\n",
    "                \n",
    "                efficiency_data.append({\n",
    "                    'Strategie': strategy_labels_de.get(strategy, strategy),\n",
    "                    'Budget': f\"{int(budget_pct*100)}%\",\n",
    "                    'Effizienz': efficiency\n",
    "                })\n",
    "    \n",
    "    if efficiency_data:\n",
    "        df_eff = pd.DataFrame(efficiency_data)\n",
    "        pivot_eff = df_eff.pivot(index='Strategie', columns='Budget', values='Effizienz')\n",
    "        \n",
    "        # Normalisiere Effizienz für bessere Visualisierung\n",
    "        pivot_eff_norm = (pivot_eff - pivot_eff.min().min()) / (pivot_eff.max().max() - pivot_eff.min().min())\n",
    "        \n",
    "        if sns is not None:\n",
    "            sns.heatmap(pivot_eff_norm, annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "                       ax=ax4, cbar_kws={'label': 'Relative Effizienz'})\n",
    "        ax4.set_title('Effizienz-Matrix (Genauigkeit/Zeit)', fontsize=13)\n",
    "        ax4.set_xlabel('Budget', fontsize=11)\n",
    "        ax4.set_ylabel('Strategie', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = 'plots/gpu_svm_fashion_mnist_detaillierte_analyse.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"✓ Detaillierte Analyse erstellt: {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Label-Einsparungs-Analyse (unverändert, nur Dateinamen angepasst)\n",
    "# -------------------------------------------------------------------------------\n",
    "def calculate_label_savings(all_results, target_performance_percentages=[0.90, 0.95, 0.98]):\n",
    "    \"\"\"Berechnet Label-Einsparung für GPU-SVM auf Fashion-MNIST.\"\"\"\n",
    "    savings_results = []\n",
    "    \n",
    "    # Random Sampling Performance bei 100% als Referenz\n",
    "    random_100_results = [r for r in all_results \n",
    "                        if r['strategy'] == 'Random Sampling' \n",
    "                        and r['budget_pct'] == 1.0]\n",
    "    \n",
    "    if not random_100_results:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    random_100_acc = np.mean([r['accuracy'] for r in random_100_results])\n",
    "    \n",
    "    for target_pct in target_performance_percentages:\n",
    "        target_accuracy = random_100_acc * target_pct\n",
    "        \n",
    "        for strategy in ['Random Sampling', 'Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "            strategy_results = [r for r in all_results if r['strategy'] == strategy]\n",
    "            \n",
    "            if not strategy_results:\n",
    "                continue\n",
    "            \n",
    "            # Aggregiere Lernkurven\n",
    "            all_curves = []\n",
    "            for r in strategy_results:\n",
    "                if 'n_labeled_list' in r and 'accuracies' in r:\n",
    "                    all_curves.append((r['n_labeled_list'], r['accuracies']))\n",
    "            \n",
    "            if not all_curves:\n",
    "                continue\n",
    "            \n",
    "            # Finde minimale Labels für Ziel-Accuracy\n",
    "            labels_needed = []\n",
    "            \n",
    "            for n_labeled_list, accuracies in all_curves:\n",
    "                if len(accuracies) > 0 and max(accuracies) >= target_accuracy:\n",
    "                    for i, acc in enumerate(accuracies):\n",
    "                        if acc >= target_accuracy:\n",
    "                            labels_needed.append(n_labeled_list[i])\n",
    "                            break\n",
    "                else:\n",
    "                    labels_needed.append(60000)\n",
    "            \n",
    "            if labels_needed:\n",
    "                avg_labels_needed = np.mean(labels_needed)\n",
    "                std_labels_needed = np.std(labels_needed)\n",
    "                \n",
    "                savings_pct = ((60000 - avg_labels_needed) / 60000) * 100\n",
    "                \n",
    "                if strategy != 'Random Sampling':\n",
    "                    random_labels = next((s['avg_labels_needed'] for s in savings_results \n",
    "                                        if s['strategy'] == 'Random Sampling' \n",
    "                                        and s['target_performance'] == int(target_pct*100)), 60000)\n",
    "                    relative_savings_pct = ((random_labels - avg_labels_needed) / random_labels) * 100 if random_labels > 0 else 0\n",
    "                else:\n",
    "                    relative_savings_pct = 0\n",
    "                \n",
    "                savings_results.append({\n",
    "                    'strategy': strategy,\n",
    "                    'target_performance': int(target_pct * 100),\n",
    "                    'target_accuracy': target_accuracy,\n",
    "                    'avg_labels_needed': avg_labels_needed,\n",
    "                    'std_labels_needed': std_labels_needed,\n",
    "                    'savings_pct': savings_pct,\n",
    "                    'relative_savings_pct': relative_savings_pct,\n",
    "                    'random_100_acc': random_100_acc\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(savings_results)\n",
    "\n",
    "def plot_label_savings(savings_df):\n",
    "    \"\"\"Visualisiert Label-Einsparungen auf Deutsch für Fashion-MNIST.\"\"\"\n",
    "    # Deutsche Labels\n",
    "    strategy_labels_de = {\n",
    "        'Random Sampling': 'Zufällige Auswahl',\n",
    "        'Entropy Sampling': 'Entropie-Auswahl',\n",
    "        'Margin Sampling': 'Margin-Auswahl',\n",
    "        'Least Confidence': 'Geringste Konfidenz'\n",
    "    }\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Label-Einsparungs-Analyse für GPU-SVM Active Learning (Fashion-MNIST)', fontsize=16)\n",
    "    \n",
    "    # 1. Benötigte Labels für verschiedene Performance-Level\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    for target in savings_df['target_performance'].unique():\n",
    "        data = savings_df[savings_df['target_performance'] == target]\n",
    "        \n",
    "        if not data.empty:\n",
    "            strategies = [strategy_labels_de.get(s, s) for s in data['strategy'].values]\n",
    "            labels_needed = data['avg_labels_needed'].values\n",
    "            errors = data['std_labels_needed'].values\n",
    "            \n",
    "            x = np.arange(len(strategies))\n",
    "            width = 0.25\n",
    "            offset = (target - 95) * width / 3\n",
    "            \n",
    "            bars = ax1.bar(x + offset, labels_needed, width, \n",
    "                           yerr=errors, capsize=5,\n",
    "                           label=f'{target}% der Baseline',\n",
    "                           alpha=0.8)\n",
    "            \n",
    "            # Werte auf Balken\n",
    "            for bar, value in zip(bars, labels_needed):\n",
    "                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "                        f'{int(value):,}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    ax1.set_xlabel('Strategie', fontsize=11)\n",
    "    ax1.set_ylabel('Benötigte Labels', fontsize=11)\n",
    "    ax1.set_title('Benötigte Labels für Ziel-Performance', fontsize=13)\n",
    "    ax1.set_xticks(np.arange(len(strategies)))\n",
    "    ax1.set_xticklabels(strategies, rotation=25, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Referenzlinie\n",
    "    ax1.axhline(y=60000, color='red', linestyle='--', alpha=0.5)\n",
    "    ax1.text(0.02, 60000, 'Vollständiger Datensatz', transform=ax1.get_yaxis_transform(), \n",
    "            va='bottom', ha='left', color='red', fontsize=9)\n",
    "    \n",
    "    # 2. Relative Einsparung Heatmap\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    # Pivot für Heatmap\n",
    "    savings_pivot = []\n",
    "    for strategy in ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "        row = []\n",
    "        for target in [90, 95, 98]:\n",
    "            data = savings_df[(savings_df['strategy'] == strategy) & \n",
    "                            (savings_df['target_performance'] == target)]\n",
    "            if not data.empty:\n",
    "                row.append(data['relative_savings_pct'].values[0])\n",
    "            else:\n",
    "                row.append(0)\n",
    "        savings_pivot.append(row)\n",
    "    \n",
    "    savings_array = np.array(savings_pivot)\n",
    "    \n",
    "    if sns is not None:\n",
    "        im = ax2.imshow(savings_array, cmap='RdYlGn', aspect='auto')\n",
    "        \n",
    "        # Labels\n",
    "        ax2.set_xticks(np.arange(3))\n",
    "        ax2.set_yticks(np.arange(3))\n",
    "        ax2.set_xticklabels(['90%', '95%', '98%'])\n",
    "        ax2.set_yticklabels([strategy_labels_de.get(s, s) for s in \n",
    "                           ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']])\n",
    "        \n",
    "        # Werte in Zellen\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                text = ax2.text(j, i, f'{savings_array[i, j]:.1f}%',\n",
    "                              ha=\"center\", va=\"center\", color=\"black\", fontsize=11)\n",
    "        \n",
    "        # Colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax2)\n",
    "        cbar.set_label('Einsparung ggü. Zufälliger Auswahl (%)', fontsize=10)\n",
    "        \n",
    "    ax2.set_title('Relative Label-Einsparung', fontsize=13)\n",
    "    ax2.set_xlabel('Ziel-Performance', fontsize=11)\n",
    "    ax2.set_ylabel('Strategie', fontsize=11)\n",
    "    \n",
    "    # 3. Label-Einsparung über Performance-Level\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    for strategy in ['Entropy Sampling', 'Margin Sampling', 'Least Confidence']:\n",
    "        data = savings_df[savings_df['strategy'] == strategy]\n",
    "        if not data.empty:\n",
    "            targets = data['target_performance'].values\n",
    "            savings = data['savings_pct'].values\n",
    "            \n",
    "            ax3.plot(targets, savings, marker='o', linewidth=2, markersize=8,\n",
    "                    label=strategy_labels_de.get(strategy, strategy))\n",
    "            \n",
    "            # Werte an Punkten\n",
    "            for t, s in zip(targets, savings):\n",
    "                ax3.text(t, s+1, f'{s:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    ax3.set_xlabel('Ziel-Performance (%)', fontsize=11)\n",
    "    ax3.set_ylabel('Label-Einsparung (%)', fontsize=11)\n",
    "    ax3.set_title('Label-Einsparung bei verschiedenen Performance-Zielen', fontsize=13)\n",
    "    ax3.set_xticks([90, 95, 98])\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Zusammenfassungstabelle\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('tight')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Erstelle Zusammenfassungstabelle für 95% Performance\n",
    "    data_95 = savings_df[savings_df['target_performance'] == 95]\n",
    "    \n",
    "    if not data_95.empty:\n",
    "        table_data = []\n",
    "        for _, row in data_95.iterrows():\n",
    "            strategy = strategy_labels_de.get(row['strategy'], row['strategy'])\n",
    "            labels = int(row['avg_labels_needed'])\n",
    "            savings = row['savings_pct']\n",
    "            rel_savings = row['relative_savings_pct']\n",
    "            \n",
    "            table_data.append([\n",
    "                strategy,\n",
    "                f\"{labels:,} ± {int(row['std_labels_needed']):,}\",\n",
    "                f\"{savings:.1f}%\",\n",
    "                f\"{rel_savings:.1f}%\" if row['strategy'] != 'Random Sampling' else \"-\"\n",
    "            ])\n",
    "        \n",
    "        table = ax4.table(cellText=table_data,\n",
    "                         colLabels=['Strategie', 'Benötigte Labels', 'Absolute Einsparung', 'Relative Einsparung'],\n",
    "                         cellLoc='center',\n",
    "                         loc='center')\n",
    "        \n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.scale(1.2, 2)\n",
    "        \n",
    "        # Style header\n",
    "        for i in range(4):\n",
    "            table[(0, i)].set_facecolor('#40466e')\n",
    "            table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "        \n",
    "        # Färbe beste Strategie\n",
    "        min_labels_idx = data_95['avg_labels_needed'].argmin()\n",
    "        for i in range(4):\n",
    "            table[(min_labels_idx + 1, i)].set_facecolor('#90EE90')\n",
    "    \n",
    "    ax4.set_title('Zusammenfassung für 95% Ziel-Performance', fontsize=13, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = 'plots/gpu_svm_fashion_mnist_label_einsparung.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"✓ Label-Einsparungs-Analyse erstellt: {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "def create_label_savings_report(savings_df, all_results):\n",
    "    \"\"\"Erstellt deutschen Bericht über Label-Einsparungen für Fashion-MNIST.\"\"\"\n",
    "    strategy_labels_de = {\n",
    "        'Random Sampling': 'Zufällige Auswahl',\n",
    "        'Entropy Sampling': 'Entropie-Auswahl',\n",
    "        'Margin Sampling': 'Margin-Auswahl',\n",
    "        'Least Confidence': 'Geringste Konfidenz'\n",
    "    }\n",
    "    \n",
    "    report = []\n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(\"LABEL-EINSPARUNGS-BERICHT - GPU-SVM ACTIVE LEARNING (FASHION-MNIST)\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    # Zusammenfassung\n",
    "    data_95 = savings_df[savings_df['target_performance'] == 95]\n",
    "    if not data_95.empty:\n",
    "        best_strategy = data_95.loc[data_95['avg_labels_needed'].idxmin()]\n",
    "        \n",
    "        report.append(f\"\\nHAUPTERGEBNIS:\")\n",
    "        report.append(f\"Die {strategy_labels_de.get(best_strategy['strategy'], best_strategy['strategy'])}-Strategie\")\n",
    "        report.append(f\"benötigt nur {int(best_strategy['avg_labels_needed']):,} Labels\")\n",
    "        report.append(f\"um 95% der Baseline-Performance zu erreichen.\")\n",
    "        report.append(f\"Das entspricht einer Einsparung von {best_strategy['savings_pct']:.1f}%!\")\n",
    "    \n",
    "    # Detaillierte Ergebnisse\n",
    "    for target_perf in sorted(savings_df['target_performance'].unique()):\n",
    "        report.append(f\"\\n\\nZIEL: {target_perf}% der Baseline-Performance\")\n",
    "        report.append(\"-\"*60)\n",
    "        \n",
    "        target_data = savings_df[savings_df['target_performance'] == target_perf]\n",
    "        \n",
    "        if not target_data.empty:\n",
    "            baseline_acc = target_data['random_100_acc'].iloc[0]\n",
    "            target_acc = target_data['target_accuracy'].iloc[0]\n",
    "            \n",
    "            report.append(f\"Baseline-Genauigkeit (100% Daten): {baseline_acc:.4f}\")\n",
    "            report.append(f\"Ziel-Genauigkeit: {target_acc:.4f}\")\n",
    "            report.append(f\"\\nBenötigte Labels:\")\n",
    "            \n",
    "            # Sortiere nach Labels\n",
    "            sorted_data = target_data.sort_values('avg_labels_needed')\n",
    "            \n",
    "            for _, row in sorted_data.iterrows():\n",
    "                strategy = strategy_labels_de.get(row['strategy'], row['strategy'])\n",
    "                labels = row['avg_labels_needed']\n",
    "                std = row['std_labels_needed']\n",
    "                savings = row['savings_pct']\n",
    "                rel_savings = row['relative_savings_pct']\n",
    "                \n",
    "                report.append(f\"  - {strategy:<20}: {int(labels):>6,} ± {int(std):>4} \"\n",
    "                            f\"({savings:>5.1f}% Einsparung)\")\n",
    "                \n",
    "                if row['strategy'] != 'Random Sampling' and rel_savings > 0:\n",
    "                    report.append(f\"    → {rel_savings:.1f}% weniger Labels als Zufällige Auswahl\")\n",
    "    \n",
    "    # GPU-spezifische Informationen\n",
    "    report.append(\"\\n\\nGPU-PERFORMANCE:\")\n",
    "    report.append(\"-\"*60)\n",
    "    report.append(f\"Backend: {all_results[0].get('backend', 'unknown').upper() if all_results else 'N/A'}\")\n",
    "    report.append(f\"GPU verfügbar: {'Ja' if GPU_AVAILABLE else 'Nein'}\")\n",
    "    report.append(f\"TensorFloat-32: {'Aktiviert' if torch.cuda.is_available() else 'N/A'}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        report.append(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        report.append(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "        if 'RTX' in torch.cuda.get_device_name(0):\n",
    "            report.append(\"Tensor Cores: ✓ Verfügbar und aktiviert\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Ausgabe und Speichern\n",
    "    report_text = \"\\n\".join(report)\n",
    "    print(report_text)\n",
    "    \n",
    "    filename = 'reports/gpu_svm_fashion_mnist_label_einsparungs_bericht.txt'\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    logger.info(f\"✓ Label-Einsparungs-Bericht gespeichert: {filename}\")\n",
    "    \n",
    "    return report_text\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Hauptprogramm\n",
    "# -------------------------------------------------------------------------------\n",
    "def main():\n",
    "    \"\"\"Haupteinstiegspunkt für GPU-optimierte SVM Active Learning auf Fashion-MNIST.\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"GPU-OPTIMIERTES ACTIVE LEARNING FÜR SVM - FASHION-MNIST\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # System Info\n",
    "    print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"NumPy Version: {np.__version__}\")\n",
    "    print(f\"Scikit-learn Version: {sklearn.__version__}\")\n",
    "    \n",
    "    # GPU Setup\n",
    "    print(\"\\nGPU Setup:\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✓ CUDA verfügbar: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "        print(f\"  TensorFloat-32: Aktiviert\")\n",
    "        print(f\"  Float32 MatMul Präzision: {torch.get_float32_matmul_precision()}\")\n",
    "    else:\n",
    "        print(\"✗ Keine CUDA GPU gefunden\")\n",
    "    \n",
    "    # Prüfe ob GPU-Beschleunigung verfügbar ist\n",
    "    if not GPU_AVAILABLE:\n",
    "        print(\"\\n\" + \"!\"*80)\n",
    "        print(\"WICHTIG: Keine GPU-Beschleunigung verfügbar!\")\n",
    "        print(\"Das Programm läuft im CPU-Modus, was DEUTLICH langsamer ist.\")\n",
    "        print(\"\\nFür Ihre RTX 4060 empfehle ich folgende Installation:\")\n",
    "        print(\"-\"*80)\n",
    "        print(\"# Option 1: RAPIDS cuML (empfohlen)\")\n",
    "        print(\"conda create -n rapids python=3.11\")\n",
    "        print(\"conda activate rapids\")\n",
    "        print(\"conda install -c rapidsai -c conda-forge -c nvidia \\\\\")\n",
    "        print(\"    rapids=24.12 python=3.11 cudatoolkit=12.0\")\n",
    "        print(\"\\n# Option 2: Wenn RAPIDS nicht funktioniert\")\n",
    "        print(\"pip install cupy-cuda12x\")\n",
    "        print(\"conda install -c conda-forge cuml\")\n",
    "        print(\"!\"*80)\n",
    "        \n",
    "        # Frage ob fortfahren\n",
    "        response = input(\"\\nMöchten Sie trotzdem im CPU-Modus fortfahren? (j/n): \")\n",
    "        if response.lower() != 'j':\n",
    "            print(\"Programm beendet. Bitte installieren Sie GPU-Unterstützung.\")\n",
    "            return 0\n",
    "    \n",
    "    # Initialisiere GPU Memory Pool\n",
    "    if CUML_AVAILABLE:\n",
    "        print(\"\\nGPU Memory Setup:\")\n",
    "        gpu_setup_success = setup_gpu_memory()\n",
    "        if not gpu_setup_success:\n",
    "            print(\"\\n⚠ GPU Memory Setup fehlgeschlagen, aber RAPIDS cuML wird trotzdem verwendet.\")\n",
    "        \n",
    "        if not USE_MEMORY_POOL:\n",
    "            print(\"\\nHinweis: RMM Memory Pool ist deaktiviert (USE_MEMORY_POOL = False)\")\n",
    "            print(\"Falls Sie Speicherprobleme haben, können Sie den Pool aktivieren:\")\n",
    "            print(\"  Setzen Sie USE_MEMORY_POOL = True in der Konfiguration\")\n",
    "            print(\"\\nFür GPU Monitoring installieren Sie:\")\n",
    "            print(\"  pip install nvidia-ml-py gpustat\")\n",
    "            print(\"  Dann verwenden Sie: gpustat -i 1\")\n",
    "    \n",
    "    print(f\"\\nExperiment-Konfiguration:\")\n",
    "    print(f\"- Datensatz: Fashion-MNIST\")\n",
    "    print(f\"- Anzahl Runs: {N_RUNS}\")\n",
    "    print(f\"- Budget-Stufen: {[f'{int(b*100)}%' for b in BUDGET_PERCENTAGES]}\")\n",
    "    print(f\"- Batch-Größe: {BATCH_SIZE}\")\n",
    "    print(f\"- GPU Backends: cuML={CUML_AVAILABLE}, ThunderSVM={THUNDERSVM_AVAILABLE}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Daten laden (Fashion-MNIST)\n",
    "    try:\n",
    "        X_train, y_train, X_test, y_test = load_fashion_mnist_data()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Kritischer Fehler beim Laden der Daten: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    # Query-Strategien\n",
    "    strategies = [\n",
    "        ('Random Sampling', random_sampling),\n",
    "        ('Entropy Sampling', entropy_sampling),\n",
    "        ('Margin Sampling', margin_sampling),\n",
    "        ('Least Confidence', least_confidence_sampling)\n",
    "    ]\n",
    "    \n",
    "    # Experimente durchführen\n",
    "    all_results = []\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    for strategy_name, strategy_func in strategies:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Strategie: {strategy_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            results = run_gpu_svm_active_learning(\n",
    "                X_train, y_train, X_test, y_test,\n",
    "                strategy_name, strategy_func,\n",
    "                BUDGET_PERCENTAGES, BATCH_SIZE\n",
    "            )\n",
    "            all_results.extend(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Kritischer Fehler bei {strategy_name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Gesamtzeit\n",
    "    total_time = time.time() - total_start_time\n",
    "    print(f\"\\n✓ Alle Experimente abgeschlossen in {total_time/60:.1f} Minuten\")\n",
    "    \n",
    "    # Ergebnisse verarbeiten\n",
    "    if not all_results:\n",
    "        logger.error(\"Keine Experimenteergebnisse vorhanden!\")\n",
    "        return 1\n",
    "    \n",
    "    # DataFrame für Analyse\n",
    "    results_df = pd.DataFrame([{\n",
    "        'strategy': r['strategy'],\n",
    "        'budget_pct': r['budget_pct'],\n",
    "        'run': r['run'],\n",
    "        'n_labeled': r['n_labeled'],\n",
    "        'accuracy': r['accuracy'],\n",
    "        'f1_score': r['f1_score'],\n",
    "        'avg_query_time': r.get('avg_query_time', 0),\n",
    "        'avg_train_time': r.get('avg_train_time', 0),\n",
    "        'backend': r.get('backend', 'unknown')\n",
    "    } for r in all_results])\n",
    "    \n",
    "    # Statistische Analyse\n",
    "    print(\"\\nFühre statistische Analyse durch...\")\n",
    "    stat_results = perform_statistical_analysis(results_df)\n",
    "    create_statistical_report(stat_results)\n",
    "    \n",
    "    # Visualisierungen\n",
    "    print(\"\\nErstelle Visualisierungen...\")\n",
    "    plot_gpu_svm_results(all_results, stat_results)\n",
    "    \n",
    "    # Label-Einsparungsanalyse\n",
    "    print(\"\\nBerechne Label-Einsparungen...\")\n",
    "    savings_df = calculate_label_savings(all_results)\n",
    "    \n",
    "    if not savings_df.empty:\n",
    "        plot_label_savings(savings_df)\n",
    "        create_label_savings_report(savings_df, all_results)\n",
    "    \n",
    "    # Ergebnisse speichern\n",
    "    csv_filename = 'results/gpu_svm_fashion_mnist_results.csv'\n",
    "    results_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"\\n✓ Ergebnisse gespeichert: {csv_filename}\")\n",
    "    \n",
    "    if not stat_results.empty:\n",
    "        stat_csv = 'results/gpu_svm_fashion_mnist_statistical_analysis.csv'\n",
    "        stat_results.to_csv(stat_csv, index=False)\n",
    "        print(f\"✓ Statistische Analyse gespeichert: {stat_csv}\")\n",
    "    \n",
    "    if not savings_df.empty:\n",
    "        savings_csv = 'results/gpu_svm_fashion_mnist_label_savings.csv'\n",
    "        savings_df.to_csv(savings_csv, index=False)\n",
    "        print(f\"✓ Label-Einsparungen gespeichert: {savings_csv}\")\n",
    "    \n",
    "    # Excel Export\n",
    "    if EXCEL_AVAILABLE:\n",
    "        excel_filename = 'results/gpu_svm_fashion_mnist_summary.xlsx'\n",
    "        try:\n",
    "            with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "                results_df.to_excel(writer, sheet_name='Raw Results', index=False)\n",
    "                \n",
    "                if not stat_results.empty:\n",
    "                    stat_results.to_excel(writer, sheet_name='Statistical Analysis', index=False)\n",
    "                \n",
    "                if not savings_df.empty:\n",
    "                    savings_df.to_excel(writer, sheet_name='Label Savings', index=False)\n",
    "                \n",
    "                # Summary\n",
    "                summary = results_df.groupby(['strategy', 'budget_pct'])[['accuracy', 'f1_score']].agg(['mean', 'std'])\n",
    "                summary.to_excel(writer, sheet_name='Summary Statistics')\n",
    "            \n",
    "            print(f\"✓ Excel-Zusammenfassung gespeichert: {excel_filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Excel-Export fehlgeschlagen: {e}\")\n",
    "    \n",
    "    # Abschlusszusammenfassung\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPERIMENT ERFOLGREICH ABGESCHLOSSEN\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Datensatz: Fashion-MNIST\")\n",
    "    print(f\"GPU Backend verwendet: {all_results[0].get('backend', 'unknown') if all_results else 'unknown'}\")\n",
    "    print(f\"Gesamtanzahl Experimente: {len(all_results)}\")\n",
    "    print(f\"Durchschnittliche Trainingszeit: {np.mean([r['avg_train_time'] for r in all_results]):.2f}s\")\n",
    "    \n",
    "    if not stat_results.empty and 'significant' in stat_results.columns:\n",
    "        sig_count = stat_results['significant'].sum()\n",
    "        print(f\"\\nSignifikante Verbesserungen: {sig_count}/{len(stat_results)} ({sig_count/len(stat_results)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nOutput-Dateien:\")\n",
    "    print(\"- Visualisierungen: plots/\")\n",
    "    print(\"  - gpu_svm_fashion_mnist_performance.png\")\n",
    "    print(\"  - gpu_svm_fashion_mnist_metriken.png\")\n",
    "    print(\"  - gpu_svm_fashion_mnist_detaillierte_analyse.png\")\n",
    "    print(\"  - gpu_svm_fashion_mnist_label_einsparung.png\")\n",
    "    print(\"- Ergebnisse: results/\")\n",
    "    print(\"  - gpu_svm_fashion_mnist_results.csv\")\n",
    "    print(\"  - gpu_svm_fashion_mnist_statistical_analysis.csv\")\n",
    "    print(\"  - gpu_svm_fashion_mnist_label_savings.csv\")\n",
    "    print(\"  - gpu_svm_fashion_mnist_summary.xlsx\")\n",
    "    print(\"- Berichte: reports/\")\n",
    "    print(\"  - gpu_svm_fashion_mnist_statistischer_bericht.txt\")\n",
    "    print(\"  - gpu_svm_fashion_mnist_label_einsparungs_bericht.txt\")\n",
    "    print(\"- Logs: logs/\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        exit_code = main()\n",
    "        sys.exit(exit_code)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unerwarteter Fehler: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
